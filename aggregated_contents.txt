File: postcode/databases/arangodb/arangodb_connector.py
----------------------------------------
import logging
from typing import Any
from arango.client import ArangoClient
from arango.database import StandardDatabase
from arango.result import Result
from arango.typings import Jsons, Json

import postcode.databases.arangodb.helper_functions as helper_functions


class ArangoDBConnector:
    """
    A connector class for interacting with ArangoDB to manage collections and ensure proper database setup.

    This class provides methods to connect to an ArangoDB instance, create or ensure the existence of a specified database, collections, and edge collections. It also supports deletion of all user-defined collections within the database.

    Attributes:
        - client (ArangoClient): The ArangoDB client instance.
        - username (str): The username used for authentication.
        - password (str): The password used for authentication.
        - db_name (str): The name of the ArangoDB database.

    Example:
        ```python
        # This example demonstrates how to use ArangoDBConnector to connect to an ArangoDB instance and ensure collections.
        connector = ArangoDBConnector(url="http://localhost:8529", username="root", password="openSesame", db_name="postcode")
        connector.ensure_collections()
        ```

    Methods:
        - ensure_collections(): Ensures the existence of required collections and edge collections.
        - ensure_collection(collection_name, schema=None): Ensures the existence of a collection with an optional specified schema.
        - ensure_edge_collection(collection_name): Ensures the existence of an edge collection.
        - delete_all_collections(): Deletes all user-defined collections within the ArangoDB database.
    """

    def __init__(
        self,
        url: str = "http://localhost:8529",
        username: str = "root",
        password: str = "openSesame",
        db_name: str = "postcode",
    ) -> None:
        self.client = ArangoClient(hosts=url)
        self.username: str = username
        self.password: str = password
        self.db_name: str = db_name
        self.db: StandardDatabase = self._ensure_database()

    def _ensure_database(self) -> StandardDatabase:
        """
        Ensures the existence of the specified database, creating it if necessary.

        Returns:
            StandardDatabase: The ArangoDB database instance.
        """

        sys_db: StandardDatabase = self.client.db(
            "_system", username=self.username, password=self.password
        )
        if not sys_db.has_database(self.db_name):
            sys_db.create_database(self.db_name)
        return self.client.db(
            self.db_name, username=self.username, password=self.password
        )

    # def _ensure_vertex_collections(self, vertex_collections: list[str]) -> None:
    #     for collection in vertex_collections:
    #         if not self.db.has_collection(collection):
    #             self.db.create_collection(collection)

    def _get_current_schema(self, collection_name: str) -> dict:
        """
        Retrieves the current schema of a collection.

        Args:
            - collection_name (str): The name of the collection.

        Returns:
            dict: The current schema of the collection.
        """

        collection = self.db.collection(collection_name)
        try:
            properties: Result[Json] = collection.properties()
            return properties.get("schema", {})  # type: ignore # FIXME: Fix type error
        except Exception as e:
            logging.error(f"Error retrieving current schema for {collection_name}: {e}")
            return {}

    def ensure_collection(
        self, collection_name: str, schema: dict[str, Any] | None = None
    ) -> None:
        """
        Ensures the existence of a collection with an optional specified schema.

        Args:
            - collection_name (str): The name of the collection.
            - schema (dict[str, Any], optional): The schema to be applied to the collection. Defaults to None.
        """

        if not self.db.has_collection(collection_name) and not schema:
            self.db.create_collection(collection_name)
            logging.info(f"Created collection: {collection_name}")
        # else:
        #     current_schema = self._get_current_schema(collection_name)
        #     self.db.collection(collection_name)
        # if current_schema != schema:
        #     collection = self.db.collection(collection_name)
        #     try:
        #         collection.configure(schema=schema)
        #         logging.info(f"Updated schema for collection: {collection_name}")
        #     except Exception as e:
        #         logging.error(f"Error updating schema for {collection_name}: {e}")

    def ensure_edge_collection(self, collection_name: str) -> None:
        """
        Ensures the existence of an edge collection.

        Args:
            - collection_name (str): The name of the edge collection.
        """

        if not self.db.has_collection(collection_name):
            self.db.create_collection(collection_name, edge=True)
            logging.info(f"Created edge collection: {collection_name}")

    def delete_all_collections(self) -> None:
        """Deletes all user-defined collections within the ArangoDB database."""
        collections: Result[Jsons] = self.db.collections()

        for collection in collections:  # type: ignore # FIXME: Fix type error
            if not collection["name"].startswith("_"):  # Skip system collections
                self.db.delete_collection(collection["name"])
                logging.info(f"Deleted collection: {collection['name']}")

    def ensure_collections(self) -> None:
        """
        Ensures the existence of required collections and edge collections.

        This includes creating collections for modules, classes, functions, standalone code blocks, and the "code_edges" edge collection.
        """
        # model_schemas: dict[str, dict[str, Any]] = self._get_model_schemas()
        required_collections: list[
            str
        ] = helper_functions.pluralized_and_lowered_block_types()

        for collection_name in required_collections:
            # schema: dict[str, Any] = model_schemas[collection_name]
            # self.ensure_collection(collection_name, schema)
            self.ensure_collection(collection_name)

        self.ensure_edge_collection("code_edges")

    # def _get_model_schemas(self) -> dict[str, dict[str, Any]]:
    #     return {
    #         "modules": ModuleModel.model_json_schema(),
    #         "classes": ClassModel.model_json_schema(),
    #         "functions": FunctionModel.model_json_schema(),
    #         "standalone_blocks": StandaloneCodeBlockModel.model_json_schema(),
    #     }



File: postcode/databases/arangodb/helper_functions.py
----------------------------------------
from postcode.models.enums import BlockType
from postcode.models.models import (
    ModuleModel,
    ClassModel,
    FunctionModel,
    StandaloneCodeBlockModel,
    DirectoryModel,
)

from postcode.types.postcode import ModelType


def pluralized_and_lowered_block_types() -> list[str]:
    """Returns a list of the pluralized and lowered block types."""

    return [pluralize_block_type(block_type).lower() for block_type in BlockType]


def pluralize_block_type(block_type: str) -> str:
    """Pluralizes the block type."""

    if block_type == BlockType.CLASS:
        return "classes"
    elif block_type == BlockType.DIRECTORY:
        return "directories"
    else:
        return f"{block_type.lower()}s"


def create_model_from_vertex(vertex_data: dict) -> ModelType:
    """
    Creates a model from the vertex data.

    Args:
        - vertex_data (dict): The vertex data.
    """

    block_type: str | None = vertex_data.get("block_type")

    if block_type == BlockType.MODULE:
        return ModuleModel(**vertex_data)
    elif block_type == BlockType.CLASS:
        return ClassModel(**vertex_data)
    elif block_type == BlockType.FUNCTION:
        return FunctionModel(**vertex_data)
    elif block_type == BlockType.STANDALONE_CODE_BLOCK:
        return StandaloneCodeBlockModel(**vertex_data)
    elif block_type == BlockType.DIRECTORY:
        return DirectoryModel(**vertex_data)
    else:
        raise ValueError(f"Unknown block type: {block_type}")



File: postcode/databases/arangodb/arangodb_manager.py
----------------------------------------
import logging
from typing import Any, Callable

from arango.result import Result
from arango.cursor import Cursor
from arango.graph import Graph
from arango.collection import StandardCollection
from arango.typings import Json

from postcode.databases.arangodb.arangodb_connector import ArangoDBConnector

from postcode.types.postcode import ModelType
from postcode.models.models import (
    ClassModel,
    FunctionModel,
    ModuleModel,
    StandaloneCodeBlockModel,
    DirectoryModel,
)
import postcode.databases.arangodb.helper_functions as helper_functions

# NOTE: Remember, when adding logic to connect dependencies, the `from` the external dependency `to` the internal definition using it


class ArangoDBManager:
    """
    A manager class for handling interactions between the application and ArangoDB.

    This class provides methods for upserting models into ArangoDB, creating edges, processing imports and dependencies, deleting vertices, and querying the graph for related models.

    Attributes:
        - db_connector (ArangoDBConnector): The ArangoDB connector instance used for database interactions.
        - default_graph_name (str): The default graph name used for graph-related operations.

    Example:
        ```python
        # This example demonstrates how to use ArangoDBManager to upsert models and create edges in ArangoDB.
        connector = ArangoDBConnector(url="http://localhost:8529", username="root", password="openSesame", db_name="postcode")
        manager = ArangoDBManager(db_connector=connector)
        models_to_upsert = [ModuleModel(id="module_1", name="Module 1"), FunctionModel(id="function_1", name="Function 1")]
        manager.upsert_models(models_to_upsert)
        ```

    Methods:
        - upsert_models(module_models): Upserts a list of models into the ArangoDB database.
        - process_imports_and_dependencies(): Processes the imports and dependencies in the ArangoDB database, creating edges accordingly.
        - delete_vertex_by_id(vertex_key, graph_name=None): Deletes a vertex from the graph by its key.
        - get_graph(graph_name=None): Retrieves a graph instance by its name.
        - get_or_create_graph(graph_name=None): Retrieves an existing graph or creates a new one if not present.
        - delete_graph(graph_name=None): Deletes a graph by its name.
        - get_outbound_models(start_key): Retrieves all outbound models from a given starting key.
        - get_inbound_models(end_key): Retrieves all inbound models to a given ending key.
        - get_vertex_model_by_id(id): Retrieves a vertex model by its ID.
        - update_vertex_summary_by_id(id, new_summary): Updates the summary of a vertex by its ID.
        - get_all_modules(): Retrieves all modules from the graph.
        - get_all_vertices(): Retrieves all vertices from the graph.
    """

    def __init__(
        self,
        db_connector: ArangoDBConnector,
        default_graph_name: str = "codebase_graph",
    ) -> None:
        self.db_connector: ArangoDBConnector = db_connector

        self.processed_id_set = set()
        self.default_graph_name: str = default_graph_name

    def upsert_models(self, module_models: list[ModelType]) -> "ArangoDBManager":
        """
        Upserts a list of models into the ArangoDB database.

        Args:
            - module_models (list[ModelType]): The list of models to be upserted.

        Returns:
            - ArangoDBManager: The ArangoDBManager instance.
        """

        for model in module_models:
            self._upsert_model(model)
        return self

    def _upsert_model(self, model: ModelType) -> None:
        """
        Upserts a single model into the ArangoDB database.

        Args:
            - model (ModelType): The model to be upserted.
        """

        collection_name: str = self._get_collection_name_from_id(model.id)
        self._upsert_vertex(model, collection_name)

    def _upsert_vertex(self, model: ModelType, collection_name: str) -> None:
        """
        Upserts a vertex (document) into the specified collection in the ArangoDB database.

        Args:
            - model (ModelType): The model representing the vertex.
            - collection_name (str): The name of the collection.
        """

        model_data: dict[str, Any] = model.model_dump()
        model_data["_key"] = model.id

        try:
            self.db_connector.ensure_collection(
                collection_name, model.model_json_schema()
            )
            query: str = f"""
            UPSERT {{_key: @key}}
            INSERT @doc
            UPDATE @doc
            IN {collection_name}
            """
            bind_vars: dict[str, Any] = {"key": model.id, "doc": model_data}
            self.db_connector.db.aql.execute(query, bind_vars=bind_vars)

            if not isinstance(model, ModuleModel) and model.parent_id:
                parent_type: str = self._get_collection_name_from_id(model.parent_id)
                self._upsert_edge(
                    model.id, model.parent_id, collection_name, parent_type
                )
        except Exception as e:
            logging.error(f"Error upserting {collection_name} vertex (ArangoDB): {e}")

    def _upsert_edge(
        self, from_key: str, to_key: str, source_type: str, target_type: str
    ) -> None:
        """
        Upserts an edge between two vertices in the ArangoDB database.

        Args:
            - from_key (str): The key of the source vertex.
            - to_key (str): The key of the target vertex.
            - source_type (str): The type of the source vertex.
            - target_type (str): The type of the target vertex.
        """

        source_string: str = f"{source_type}/{from_key}"
        target_string: str = f"{target_type}/{to_key}"

        edge_data: dict[str, str] = {
            "_from": source_string,
            "_to": target_string,
            "source_type": source_type,
            "target_type": target_type,
        }

        try:
            self.db_connector.ensure_edge_collection("code_edges")
            query = f"""
            UPSERT {{_from: @from, _to: @to}}
            INSERT @doc
            UPDATE @doc
            IN code_edges
            """
            bind_vars = {
                "from": edge_data["_from"],
                "to": edge_data["_to"],
                "doc": edge_data,
            }
            self.db_connector.db.aql.execute(query, bind_vars=bind_vars)
        except Exception as e:
            logging.error(f"Error upserting edge (ArangoDB): {e}")

    def _get_collection_name_from_id(self, block_id: str) -> str:
        """
        Gets the collection name based on the block ID.

        Args:
            - block_id (str): The ID of the block.

        Returns:
            - str: The name of the collection.
        """

        block_id_parts: list[str] = block_id.split("__*__")
        block_type_part: str = block_id_parts[-1]

        block_type_functions: dict[str, Callable[..., str]] = {
            "MODULE": lambda: "modules",
            "CLASS": lambda: "classes",
            "FUNCTION": lambda: "functions",
            "STANDALONE_BLOCK": lambda: "standalone_blocks",
            "DIRECTORY": lambda: "directories",
        }

        for key, func in block_type_functions.items():
            if block_type_part.startswith(key):
                return func()

        return "unknown"

    def process_imports_and_dependencies(self) -> "ArangoDBManager":
        """
        Processes the imports and dependencies in the ArangoDB database, creating edges accordingly.

        Returns:
            - ArangoDBManager: The ArangoDBManager instance.
        """

        for vertex_collection in helper_functions.pluralized_and_lowered_block_types():
            cursor: Result[Cursor] = self.db_connector.db.collection(
                vertex_collection
            ).all()
            if isinstance(cursor, Cursor):
                for vertex in cursor:
                    vertex_key = vertex["_key"]
                    if vertex_collection == "modules":
                        self._create_edges_for_imports(
                            vertex_key, vertex.get("imports", [])
                        )
                    else:
                        self._create_edges_for_dependencies(
                            vertex_key, vertex.get("dependencies", [])
                        )
            else:
                logging.error(
                    f"Error getting cursor for vertex collection: {vertex_collection}"
                )
        return self

    def _create_edges_for_imports(
        self, module_key: str, imports: list[dict[str, Any]]
    ) -> None:
        """
        Creates edges in the graph for the given module's imports.

        Args:
            - module_key (str): The key of the module for which imports are processed.
            - imports (list[dict[str, Any]]): The list of import information.
        """

        if not imports:
            # logging.debug(f"No imports found for module {module_key}")
            return

        # logging.info(f"Processing imports for module {module_key}")

        for _import in imports:
            import_names: list[dict[str, str]] = _import.get("import_names", [])
            if not import_names:
                # logging.debug(f"No import names found in import {_import}")
                continue

            for import_name in import_names:
                local_block_id: str | None = import_name.get("local_block_id")

                if local_block_id:
                    target_type = self._get_collection_name_from_id(local_block_id)
                    try:
                        self._upsert_edge(
                            local_block_id, module_key, target_type, "modules"
                        )

                        # logging.info(
                        #     f"Upserted edge for import {module_key} to {local_block_id}"
                        # )
                    except Exception as e:
                        logging.error(
                            f"Error creating edge for import {module_key} to {local_block_id}: {e}"
                        )
                else:
                    # logging.warning(
                    #     f"Skipped import {import_name} in module {module_key}"
                    # )
                    ...

    def _create_edges_for_dependencies(
        self, block_key: str, dependencies: list[dict[str, Any]]
    ) -> None:
        """
        Creates edges in the graph for the given block's dependencies.

        Args:
            - block_key (str): The key of the block for which dependencies are processed.
            - dependencies (list[dict[str, Any]]): The list of dependency information.
        """

        if not dependencies:
            return

        for dependency in dependencies:
            code_block_id: str | None = dependency.get("code_block_id")
            if code_block_id:
                source_type: str = self._get_collection_name_from_id(code_block_id)
                target_type: str = self._get_collection_name_from_id(block_key)
                try:
                    self._upsert_edge(
                        code_block_id, block_key, source_type, target_type
                    )
                    # logging.info(
                    #     f"Upserted edge for dependency {block_key} to {code_block_id}"
                    # )
                except Exception as e:
                    logging.error(
                        f"Error creating edge for dependency {block_key} to {code_block_id}: {e}"
                    )

    def delete_vertex_by_id(
        self, vertex_key: str, graph_name: str | None = None
    ) -> None:
        """
        Deletes a vertex from the graph by its key.

        Args:
            - vertex_key (str): The key of the vertex to be deleted.
            - graph_name (str, optional): The name of the graph. Defaults to None.
        """

        collection_name: str = self._get_collection_name_from_id(vertex_key)
        if collection_name == "unknown":
            logging.error(f"Unknown vertex type for key: {vertex_key}")
            return None

        if not graph_name:
            graph_name = self.default_graph_name

        try:
            vertex_coll = self.db_connector.db.graph(graph_name).vertex_collection(
                collection_name
            )

            vertex_coll.delete(vertex_key)

            # logging.info(
            #     f"Vertex '{vertex_key}' from collection '{collection_name}' was successfully deleted."
            # )

        except Exception as e:
            logging.error(
                f"Error deleting vertex '{vertex_key}' from collection '{collection_name}': {e}"
            )

    def get_graph(self, graph_name: str | None = None) -> Graph | None:
        """
        Retrieves a graph instance by its name.

        Args:
            - graph_name (str, optional): The name of the graph. Defaults to None.

        Returns:
            - Graph | None: The graph instance or None if not found.
        """

        if not graph_name:
            graph_name = self.default_graph_name
        try:
            return self.db_connector.db.graph(self.default_graph_name)
        except Exception as e:
            logging.error(f"Error getting graph '{self.default_graph_name}': {e}")
            return None

    def get_or_create_graph(self, graph_name: str | None = None) -> Result[Graph]:
        """
        Retrieves an existing graph or creates a new one if not present.

        Args:
            - graph_name (str, optional): The name of the graph. Defaults to None.

        Returns:
            - Result[Graph]: The result of the operation.
        """

        if not graph_name:
            graph_name = self.default_graph_name

        try:
            if not self.db_connector.db.has_graph(graph_name):
                edge_definitions: list[dict[str, str | list[str]]] = [
                    {
                        "edge_collection": "code_edges",
                        "from_vertex_collections": helper_functions.pluralized_and_lowered_block_types(),
                        "to_vertex_collections": helper_functions.pluralized_and_lowered_block_types(),
                    }
                ]

                # logging.info(f"Graph '{graph_name}' created successfully.")
                return self.db_connector.db.create_graph(
                    graph_name, edge_definitions=edge_definitions
                )

            else:
                return self.get_graph()

        except Exception as e:
            logging.error(f"Error creating graph '{graph_name}': {e}")

    def delete_graph(self, graph_name: str | None = None) -> None:
        """
        Deletes a graph by its name.

        Args:
            - graph_name (str, optional): The name of the graph. Defaults to None.
        """

        if not graph_name:
            graph_name = self.default_graph_name
        try:
            self.db_connector.db.delete_graph(graph_name)
            logging.info(f"Graph '{graph_name}' deleted successfully.")
        except Exception as e:
            logging.error(f"Error deleting graph '{graph_name}': {e}")

    def get_outbound_models(self, start_key: str) -> list[ModelType] | None:
        """
        Retrieves all outbound models from a given starting key.

        Args:
            - start_key (str): The key of the starting vertex.

        Returns:
            - list[ModelType] | None: List of outbound models or None if an error occurs.
        """

        vertex_type: str = self._get_collection_name_from_id(start_key)

        query: str = f"""
        FOR v, e, p IN 1..100 OUTBOUND '{vertex_type}/{start_key}' GRAPH '{self.default_graph_name}'
        RETURN DISTINCT v
        """

        try:
            cursor = self.db_connector.db.aql.execute(query)
            if isinstance(cursor, Cursor):
                return [
                    helper_functions.create_model_from_vertex(doc) for doc in cursor
                ]
            else:
                logging.error(f"Error getting cursor for query: {query}")
                return None
        except Exception as e:
            logging.error(f"Error in get_all_downstream_vertices: {e}")
            return None

    def get_inbound_models(self, end_key: str) -> list[ModelType] | None:
        """
        Retrieves all inbound models to a given ending key.

        Args:
            - end_key (str): The key of the ending vertex.

        Returns:
            - list[ModelType] | None: List of inbound models or None if an error occurs.
        """

        vertex_type: str = self._get_collection_name_from_id(end_key)

        query: str = f"""
        FOR v, e, p IN 1..100 INBOUND '{vertex_type}/{end_key}' GRAPH '{self.default_graph_name}'
        RETURN DISTINCT v
        """

        try:
            cursor: Result[Cursor] = self.db_connector.db.aql.execute(query)
            if isinstance(cursor, Cursor):
                return [
                    helper_functions.create_model_from_vertex(doc) for doc in cursor
                ]
            else:
                logging.error(f"Error getting cursor for query: {query}")
                return None
        except Exception as e:
            logging.error(f"Error in get_all_upstream_vertices: {e}")
            return None

    def get_vertex_model_by_id(self, id: str) -> ModelType | None:
        """
        Retrieves a vertex model by its ID.

        Args:
            - id (str): The ID of the vertex.

        Returns:
            - ModelType | None: The vertex model or None if not found or an error occurs.
        """

        try:
            collection_name: str = self._get_collection_name_from_id(id)
            if collection_name == "unknown":
                logging.error(f"Unknown vertex type for ID: {id}")
                return None

            vertex_collection: StandardCollection = self.db_connector.db.collection(
                collection_name
            )
            vertex_result: Result[Json | None] = vertex_collection.get(id)

            if not vertex_result or not isinstance(vertex_result, dict):
                logging.error(
                    f"Vertex with ID {id} not found or is in an invalid format."
                )
                return None

            model_class: ModelType | None = self._get_model_class_from_collection_name(
                collection_name
            )
            if not model_class:
                logging.error(f"No model class found for collection: {collection_name}")
                return None

            return model_class(**vertex_result)  # type: ignore # FIXME: Fix type error

        except Exception as e:
            logging.error(f"Error in get_vertex_by_id: {e}")
            return None

    def _get_model_class_from_collection_name(
        self, collection_name: str
    ) -> ModelType | None:
        """
        Retrieves a vertex model by its ID.

        Args:
            - id (str): The ID of the vertex.

        Returns:
            - ModelType | None: The vertex model or None if not found or an error occurs.
        """

        model_class_map: dict = {
            "modules": ModuleModel,
            "classes": ClassModel,
            "functions": FunctionModel,
            "standalone_blocks": StandaloneCodeBlockModel,
            "directories": DirectoryModel,
        }
        return model_class_map.get(collection_name)

    def update_vertex_summary_by_id(self, id: str, new_summary: str) -> None:
        """
        Updates the summary of a vertex by its ID.

        Args:
            - id (str): The ID of the vertex.
            - new_summary (str): The new summary to be set.
        """

        try:
            collection_name: str = self._get_collection_name_from_id(id)
            if collection_name == "unknown":
                logging.error(f"Unknown vertex type for id: {id}")
                return

            vertex_collection: StandardCollection = self.db_connector.db.collection(
                collection_name
            )
            vertex_result: Result[Json | None] = vertex_collection.get(id)

            if not vertex_result:
                logging.error(f"Vertex with id {id} not found.")
                return

            if isinstance(vertex_result, dict):
                vertex = vertex_result
            else:
                logging.error("Retrieved vertex is not in a mutable format.")
                return None

            vertex["summary"] = new_summary

            vertex_collection.update(vertex)
            logging.info(f"Vertex with id {id} updated successfully.")

        except Exception as e:
            logging.error(f"Error in `update_vertex_by_id`: {e}")

    def get_all_modules(self) -> list[ModuleModel] | None:
        """
        Retrieves all modules from the graph.

        Returns:
            list[ModuleModel] | None: List of modules or None if an error occurs.
        """

        try:
            collection_name = "modules"
            module_collection: StandardCollection = self.db_connector.db.collection(
                collection_name
            )

            cursor: Result[Cursor] = module_collection.all()

            modules: list[ModuleModel] = []
            for doc in cursor:  # type: ignore # FIXME: Fix type error
                try:
                    module = ModuleModel(**doc)
                    modules.append(module)
                except Exception as e:
                    logging.error(f"Retrieved document is not in a valid format: {e}")
                    continue

            return modules

        except Exception as e:
            logging.error(f"Error in get_all_modules: {e}")
            return None

    def get_all_vertices(self) -> list[ModelType] | None:
        """
        Retrieves all vertices from the graph.

        Returns:
            list[ModelType] | None: List of vertices or None if an error occurs.
        """

        all_vertices: list[ModelType] = []
        vertex_collections: list[
            str
        ] = helper_functions.pluralized_and_lowered_block_types()

        for collection_name in vertex_collections:
            try:
                collection: StandardCollection = self.db_connector.db.collection(
                    collection_name
                )
                cursor: Result[Cursor] = collection.all()

                for doc in cursor:  # type: ignore # FIXME: Fix type error
                    model_class: ModelType | None = (
                        self._get_model_class_from_collection_name(collection_name)
                    )
                    if model_class:
                        model: ModelType = model_class(**doc)  # type: ignore # FIXME: Fix type error
                        all_vertices.append(model)
                    else:
                        logging.warning(
                            f"No model class found for collection: {collection_name}"
                        )

            except Exception as e:
                logging.error(f"Error fetching vertices from {collection_name}: {e}")

        return all_vertices



File: postcode/types/postcode.py
----------------------------------------
"""
PostCode types
--------------

This module contains types defined by the postcode library.
These types are used for easy implementation in the postcode project and
provide convenience for users of the postcode library.
"""

from typing import Union
from postcode.models.models import (
    ClassModel,
    FunctionModel,
    ModuleModel,
    StandaloneCodeBlockModel,
    DirectoryModel,
)

from postcode.python_parser.model_builders.class_model_builder import ClassModelBuilder
from postcode.python_parser.model_builders.function_model_builder import (
    FunctionModelBuilder,
)
from postcode.python_parser.model_builders.module_model_builder import (
    ModuleModelBuilder,
)
from postcode.python_parser.model_builders.standalone_block_model_builder import (
    StandaloneBlockModelBuilder,
)

ModelType = Union[
    ModuleModel,
    ClassModel,
    FunctionModel,
    StandaloneCodeBlockModel,
    DirectoryModel,
]

BuilderType = Union[
    ModuleModelBuilder,
    ClassModelBuilder,
    FunctionModelBuilder,
    StandaloneBlockModelBuilder,
]



File: postcode/types/openai.py
----------------------------------------
"""
OpenAI Types
------------

This module contains types defined by the openai third-party library.
These types are used for easy implementation in the postcode project and
provide convenience for users of the postcode library.
"""

from openai.types.chat.chat_completion_system_message_param import (
    ChatCompletionSystemMessageParam,
)
from openai.types.chat.chat_completion_user_message_param import (
    ChatCompletionUserMessageParam,
)
from openai.types.chat.chat_completion_message_param import ChatCompletionMessageParam
from openai.types.chat.chat_completion import ChatCompletion



File: postcode/types/chroma.py
----------------------------------------
"""
ChromaDB Types
--------------

This module contains types defined by the chromadb third-party library.
These types are used for easy implementation in the postcode project and
provide convenience for users of the postcode library.
"""

import chromadb.utils.embedding_functions as ef

from chromadb.config import DEFAULT_DATABASE, DEFAULT_TENANT, Settings
from chromadb.api import ClientAPI
from chromadb.api.types import (
    DataLoader,
    CollectionMetadata,
    GetResult,
    QueryResult,
    Where,
    WhereDocument,
    Include,
    URIs,
    Loadable,
    Metadata,
    Embedding,
    Document,
)
from chromadb import Collection
from chromadb import EmbeddingFunction

from chromadb.api.types import (
    CollectionMetadata,
    Documents,
    Embeddable,
    EmbeddingFunction,
    DataLoader,
    Embeddings,
    IDs,
    Include,
    Loadable,
    Metadatas,
    URIs,
    Where,
    QueryResult,
    GetResult,
    WhereDocument,
)
from chromadb.config import Component, Settings
from chromadb.types import Database, Tenant
import chromadb.utils.embedding_functions as ef



File: postcode/ai_services/chat/prompts/chat_prompts.py
----------------------------------------
DEFAULT_SYSTEM_PROMPT = """
You are a chatbot that specializes in answering questions about a particular python codebase. You will be given a user question
and contextual summaries or code from the code base. You must answer the user question using the contextual summaries or code.

If the question cannot be answered using the contextual summaries or code, you must respond with "My knowledge base does not include
the necessary information to answer your question. Think step by step from first principles inferred from the context to answer your question.
"""

DEFAULT_PROMPT_TEMPLATE = """
CONTEXT: {context}

User Question: {user_question}
"""



File: postcode/ai_services/chat/openai_agents.py
----------------------------------------
import logging
from typing import Sequence
from openai import OpenAI

from postcode.ai_services.openai_configs import OpenAIConfigs
import postcode.types.chroma as chroma_types
import postcode.types.openai as openai_types

from postcode.ai_services.librarians.chroma_librarians import ChromaLibrarian
from postcode.ai_services.chat.prompts.chat_prompts import (
    DEFAULT_PROMPT_TEMPLATE,
    DEFAULT_SYSTEM_PROMPT,
)


class OpenAIChatAgent:
    """
    Represents an agent that interacts with the OpenAI API for generating responses to user questions.

    Args:
        - `chroma_librarian` (ChromaLibrarian): The librarian handling Chroma queries.
        - `configs` (OpenAIConfigs, optional): Configuration settings for the OpenAI agent.

    Methods:
        - `get_response`(user_question, prompt_template=DEFAULT_PROMPT_TEMPLATE):
            Generates a response to the user's question using the specified prompt template.



    Attributes:
        - `chroma_librarian` (ChromaLibrarian): The Chroma librarian instance.
        - `model` (str): The OpenAI model being used.
        - `client`: The OpenAI API client.
    """

    def __init__(
        self,
        chroma_librarian: ChromaLibrarian,
        configs: OpenAIConfigs = OpenAIConfigs(),
    ) -> None:
        self.chroma_librarian: ChromaLibrarian = chroma_librarian
        self.configs: OpenAIConfigs = configs
        self.client = OpenAI()

    def get_response(
        self, user_question: str, prompt_template: str = DEFAULT_PROMPT_TEMPLATE
    ) -> str | None:
        """
        Generates a response to the user's question using the OpenAI API.

        Args:
            - `user_question` (str): The user's question.
            - `prompt_template` (str, optional): The template for formatting the prompt.
                default: DEFAULT_PROMPT_TEMPLATE.

        Returns:
            - `str | None`: The generated response or None if the response could not be generated.

        Raises:
            - `ValueError`: If user_question is empty.
            - `RuntimeError`: If there is an issue with the OpenAI API request.
            - `KeyError`: If the prompt template is missing required keys.

        Example:
            ```python
            agent = OpenAIChatAgent(chroma_librarian, model="gpt-4o")
            try:
                response = agent.get_response("What code blocks use recursion?")
                print(response)
            except ValueError as ve:
                print(f"ValueError: {ve}")
            except RuntimeError as re:
                print(f"RuntimeError: {re}")
            except KeyError as ke:
                print(f"KeyError: {ke}")
            ```
        """
        if not user_question:
            raise ValueError("User question cannot be empty.")

        try:
            chroma_results: chroma_types.QueryResult | None = (
                self.chroma_librarian.query_chroma(user_question)
            )

            if not chroma_results:
                return "I don't know how to answer that question."

            documents: list[list[str]] | None = chroma_results["documents"]

            if not documents:
                return "I don't know how to answer that question."

            context: str = ""
            for document in documents:
                context += "\n".join(document) + "\n"

            prompt: str = self._format_prompt(context, user_question, prompt_template)

            messages: Sequence[dict[str, str]] = [
                {"role": "system", "content": DEFAULT_SYSTEM_PROMPT},
                {"role": "user", "content": prompt},
            ]

            response: openai_types.ChatCompletion = self.client.chat.completions.create(
                model=self.configs.model,
                messages=messages,  # type: ignore # FIXME: fix type hinting error
                temperature=self.configs.temperature,
                # response_format={"type": "json_object"},
            )
            return response.choices[0].message.content

        except Exception as e:
            raise RuntimeError(f"Error interacting with OpenAI API: {e}") from e

    def _format_prompt(
        self,
        context: str,
        user_question: str,
        prompt_template: str,
    ) -> str:
        """
        Formats the prompt for the OpenAI API based on the provided context, user's question, and template.

        Args:
            - `context` (str): The context derived from Chroma query results.
            - `user_question` (str): The user's question.
            - `prompt_template` (str): The template for formatting the prompt.

        Returns:
            - `str`: The formatted prompt.

        Raises:
            - `KeyError`: If the prompt template is missing required keys.

        Example:
            ```python
            prompt = agent._format_prompt("Context here", "What is the meaning of life?", "Template {context} {user_question}")
            print(prompt)
            ```
        """

        try:
            return prompt_template.format(context=context, user_question=user_question)

        except KeyError as e:
            raise KeyError(f"Prompt template is missing the following key: {e}") from e



File: postcode/ai_services/openai_configs.py
----------------------------------------
from typing import Literal, Protocol
from dataclasses import dataclass

from pydantic import BaseModel

from postcode.ai_services.summarizer.prompts import summarization_prompts
from postcode.ai_services.chat.prompts import chat_prompts


class OpenAIConfigs(BaseModel):
    """
    Configs for the summarization completion.

    Used to set the chat completion parameters for the OpenAI chat completions method call.

    Args:
        - `system_message` (str): The system message used for chat completion.
        - `model` (str): The model to use for the completion. Default is "gpt-4o".
        - `max_tokens` (int | None): The maximum number of tokens to generate. 'None' implies no limit. Default is None.
        - `stream` (bool): Whether to stream back partial progress. Default is False.
        - `temperature` (float): Sampling temperature to use. Default is 0.0.

    Notes:
        - model must be a valid OpenAI model name.

    Examples:
        ```Python
        system_message = "Summarize the following code."
        summary_completion_configs = SummaryCompletionConfigs(
            system_message=system_message,
            model="gpt-4o",
            max_tokens=100,
            presence_penalty=0.0,
            stream=False,
            temperature=0.0,
        )
        ```
    """

    system_message: str = summarization_prompts.SUMMARIZER_DEFAULT_INSTRUCTIONS
    model: Literal[
        "gpt-4o",
        "gpt-4-1106-preview",
        "gpt-4-vision-preview",
        "gpt-4",
        "gpt-4-0314",
        "gpt-4-0613",
        "gpt-4-32k",
        "gpt-4-32k-0314",
        "gpt-4-32k-0613",
        "gpt-3.5-turbo-1106",
        "gpt-3.5-turbo",
        "gpt-3.5-turbo-16k",
        "gpt-3.5-turbo-0301",
        "gpt-3.5-turbo-0613",
        "gpt-3.5-turbo-16k-0613",
    ] = "gpt-4o"
    max_tokens: int | None = None
    stream: bool = False
    temperature: float = 0.0


class SummaryCompletionConfigs(OpenAIConfigs):
    """
    Configs for the summarization completion.

    Used to set the chat completion parameters for the OpenAI chat completions method call.

    Args:
        - `system_message` (str): The system message used for chat completion.
        - `model` (str): The model to use for the completion. Default is "gpt-4o".
        - `max_tokens` (int | None): The maximum number of tokens to generate. 'None' implies no limit. Default is None.
        - `stream` (bool): Whether to stream back partial progress. Default is False.
        - `temperature` (float): Sampling temperature to use. Default is 0.0.

    Notes:
        - model must be a valid OpenAI model name.

    Examples:
        ```Python
        system_message = "Summarize the following code."
        summary_completion_configs = SummaryCompletionConfigs(
            system_message=system_message,
            model="gpt-4o",
            max_tokens=100,
            presence_penalty=0.0,
            stream=False,
            temperature=0.0,
        )
        ```
    """


class ChatCompletionConfigs(SummaryCompletionConfigs):
    """
    Configs for the chat completion.

    Used to set the chat completion parameters for the OpenAI chat completions method call.

    Args:
        - `system_message` (str): The system message used for chat completion.
        - `model` (str): The model to use for the completion. Default is "gpt-4o".
        - `max_tokens` (int | None): The maximum number of tokens to generate. 'None' implies no limit. Default is None.
        - `stream` (bool): Whether to stream back partial progress. Default is False.
        - `temperature` (float): Sampling temperature to use. Default is 0.0.

    Notes:
        - model must be a valid OpenAI model name.

    Examples:
        ```Python
        system_message = "Summarize the following code."
        chat_completion_configs = ChatCompletionConfigs(
            system_message=system_message,
            model="gpt-4o",
            max_tokens=100,
            presence_penalty=0.0,
            stream=False,
            temperature=0.0,
        )
        ```
    """

    system_message: str = chat_prompts.DEFAULT_SYSTEM_PROMPT


@dataclass
class OpenAIReturnContext:
    """
    A dataclass for storing the return context of an OpenAI completion.

    Attributes:
        - prompt_tokens (int): The number of tokens in the prompt.
        - completion_tokens (int): The number of tokens in the completion.
        - summary (str | None): The summary of the code snippet.
    """

    prompt_tokens: int
    completion_tokens: int
    summary: str | None



File: postcode/ai_services/librarians/prompts/prompt_creator.py
----------------------------------------
import postcode.ai_services.librarians.prompts.chroma_librarian_prompts as prompts


class ChromaLibrarianPromptCreator:
    """
    Class for creating prompts for the Chroma Librarian.

    Methods:
        - `create_prompt`: Static method that creates a prompt for the Chroma Librarian.

    Examples:
        ```Python
        # Create a prompt
        prompt: str | None = ChromaLibrarianPromptCreator.create_prompt(
            user_question,
            prompt_template,
            queries_count,
        )
        ```
    """

    @staticmethod
    def create_prompt(
        user_question: str,
        prompt_template: str = prompts.DEFAULT_CHROMA_LIBRARIAN_PROMPT,
        queries_count: int = 3,
    ) -> str:
        """
        Creates a prompt for the Chroma Librarian by interpolating the given prompt template with the given user question and queries count.

        Args:
            - user_question (str): The user's question.
            - prompt_template (str): The template to interpolate.
                - default: DEFAULT_CHROMA_LIBRARIAN_PROMPT defined in `chroma_librarian_prompts.py`.
            - queries_count (int): The number of queries to make.
                - default: 3
        """

        return prompt_template.format(
            user_question=user_question,
            prompt_template=prompt_template,
            queries_count=queries_count,
        )



File: postcode/ai_services/librarians/prompts/chroma_librarian_prompts.py
----------------------------------------
DEFAULT_CHROMA_LIBRARIAN_SYSTEM_PROMPT: str = f"""
You are an expert at writing queries to retrieve data from a ChromaDB vector database. You take user questions and
write a given number of queries that will best retrieve the relevant data from the vector store. The vector contains
data for a Python project, so write your queries accordingly. Always return your queries as a list
in a json object where the key to the list is "query_list".
"""

DEFAULT_CHROMA_LIBRARIAN_PROMPT: str = """
Given the following user question, write {queries_count} queries that will best retrieve the relevant data from the
vector store.

When creating queries for a vector database, especially concerning specific functionalities or components within a Python project, it's helpful to:
    1. Specify the Component: Clearly mention the class, module, or function you're interested in.
    2. Focus on the Action or Feature: Highlight what you want to know about - whether it's retrieving results, serialization, validation methods, etc.
    3. Vary the Structure: Include variations of your query to cover different ways the information might be phrased or indexed.
    4. Do not mention the language, eg. Python, in your query, as it is unnecessary and will confuse the results.

Examples:
    - User question:
        - How do I get the results from the chromadb vector database using a list of queries in this project?
    - Your queries:
        "query_list": [
            "chromadb vector database results from list of queries",
            "query chromadb vector database",
            "search vector database"
        ]

    - User Question:
        - "What methods are available for data validation in the UserInputValidator module?"
    - Your Queries:
        "query_list": [
            "Methods in UserInputValidator module for data validation in Python",
            "UserInputValidator Python module data validation techniques",
            "List methods UserInputValidator for validating data in Python"
        ]

User Question: {user_question}

Make sure to return your queries as a list in a json object where the key to the list is "query_list".
"""

prompts_list: list[str] = [
    DEFAULT_CHROMA_LIBRARIAN_SYSTEM_PROMPT,
    DEFAULT_CHROMA_LIBRARIAN_PROMPT,
]



File: postcode/ai_services/librarians/chroma_librarians.py
----------------------------------------
import logging
import json

from openai import OpenAI
from pydantic import BaseModel
import postcode.types.openai as openai_types
from postcode.databases.chroma.chromadb_collection_manager import (
    ChromaCollectionManager,
)
from postcode.ai_services.librarians.prompts.prompt_creator import (
    ChromaLibrarianPromptCreator,
)
from postcode.ai_services.librarians.prompts.chroma_librarian_prompts import (
    DEFAULT_CHROMA_LIBRARIAN_PROMPT,
    DEFAULT_CHROMA_LIBRARIAN_SYSTEM_PROMPT,
)
import postcode.types.chroma as chroma_types

# TOOLS: list[dict[str, Any]] = [
#     {
#         "type": "function",
#         "function": {
#             "name": "query_chroma",
#             "description": "Get the results from the chromadb vector database using a list of queries.",
#             "parameters": {
#                 "type": "object",
#                 "properties": {
#                     "queries": {
#                         "type": "list[str]",
#                         "description": "List of queries to use to get the results from the chromadb vector database.",
#                     },
#                     "n_results": {
#                         "type": "int",
#                         "description": "Number of results to return, default is 10.",
#                     },
#                 },
#                 "required": ["queries"],
#             },
#         },
#     }
# ]


class OpenAIResponseContent(BaseModel):
    """
    Pydantic model representing the content structure of an OpenAI response.

    OpenAI is set to respond with a JSON object, so this model is used to parse the response.

    Attributes:
        - query_list (list[str]): List of queries in the OpenAI response.
    """

    query_list: list[str]


class ChromaLibrarian:
    def __init__(
        self,
        collection_manager: ChromaCollectionManager,
        model: str = "gpt-3.5-turbo-1106",
    ) -> None:
        """
        Represents a librarian for interacting with the Chroma database using OpenAI.

        Args:
            - collection_manager (ChromaCollectionManager): The manager for Chroma collections.
            - model (str, optional): The OpenAI model to use. Defaults to "gpt-3.5-turbo-1106".

        Methods:
            - query_chroma(user_question):
                Queries the Chroma database using the provided user question.

            - _query_collection(queries, n_results=3):
                Queries the Chroma collection manager with a list of queries.

            - _get_chroma_queries(user_question, queries_count=3, retries=3):
                Generates Chroma queries based on the user question.

        Attributes:
            - collection_manager (ChromaCollectionManager): The Chroma collection manager.
            - model (str): The OpenAI model being used.
            - client: The OpenAI API client.

        Examples:
            ```python
            chroma_librarian = ChromaLibrarian(chroma_collection_manager)
            chroma_librarian.query_chroma("Which models are inherited by others?")
            ```
        """

        self.collection_manager: ChromaCollectionManager = collection_manager
        self.model: str = model
        self.client = OpenAI()

    def query_chroma(self, user_question: str) -> chroma_types.QueryResult | None:
        """
        Queries the Chroma database using the provided user question.

        Args:
            - user_question (str): The user's question.

        Returns:
            - chroma_types.QueryResult | None: The result of the Chroma query, or None if unsuccessful.
        """

        queries: list[str] | None = self._get_chroma_queries(user_question)
        if not queries:
            return None

        print(queries)

        return self._query_collection(queries)

    def _query_collection(
        self,
        queries: list[str],
        n_results: int = 3,
    ) -> chroma_types.QueryResult | None:
        """
        Queries the Chroma collection manager with a list of queries.

        Args:
            - queries (list[str]): List of queries to use in the Chroma collection manager.
            - n_results (int, optional): Number of results to return. Defaults to 3.

        Returns:
            - chroma_types.QueryResult | None: The result of the Chroma query, or None if unsuccessful.
        """

        return self.collection_manager.query_collection(
            queries,
            n_results=n_results,
            include_in_result=["metadatas", "documents"],
        )

    def _get_chroma_queries(
        self, user_question: str, queries_count: int = 3, retries: int = 3
    ) -> list[str] | None:
        """
        Generates Chroma queries based on the user question.

        Args:
            - user_question (str): The user's question.
            - queries_count (int, optional): Number of queries to generate. Defaults to 3.
            - retries (int, optional): Number of retries in case of failure. Defaults to 3.

        Returns:
            - list[str] | None: The generated list of Chroma queries, or None if unsuccessful.
        """

        while retries > 0:
            retries -= 1

            prompt: str = ChromaLibrarianPromptCreator.create_prompt(
                user_question,
                prompt_template=DEFAULT_CHROMA_LIBRARIAN_PROMPT,
                queries_count=queries_count,
            )

            try:
                completion: openai_types.ChatCompletion = (
                    self.client.chat.completions.create(
                        model=self.model,
                        response_format={"type": "json_object"},
                        messages=[
                            {
                                "role": "system",
                                "content": DEFAULT_CHROMA_LIBRARIAN_SYSTEM_PROMPT,
                            },
                            {"role": "user", "content": prompt},
                        ],
                    )
                )
                content: str | None = completion.choices[0].message.content
                if not content:
                    continue

                content_json = json.loads(content)
                content_model = OpenAIResponseContent(
                    query_list=content_json["query_list"]
                )
                content_model.query_list.append(user_question)
                queries_count += 1

                if content:
                    queries: list[str] = content_model.query_list
                    if queries and len(queries) == queries_count:
                        return queries

            except Exception as e:
                logging.error(f"An error occurred: {e}")

        return None



File: postcode/ai_services/summarizer/graph_db_summarization_manager.py
----------------------------------------
# TODO: Add logic to gather all child summaries of a directory (modules and directories within the directory)

import logging
from rich import print

from postcode.ai_services.openai_configs import OpenAIReturnContext
from postcode.ai_services.summarizer.summarizer_protocol import Summarizer
from postcode.ai_services.summarizer.summarization_mapper import SummarizationMapper
from postcode.databases.arangodb.arangodb_manager import ArangoDBManager

from postcode.types.postcode import ModelType

from postcode.models.models import (
    ClassModel,
    DependencyModel,
    DirectoryModel,
    FunctionModel,
    ImportModel,
    ModuleModel,
    StandaloneCodeBlockModel,
)


class GraphDBSummarizationManager:
    """
    A class for managing summarization of models in a graph database.

    This class handles the process of summarizing code models, including support for multi-pass summarization.
    It interacts with a graph database to store and retrieve model information and summaries.

    Args:
        - `all_models_tuple` (tuple[ModelType, ...]): Tuple of all models available for summarization.
        - `summarization_mapper` (SummarizationMapper): The SummarizationMapper instance for creating summarization maps.
        - `summarizer` (Summarizer): The Summarizer instance for generating code summaries.
        - `graph_manager` (ArangoDBManager): The ArangoDBManager instance for handling database interactions.

    Properties:
        - `total_cost` (float): Provides the total cost of the summarization process.

    Methods:
        - `create_summaries_and_return_updated_models`(num_passes: int = 1): Creates summaries and updates models in the graph database.

    Example:
        ```python
        # Instantiate GraphDBSummarizationManager
        summarization_manager = GraphDBSummarizationManager(
            all_models_tuple=(ModuleModel(id="module_1"), FunctionModel(id="function_1")),
            summarization_mapper=my_summarization_mapper_instance,
            summarizer=my_summarizer_instance,
            graph_manager=my_arangodb_manager_instance
        )

        # Create summaries and update models with multi-pass summarization
        updated_models = summarization_manager.create_summaries_and_return_updated_models(num_passes=3)
        ```
    """

    def __init__(
        self,
        all_models_tuple: tuple[ModelType, ...],
        summarization_mapper: SummarizationMapper,
        summarizer: Summarizer,
        graph_manager: ArangoDBManager,
    ) -> None:
        self.all_models_tuple: tuple[ModelType, ...] = all_models_tuple
        self.summarization_mapper: SummarizationMapper = summarization_mapper
        self.summarizer: Summarizer = summarizer
        self.graph_manager: ArangoDBManager = graph_manager

        self.summarized_code_block_ids: set[str] = set()
        self.prompt_tokens: int = 0
        self.completion_tokens: int = 0

    @property
    def total_cost(self) -> float:
        """Provides the total cost of the summarization process."""
        prompt_cost: int = self.prompt_tokens * 1  # Costs 1 cent per 1,000 tokens
        completion_cost: int = (
            self.completion_tokens * 3
        )  # Costs 3 cents per 1,000 tokens
        return (prompt_cost + completion_cost) / 100_000  # Convert to dollars

    def create_summaries_and_return_updated_models(
        self, num_passes: int = 1
    ) -> list[ModelType] | None:
        """
        Creates summaries and updates models in the graph database.

        This method supports both single-pass and multi-pass summarization. In multi-pass mode,
        it performs bottom-up, top-down, and final bottom-up passes to create comprehensive summaries.

        Args:
            - `num_passes` (int): Number of summarization passes to perform. Must be either 1 or 3. Default is 1.

        Returns:
            - `list[ModelType] | None`: Updated models in the graph database or None if graph_manager is not provided.

        Raises:
            - `ValueError`: If num_passes is not 1 or 3.
        """
        if num_passes not in [1, 3]:
            raise ValueError("Number of passes must be either 1 or 3")

        return self._handle_summarization_passes(num_passes)

    # def _single_pass_summarization(self) -> list[ModelType] | None:
    #     """Performs a single-pass (bottom-up) summarization."""

    #     return self._process_summarization_map(
    #         self.summarization_mapper.create_bottom_up_summarization_map(1)
    #     )

    def _handle_summarization_passes(
        self, num_of_passes: int
    ) -> list[ModelType] | None:
        if num_of_passes == 1:
            logging.info("Starting single-pass summarization")
            models: (
                list[
                    ModuleModel
                    | ClassModel
                    | FunctionModel
                    | StandaloneCodeBlockModel
                    | DirectoryModel
                ]
                | None
            ) = self._process_summarization_map(
                self.summarization_mapper.create_bottom_up_summarization_map(1), 1
            )

        else:
            logging.info("Starting multi-pass summarization")

            for pass_num in range(1, num_of_passes + 1):
                if pass_num % 2 != 0:
                    logging.info(f"[blue]Pass number:[/blue] {pass_num} (bottom-up)")
                    models = self._process_summarization_map(
                        self.summarization_mapper.create_bottom_up_summarization_map(
                            pass_num
                        ),
                        pass_num,
                    )
                else:
                    logging.info(f"[blue]Pass number:[/blue] {pass_num} (top-down)")
                    models = self._process_summarization_map(
                        self.summarization_mapper.create_top_down_summarization_map(
                            pass_num
                        ),
                        pass_num,
                        models,
                        top_down=True,
                    )
                self.summarization_mapper.model_visited_in_db = set()

        return models

    def _process_summarization_map(
        self,
        summarization_map: list[ModelType],
        pass_number: int,
        models: list[ModelType] | None = None,
        top_down: bool = False,
    ) -> list[ModelType] | None:
        """
        Processes a summarization map to create or update summaries for models.

        Args:
            - `summarization_map` (list[ModelType]): The map of models to summarize.
            - `pass_number` (int): The current summarization pass number.
            - `models` (list[ModelType] | None): Previously summarized models (if any).
            - `top_down` (bool): Whether this is a top-down summarization pass.

        Returns:
            - `list[ModelType] | None`: Updated list of models with new summaries.
        """
        models_to_summarize_count: int = len(summarization_map)
        models_summarized_count: int = 0

        for model in summarization_map:
            models_summarized_count += 1
            if isinstance(model, ImportModel):
                import_details = self._get_import_details(model)
            else:
                import_details = None
            logging.info(
                f"Summarizing model {models_summarized_count} out of {models_to_summarize_count}; {model.id}."
            )

            # Check if the model is an instance of ImportModel before calling _get_import_details
            if isinstance(model, ImportModel):
                import_details = self._get_import_details(model)

            children_summaries: str | None = self._get_child_summaries(model)
            dependency_summaries: str | None = self._get_dependencies_summaries(model)

            parent_summary: str | None = None
            if top_down and models:
                parent_model = next(
                    (m for m in models if m.id == model.parent_id), None
                )
                if parent_model:
                    parent_summary = parent_model.summary

            code_content: str = (
                model.code_content if not isinstance(model, DirectoryModel) else ""
            )

            previous_summary: str | None = None
            if not pass_number == 1:
                previous_summary = model.summary

            summary_return_context: OpenAIReturnContext | None = (
                self.summarizer.summarize_code(
                    code_content,
                    model_id=model.id,
                    children_summaries=children_summaries,
                    dependency_summaries=dependency_summaries,
                    import_details=import_details,
                    parent_summary=parent_summary,
                    pass_number=pass_number,
                    previous_summary=previous_summary,
                )
            )
            if summary_return_context:
                if summary_return_context.summary:
                    self.graph_manager.update_vertex_summary_by_id(
                        model.id, summary_return_context.summary
                    )
                    model.summary = summary_return_context.summary
                print(summary_return_context.summary)
                self.prompt_tokens += summary_return_context.prompt_tokens
                self.completion_tokens += summary_return_context.completion_tokens
                logging.info(f"Total cost: ${self.total_cost:.2f}")

        return self.graph_manager.get_all_vertices() if self.graph_manager else None

    def _get_child_summaries(self, model: ModelType) -> str | None:
        """
        Gathers summaries of child models.

        Args:
            - `model` (ModelType): The model to gather child summaries for.

        Returns:
            - `str | None`: A string of concatenated child summaries or None if the model has no children.
        """
        child_summary_list: list[str] = []
        if model.children_ids:
            for child_id in model.children_ids:
                if child := self.graph_manager.get_vertex_model_by_id(child_id):
                    if child.summary:
                        child_summary_list.append(child.summary)
                    else:
                        # TODO: Add logic to gather all child summaries of a directory (modules and directories within the directory)
                        if not isinstance(child, DirectoryModel):
                            child_summary_list.append(
                                f"Child ({child_id}) code content:\n{child.code_content}\n"
                            )
        return (
            self._stringify_children_summaries(child_summary_list)
            if child_summary_list
            else None
        )

    def _stringify_children_summaries(self, children_summary_list: list[str]) -> str:
        """
        Converts all of the child summaries to a single string to be used in the prompt.

        Args:
            - `children_summary_list` (list[str]): A list of child summaries.

        Returns:
            - `str`: A string of all of the child summaries.
        """
        return "\n".join(children_summary_list)

    def _get_dependencies_summaries(self, model: ModelType) -> str | None:
        """
        Gathers summaries of dependencies and returns them as a string to be used in the prompt.

        Args:
            - `model` (ModelType): The model to gather dependency summaries for.

        Returns:
            - `str | None`: A string of dependency summaries or None if the model has no dependencies.
        """
        if isinstance(model, DirectoryModel):
            return None

        dependency_summary_list: list[str] = []

        if isinstance(model, ModuleModel):
            if model.imports:
                for _import in model.imports:
                    if import_summary := self._get_import_summary(_import):
                        dependency_summary_list.append(import_summary)
        elif model.dependencies:
            for dependency in model.dependencies:
                if isinstance(dependency, DependencyModel):
                    if dependency_summary := self._get_local_dependency_summary(
                        dependency, model
                    ):
                        dependency_summary_list.append(dependency_summary)
                elif isinstance(dependency, ImportModel):
                    if import_summary := self._get_import_summary(dependency):
                        dependency_summary_list.append(import_summary)

        return (
            self._stringify_dependencies_summaries(dependency_summary_list)
            if dependency_summary_list
            else None
        )

    def _get_local_dependency_summary(
        self,
        dependency: DependencyModel,
        model: ModelType,
    ) -> str | None:
        """
        Retrieves the summary of a local dependency to be used in the prompt.

        Args:
            - `dependency` (DependencyModel): The dependency to retrieve the summary for.
            - `model` (ModelType): The model to retrieve the summary for.

        Returns:
            - `str | None`: The summary of the local dependency or None if the dependency is not local.
        """
        if not model.children_ids:
            return None

        for child_id in model.children_ids:
            if child_id == dependency.code_block_id:
                if child := self.graph_manager.get_vertex_model_by_id(child_id):
                    if isinstance(child, DirectoryModel):
                        return None
                    return (
                        child.summary
                        if child.summary
                        else f"Dependency ({dependency.code_block_id}) code content:\n{child.code_content}\n"
                    )
        return None

    def _stringify_dependencies_summaries(
        self, dependencies_summary_list: list[str]
    ) -> str:
        """
        Converts all of the dependency summaries to a single string to be used in the prompt.

        Args:
            - `dependencies_summary_list` (list[str]): A list of dependency summaries.

        Returns:
            - `str`: A string of all of the dependency summaries.
        """
        return "\n".join(dependencies_summary_list)

    def _get_import_summary(self, import_model: ImportModel) -> str | None:
        """
        Retrieves the summary of an import to be used in the prompt.

        Args:
            - `import_model` (ImportModel): The import to retrieve the summary for.

        Returns:
            - `str | None`: The summary of the import or None if the import is not relevant.
        """
        if import_model.import_module_type == "LOCAL":
            if not import_model.import_names:
                return self._get_local_import_summary(import_model)
            else:
                return self._get_local_import_from_summary(import_model)
        else:
            return self._get_import_details(import_model)

    def _get_local_import_summary(self, dependency: ImportModel) -> str | None:
        """
        Retrieves the summary of a local import to be used in the prompt.

        Args:
            - `dependency` (ImportModel): The import to retrieve the summary for.

        Returns:
            - `str | None`: The summary of the local import or None if the import is not local.
        """
        if model := next(
            (m for m in self.all_models_tuple if m.id == dependency.local_module_id),
            None,
        ):
            if isinstance(model, DirectoryModel):
                return None
            return (
                model.summary
                if model.summary
                else f"Imported module ({dependency.local_module_id}) code content:\n{model.code_content}\n"
            )
        return None

    def _get_local_import_from_summary(self, dependency: ImportModel) -> str | None:
        """
        Retrieves the summary of a local import from to be used in the prompt.

        Args:
            - `dependency` (ImportModel): The import to retrieve the summary for.

        Returns:
            - `str | None`: The summary of the local import from or None if the import is not local.
        """
        for import_name in dependency.import_names:
            if model := next(
                (
                    m
                    for m in self.all_models_tuple
                    if m.id == import_name.local_block_id
                ),
                None,
            ):
                if isinstance(model, DirectoryModel):
                    return None
                return (
                    model.summary
                    if model.summary
                    else f"Imported code block ({dependency.local_module_id}) code content:\n{model.code_content}\n"
                )
        return None

    def _get_import_details(self, import_model: ImportModel) -> str | None:
        """
        Retrieves the details of an import to be used in the prompt.

        Args:
            - `import_model` (ImportModel): The import to retrieve the details for.

        Returns:
            - `str | None`: The details of the import or None if the import is not relevant.
        """
        if import_model.import_module_type == "LOCAL" or not import_model.import_names:
            return None

        import_names_list: list[str] = [
            f"{name.name} as {name.as_name}" if name.as_name else name.name
            for name in import_model.import_names
        ]

        if import_model.imported_from:
            return f"from {import_model.imported_from} import {', '.join(import_names_list)}"
        else:
            return f"import {', '.join(import_names_list)}"



File: postcode/ai_services/summarizer/summarizer_protocol.py
----------------------------------------
from typing import Protocol
from postcode.ai_services.openai_configs import OpenAIReturnContext


class Summarizer(Protocol):
    """A protocol for summary classes."""

    def summarize_code(
        self,
        code: str,
        *,
        model_id: str,
        children_summaries: str | None,
        dependency_summaries: str | None,
        import_details: str | None,
        parent_summary: str | None = None,
        pass_number: int = 1,
        previous_summary: str | None = None,
    ) -> OpenAIReturnContext | None:
        """
        Summarizes the provided code snippet.

        Args:
            - code (str): The code snippet to summarize.
            - model_id (str): The identifier of the model being summarized.
            - children_summaries (str | None): Summaries of child elements, if any.
            - dependency_summaries (str | None): Summaries of dependencies, if any.
            - import_details (str | None): Details of imports used in the code.
            - parent_summary (str | None): Summary of the parent element, if applicable.
            - pass_number (int): The current pass number in multi-pass summarization. Default is 1.

        Returns:
            OpenAIReturnContext | None: The summary context, or None if summarization fails.
        """
        ...

    def test_summarize_code(
        self,
        code: str,
        *,
        model_id: str,
        children_summaries: str | None,
        dependency_summaries: str | None,
        import_details: str | None,
        parent_summary: str | None = None,
        pass_number: int = 1,
    ) -> OpenAIReturnContext | None:
        """
        A method for testing the summarize_code functionality without making API calls.

        Args:
            - code (str): The code snippet to summarize (not used in the test method).
            - model_id (str): The identifier of the model being summarized.
            - children_summaries (str | None): Summaries of child elements, if any.
            - dependency_summaries (str | None): Summaries of dependencies, if any.
            - import_details (str | None): Details of imports used in the code.
            - parent_summary (str | None): Summary of the parent element, if applicable.
            - pass_number (int): The current pass number in multi-pass summarization. Default is 1.

        Returns:
            OpenAIReturnContext | None: A context object containing a test summary and token usage information.
        """
        ...



File: postcode/ai_services/summarizer/summarization_mapper.py
----------------------------------------
import logging
from postcode.databases.arangodb.arangodb_manager import ArangoDBManager
from postcode.types.postcode import ModelType


class SummarizationMapper:
    """
    A class for generating summarization maps based on specified module IDs and associated models.

    This class facilitates the creation of both bottom-up and top-down summarization maps by traversing
    inbound and outbound relationships in a graph structure. It utilizes an ArangoDBManager instance
    for querying relationships between models.

    Args:
        module_ids_to_update (list[str]): The list of module IDs to consider during summarization map creation.
        all_models (tuple[ModelType, ...]): Tuple of all models available for summarization.
        arangodb_manager (ArangoDBManager): The ArangoDBManager instance for handling database interactions.

    Methods:
        create_bottom_up_summarization_map(pass_num: int): Creates a bottom-up summarization map for the specified module IDs.
        create_top_down_summarization_map(pass_num: int): Creates a top-down summarization map for the specified module IDs.
    """

    def __init__(
        self,
        module_ids_to_update: list[str],
        all_models: tuple[ModelType, ...],
        arangodb_manager: ArangoDBManager,
    ) -> None:
        self.module_ids_to_update: list[str] = module_ids_to_update
        self.all_models: tuple[ModelType, ...] = all_models
        self.arangodb_manager: ArangoDBManager = arangodb_manager

        self.models_to_update: list[ModelType] = self._get_models_to_update()
        self.model_visited_in_db: set[str] = set()
        self.summarization_map: list[ModelType] = []
        self.temp_map: list[ModelType] = []

    def _get_models_to_update(self) -> list[ModelType]:
        """
        Returns all models that need to be updated based on the module IDs.

        This method queries the ArangoDBManager to find the models that are either directly associated with
        the module IDs or related through dependencies.

        Returns:
            list[ModelType]: List of models to be updated.
        """
        models_to_update: list[ModelType] = []
        for model in self.all_models:
            for module_id in self.module_ids_to_update:
                if module_id in model.id:
                    models_to_update.append(model)
                    break
        return models_to_update

    def _set_inbound_models_in_summarization_map(self, model_id: str) -> None:
        """
        Sets inbound models in the summarization map recursively.

        Args:
            model_id (str): The ID of the model.
        """
        if model_id in self.model_visited_in_db:
            return
        self.model_visited_in_db.add(model_id)
        inbound_models = self.arangodb_manager.get_inbound_models(model_id)
        if inbound_models:
            for model in inbound_models:
                self._set_inbound_models_in_summarization_map(model.id)
                self.temp_map.append(model)

    def _set_outbound_models_in_summarization_map(self, model_id: str) -> None:
        """
        Sets outbound models in the summarization map recursively.

        Args:
            model_id (str): The ID of the model.
        """
        if model_id in self.model_visited_in_db:
            return
        self.model_visited_in_db.add(model_id)
        outbound_models = self.arangodb_manager.get_outbound_models(model_id)
        if outbound_models:
            for model in outbound_models:
                self._set_outbound_models_in_summarization_map(model.id)
                self.temp_map.append(model)

    def create_bottom_up_summarization_map(self, pass_num: int) -> list[ModelType]:
        """
        Creates a bottom-up summarization map for the specified module IDs.

        This method creates a summarization map starting from the lowest-level models
        and working up to higher-level models by first traversing inbound relationships.

        Args:
            pass_num (int): The current pass number, used to differentiate between passes.

        Returns:
            list[ModelType]: The bottom-up summarization map.
        """
        logging.info(f"Creating bottom-up summarization map for pass {pass_num}")
        self._refresh_models_to_update()

        for model in self.models_to_update:
            logging.debug(f"Setting inbound models in summarization map: {model.id}")
            self._set_inbound_models_in_summarization_map(model.id)
            self.temp_map.append(model)
            self.model_visited_in_db.remove(model.id)
            self.summarization_map.extend(self.temp_map)
            self.temp_map = []

        for model in self.models_to_update:
            logging.debug(f"Setting outbound models in summarization map: {model.id}")
            self._set_outbound_models_in_summarization_map(model.id)
            self.summarization_map.extend(self.temp_map)
            self.temp_map = []

        logging.info("Bottom-up summarization map created")
        return self._remove_duplicates(self.summarization_map)[::-1]

    def create_top_down_summarization_map(self, pass_num: int) -> list[ModelType]:
        """
        Creates a top-down summarization map for the specified module IDs.

        This method creates a summarization map starting from the highest-level models
        and working down to lower-level models by first traversing outbound relationships.

        Args:
            pass_num (int): The current pass number, used to differentiate between passes.

        Returns:
            list[ModelType]: The top-down summarization map.
        """
        logging.info(f"Creating top-down summarization map for pass {pass_num}")
        self._refresh_models_to_update()

        for model in self.models_to_update:
            logging.debug(f"Setting outbound models in summarization map: {model.id}")
            self._set_outbound_models_in_summarization_map(model.id)
            self.temp_map.append(model)
            self.model_visited_in_db.remove(model.id)
            self.summarization_map.extend(self.temp_map)
            self.temp_map = []

        for model in self.models_to_update:
            logging.debug(f"Setting inbound models in summarization map: {model.id}")
            self._set_inbound_models_in_summarization_map(model.id)
            self.summarization_map.extend(self.temp_map)
            self.temp_map = []

        logging.info("Top-down summarization map created")
        return self._remove_duplicates(self.summarization_map)

    def _remove_duplicates(self, summarization_map: list[ModelType]) -> list[ModelType]:
        """
        Removes duplicate models from the summarization map while preserving order.

        Args:
            summarization_map (list[ModelType]): The original summarization map.

        Returns:
            list[ModelType]: The summarization map with duplicates removed.
        """
        summary_ids: set[str] = set()
        unique_summary_map: list[ModelType] = []
        for model in summarization_map:
            if model.id not in summary_ids:
                unique_summary_map.append(model)
                summary_ids.add(model.id)
        return unique_summary_map

    def _refresh_models_to_update(self) -> None:
        """
        Refreshes the models_to_update list based on the current module_ids_to_update and all_models.

        This method re-queries the database via ArangoDBManager to get the correct list of models to process
        for either top-down or bottom-up summarization.
        """
        refreshed_models = []
        for module_id in self.module_ids_to_update:
            outbound_models = self.arangodb_manager.get_outbound_models(
                module_id
            )  # For top-down
            if outbound_models:
                refreshed_models.extend(outbound_models)

        self.models_to_update = (
            refreshed_models if refreshed_models else self.models_to_update
        )



File: postcode/ai_services/summarizer/prompts/prompt_creator.py
----------------------------------------
import logging
import re
from typing import Callable

from rich import print

import postcode.ai_services.summarizer.prompts.summarization_prompts as prompts


class SummarizationPromptCreator:
    """
    Class for creating prompts for the summarizer, supporting multi-pass summarization.

    Methods:
        - `create_prompt`: Static method that creates a prompt for the summarizer.

    Examples:
        ```Python
        # Create a prompt for single-pass summarization
        prompt: str | None = SummarizationPromptCreator.create_prompt(
            code,
            children_summaries,
            dependency_summaries,
            import_details,
        )

        # Create a prompt for multi-pass summarization
        prompt: str | None = SummarizationPromptCreator.create_prompt(
            code,
            children_summaries,
            dependency_summaries,
            import_details,
            parent_summary,
            pass_number=2,
            previous_summary="Previous summary of the code."
        )
        ```
    """

    _interpolation_strategies: dict[str, Callable[..., str]] = {
        # Pass 1 strategies (unchanged)
        "children_dependencies_import_details_parent_pass1": lambda code, children_summaries, dependencies, import_details, parent_summary, pass_number, previous_summary: SummarizationPromptCreator._interpolate_prompt_string(
            prompts.CODE_SUMMARY_PROMPT_PASS_1,
            code=code,
            children_summaries=children_summaries,
            dependencies=dependencies,
            import_details=import_details,
            EXAMPLE_1=prompts.EXAMPLE_1,
            EXAMPLE_2=prompts.EXAMPLE_2,
        ),
        "children_dependencies_noimport_details_noparent_pass1": lambda code, children_summaries, dependencies, import_details, parent_summary, pass_number, previous_summary: SummarizationPromptCreator._interpolate_prompt_string(
            prompts.CODE_SUMMARY_PROMPT_PASS_1,
            code=code,
            children_summaries=children_summaries,
            dependencies=dependencies,
            EXAMPLE_1=prompts.EXAMPLE_1,
            EXAMPLE_2=prompts.EXAMPLE_2,
        ),
        "children_nodependencies_import_details_noparent_pass1": lambda code, children_summaries, dependencies, import_details, parent_summary, pass_number, previous_summary: SummarizationPromptCreator._interpolate_prompt_string(
            prompts.CODE_SUMMARY_PROMPT_PASS_1,
            code=code,
            children_summaries=children_summaries,
            import_details=import_details,
            EXAMPLE_1=prompts.EXAMPLE_1,
            EXAMPLE_2=prompts.EXAMPLE_2,
        ),
        "children_nodependencies_noimport_details_noparent_pass1": lambda code, children_summaries, dependencies, import_details, parent_summary, pass_number, previous_summary: SummarizationPromptCreator._interpolate_prompt_string(
            prompts.CODE_SUMMARY_PROMPT_PASS_1,
            code=code,
            children_summaries=children_summaries,
            EXAMPLE_1=prompts.EXAMPLE_1,
            EXAMPLE_2=prompts.EXAMPLE_2,
        ),
        "nochildren_dependencies_import_details_noparent_pass1": lambda code, children_summaries, dependencies, import_details, parent_summary, pass_number, previous_summary: SummarizationPromptCreator._interpolate_prompt_string(
            prompts.CODE_SUMMARY_PROMPT_PASS_1,
            code=code,
            dependencies=dependencies,
            import_details=import_details,
            EXAMPLE_1=prompts.EXAMPLE_1,
            EXAMPLE_2=prompts.EXAMPLE_2,
        ),
        "nochildren_dependencies_noimport_details_noparent_pass1": lambda code, children_summaries, dependencies, import_details, parent_summary, pass_number, previous_summary: SummarizationPromptCreator._interpolate_prompt_string(
            prompts.CODE_SUMMARY_PROMPT_PASS_1,
            code=code,
            dependencies=dependencies,
            EXAMPLE_1=prompts.EXAMPLE_1,
            EXAMPLE_2=prompts.EXAMPLE_2,
        ),
        "nochildren_nodependencies_import_details_noparent_pass1": lambda code, children_summaries, dependencies, import_details, parent_summary, pass_number, previous_summary: SummarizationPromptCreator._interpolate_prompt_string(
            prompts.CODE_SUMMARY_PROMPT_PASS_1,
            code=code,
            import_details=import_details,
            EXAMPLE_1=prompts.EXAMPLE_1,
            EXAMPLE_2=prompts.EXAMPLE_2,
        ),
        "nochildren_nodependencies_noimport_details_noparent_pass1": lambda code, children_summaries, dependencies, import_details, parent_summary, pass_number, previous_summary: SummarizationPromptCreator._interpolate_prompt_string(
            prompts.CODE_SUMMARY_PROMPT_PASS_1,
            code=code,
            EXAMPLE_1=prompts.EXAMPLE_1,
            EXAMPLE_2=prompts.EXAMPLE_2,
        ),
        # Pass 2 strategies (updated to include previous_summary)
        "children_dependencies_import_details_parent_pass2": lambda code, children_summaries, dependencies, import_details, parent_summary, pass_number, previous_summary: SummarizationPromptCreator._interpolate_prompt_string(
            prompts.CODE_SUMMARY_PROMPT_PASS_2,
            code=code,
            children_summaries=children_summaries,
            dependencies=dependencies,
            import_details=import_details,
            parent_summary=parent_summary,
            previous_summary=previous_summary,
            EXAMPLE_1=prompts.EXAMPLE_1,
            EXAMPLE_2=prompts.EXAMPLE_2,
        ),
        "children_dependencies_noimport_details_parent_pass2": lambda code, children_summaries, dependencies, import_details, parent_summary, pass_number, previous_summary: SummarizationPromptCreator._interpolate_prompt_string(
            prompts.CODE_SUMMARY_PROMPT_PASS_2,
            code=code,
            children_summaries=children_summaries,
            dependencies=dependencies,
            parent_summary=parent_summary,
            previous_summary=previous_summary,
            EXAMPLE_1=prompts.EXAMPLE_1,
            EXAMPLE_2=prompts.EXAMPLE_2,
        ),
        "children_nodependencies_import_details_parent_pass2": lambda code, children_summaries, dependencies, import_details, parent_summary, pass_number, previous_summary: SummarizationPromptCreator._interpolate_prompt_string(
            prompts.CODE_SUMMARY_PROMPT_PASS_2,
            code=code,
            children_summaries=children_summaries,
            import_details=import_details,
            parent_summary=parent_summary,
            previous_summary=previous_summary,
            EXAMPLE_1=prompts.EXAMPLE_1,
            EXAMPLE_2=prompts.EXAMPLE_2,
        ),
        "children_nodependencies_noimport_details_parent_pass2": lambda code, children_summaries, dependencies, import_details, parent_summary, pass_number, previous_summary: SummarizationPromptCreator._interpolate_prompt_string(
            prompts.CODE_SUMMARY_PROMPT_PASS_2,
            code=code,
            children_summaries=children_summaries,
            parent_summary=parent_summary,
            previous_summary=previous_summary,
            EXAMPLE_1=prompts.EXAMPLE_1,
            EXAMPLE_2=prompts.EXAMPLE_2,
        ),
        "nochildren_dependencies_import_details_parent_pass2": lambda code, children_summaries, dependencies, import_details, parent_summary, pass_number, previous_summary: SummarizationPromptCreator._interpolate_prompt_string(
            prompts.CODE_SUMMARY_PROMPT_PASS_2,
            code=code,
            dependencies=dependencies,
            import_details=import_details,
            parent_summary=parent_summary,
            previous_summary=previous_summary,
            EXAMPLE_1=prompts.EXAMPLE_1,
            EXAMPLE_2=prompts.EXAMPLE_2,
        ),
        "nochildren_dependencies_noimport_details_parent_pass2": lambda code, children_summaries, dependencies, import_details, parent_summary, pass_number, previous_summary: SummarizationPromptCreator._interpolate_prompt_string(
            prompts.CODE_SUMMARY_PROMPT_PASS_2,
            code=code,
            dependencies=dependencies,
            parent_summary=parent_summary,
            previous_summary=previous_summary,
            EXAMPLE_1=prompts.EXAMPLE_1,
            EXAMPLE_2=prompts.EXAMPLE_2,
        ),
        "nochildren_nodependencies_import_details_parent_pass2": lambda code, children_summaries, dependencies, import_details, parent_summary, pass_number, previous_summary: SummarizationPromptCreator._interpolate_prompt_string(
            prompts.CODE_SUMMARY_PROMPT_PASS_2,
            code=code,
            import_details=import_details,
            parent_summary=parent_summary,
            previous_summary=previous_summary,
            EXAMPLE_1=prompts.EXAMPLE_1,
            EXAMPLE_2=prompts.EXAMPLE_2,
        ),
        "nochildren_nodependencies_noimport_details_parent_pass2": lambda code, children_summaries, dependencies, import_details, parent_summary, pass_number, previous_summary: SummarizationPromptCreator._interpolate_prompt_string(
            prompts.CODE_SUMMARY_PROMPT_PASS_2,
            code=code,
            parent_summary=parent_summary,
            previous_summary=previous_summary,
            EXAMPLE_1=prompts.EXAMPLE_1,
            EXAMPLE_2=prompts.EXAMPLE_2,
        ),
        "nochildren_nodependencies_noimport_details_noparent_pass2": lambda code, children_summaries, dependencies, import_details, parent_summary, pass_number, previous_summary: SummarizationPromptCreator._interpolate_prompt_string(
            prompts.CODE_SUMMARY_PROMPT_PASS_2,
            code=code,
            previous_summary=previous_summary,
            EXAMPLE_1=prompts.EXAMPLE_1,
            EXAMPLE_2=prompts.EXAMPLE_2,
        ),
        "children_dependencies_noimport_details_noparent_pass2": lambda code, children_summaries, dependencies, import_details, parent_summary, pass_number, previous_summary: SummarizationPromptCreator._interpolate_prompt_string(
            prompts.CODE_SUMMARY_PROMPT_PASS_2,
            code=code,
            children_summaries=children_summaries,
            dependencies=dependencies,
            previous_summary=previous_summary,
            EXAMPLE_1=prompts.EXAMPLE_1,
            EXAMPLE_2=prompts.EXAMPLE_2,
        ),
        "nochildren_dependencies_noimport_details_noparent_pass2": lambda code, children_summaries, dependencies, import_details, parent_summary, pass_number, previous_summary: SummarizationPromptCreator._interpolate_prompt_string(
            prompts.CODE_SUMMARY_PROMPT_PASS_2,
            code=code,
            dependencies=dependencies,
            previous_summary=previous_summary,
            EXAMPLE_1=prompts.EXAMPLE_1,
            EXAMPLE_2=prompts.EXAMPLE_2,
        ),
        "children_nodependencies_noimport_details_noparent_pass2": lambda code, children_summaries, dependencies, import_details, parent_summary, pass_number, previous_summary: SummarizationPromptCreator._interpolate_prompt_string(
            prompts.CODE_SUMMARY_PROMPT_PASS_2,
            code=code,
            children_summaries=children_summaries,
            previous_summary=previous_summary,
            EXAMPLE_1=prompts.EXAMPLE_1,
            EXAMPLE_2=prompts.EXAMPLE_2,
        ),
        # Pass 3 strategies (updated to include previous_summary)
        "children_dependencies_import_details_parent_pass3": lambda code, children_summaries, dependencies, import_details, parent_summary, pass_number, previous_summary: SummarizationPromptCreator._interpolate_prompt_string(
            prompts.CODE_SUMMARY_PROMPT_PASS_3,
            code=code,
            children_summaries=children_summaries,
            dependencies=dependencies,
            import_details=import_details,
            parent_summary=parent_summary,
            previous_summary=previous_summary,
            EXAMPLE_1=prompts.EXAMPLE_1,
            EXAMPLE_2=prompts.EXAMPLE_2,
        ),
        "children_dependencies_noimport_details_parent_pass3": lambda code, children_summaries, dependencies, import_details, parent_summary, pass_number, previous_summary: SummarizationPromptCreator._interpolate_prompt_string(
            prompts.CODE_SUMMARY_PROMPT_PASS_3,
            code=code,
            children_summaries=children_summaries,
            dependencies=dependencies,
            parent_summary=parent_summary,
            previous_summary=previous_summary,
            EXAMPLE_1=prompts.EXAMPLE_1,
            EXAMPLE_2=prompts.EXAMPLE_2,
        ),
        "children_nodependencies_import_details_parent_pass3": lambda code, children_summaries, dependencies, import_details, parent_summary, pass_number, previous_summary: SummarizationPromptCreator._interpolate_prompt_string(
            prompts.CODE_SUMMARY_PROMPT_PASS_3,
            code=code,
            children_summaries=children_summaries,
            import_details=import_details,
            parent_summary=parent_summary,
            previous_summary=previous_summary,
            EXAMPLE_1=prompts.EXAMPLE_1,
            EXAMPLE_2=prompts.EXAMPLE_2,
        ),
        "children_nodependencies_noimport_details_parent_pass3": lambda code, children_summaries, dependencies, import_details, parent_summary, pass_number, previous_summary: SummarizationPromptCreator._interpolate_prompt_string(
            prompts.CODE_SUMMARY_PROMPT_PASS_3,
            code=code,
            children_summaries=children_summaries,
            parent_summary=parent_summary,
            previous_summary=previous_summary,
            EXAMPLE_1=prompts.EXAMPLE_1,
            EXAMPLE_2=prompts.EXAMPLE_2,
        ),
        "children_dependencies_noimport_details_noparent_pass3": lambda code, children_summaries, dependencies, import_details, parent_summary, pass_number, previous_summary: SummarizationPromptCreator._interpolate_prompt_string(
            prompts.CODE_SUMMARY_PROMPT_PASS_3,
            code=code,
            children_summaries=children_summaries,
            dependencies=dependencies,
            previous_summary=previous_summary,
            EXAMPLE_1=prompts.EXAMPLE_1,
            EXAMPLE_2=prompts.EXAMPLE_2,
        ),
        "nochildren_dependencies_import_details_parent_pass3": lambda code, children_summaries, dependencies, import_details, parent_summary, pass_number, previous_summary: SummarizationPromptCreator._interpolate_prompt_string(
            prompts.CODE_SUMMARY_PROMPT_PASS_3,
            code=code,
            dependencies=dependencies,
            import_details=import_details,
            parent_summary=parent_summary,
            previous_summary=previous_summary,
            EXAMPLE_1=prompts.EXAMPLE_1,
            EXAMPLE_2=prompts.EXAMPLE_2,
        ),
        "nochildren_dependencies_noimport_details_parent_pass3": lambda code, children_summaries, dependencies, import_details, parent_summary, pass_number, previous_summary: SummarizationPromptCreator._interpolate_prompt_string(
            prompts.CODE_SUMMARY_PROMPT_PASS_3,
            code=code,
            dependencies=dependencies,
            parent_summary=parent_summary,
            previous_summary=previous_summary,
            EXAMPLE_1=prompts.EXAMPLE_1,
            EXAMPLE_2=prompts.EXAMPLE_2,
        ),
        "nochildren_dependencies_noimport_details_noparent_pass3": lambda code, children_summaries, dependencies, import_details, parent_summary, pass_number, previous_summary: SummarizationPromptCreator._interpolate_prompt_string(
            prompts.CODE_SUMMARY_PROMPT_PASS_3,
            code=code,
            dependencies=dependencies,
            previous_summary=previous_summary,
            EXAMPLE_1=prompts.EXAMPLE_1,
            EXAMPLE_2=prompts.EXAMPLE_2,
        ),
        "nochildren_nodependencies_import_details_parent_pass3": lambda code, children_summaries, dependencies, import_details, parent_summary, pass_number, previous_summary: SummarizationPromptCreator._interpolate_prompt_string(
            prompts.CODE_SUMMARY_PROMPT_PASS_3,
            code=code,
            import_details=import_details,
            parent_summary=parent_summary,
            previous_summary=previous_summary,
            EXAMPLE_1=prompts.EXAMPLE_1,
            EXAMPLE_2=prompts.EXAMPLE_2,
        ),
        "nochildren_nodependencies_noimport_details_parent_pass3": lambda code, children_summaries, dependencies, import_details, parent_summary, pass_number, previous_summary: SummarizationPromptCreator._interpolate_prompt_string(
            prompts.CODE_SUMMARY_PROMPT_PASS_3,
            code=code,
            parent_summary=parent_summary,
            previous_summary=previous_summary,
            EXAMPLE_1=prompts.EXAMPLE_1,
            EXAMPLE_2=prompts.EXAMPLE_2,
        ),
        "nochildren_nodependencies_noimport_details_noparent_pass3": lambda code, children_summaries, dependencies, import_details, parent_summary, pass_number, previous_summary: SummarizationPromptCreator._interpolate_prompt_string(
            prompts.CODE_SUMMARY_PROMPT_PASS_3,
            code=code,
            previous_summary=previous_summary,
            EXAMPLE_1=prompts.EXAMPLE_1,
            EXAMPLE_2=prompts.EXAMPLE_2,
        ),
        "children_nodependencies_noimport_details_noparent_pass2": lambda code, children_summaries, dependencies, import_details, parent_summary, pass_number, previous_summary: SummarizationPromptCreator._interpolate_prompt_string(
            prompts.CODE_SUMMARY_PROMPT_PASS_2,
            code=code,
            children_summaries=children_summaries,
            previous_summary=previous_summary,
            EXAMPLE_1=prompts.EXAMPLE_1,
            EXAMPLE_2=prompts.EXAMPLE_2,
        ),
    }

    @staticmethod
    def _interpolate_prompt_string(prompt_template: str, **kwargs) -> str:
        """
        Returns a prompt string with the provided values interpolated into the template
        and all traces of unused placeholders removed.

        Args:
            - `prompt_template` (str): The template string to interpolate.
            - `**kwargs`: Keyword arguments containing the values to interpolate.

        Returns:
            - `str`: The interpolated prompt string with all traces of unused placeholders removed.
        """

        prompt_string: str = prompt_template

        # First, replace all provided values
        for key, value in kwargs.items():
            if value is not None:
                placeholder: str = f"{{{key}}}"
                prompt_string = prompt_string.replace(placeholder, str(value))

        # Remove lines containing unused placeholders and their associated labels
        lines: list[str] = prompt_string.split("\n")
        cleaned_lines: list[str] = []
        skip_next = False
        for i, line in enumerate(lines):
            if skip_next:
                skip_next = False
                continue

            # Check if the line or the next line contains an unused placeholder
            current_line_has_placeholder = re.search(r"\{[^}]+\}", line)
            next_line_has_placeholder = i + 1 < len(lines) and re.search(
                r"\{[^}]+\}", lines[i + 1]
            )

            if current_line_has_placeholder or next_line_has_placeholder:
                # If this line is a label and the next line is an unused placeholder, skip both
                if not current_line_has_placeholder and next_line_has_placeholder:
                    skip_next = True
                continue

            # Keep lines without unused placeholders
            cleaned_lines.append(line)

        cleaned_prompt: str = "\n".join(cleaned_lines)
        cleaned_prompt = re.sub(r"\n\s*\n", "\n\n", cleaned_prompt).strip()
        # print(
        #     f"\n\n[u][blue]Prompt:[/blue][/u]\n\n{cleaned_prompt}\n\n[u][magenta]End Prompt[/magenta][/u]\n\n"
        # )

        return cleaned_prompt

    @staticmethod
    def create_prompt(
        code: str,
        children_summaries: str | None = None,
        dependency_summaries: str | None = None,
        import_details: str | None = None,
        parent_summary: str | None = None,
        pass_number: int = 1,
        previous_summary: str | None = None,
    ) -> str | None:
        """
        Dynamically creates a prompt for the summarizer based on the provided arguments, supporting multi-pass summarization.

        Args:
            - `code` (str): The code snippet to summarize.
            - `children_summaries` (str, optional): The summaries of the children of the code snippet.
            - `dependency_summaries` (str, optional): The summaries of the dependencies of the code snippet.
            - `import_details` (str, optional): The import details of the code snippet.
            - `parent_summary` (str, optional): The summary of the parent code block (for multi-pass summarization).
            - `pass_number` (int, optional): The current pass number in multi-pass summarization. Default is 1.
            - `previous_summary` (str, optional): The summary from the previous pass in multi-pass summarization.

        Returns:
            - `str`: The prompt for the summarizer.

        Raises:
            - `ValueError`: If no strategy is found for the given combination of arguments.

        Examples:
            ```Python
            # Create a prompt for single-pass summarization
            prompt: str | None = SummarizationPromptCreator.create_prompt(
                code,
                children_summaries,
                dependency_summaries,
                import_details,
            )

            # Create a prompt for multi-pass summarization (e.g., second pass)
            prompt: str | None = SummarizationPromptCreator.create_prompt(
                code,
                children_summaries,
                dependency_summaries,
                import_details,
                parent_summary,
                pass_number=2,
                previous_summary="Previous summary of the code."
            )
            ```
        """

        strategy_key: str = "_".join(
            [
                "children" if children_summaries else "nochildren",
                "dependencies" if dependency_summaries else "nodependencies",
                "import_details" if import_details else "noimport_details",
                "parent" if parent_summary else "noparent",
                f"pass{pass_number}",
            ]
        )
        strategy: Callable[..., str] | None = (
            SummarizationPromptCreator._interpolation_strategies.get(strategy_key)
        )
        if not strategy:
            raise ValueError(f"Could not find strategy for {strategy_key}")
        else:
            # logging.info(f"Using strategy: {strategy_key}")
            # print(
            #     f"With children_summaries: {children_summaries}\n dependency_summaries: {dependency_summaries}\n "
            #     f"import_details: {import_details}\n parent_summary: {parent_summary}\n pass_number: {pass_number}\n "
            #     f"previous_summary: {previous_summary}"
            # )
            return strategy(
                code,
                children_summaries,
                dependency_summaries,
                import_details,
                parent_summary,
                pass_number,
                previous_summary,
            )



File: postcode/ai_services/summarizer/prompts/summarization_prompts.py
----------------------------------------
EXAMPLE_1 = """
This implements a data processing pipeline for analyzing genomic sequencing data. Its purpose is to process raw sequencing reads, align them to a reference genome, and perform analyses like variant calling and gene expression quantification. Key components include: SequenceReader for parsing sequencing files; AlignmentEngine using the Burrows-Wheeler Aligner; VariantCaller for identifying genomic variants; and ExpressionQuantifier for calculating gene expression levels.
The implementation uses parallel processing with a producer-consumer pattern and thread pool. It employs a suffix array for fast alignment and a hidden Markov model for variant calling. The pipeline features robust error handling with a custom PipelineException class.
The technical stack includes BioPython, NumPy, SciPy, Pandas, and Dask. It integrates with SAMtools and BEDTools for specific genomic operations.
In the context of a bioinformatics platform, this pipeline processes raw data into actionable insights. It interfaces with data acquisition systems, LIMS, and visualization tools. Its modular design supports various sequencing technologies and experimental designs.
"""

EXAMPLE_2 = """
This code creates a flexible reinforcement learning (RL) framework for training and evaluating agents in various environments. It provides a unified interface for RL algorithms, environments, and neural networks. Key components include: Agent base class; Environment class; ReplayBuffer for experience replay; PolicyNetwork and ValueNetwork for function approximation; and Trainer for orchestrating training.
The implementation uses a modular design, supporting both on-policy (e.g., PPO) and off-policy (e.g., SAC) methods. It implements importance sampling and Generalized Advantage Estimation. A custom TensorBoard logger visualizes training progress.
The technical stack comprises PyTorch, NumPy, Gym, Ray, and MLflow. It integrates with simulators like Mujoco and Bullet for robotics simulations.
In AI research and development, this framework serves as a tool for exploring RL algorithms. It interfaces with HPC clusters, databases, and provides APIs for integration with higher-level AI systems. Its modular architecture supports collaborative research and a wide range of applications from game-playing to autonomous vehicles.
"""

CODE_SUMMARY_PROMPT_PASS_1 = """
You are an expert code analyst tasked with summarizing Python code. Your goal is to create a comprehensive and informative summary that captures the essence of the code's functionality, structure, and purpose. This summary will be used in a vector search system, so it needs to be semantically rich and consistently structured.

Provide your summary with the following information but written in paragraph form:

1. Purpose: [Comprehensive description of the code's main goal, functionality, and significance]
2. Key Components: [Main functions, classes, or modules with refined descriptions, separated by semicolons]
3. Implementation: [Detailed explanation of how the code works, including notable algorithms, data structures, and design patterns]
4. Technical Stack: [Comprehensive list of libraries, frameworks, or technologies used, with brief explanations of their roles, separated by commas]
5. Context: [How this code fits into the larger project or system, including its interactions with other components]

Ensure the summary is very detailed and technical.

Evaluation Criteria:
- Accuracy: The summary correctly represents the code's functionality.
- Conciseness: Information is presented clearly and efficiently within the given length constraints.
- Semantic Richness: Use of relevant technical terms and concepts that would be valuable in a vector search.
- Consistency: Adherence to the specified structure for easy parsing and embedding.

Examples:
Here are two high-quality examples of code summaries following the specified format:

Example 1:
{EXAMPLE_1}

Example 2:
{EXAMPLE_2}

Process:
1. Analyze the overall structure and purpose of the code.
2. Identify key functions, classes, and their relationships.
3. Understand the main algorithms or processes implemented.
4. Recognize the technical stack and any unique features of the implementation.
5. Consider how this code relates to its dependencies or the larger system.
6. Synthesize this information into a cohesive summary following the output format and drawing inspiration from the provided examples.

Now, please summarize the following code:

```python
{code}
```

Additional Context:
Children Summaries: {children_summaries}
Dependency's Summaries: {dependency_summaries}
Imports: {import_details}

Remember to follow the specified output format and evaluation criteria in your summary, optimizing for vector search retrieval. Use the provided examples as a guide for the level of detail and style expected in your summary.
"""

CODE_SUMMARY_PROMPT_PASS_2 = """
You are an expert code analyst performing the second pass of a multi-pass code summarization task. Your goal is to build upon the first-pass summary and provide more detailed information about the implementation and technical stack and how this code fits into the larger project or system. This summary will be used in a vector search system and as input for the final pass.

Provide your summary with the following information but written in paragraph form:

1. Purpose: [Comprehensive description of the code's main goal, functionality, and significance]
2. Key Components: [Main functions, classes, or modules with refined descriptions, separated by semicolons]
3. Implementation: [Detailed explanation of how the code works, including notable algorithms, data structures, and design patterns]
4. Technical Stack: [Comprehensive list of libraries, frameworks, or technologies used, with brief explanations of their roles, separated by commas]
5. Context: [How this code fits into the larger project or system, including its interactions with other components]

Ensure the summary is very detailed and technical.

Evaluation Criteria:
- Accuracy: The summary correctly represents the code's functionality and implementation details.
- Conciseness: Information is presented clearly and efficiently within the given length constraints.
- Semantic Richness: Use of relevant technical terms and concepts that would be valuable in a vector search.
- Consistency: Adherence to the specified structure for easy parsing and embedding.

EXAMPLE 1:
{EXAMPLE_1}

EXAMPLE 2:
{EXAMPLE_2}

Previous Summary:
{previous_summary}

Now, please provide a second-pass summary of the following code, building upon the first-pass summary:

```python
{code}
```

Additional Context:
Summary of parents or codeblocks that depend on this one: {parent_summary}
Imports: {import_details}
Dependencies: {dependency_summaries}

Focus on providing more detailed information about the implementation and technical stack and how the code fits in with the larger codebase; refining, expanding, and updating the first-pass summary given the additional context and higher level view of how this code fits into the grander scheme.
"""

CODE_SUMMARY_PROMPT_PASS_3 = """
You are an expert code analyst performing the final pass of a multi-pass code summarization task. Your goal is to refine and contextualize the previous summary, providing a comprehensive overview of the code that includes its role in the larger system. This final summary will be used in a vector search system.

Provide your summary with the following information but written in paragraph form:

1. Purpose: [Comprehensive description of the code's main goal, functionality, and significance]
2. Key Components: [Main functions, classes, or modules with refined descriptions, separated by semicolons]
3. Implementation: [Detailed explanation of how the code works, including notable algorithms, data structures, and design patterns]
4. Technical Stack: [Comprehensive list of libraries, frameworks, or technologies used, with brief explanations of their roles, separated by commas]
5. Context: [How this code fits into the larger project or system, including its interactions with other components]

Ensure the summary is very detailed and technical.

Evaluation Criteria:
- Accuracy: The summary correctly represents the code's functionality, implementation details, and context.
- Conciseness: Information is presented clearly and efficiently within the given length constraints.
- Semantic Richness: Use of relevant technical terms and concepts that would be valuable in a vector search.
- Consistency: Adherence to the specified structure for easy parsing and embedding.
- Contextual Relevance: Clear explanation of the code's role in the larger system.

EXAMPLE 1:
{EXAMPLE_1}

EXAMPLE 2:
{EXAMPLE_2}

Previous Summary:
{previous_summary}


Now, please provide a final, comprehensive summary of the following code, building upon the previous summary and the context provided:

```python
{code}
```

Additional Context:
Children Summaries: {children_summaries}
Dependencies: {dependency_summaries}
Imports: {import_details}

Focus on refining, expanding, and updating the previous summary, adding context about the code's role in the larger system, and ensuring a comprehensive final summary.
"""


SUMMARIZER_DEFAULT_INSTRUCTIONS = """You are a code summarizer. Your task is to analyze the code provided and create a concise summary of the
given code based on the prompt provided. Your summary should be technical yet understandable, providing a clear picture of the code's purpose, main
features, and key components.
"""

SUMMARIZER_DEFAULT_DESCRIPTION = """Summarizes Python code."""

summary_prompt_list: list[str] = [
    EXAMPLE_1,
    EXAMPLE_2,
    CODE_SUMMARY_PROMPT_PASS_1,
    CODE_SUMMARY_PROMPT_PASS_2,
    CODE_SUMMARY_PROMPT_PASS_3,
]



File: postcode/ai_services/summarizer/openai_summarizer.py
----------------------------------------
import logging

from openai import OpenAI
from openai.types.chat.chat_completion_system_message_param import (
    ChatCompletionSystemMessageParam,
)
from openai.types.chat.chat_completion_user_message_param import (
    ChatCompletionUserMessageParam,
)
from openai.types.chat.chat_completion_message_param import ChatCompletionMessageParam
from openai.types.chat.chat_completion import ChatCompletion

from postcode.ai_services.summarizer.prompts.prompt_creator import (
    SummarizationPromptCreator,
)
from postcode.ai_services.openai_configs import (
    OpenAIConfigs,
    OpenAIReturnContext,
)


class OpenAISummarizer:
    """
    A class for summarizing code snippets using the OpenAI API.

    This class provides functionality to generate summaries of code snippets using OpenAI's language models.
    It supports multi-pass summarization, allowing for more comprehensive and context-aware summaries.

    Args:
        - `configs` (OpenAIConfigs, optional): Configuration settings for the OpenAI summarizer.

    Attributes:
        - client (OpenAI): The OpenAI client instance.
        - configs (OpenAIConfigs): Configuration settings for the summarizer.

    Methods:
        - summarize_code: Summarizes the provided code snippet using the OpenAI API.
        - test_summarize_code: A method for testing the summarization functionality.

    Example:
        ```Python
        summarizer = OpenAISummarizer()
        summary = summarizer.summarize_code(
            code="def hello_world():\n    print('Hello, world!')",
            model_id="function_1",
            children_summaries="No child functions.",
            dependency_summaries="No dependencies.",
            import_details="No imports.",
            parent_summary="Module containing greeting functions.",
            pass_number=1
        )
        print(summary.summary if summary else "Summarization failed")
        ```
    """

    def __init__(
        self,
        configs: OpenAIConfigs = OpenAIConfigs(),
    ) -> None:
        self.client: OpenAI = OpenAI()
        self.configs: OpenAIConfigs = configs

    def _create_system_message(self, content: str) -> ChatCompletionSystemMessageParam:
        """Creates a system message for chat completion using OpenAi's ChatCompletionSystemMessageParam class."""
        return ChatCompletionSystemMessageParam(content=content, role="system")

    def _create_user_message(self, content: str) -> ChatCompletionUserMessageParam:
        """Creates a user message for chat completion using OpenAi's ChatCompletionUserMessageParam class."""
        return ChatCompletionUserMessageParam(content=content, role="user")

    def _create_messages_list(
        self,
        system_message: str,
        user_message: str,
    ) -> list[ChatCompletionMessageParam]:
        """
        Creates a list of messages for chat completion, including both system and user messages.

        Args:
            - system_message (str): The system message content.
            - user_message (str): The user message content.

        Returns:
            - list[ChatCompletionMessageParam]: A list containing the system and user messages as OpenAI's
                ChatCompletionMessageParam classes.
        """

        return [
            self._create_system_message(system_message),
            self._create_user_message(user_message),
        ]

    def _create_prompt(
        self,
        code: str,
        children_summaries: str | None,
        dependency_summaries: str | None,
        import_details: str | None,
        parent_summary: str | None,
        pass_number: int,
        previous_summary: str | None,
    ) -> str:
        """
        Creates a prompt for code summarization.

        Args:
            - code (str): The code to summarize.
            - children_summaries (str | None): Summaries of child elements.
            - dependency_summaries (str | None): Summaries of dependencies.
            - import_details (str | None): Details of imports.
            - parent_summary (str | None): Summary of the parent element.
            - pass_number (int): The current pass number in multi-pass summarization.
            - previous_summary (str | None): The summary from the previous pass.

        Returns:
            - str: The created prompt.

        Raises:
            - Exception: If prompt creation fails.
        """
        prompt_creator: SummarizationPromptCreator = SummarizationPromptCreator()
        prompt: str | None = prompt_creator.create_prompt(
            code,
            children_summaries,
            dependency_summaries,
            import_details,
            parent_summary,
            pass_number,
            previous_summary,
        )

        if prompt:
            return prompt
        else:
            raise Exception("Prompt creation failed.")

    def _get_summary(
        self,
        messages: list[ChatCompletionMessageParam],
    ) -> OpenAIReturnContext | None:
        """
        Retrieves the summary from the OpenAI API based on the provided messages and configuration settings.

        Args:
            - messages (list[ChatCompletionMessageParam]): A list of messages for chat completion.

        Returns:
            OpenAIReturnContext | None: The summary generated by the OpenAI API, or None if no summary is found.
        """

        try:
            response: ChatCompletion = self.client.chat.completions.create(
                messages=messages,
                model=self.configs.model,
                max_tokens=self.configs.max_tokens,
                temperature=self.configs.temperature,
            )
            prompt_tokens: int = 0
            completion_tokens: int = 0
            summary: str | None = response.choices[0].message.content
            if response.usage:
                prompt_tokens = response.usage.prompt_tokens
                completion_tokens = response.usage.completion_tokens

            return OpenAIReturnContext(
                prompt_tokens=prompt_tokens,
                completion_tokens=completion_tokens,
                summary=summary,
            )

        except Exception as e:
            logging.error(e)
            return None

    def summarize_code(
        self,
        code: str,
        *,
        model_id: str,
        children_summaries: str | None,
        dependency_summaries: str | None,
        import_details: str | None,
        parent_summary: str | None = None,
        pass_number: int = 1,
        previous_summary: str | None = None,
    ) -> OpenAIReturnContext | None:
        """
        Summarizes the provided code snippet using the OpenAI API.

        This method generates a summary of the given code, taking into account various contextual
        information such as children summaries, dependencies, imports, and parent summaries.
        It supports multi-pass summarization, allowing for refinement of summaries over multiple passes.

        Args:
            - code (str): The code snippet to summarize.
            - model_id (str): The identifier of the model being summarized.
            - children_summaries (str | None): Summaries of child elements, if any.
            - dependency_summaries (str | None): Summaries of dependencies, if any.
            - import_details (str | None): Details of imports used in the code.
            - parent_summary (str | None): Summary of the parent element, if applicable.
            - pass_number (int): The current pass number in multi-pass summarization. Default is 1.

        Returns:
            - OpenAIReturnContext | None: A context object containing the summary and token usage information,
                                          or None if summarization fails.

        Example:
            ```Python
            summarizer = OpenAISummarizer()
            summary_context = summarizer.summarize_code(
                code="def greet(name):\n    return f'Hello, {name}!'",
                model_id="function_greet",
                children_summaries=None,
                dependency_summaries=None,
                import_details=None,
                parent_summary="Module with greeting functions",
                pass_number=2
            )
            if summary_context:
                print(f"Summary: {summary_context.summary}")
                print(f"Tokens used: {summary_context.prompt_tokens + summary_context.completion_tokens}")
            ```
        """

        logging.info(
            f"([blue]Pass {pass_number}[/blue]) - [green]Summarizing code for model:[/green] {model_id}"
        )
        prompt: str = self._create_prompt(
            code,
            children_summaries,
            dependency_summaries,
            import_details,
            parent_summary,
            pass_number,
            previous_summary,
        )
        messages: list[ChatCompletionMessageParam] = self._create_messages_list(
            system_message=self.configs.system_message, user_message=prompt
        )

        if summary_return_context := self._get_summary(messages):
            if summary_return_context.summary:
                summary_return_context.summary = summary_return_context.summary.split(
                    "FINAL SUMMARY:"
                )[-1].strip()
                return summary_return_context
        return None

    def test_summarize_code(
        self,
        code: str,
        *,
        model_id: str,
        children_summaries: str | None,
        dependency_summaries: str | None,
        import_details: str | None,
        parent_summary: str | None = None,
        pass_number: int = 1,
    ) -> OpenAIReturnContext | None:
        """
        A method for testing the summarize_code functionality without making API calls.

        This method mimics the behavior of summarize_code but returns a predefined summary instead of
        making an actual API call. It's useful for testing the summarization pipeline without incurring
        API costs or when you want to test the surrounding logic.

        Args:
            - code (str): The code snippet to summarize (not used in the test method).
            - model_id (str): The identifier of the model being summarized.
            - children_summaries (str | None): Summaries of child elements, if any.
            - dependency_summaries (str | None): Summaries of dependencies, if any.
            - import_details (str | None): Details of imports used in the code.
            - parent_summary (str | None): Summary of the parent element, if applicable.
            - pass_number (int): The current pass number in multi-pass summarization. Default is 1.

        Returns:
            - OpenAIReturnContext | None: A context object containing a test summary and token usage information.

        Example:
            ```Python
            summarizer = OpenAISummarizer()
            test_summary = summarizer.test_summarize_code(
                code="print('Hello, World!')",
                model_id="test_function",
                children_summaries=None,
                dependency_summaries=None,
                import_details=None,
                parent_summary="Test Module",
                pass_number=1
            )
            print(test_summary.summary if test_summary else "Test summarization failed")
            ```
        """

        summary = f"""\nTest Summary for {model_id}:\n
        Pass Number: {pass_number}
        Parent Summary: {parent_summary}
        Children Summaries: {children_summaries}
        Dependency Summaries: {dependency_summaries}
        Import Details: {import_details}
        """
        summary_context = OpenAIReturnContext(
            summary=summary,
            prompt_tokens=1,
            completion_tokens=1,
        )

        return summary_context



File: postcode/tests/ai_services/__init__.py
----------------------------------------



File: postcode/tests/ai_services/librarians/test_chroma_librarians.py
----------------------------------------
# TODO: Complete tests for ChromaLibrarian

import json
from typing import Any, Generator
import pytest
from unittest.mock import patch, MagicMock

from postcode.ai_services.librarians.chroma_librarians import ChromaLibrarian
from postcode.databases.chroma.chromadb_collection_manager import (
    ChromaCollectionManager,
)

import postcode.types.chroma as chroma_types


@pytest.fixture
def mock_openai_client() -> Generator[MagicMock, Any, None]:
    with patch("openai.OpenAI") as mock_openai:
        yield mock_openai()


@pytest.fixture
def mock_chroma_collection_manager() -> Generator[MagicMock, Any, None]:
    with patch(
        "postcode.databases.chroma.chromadb_collection_manager.ChromaCollectionManager"
    ) as mock_manager:
        yield mock_manager()


def test_query_chroma(
    mock_chroma_collection_manager: MagicMock, mock_openai_client: MagicMock
) -> None:
    librarian = ChromaLibrarian(mock_chroma_collection_manager)

    mock_openai_client.chat.completions.create.return_value = MagicMock(
        choices=[
            MagicMock(
                message=MagicMock(
                    content=json.dumps({"query_list": ["query1", "query2", "query3"]})
                )
            )
        ]
    )

    mock_chroma_collection_manager.query_collection.return_value = MagicMock()

    result: chroma_types.QueryResult | None = librarian.query_chroma("user_question")

    assert result is not None
    assert mock_chroma_collection_manager.query_collection.called



File: postcode/tests/ai_services/librarians/__init__.py
----------------------------------------



File: postcode/tests/__init__.py
----------------------------------------



File: postcode/__init__.py
----------------------------------------
from postcode.databases.chroma.chromadb_collection_manager import (
    ChromaCollectionManager,
)
from postcode.api import Postcode
from postcode.updaters.graph_db_updater import GraphDBUpdater
from postcode.databases.arangodb.arangodb_connector import ArangoDBConnector
from postcode.ai_services.summarizer.openai_summarizer import OpenAISummarizer
from postcode.ai_services.openai_configs import (
    ChatCompletionConfigs,
    SummaryCompletionConfigs,
)



File: postcode/python_parser/visitors/base_code_block_visitor.py
----------------------------------------
from typing import Union
import libcst
from libcst.metadata import (
    WhitespaceInclusivePositionProvider,
    CodeRange,
)
from libcst._metadata_dependent import _UNDEFINED_DEFAULT
from postcode.python_parser.model_builders.class_model_builder import ClassModelBuilder
from postcode.python_parser.model_builders.function_model_builder import (
    FunctionModelBuilder,
)
from postcode.python_parser.model_builders.module_model_builder import (
    ModuleModelBuilder,
)
from postcode.python_parser.model_builders.standalone_block_model_builder import (
    StandaloneBlockModelBuilder,
)

# from postcode.types.postcode import BuilderType
from postcode.models.models import CommentModel
import postcode.python_parser.visitors.node_processing.common_functions as common_functions
from postcode.utilities.processing_context import PositionData


BuilderType = Union[
    ModuleModelBuilder,
    ClassModelBuilder,
    FunctionModelBuilder,
    StandaloneBlockModelBuilder,
]


class BaseVisitor(libcst.CSTVisitor):
    """
    Base visitor class for traversing and processing nodes in a CST (Concrete Syntax Tree).

    This abstract class provides the foundational functionality for processing various nodes in a CST, using the libcst library. It is designed to be extended by more specific visitor classes like ModuleVisitor.

    Attributes:
        id (str): An identifier for the visitor instance.
        builder_stack (list[BuilderType]): A stack of model builders for handling different CST nodes.

    METADATA_DEPENDENCIES (tuple): Metadata dependencies required for processing the CST nodes.
    """

    METADATA_DEPENDENCIES: tuple[type[WhitespaceInclusivePositionProvider]] = (
        WhitespaceInclusivePositionProvider,
    )

    def __init__(self, id: str) -> None:
        self.id: str = id
        self.builder_stack: list[BuilderType] = []

    def visit_Comment(self, node: libcst.Comment) -> None:
        """
        Visits a Comment node in the CST.

        Extracts important comments from the node and adds them to the current builder in the stack.
        """

        parent_builder = self.builder_stack[-1]
        content: CommentModel | None = common_functions.extract_important_comment(node)
        if content:
            parent_builder.add_important_comment(content)

    def get_node_position_data(
        self,
        node: libcst.CSTNode,
    ) -> PositionData:
        """
        Retrieves position data for a given CST node.

        Extracts the start and end line numbers of the node in the source code.

        Args:
            node (libcst.CSTNode): The CST node to get position data for.

        Returns:
            PositionData: An object containing start and end line numbers of the node.
        """

        position_data: CodeRange | type[_UNDEFINED_DEFAULT] = self.get_metadata(
            WhitespaceInclusivePositionProvider, node
        )

        start, end = 0, 0
        if isinstance(position_data, CodeRange):
            start: int = position_data.start.line
            end: int = position_data.end.line
        return PositionData(start=start, end=end)



File: postcode/python_parser/visitors/node_processing/gather_dependencies.py
----------------------------------------
import re
from typing import Callable, Sequence

from postcode.python_parser.model_builders.class_model_builder import ClassModelBuilder
from postcode.python_parser.model_builders.function_model_builder import (
    FunctionModelBuilder,
)
from postcode.python_parser.model_builders.module_model_builder import (
    ModuleModelBuilder,
)
from postcode.python_parser.model_builders.standalone_block_model_builder import (
    StandaloneBlockModelBuilder,
)
from postcode.models.models import ImportModel, DependencyModel


def gather_and_set_children_dependencies(module_builder: ModuleModelBuilder) -> None:
    """
    Gathers and sets dependencies for each child code block in the module.

    This function iterates over each child builder of the module builder, gathers import and non-import dependencies,
    and sets these dependencies for each block.

    Args:
        - module_builder (ModuleModelBuilder): A builder object representing the entire module.

    Example:
        ```Python
        module_builder = ModuleModelBuilder(...)  # initialize with necessary parameters
        gather_and_set_children_dependencies(module_builder)
        # After execution, each child block builder of the module_builder will have its dependencies set.
        ```
    """

    for block_builder in module_builder.child_builders:
        block_dependencies: list[ImportModel | DependencyModel] = []
        code_content: str = block_builder.common_attributes.code_content

        import_dependencies: list[ImportModel] = _gather_import_dependencies(
            module_builder.module_attributes.imports, code_content
        )
        block_dependencies.extend(import_dependencies)

        non_import_dependencies: list[
            DependencyModel
        ] = _gather_non_import_dependencies(
            module_builder.child_builders,
            block_builder,
            code_content,
            _create_module_dependency_model,
        )
        block_dependencies.extend(non_import_dependencies)

        block_builder.set_dependencies(block_dependencies)


def _gather_import_dependencies(
    imports: list[ImportModel] | None, code_content: str
) -> list[ImportModel]:
    """
    Gathers import dependencies from the provided code content.

    This function checks for the presence of import names (and their aliases) in the given code content
    and returns a list of import models that are dependencies for the code block.

    Args:
        - imports (list[ImportModel] | None): A list of import models to check against the code content.
        - code_content (str): The string content of the code block being analyzed.

    Returns:
        - list[ImportModel]: A list of import models that the code content depends on.
    """

    block_dependencies: list[ImportModel] = []

    if imports:
        for import_model in imports:
            for import_name_model in import_model.import_names:
                if import_name_model.as_name:
                    if import_name_model.as_name in code_content:
                        block_dependencies.append(import_model)

                if import_name_model.name in code_content:
                    block_dependencies.append(import_model)

    return block_dependencies


def _get_standalone_block_dependency(
    builder: StandaloneBlockModelBuilder,
    code_content: str,
    dependency_creator: Callable[[str], DependencyModel],
) -> DependencyModel | None:
    """
    Identifies if the given standalone block is a dependency based on variable usage.

    This function checks if any of the variable assignments in the standalone block are used in the given code content.
    If so, it returns the ID of the standalone block builder.

    Args:
        - builder (StandaloneBlockModelBuilder): The standalone block builder to check for dependencies.
        - code_content (str): The code content to analyze for variable usage.
        - dependency_creator (Callable[[str], DependencyModel]): A callable function to create a DependencyModel.

    Returns:
        - DependencyModel | None: The ID of the standalone block builder if a dependency is found, otherwise None.
    """

    variables: list[
        str
    ] | None = builder.standalone_block_attributes.variable_assignments
    if variables:
        for variable in variables:
            if re.search(rf"\b{variable}\b\s*=", code_content) is None and re.search(
                rf"\b{variable}\b", code_content
            ):
                return dependency_creator(builder.id)


def _gather_standalone_block_dependency_for_standalone_block(
    builder: StandaloneBlockModelBuilder,
    code_content: str,
    dependency_creator: Callable[[str], DependencyModel],
) -> DependencyModel | None:
    """
    Determines if a given standalone block is a dependency for another standalone block.

    This function checks if any of the variable assignments in the provided standalone block
    are present in the given code content of another standalone block.

    Args:
        - builder (StandaloneBlockModelBuilder): The standalone block builder to check for dependencies.
        - code_content (str): The code content of another standalone block to analyze.

    Returns:
        - DependencyModel | None: The ID of the standalone block builder if a dependency is found, otherwise None.
    """

    variables: list[
        str
    ] | None = builder.standalone_block_attributes.variable_assignments
    if variables:
        for variable in variables:
            if variable in code_content:
                return dependency_creator(builder.id)


def _not_same_builder(
    builder: ClassModelBuilder | FunctionModelBuilder | StandaloneBlockModelBuilder,
    block_builder: ClassModelBuilder
    | FunctionModelBuilder
    | StandaloneBlockModelBuilder,
) -> bool:
    """
    Checks if the given builders are not the same, returning boolean.

    Args:
        - builder (ClassModelBuilder | FunctionModelBuilder | StandaloneBlockModelBuilder): The first builder to compare.
        - block_builder (ClassModelBuilder | FunctionModelBuilder | StandaloneBlockModelBuilder): The second builder to compare.

    Returns:
        - bool: True if the builders are not the same, False otherwise.
    """

    return builder != block_builder


def _gather_non_import_dependencies(
    children_builders: Sequence[
        ClassModelBuilder | FunctionModelBuilder | StandaloneBlockModelBuilder
    ],
    block_builder: ClassModelBuilder
    | FunctionModelBuilder
    | StandaloneBlockModelBuilder,
    code_content: str,
    dependency_creator: Callable[[str], DependencyModel],
) -> list[DependencyModel]:
    """
    Gather non-import dependencies from the given `children_builders` and `block_builder`
    based on the provided `code_content`.

    Args:
        - children_builders (Sequence): List of builders representing child nodes.
        - block_builder: Builder representing the current block.
        - code_content (str): Content of the code.
        - dependency_creator (Callable[[str], DependencyModel]): A callable function to create a DependencyModel.

    Returns:
        - list[DependencyModel]: List of dependencies.
    """

    block_dependencies: list[DependencyModel] = []
    for builder in children_builders:
        if _not_same_builder(builder, block_builder):
            if isinstance(builder, ClassModelBuilder):
                if builder.class_attributes.class_name in code_content:
                    module_dependency = dependency_creator(builder.id)
                    block_dependencies.append(module_dependency)

            elif isinstance(builder, FunctionModelBuilder):
                if builder.function_attributes.function_name in code_content:
                    module_dependency = dependency_creator(builder.id)
                    block_dependencies.append(module_dependency)

            elif isinstance(builder, StandaloneBlockModelBuilder) and isinstance(
                block_builder, StandaloneBlockModelBuilder
            ):
                module_dependency: DependencyModel | None = (
                    _gather_standalone_block_dependency_for_standalone_block(
                        builder, code_content, dependency_creator
                    )
                )
                if module_dependency:
                    block_dependencies.append(module_dependency)

            # TODO: Improve logic to find variable dependencies
            elif isinstance(builder, StandaloneBlockModelBuilder):
                module_dependency = _get_standalone_block_dependency(
                    builder, code_content, dependency_creator
                )
                if module_dependency:
                    block_dependencies.append(module_dependency)

    return block_dependencies


def _create_module_dependency_model(module_code_block_id: str) -> DependencyModel:
    """
    Creates a DependencyModel for a module based on its code block ID.

    Args:
        - module_code_block_id (str): The code block ID of the module.

    Returns:
        - DependencyModel: A DependencyModel instance for the module.
    """

    return DependencyModel(code_block_id=module_code_block_id)



File: postcode/python_parser/visitors/node_processing/class_def_functions.py
----------------------------------------
from typing import Sequence

import libcst

from postcode.python_parser.model_builders.class_model_builder import ClassModelBuilder
from postcode.models.models import ClassKeywordModel, DecoratorModel
import postcode.python_parser.visitors.node_processing.common_functions as common_functions

from postcode.utilities.processing_context import PositionData


def process_class_def(
    node: libcst.ClassDef,
    position_data: PositionData,
    builder: ClassModelBuilder,
) -> None:
    """
    Processes a libcst.ClassDef node to build a class model.

    Extracts various components of a class definition such as its docstring, code content, base classes, decorators, and keywords,
    and updates the provided ClassModelBuilder with these details.

    Args:
        - node (libcst.ClassDef): The class definition node from the CST.
        - position_data (PositionData): Positional data for the class in the source code.
        - builder (ClassModelBuilder): The builder used to construct the class model.

    Example:
        ```Python
        class_builder = ClassModelBuilder(id="class1", ...)
        process_class_def(class_node, position_data, class_builder)
        # Processes the class definition and updates the class builder.
        ```
    """

    docstring: str | None = node.get_docstring()
    code_content: str = common_functions.extract_code_content(node)
    bases: list[str] | None = _extract_bases(node.bases)
    keywords: list[ClassKeywordModel] | None = _extract_keywords(node.keywords)
    decorators: list[DecoratorModel] | None = common_functions.extract_decorators(
        node.decorators
    )

    (
        builder.set_docstring(docstring)
        .set_code_content(code_content)
        .set_start_line_num(position_data.start)
        .set_end_line_num(position_data.end)
    )
    builder.set_bases(bases).set_decorators(decorators).set_keywords(keywords)


def _extract_bases(bases: Sequence[libcst.Arg]) -> list[str] | None:
    """
    Extracts the base classes from a sequence of libcst.Arg representing class bases.

    Args:
        - bases (Sequence[libcst.Arg]): A sequence of libcst.Arg nodes representing class base classes.

    Returns:
        - list[str] | None: A list of base class names, or None if there are no bases.

    Example:
        ```Python
        class_bases = _extract_bases(class_node.bases)
        # Returns a list of base class names from the class definition.
        ```
    """

    bases_list: list[str] = []
    for base in bases:
        if (
            isinstance(base, libcst.Arg)
            and isinstance(base.value, libcst.Name)
            and base.value.value
        ):
            bases_list.append(base.value.value)
    return bases_list if bases_list else None


def _extract_keywords(
    keywords: Sequence[libcst.Arg],
) -> list[ClassKeywordModel] | None:
    """
    Extracts class keywords (like metaclass) from a sequence of libcst.Arg representing class keywords.

    Args:
        - keywords (Sequence[libcst.Arg]): A sequence of libcst.Arg nodes representing class keywords.

    Returns:
        - list[ClassKeywordModel] | None: A list of ClassKeywordModel objects representing each keyword,
        or None if there are no keywords.

    Example:
        ```Python
        class_keywords = _extract_keywords(class_node.keywords)
        # Returns a list of ClassKeywordModel objects for each keyword in the class definition.
        ```
    """

    keywords_list: list[ClassKeywordModel] = []

    for keyword in keywords:
        if keyword.keyword is not None:
            keyword_name: str = keyword.keyword.value
            args: str | None = (
                common_functions.extract_stripped_code_content(keyword.value)
                if keyword.value
                else None
            )
            content: str = common_functions.extract_stripped_code_content(keyword)

            keyword_model = ClassKeywordModel(
                content=content, keyword_name=keyword_name, args=args
            )
            keywords_list.append(keyword_model)

    return keywords_list if keywords_list else None



File: postcode/python_parser/visitors/node_processing/standalone_code_block_functions.py
----------------------------------------
from typing import Sequence
import libcst

from postcode.utilities.logger.decorators import logging_decorator

from postcode.python_parser.id_generation.id_generation_strategies import (
    StandaloneCodeBlockIDGenerationStrategy,
)

from postcode.python_parser.model_builders.builder_factory import BuilderFactory
from postcode.python_parser.model_builders.standalone_block_model_builder import (
    StandaloneBlockModelBuilder,
)
from postcode.models.models import CommentModel, BlockType

import postcode.python_parser.visitors.node_processing.common_functions as common_functions
from postcode.utilities.processing_context import NodeAndPositionData


def gather_standalone_lines(
    node_body: Sequence[libcst.CSTNode], visitor_instance
) -> list[NodeAndPositionData]:
    """
    Gathers standalone lines of code that are not part of class or function definitions or import statements.

    This function iterates over a sequence of libcst.CSTNode, identifying blocks of code that stand alone.
    Standalone blocks are those not encapsulated in class or function definitions and not part of import statements.

    Args:
        - node_body (Sequence[libcst.CSTNode]): A sequence of CSTNodes representing the body of a module or a block.
        - visitor_instance: An instance of a visitor class that provides additional context and utilities.

    Returns:
        - list[NodeAndPositionData]: A list of NodeAndPositionData, each representing a standalone block of code with its start and end line numbers.

    Example:
        ```Python
        visitor_instance = ModuleVisitor(id="module1", ...)
        standalone_blocks = gather_standalone_lines(module_ast.body, visitor_instance)
        # This will process the module AST and return standalone blocks of code.
        ```
    """

    standalone_blocks: list[NodeAndPositionData] = []
    standalone_block: list[libcst.CSTNode] = []
    start_line = end_line = 0

    for statement in node_body:
        if _is_class_or_function_def(statement) or _is_import_statement(statement):
            if standalone_block:
                end_line = visitor_instance.get_node_position_data(
                    standalone_block[-1]
                ).end
                standalone_blocks.append(
                    NodeAndPositionData(standalone_block, start_line, end_line)
                )
                standalone_block = []
                start_line = end_line = 0
        else:
            if not standalone_block:
                start_line = visitor_instance.get_node_position_data(statement).start
            standalone_block.append(statement)

    if standalone_block:
        end_line = visitor_instance.get_node_position_data(standalone_block[-1]).end
        standalone_blocks.append(
            NodeAndPositionData(standalone_block, start_line, end_line)
        )

    return standalone_blocks


def process_standalone_blocks(
    code_blocks: list[NodeAndPositionData], parent_id: str, file_path: str
) -> list[StandaloneBlockModelBuilder]:
    """
    Processes standalone blocks of code and builds models for each block.

    Iterates over a list of standalone code blocks, processing each to build a model representing the block.
    Each block is assigned an identifier and associated with a parent identifier.

    Args:
        - code_blocks (list[NodeAndPositionData]): A list of NodeAndPositionData representing standalone code blocks.
        - parent_id (str): The identifier of the parent (usually a module or class).
        - file_path (str): The file path of the module containing the standalone blocks.

    Returns:
        - list[StandaloneBlockModelBuilder]: A list of StandaloneBlockModelBuilder, each representing a processed standalone block.

    Example:
        ```Python
        standalone_blocks_models = process_standalone_blocks(standalone_blocks, "module1")
        # Processes standalone blocks and creates models for them.
        ```
    """

    models: list[StandaloneBlockModelBuilder] = []
    for count, code_block in enumerate(code_blocks):
        models.append(
            _process_standalone_block(
                code_block, parent_id, count + 1, file_path=file_path
            )
        )

    return models


def _is_class_or_function_def(statement: libcst.CSTNode) -> bool:
    """Returns True if the statement is a class or function definition."""

    return isinstance(statement, (libcst.ClassDef, libcst.FunctionDef))


def _is_import_statement(statement: libcst.CSTNode) -> bool:
    """Returns True if the statement is an import statement."""

    return isinstance(statement, libcst.SimpleStatementLine) and any(
        isinstance(elem, (libcst.Import, libcst.ImportFrom)) for elem in statement.body
    )


# TODO: Fix important comment logic
def _process_standalone_block(
    standalone_block: NodeAndPositionData, parent_id: str, count: int, file_path: str
) -> StandaloneBlockModelBuilder:
    """Processes a standalone block of code and sets the attributes in the model builder, returns the builder instance."""

    id: str = StandaloneCodeBlockIDGenerationStrategy.generate_id(parent_id, count)
    builder: StandaloneBlockModelBuilder = BuilderFactory.create_builder_instance(
        block_type=BlockType.STANDALONE_CODE_BLOCK,
        id=id,
        parent_id=parent_id,
        file_path=file_path,
    )
    content, variable_assignments, important_comments = _process_nodes(standalone_block)
    (
        builder.set_start_line_num(standalone_block.start)
        .set_end_line_num(standalone_block.end)
        .set_code_content(content)
    )
    for important_comment in important_comments:
        builder.add_important_comment(important_comment)
    builder.set_variable_assignments(variable_assignments)

    return builder


@logging_decorator(syntax_highlighting=True)
def _process_nodes(
    standalone_block: NodeAndPositionData,
) -> tuple[str, list[str], list[CommentModel]]:
    """Processes the nodes in a standalone block of code and returns the content, variable assignments and important comments."""

    content: str = ""
    variable_assignments: list[str] = []
    important_comments: list[CommentModel] = []

    for line in standalone_block.nodes:
        if isinstance(line, libcst.SimpleStatementLine):
            variable_assignments.extend(_extract_variable_assignments(line))

        important_comments.extend(_process_leading_lines(line))
        line_content: str = common_functions.extract_stripped_code_content(line)
        content += line_content + "\n"

    return content, variable_assignments, important_comments


def _process_leading_lines(line: libcst.CSTNode) -> list[CommentModel]:
    """Processes the leading lines of a node and returns the important comments."""

    important_comments: list[CommentModel] = []

    if isinstance(line, libcst.SimpleStatementLine):
        for leading_line in line.leading_lines:
            important_comment: CommentModel | None = (
                common_functions.extract_important_comment(leading_line)
            )
            if important_comment:
                important_comments.append(important_comment)

    return important_comments


def _extract_variable_assignments(
    node: libcst.SimpleStatementLine,
) -> list[str]:
    """Extracts variable assignments from a SimpleStatementLine node."""

    variable_assignments: list[str] = []
    for stmt in node.body:
        if isinstance(stmt, (libcst.AnnAssign, libcst.Assign)):
            variable_assignments.append(
                common_functions.extract_stripped_code_content(stmt)
            )

    return variable_assignments



File: postcode/python_parser/visitors/node_processing/common_functions.py
----------------------------------------
import logging
from typing import Sequence
import libcst


from postcode.models.models import CommentModel, DecoratorModel, CommentType


def extract_code_content(
    node: libcst.CSTNode,
) -> str:
    """
    Extracts the code content from a given CST node.

    This function converts a CST node to its string representation, maintaining the original code format.

    Args:
        - node (libcst.CSTNode): The CST node to extract code from.

    Returns:
        - str: The string representation of the code for the given CST node.

    Example:
        ```Python
        extract_code_content(some_cst_node)
        # Returns the code content as a string.
        ```
    """

    return libcst.Module([]).code_for_node(node)


def extract_stripped_code_content(
    node: libcst.CSTNode,
) -> str:
    """
    Extracts the stripped code content from a given CST node.

    Similar to extract_code_content, but also strips leading and trailing whitespace from the code string.

    Args:
        - node (libcst.CSTNode): The CST node to extract code from.

    Returns:
        - str: The stripped string representation of the code for the CST node.

    Example:
        ```Python
        extract_stripped_code_content(some_cst_node)
        # Returns the stripped code content as a string.
        ```
    """

    return extract_code_content(node).strip()


def extract_important_comment(
    comment_or_empty_line_node: libcst.CSTNode,
) -> CommentModel | None:
    """
    Extracts an important comment from a given CST node.

    Processes a libcst.Comment or libcst.EmptyLine node to extract important comments, categorizing them based on predefined types.

    Args:
        - comment_or_empty_line_node (libcst.CSTNode): A CST node representing a comment or an empty line with a comment.

    Returns:
        - CommentModel | None: A CommentModel object if an important comment is found, otherwise None.

    Example:
        ```Python
        extract_important_comment(some_comment_node)
        # Returns a CommentModel for the comment, or None if not important.
        ```
    """

    comment_text: str | None = None

    if isinstance(comment_or_empty_line_node, libcst.EmptyLine):
        if comment_or_empty_line_node.comment:
            comment_text = comment_or_empty_line_node.comment.value
    elif isinstance(comment_or_empty_line_node, libcst.Comment):
        comment_text = comment_or_empty_line_node.value

    if not comment_text:
        return None

    comment_types: list[CommentType] = [
        comment_type
        for comment_type in CommentType
        if comment_type.value in comment_text.upper()
    ]

    if comment_types:
        return CommentModel(
            content=comment_text,
            comment_types=comment_types,
        )


def extract_decorators(
    decorators: Sequence[libcst.Decorator],
) -> list[DecoratorModel] | None:
    """
    Extracts a list of decorator models from a sequence of libcst.Decorator nodes.

    Processes each decorator node to form a model representing the decorator's name and its arguments, if any.

    Args:
        - decorators (Sequence[libcst.Decorator]): A sequence of libcst.Decorator nodes.

    Returns:
        - list[DecoratorModel] | None: A list of DecoratorModel objects, or None if no decorators are found.

    Example:
        ```Python
        extract_decorators(function_node.decorators)
        # Returns a list of DecoratorModel objects representing each decorator in the function.
        ```
    """

    decorators_list: list[DecoratorModel] = []
    for decorator in decorators:
        decorator_model: DecoratorModel | None = extract_decorator(decorator)
        if isinstance(decorator_model, DecoratorModel):
            decorators_list.append(extract_decorator(decorator))  # type: ignore
    return decorators_list if decorators_list else None


def extract_decorator(
    decorator: libcst.Decorator,
) -> DecoratorModel | None:
    """
    Extracts the decorator from a libcst.Decorator node.

    Processes a single decorator node to create a model representing the decorator's name and arguments.

    Args:
        - decorator (libcst.Decorator): A libcst.Decorator node.

    Returns:
        - DecoratorModel | None: A DecoratorModel object if the decorator is valid, otherwise None.

    Example:
        ```Python
        extract_decorator(some_decorator_node)
        # Returns a DecoratorModel object for the decorator.
        ```
    """

    decorator_name: str = ""
    arg_list: list[str] | None = None
    if isinstance(decorator.decorator, libcst.Name):
        decorator_name: str = decorator.decorator.value
    if isinstance(decorator.decorator, libcst.Call):
        func = decorator.decorator.func
        if isinstance(func, libcst.Name) or isinstance(func, libcst.Attribute):
            if decorator.decorator.args:
                arg_list = [
                    extract_stripped_code_content(arg)
                    for arg in decorator.decorator.args
                ]
        if isinstance(func, libcst.Name):
            decorator_name = func.value
        elif isinstance(func, libcst.Attribute):
            decorator_name = func.attr.value
        else:
            logging.warning("Decorator func is not a Name or Attribute node")

    return (
        DecoratorModel(
            content=extract_stripped_code_content(decorator),
            decorator_name=decorator_name,
            decorator_args=arg_list,
        )
        if decorator_name
        else None
    )


def extract_type_annotation(node: libcst.CSTNode) -> str | None:
    """
    Extracts the type annotation from a node.

    Processes a libcst.CSTNode to extract the type annotation, if present.
    It handles various forms of type annotations, including generics and unions.

    Args:
        - node (libcst.CSTNode): The node to extract the type annotation from.

    Returns:
        - str | None: The extracted type annotation as a string, or None if no type annotation is found.

    Example:
        ```Python
        extract_type_annotation(some_cst_node)
        # Returns the type annotation as a string, or None if not present.
        ```
    """

    annotation: libcst.Annotation | None = _get_node_annotation(node)
    if annotation and isinstance(annotation, libcst.Annotation):
        return _process_type_annotation_expression(annotation.annotation)
    return None


def _get_node_annotation(node: libcst.CSTNode) -> libcst.Annotation | None:
    """
    Retrieves the annotation of a given CSTNode.

    Args:
        - node (libcst.CSTNode): The CSTNode to retrieve the annotation from.

    Returns:
        - libcst.Annotation | None: The annotation of the CSTNode if present, otherwise None.
    """

    if isinstance(node, libcst.Param) or isinstance(node, libcst.AnnAssign):
        return node.annotation
    elif isinstance(node, libcst.Annotation):
        return node
    return None


def _process_type_annotation_expression(expression: libcst.BaseExpression) -> str:
    """
    Process the type annotation expression and return a string representation recursively.

    Args:
        - expression (libcst.BaseExpression): The type annotation expression to process.

    Returns:
        - str: The string representation of the processed type annotation expression.
    """

    if isinstance(expression, libcst.Subscript):
        return _extract_generic_types_from_subscript(expression)
    elif isinstance(expression, libcst.BinaryOperation):
        left: str = _process_type_annotation_expression(expression.left)
        right: str = _process_type_annotation_expression(expression.right)
        return f"{left} | {right}"
    elif isinstance(expression, libcst.Name):
        return expression.value
    return ""


def _extract_generic_types_from_subscript(
    node: libcst.Subscript | libcst.BaseExpression,
) -> str:
    """
    Recursively extracts generic types from a Subscript node or a BaseExpression node.

    Args:
        - node (libcst.Subscript | libcst.BaseExpression): The Subscript or BaseExpression node to extract generic types from.

    Returns:
        - str: The string representation of the extracted generic types.
    """

    if isinstance(node, libcst.Subscript):
        generics: list[str] = []
        for element in node.slice:
            if isinstance(element.slice, libcst.Index):
                if isinstance(element.slice.value, libcst.BinaryOperation):
                    union_type: str = _process_type_annotation_expression(
                        element.slice.value
                    )
                    generics.append(union_type)
                else:
                    generic_type: str = _extract_generic_types_from_subscript(
                        element.slice.value
                    )
                    generics.append(generic_type)

        if isinstance(node.value, libcst.Name):
            generics_str = ", ".join(generics)
            return f"{node.value.value}[{generics_str}]"
        else:
            return ""

    elif isinstance(node, libcst.Name):
        return node.value
    return ""



File: postcode/python_parser/visitors/node_processing/module_functions.py
----------------------------------------
import sys
from typing import Sequence

import libcst

from postcode.models.models import ImportModel, ImportNameModel, ImportModuleType
import postcode.python_parser.visitors.node_processing.common_functions as common_functions


def extract_content_from_empty_lines(
    sequence: Sequence[libcst.EmptyLine],
) -> list[str]:
    """
    Extracts comments from a sequence of EmptyLine nodes.

    Args:
        - sequence (Sequence[libcst.EmptyLine]): A sequence of libcst.EmptyLine nodes to process.

    Returns:
        - list[str]: A list of string comments extracted from the EmptyLine nodes.

    Example:
        ```Python
        extract_content_from_empty_lines([libcst.EmptyLine(comment=libcst.Comment("# Comment"))])
        # Returns: ['# Comment']
        ```
    """

    return [line.comment.value for line in sequence if line.comment]


def process_import(node: libcst.Import) -> ImportModel:
    """
    Processes an Import node to create an ImportModel.

    Args:
        - node (libcst.Import): The Import node to process.

    Returns:
        - ImportModel: An ImportModel representing the processed import.

    Example:
        ```Python
        import_model = process_import(libcst.Import(names=[libcst.ImportAlias(name=libcst.Name("module"))]))
        ```
    """

    import_name_model: ImportNameModel = _build_import_name_model(node)
    import_model: ImportModel = _build_import_model(
        import_name_models=[import_name_model]
    )
    return import_model


def process_import_from(node: libcst.ImportFrom) -> ImportModel:
    """
    Processes an ImportFrom node to create an ImportModel.

    Args:
        - node (libcst.ImportFrom): The ImportFrom node to process.

    Returns:
        - ImportModel: An ImportModel representing the processed import from statement.

    Example:
        ```Python
        import_model = process_import_from(libcst.ImportFrom(module=libcst.Name("module"), names=[libcst.ImportAlias(name=libcst.Name("submodule"))]))
        ```
    """

    module_name: str | None = (
        _get_full_module_path(node.module) if node.module else None
    )
    import_names: list[ImportNameModel] = _build_import_from_name_models(node)
    import_module_type: ImportModuleType = _get_import_from_module_type(module_name)

    import_model = ImportModel(
        import_names=import_names,
        imported_from=module_name,
        import_module_type=import_module_type,
    )
    return import_model


def _get_import_name(node: libcst.Import) -> str:
    """Gets the import name from an Import node."""

    return common_functions.extract_code_content(node.names[0].name)


def _get_as_name(node: libcst.Import) -> str | None:
    """Gets the as name from an Import node."""

    first_name: libcst.ImportAlias = node.names[0]

    if first_name.asname and isinstance(first_name.asname, libcst.AsName):
        as_name_node = first_name.asname.name
        if isinstance(as_name_node, libcst.Name):
            return as_name_node.value


def _build_import_name_model(node: libcst.Import) -> ImportNameModel:
    """Builds an ImportNameModel from an Import node."""

    import_name: str | None = _get_import_name(node)
    as_name: str | None = _get_as_name(node)
    return ImportNameModel(name=import_name, as_name=as_name)


def _is_standard_library_import(import_name: str) -> bool:
    """Checks if an import is a standard library import."""

    return import_name in sys.stdlib_module_names


def _third_party_imports() -> list[str]:
    """Gets a list of all third party imports."""

    third_party_imports: list[str] = []

    for module_name, module in sys.modules.items():
        if module_name in sys.stdlib_module_names or not hasattr(module, "__file__"):
            continue

        module_file: str | None = module.__file__
        if module_file and (
            "site-packages" in module_file or "dist-packages" in module_file
        ):
            third_party_imports.append(module_name)

    return third_party_imports


def _is_third_party_import(import_name: str) -> bool:
    """Checks if an import is a third party import."""

    return import_name in _third_party_imports()


def _determine_import_module_type(module_name: str) -> ImportModuleType:
    """Determines the type of import a module is."""

    if _is_standard_library_import(module_name):
        return ImportModuleType.STANDARD_LIBRARY
    elif _is_third_party_import(module_name):
        return ImportModuleType.THIRD_PARTY
    else:
        return ImportModuleType.LOCAL


def _get_import_module_type(
    import_name_models: list[ImportNameModel],
) -> ImportModuleType:
    """Gets the import module type of a list of ImportNameModels."""

    for import_name_model in import_name_models:
        module_type = _determine_import_module_type(import_name_model.name)
        if module_type != ImportModuleType.LOCAL:
            return module_type
    return ImportModuleType.LOCAL


def _get_import_from_module_type(module_name: str | None) -> ImportModuleType:
    """Gets the import module type of an ImportFrom node."""

    if module_name:
        return _determine_import_module_type(module_name)
    return ImportModuleType.LOCAL


def _build_import_model(
    import_name_models: list[ImportNameModel],
) -> ImportModel:
    """Builds an ImportModel from a list of ImportNameModels."""

    import_module_type: ImportModuleType = _get_import_module_type(import_name_models)
    return ImportModel(
        import_names=import_name_models,
        imported_from=None,
        import_module_type=import_module_type,
    )


def _get_full_module_path(node) -> str:
    """Recursively gets the full module path from a node and returns it as a string."""

    if isinstance(node, libcst.Name):
        return node.value
    elif isinstance(node, libcst.Attribute):
        return common_functions.extract_code_content(node)
    else:
        print(f"\n\nImport Node type: {type(node)}\n")
        # return str(node)
        return common_functions.extract_code_content(node)


def _extract_as_name(import_alias: libcst.ImportAlias) -> str | None:
    """Extracts the as name from an ImportAlias node."""

    if import_alias.asname and isinstance(import_alias.asname, libcst.AsName):
        if isinstance(import_alias.asname.name, libcst.Name):
            return import_alias.asname.name.value


def _build_import_from_name_models(node: libcst.ImportFrom) -> list[ImportNameModel]:
    """Builds a list of ImportNameModels from an ImportFrom node."""

    import_names: list[ImportNameModel] = []
    if isinstance(node.names, libcst.ImportStar):
        import_names.append(ImportNameModel(name="*", as_name=None))
    else:
        for import_alias in node.names:
            if isinstance(import_alias, libcst.ImportAlias):
                name = str(import_alias.name.value)
                as_name = _extract_as_name(import_alias)
                import_names.append(ImportNameModel(name=name, as_name=as_name))
    return import_names



File: postcode/python_parser/visitors/node_processing/function_def_functions.py
----------------------------------------
from typing import Sequence

import libcst

from postcode.python_parser.model_builders.function_model_builder import (
    FunctionModelBuilder,
)

from postcode.models.models import (
    DecoratorModel,
    ParameterListModel,
    ParameterModel,
)
from postcode.models.enums import BlockType
import postcode.python_parser.visitors.node_processing.common_functions as common_functions

from postcode.utilities.processing_context import PositionData


def process_func_def(
    func_id: str,
    node: libcst.FunctionDef,
    position_data: PositionData,
    func_builder: FunctionModelBuilder,
) -> None:
    """
    Processes a libcst.FunctionDef node to build a function model.

    Extracts various components of a function definition such as its docstring, code content, decorators, and return annotations,
    and updates the provided FunctionModelBuilder with these details.

    Args:
        - func_id (str): The unique identifier for the function.
        - node (libcst.FunctionDef): The function definition node from the CST.
        - position_data (PositionData): Positional data for the function in the source code.
        - func_builder (FunctionModelBuilder): The builder used to construct the function model.

    Example:
        ```Python
        func_builder = FunctionModelBuilder(id="func1", ...)
        process_func_def("func1", function_node, position_data, func_builder)
        # Processes the function definition and updates the function builder.
        ```
    """

    docstring: str | None = node.get_docstring()
    code_content: str = common_functions.extract_code_content(node)
    decorators: list[DecoratorModel] | None = common_functions.extract_decorators(
        node.decorators
    )

    returns: str = (
        _extract_return_annotation(node.returns)
        if node.returns
        else "Function has no return annotation"
    )
    (
        func_builder.set_docstring(docstring)
        .set_code_content(code_content)
        .set_start_line_num(position_data.start)
        .set_end_line_num(position_data.end)
    )
    (
        func_builder.set_decorators(decorators)
        .set_is_method(_func_is_method(func_id))
        .set_is_async(_func_is_async(node))
        .set_return_annotation(returns)
    )


def process_parameters(
    node: libcst.Parameters,
) -> ParameterListModel | None:
    """
    Processes libcst.Parameters node to create a ParameterListModel.

    Extracts parameters, keyword-only parameters, positional-only parameters, and special arguments (like *args and **kwargs)
    from the function definition and forms a model representing these parameters.

    Args:
        - node (libcst.Parameters): The parameters node from a function definition.

    Returns:
        - ParameterListModel | None: A model representing the function's parameters, or None if there are no parameters.

    Example:
        ```Python
        parameters_model = process_parameters(function_node.params)
        # Processes the function parameters and returns a parameter model.
        ```
    """

    params: list[ParameterModel] | None = (
        _get_parameters_list(node.params) if node.params else []
    )
    kwonly_params: list[ParameterModel] | None = (
        _get_parameters_list(node.kwonly_params) if node.kwonly_params else []
    )
    posonly_params: list[ParameterModel] | None = (
        _get_parameters_list(node.posonly_params) if node.posonly_params else []
    )

    star_arg: ParameterModel | None = (
        ParameterModel(
            content=common_functions.extract_stripped_code_content(node.star_arg)
        )
        if node.star_arg and isinstance(node.star_arg, libcst.Param)
        else None
    )
    star_kwarg: ParameterModel | None = (
        ParameterModel(
            content=common_functions.extract_stripped_code_content(node.star_kwarg)
        )
        if node.star_kwarg
        else None
    )

    if params and kwonly_params and posonly_params and star_arg and star_kwarg:
        return ParameterListModel(
            params=params,
            kwonly_params=kwonly_params,
            posonly_params=posonly_params,
            star_arg=star_arg,
            star_kwarg=star_kwarg,
        )


def _func_is_method(id: str) -> bool:
    """
    Returns true if an ancestor of the function is a class.

    Args:
        - id (str): The identifier of the function.

    Returns:
        - bool: True if the function is a method, False otherwise.
    """

    return str(BlockType.CLASS) in id


def _func_is_async(node: libcst.FunctionDef) -> bool:
    """
    Returns true if the function is async.

    Args:
        - node (libcst.FunctionDef): The function definition node.

    Returns:
        - bool: True if the function is async, False otherwise.
    """

    return True if node.asynchronous else False


def _get_parameters_list(
    parameter_sequence: Sequence[libcst.Param],
) -> list[ParameterModel] | None:
    """
    Returns a list of ParameterModel representing the parameters in a function definition.

    Args:
        - parameter_sequence (Sequence[libcst.Param]): The sequence of parameters from the function definition.

    Returns:
        - list[ParameterModel] | None: A list of ParameterModel instances or None if there are no parameters.
    """

    params: list[ParameterModel] | None = None

    if parameter_sequence:
        params = []
        for parameter in parameter_sequence:
            param: ParameterModel = ParameterModel(
                content=common_functions.extract_stripped_code_content(parameter)
            )
            params.append(param)

    return params if params else None


def _extract_return_annotation(
    node_returns: libcst.Annotation | None,
) -> str:
    """ "
    Extracts the return annotation from a function definition.

    Args:
        - node_returns (libcst.Annotation | None): The return annotation node.

    Returns:
        - str: The extracted return annotation or "No return annotation" if none is found.
    """

    if isinstance(node_returns, libcst.Annotation) and node_returns:
        annotation: str | None = common_functions.extract_type_annotation(node_returns)
        return annotation if annotation else "No return annotation"
    else:
        return "No return annotation"



File: postcode/python_parser/visitors/module_visitor.py
----------------------------------------
import libcst

from postcode.python_parser.id_generation.id_generation_strategies import (
    ClassIDGenerationStrategy,
    FunctionIDGenerationStrategy,
)

from postcode.python_parser.model_builders.builder_factory import BuilderFactory
from postcode.python_parser.model_builders.class_model_builder import ClassModelBuilder
from postcode.python_parser.model_builders.function_model_builder import (
    FunctionModelBuilder,
)
from postcode.python_parser.model_builders.module_model_builder import (
    ModuleModelBuilder,
)
from postcode.python_parser.model_builders.standalone_block_model_builder import (
    StandaloneBlockModelBuilder,
)

from postcode.models.models import (
    ImportModel,
    ParameterListModel,
)
from postcode.models.enums import BlockType
from postcode.python_parser.visitors.base_code_block_visitor import BaseVisitor
import postcode.python_parser.visitors.node_processing.class_def_functions as class_def_functions
import postcode.python_parser.visitors.node_processing.function_def_functions as function_def_functions
import postcode.python_parser.visitors.node_processing.module_functions as module_functions
import postcode.python_parser.visitors.node_processing.standalone_code_block_functions as standalone_code_block_functions

from postcode.utilities.processing_context import (
    NodeAndPositionData,
    PositionData,
)
from postcode.python_parser.visitors.node_processing.gather_dependencies import (
    gather_and_set_children_dependencies,
)


class ModuleVisitor(BaseVisitor):
    """
    Visitor class for traversing and building a model of a Python module.

    This class extends BaseVisitor and is used to visit different nodes in a Python module's concrete
    syntax tree (CST) using the libcst library. It builds a structured model of the module, including
    imports, classes, and functions.

    Attributes:
        - id (str): The ID of the module to be generated before instantiation.
        - builder (ModuleModelBuilder): The builder used to construct the module model.

    Example:
        ```Python
        module_builder = ModuleModelBuilder(id="module1", name="example_module")
        visitor = ModuleVisitor(id="module1", module_builder=module_builder)
        libcst.parse_module("import os\\nclass MyClass:\\n    pass").visit(visitor)
        # This will process the module and build its corresponding model using the provided module builder.
        ```
    """

    def __init__(self, id: str, module_builder: ModuleModelBuilder) -> None:
        super().__init__(id=id)
        self.builder: ModuleModelBuilder = module_builder
        self.builder_stack.append(module_builder)

    def visit_Module(self, node: libcst.Module) -> bool | None:
        """
        Visits the root Module node of the CST.

        Extracts various components of the module such as docstring, header, footer, and code content, and
        updates the module builder with these details.
        """

        docstring: str | None = node.get_docstring()
        header: list[str] = module_functions.extract_content_from_empty_lines(
            node.header
        )
        footer: list[str] = module_functions.extract_content_from_empty_lines(
            node.footer
        )
        content: str = node.code if node.code else ""
        position_data: PositionData = self.get_node_position_data(node)
        (
            self.builder.set_docstring(docstring)
            .set_header_content(header)
            .set_footer_content(footer)
            .set_code_content(content)
            .set_start_line_num(position_data.start)
            .set_end_line_num(position_data.end)
        )
        standalone_blocks: list[
            NodeAndPositionData
        ] = standalone_code_block_functions.gather_standalone_lines(node.body, self)
        standalone_block_models: list[
            StandaloneBlockModelBuilder
        ] = standalone_code_block_functions.process_standalone_blocks(
            code_blocks=standalone_blocks,
            parent_id=self.id,
            file_path=self.builder.common_attributes.file_path,
        )
        for standalone_block_model in standalone_block_models:
            self.builder.add_child_builder(standalone_block_model)

    def visit_Import(self, node: libcst.Import) -> None:
        """
        Visits an Import node in the CST.

        Processes the import statement and updates the module builder with the import model.
        """

        import_model: ImportModel = module_functions.process_import(node)
        self.builder.add_import(import_model)

    def visit_ImportFrom(self, node: libcst.ImportFrom) -> None:
        """
        Visits an ImportFrom node in the CST.

        Processes the 'from ... import ...' statement and updates the module builder with the import model.
        """

        import_model: ImportModel = module_functions.process_import_from(node)
        self.builder.add_import(import_model)

    def visit_ClassDef(self, node: libcst.ClassDef) -> None:
        """
        Visits a ClassDef node in the CST.

        Initiates the process of building a class model from the class definition.
        """

        parent_id: str = self.builder_stack[-1].id
        class_id: str = ClassIDGenerationStrategy.generate_id(
            parent_id=parent_id, class_name=node.name.value
        )

        class_builder: ClassModelBuilder = BuilderFactory.create_builder_instance(
            block_type=BlockType.CLASS,
            id=class_id,
            name=node.name.value,
            parent_id=parent_id,
            file_path=self.builder.common_attributes.file_path,
        )

        builder = self.builder_stack[-1]
        builder.add_child_builder(class_builder)
        self.builder_stack.append(class_builder)

        position_data: PositionData = self.get_node_position_data(node)
        class_def_functions.process_class_def(node, position_data, class_builder)

    def leave_ClassDef(self, original_node: libcst.ClassDef) -> None:
        """
        Leaves a ClassDef node in the CST.

        Finalizes the class model building process by popping the current builder from the stack.
        """

        self.builder_stack.pop()

    def visit_FunctionDef(self, node: libcst.FunctionDef) -> None:
        """
        Visits a FunctionDef node in the CST.

        Initiates the process of building a function model from the function definition.
        """

        parent_id: str = self.builder_stack[-1].id
        func_id: str = FunctionIDGenerationStrategy.generate_id(
            parent_id=parent_id, function_name=node.name.value
        )

        func_builder: FunctionModelBuilder = BuilderFactory.create_builder_instance(
            block_type=BlockType.FUNCTION,
            id=func_id,
            name=node.name.value,
            parent_id=parent_id,
            file_path=self.builder.common_attributes.file_path,
        )
        builder = self.builder_stack[-1]
        builder.add_child_builder(func_builder)
        self.builder_stack.append(func_builder)

        position_data: PositionData = self.get_node_position_data(node)
        function_def_functions.process_func_def(
            func_id, node, position_data, func_builder
        )

    def visit_Parameters(self, node: libcst.Parameters) -> None:
        """
        Visits a Parameters node in the CST.

        Processes the parameters of a function and updates the current function model builder with these parameters.
        """

        builder = self.builder_stack[-1]
        parameter_list: ParameterListModel | None = (
            function_def_functions.process_parameters(node)
        )

        if isinstance(builder, FunctionModelBuilder):
            builder.set_parameters_list(parameter_list)

    def leave_FunctionDef(self, original_node: libcst.FunctionDef) -> None:
        """
        Leaves a FunctionDef node in the CST.

        Finalizes the function model building process by popping the current builder from the stack.
        """

        self.builder_stack.pop()

    def leave_Module(self, original_node: libcst.Module) -> None:
        """
        Leaves the root Module node in the CST.

        Finalizes the module model building process by setting dependencies for children of the module.
        """

        gather_and_set_children_dependencies(self.builder)



File: postcode/python_parser/parsers/python_parser.py
----------------------------------------
from typing import TYPE_CHECKING, Union
import libcst
from libcst.metadata import MetadataWrapper
from postcode.python_parser.id_generation.id_generation_strategies import (
    ModuleIDGenerationStrategy,
)
from postcode.python_parser.model_builders.builder_factory import BuilderFactory
from postcode.python_parser.model_builders.module_model_builder import (
    ModuleModelBuilder,
)

from postcode.python_parser.visitors.module_visitor import ModuleVisitor
from postcode.models.enums import BlockType

from postcode.python_parser.model_builders.class_model_builder import (
    ClassModelBuilder,
)
from postcode.python_parser.model_builders.function_model_builder import (
    FunctionModelBuilder,
)
from postcode.python_parser.model_builders.standalone_block_model_builder import (
    StandaloneBlockModelBuilder,
)


BuilderType = Union[
    ModuleModelBuilder,
    ClassModelBuilder,
    FunctionModelBuilder,
    StandaloneBlockModelBuilder,
]


class PythonParser:
    """
    A parser for Python source code, using libcst to parse and construct a module model.

    This class takes the path to a Python file, reads its contents, and parses it into a structured
    module model using the libcst library. It is designed to work with a specific file at a time.

    Attributes:
        - file_path (str): The path to the Python file to be parsed.

    Example:
        ```Python
        python_parser = PythonParser("/path/to/python/file.py")
        code = python_parser.open_file()
        module_model = python_parser.parse(code, parent_id="parent_module_id")
        # Parses the provided code and returns a structured module model.
        ```
    """

    def __init__(self, file_path: str) -> None:
        self.file_path: str = file_path

    def open_file(self) -> str:
        """
        Opens and reads the contents of the Python file specified in the file_path attribute.

        Returns:
            - str: The contents of the file as a string.

        Example:
            ```Python
            python_parser = PythonParser("/path/to/python/file.py")
            code = python_parser.open_file()
            # Reads and returns the contents of the Python file.
            ```
        """

        with open(self.file_path, "r") as file:
            return file.read()

    def parse(self, code: str, parent_id: str) -> ModuleModelBuilder | None:
        """
        Parses the provided Python code into a structured module model.

        Uses libcst to parse the provided code using the ModuleVisitor class. A ModuleModelBuilder instance is returned
        along with its hierarchy of child builders.

        Args:
            - code (str): The Python code to be parsed.
            - parent_id (str): The ID of the parent module or block.

        Returns:
            - ModuleModelBuilder | None: The module model builder for the provided code.

        Example:
            ```Python
            python_parser = PythonParser("/path/to/python/file.py")
            code = python_parser.open_file()
            module_model = python_parser.parse(code, parent_id="parent_module_id")
            # Parses the provided code and returns a module model builder.
            ```
        """

        wrapper = MetadataWrapper(libcst.parse_module(code))
        module_id: str = ModuleIDGenerationStrategy.generate_id(
            file_path=self.file_path
        )
        module_builder: ModuleModelBuilder = BuilderFactory.create_builder_instance(
            block_type=BlockType.MODULE,
            id=module_id,
            file_path=self.file_path,
            parent_id=parent_id,
        )
        visitor = ModuleVisitor(id=module_id, module_builder=module_builder)
        wrapper.visit(visitor)

        return (
            visitor.builder_stack[0]
            if isinstance(visitor.builder_stack[0], ModuleModelBuilder)
            else None
        )



File: postcode/python_parser/id_generation/id_generation_strategies.py
----------------------------------------
from abc import ABC, abstractmethod


class IDGenerationStrategy(ABC):
    """
    Abstract base class defining the interface for ID generation strategies.

    This class serves as a template for creating various ID generation strategies for different types
    of code blocks, such as modules, classes, functions, and standalone code blocks.
    """

    @staticmethod
    @abstractmethod
    def generate_id(**kwargs) -> str:
        """
        Abstract method to generate an ID based on the given context.

        Subclasses should implement this method to generate an ID specific to the block type.

        Args:
            **kwargs: Variable keyword arguments depending on the specific strategy requirements.

        Returns:
            str: The generated ID.
        """
        pass


class ModuleIDGenerationStrategy(IDGenerationStrategy):
    """ID generation strategy for modules."""

    @staticmethod
    def generate_id(file_path: str) -> str:
        """
        Generates an ID for a module based on the given file path.

        Args:
            - file_path (str): The file path of the module.

        Returns:
            - str: The generated ID, incorporating the file path.
        """
        module_path: str = ModuleIDGenerationStrategy._converted_path_string(file_path)
        return f"{module_path}__*__MODULE"

    @staticmethod
    def _converted_path_string(file_path: str) -> str:
        """
        Converts a file path to a valid ID string.

        Args:
            - file_path (str): The file path to convert.

        Returns:
            - str: The converted ID string.
        """
        return file_path.replace("/", ":")


class ClassIDGenerationStrategy(IDGenerationStrategy):
    """ID generation strategy for classes."""

    @staticmethod
    def generate_id(parent_id: str, class_name: str) -> str:
        """
        Generates an ID for a class based on the given parent ID and class name.

        Args:
            - parent_id (str): The ID of the parent (module or another class).
            - class_name (str): The name of the class.

        Returns:
            - str: The generated ID, incorporating the parent ID and class name.
        """
        return f"{parent_id}__*__CLASS-{class_name}"


class FunctionIDGenerationStrategy(IDGenerationStrategy):
    """ID generation strategy for functions."""

    @staticmethod
    def generate_id(parent_id: str, function_name: str) -> str:
        """
        Generates an ID for a function based on the given parent ID and function name.

        Args:
            - parent_id (str): The ID of the parent (module or class).
            - function_name (str): The name of the function.

        Returns:
            - str: The generated ID, incorporating the parent ID and function name.
        """
        return f"{parent_id}__*__FUNCTION-{function_name}"


class StandaloneCodeBlockIDGenerationStrategy(IDGenerationStrategy):
    """ID generation strategy for standalone code blocks."""

    @staticmethod
    def generate_id(parent_id: str, count: int) -> str:
        """
        Generates an ID for a standalone code block based on the given parent ID and a count.

        Args:
            - parent_id (str): The ID of the parent (typically a module).
            - count (int): A unique count or index for the standalone block within its parent.

        Returns:
            - str: The generated ID, incorporating the parent ID and the count.
        """
        return f"{parent_id}__*__STANDALONE_BLOCK-{count}"


class DirectoryIDGenerationStrategy(IDGenerationStrategy):
    """ID generation strategy for directories."""

    @staticmethod
    def generate_id(directory_path: str) -> str:
        """
        Generates an ID for a directory based on the given directory path.

        Args:
            - directory_path (str): The path to the directory.

        Returns:
            - str: The generated ID, incorporating the file path.
        """
        directory_path_str: str = DirectoryIDGenerationStrategy._converted_path_string(
            directory_path
        )
        return f"{directory_path_str}__*__DIRECTORY"

    @staticmethod
    def _converted_path_string(file_path: str) -> str:
        """
        Converts a file path to a valid ID string.

        Args:
            - file_path (str): The file path to convert.

        Returns:
            - str: The converted ID string.
        """
        return file_path.replace("/", ":")



File: postcode/python_parser/model_builders/module_model_builder.py
----------------------------------------
from ctypes import Union
from typing import TYPE_CHECKING, Any

from postcode.python_parser.model_builders.base_model_builder import BaseModelBuilder

from postcode.utilities.logger.decorators import logging_decorator
from postcode.models.models import (
    ModuleModel,
    ImportModel,
    ModuleSpecificAttributes,
)
from postcode.models.enums import BlockType


from postcode.models.models import (
    ClassModel,
    FunctionModel,
    StandaloneCodeBlockModel,
)


class ModuleModelBuilder(BaseModelBuilder):
    """
    A builder class for constructing a model of a Python module.

    This class extends BaseModelBuilder and specializes in building a detailed model of a Python module, capturing various aspects such as the module's docstring, header content, footer content, and imports. It allows for the incremental construction of the module model by adding or setting various components.

    Attributes:
        - module_attributes (ModuleSpecificAttributes): An instance containing attributes specific to a module, like file path, docstring, header, footer, and imports.

    Args:
        - id (str): The unique identifier for the module model.
        - file_path (str): The file path of the module being modeled.

    Example:
        ```Python
        module_builder = ModuleModelBuilder(id='module1', file_path='/path/to/module.py')
        module_builder.set_docstring("This is a docstring").add_import(some_import_model)
        # Configures the module builder with a docstring and an import.
        ```
    """

    def __init__(self, id: str, file_path: str, parent_id: str) -> None:
        super().__init__(
            id=id, block_type=BlockType.MODULE, parent_id=parent_id, file_path=file_path
        )

        self.module_attributes = ModuleSpecificAttributes(
            docstring=None,
            header=None,
            footer=None,
            imports=None,
        )

    def set_docstring(self, docstring: str | None) -> "ModuleModelBuilder":
        """Set the docstring."""
        if docstring:
            self.module_attributes.docstring = docstring
        return self

    def set_header_content(self, header_content: list[str]) -> "ModuleModelBuilder":
        """Set the header."""
        if not self.module_attributes.header:
            self.module_attributes.header = []
        for line in header_content:
            self.module_attributes.header.append(line)
        return self

    def set_footer_content(self, footer_content: list[str]) -> "ModuleModelBuilder":
        """Set the footer."""
        if not self.module_attributes.footer:
            self.module_attributes.footer = []
        for line in footer_content:
            self.module_attributes.footer.append(line)
        return self

    def add_import(self, import_model: ImportModel) -> "ModuleModelBuilder":
        """Add an import to the imports list."""
        if not self.module_attributes.imports:
            self.module_attributes.imports = []
        # if "OpenAISummarizer" in [name.name for name in import_model.import_names]:
        #     print("Adding OpenAISummarizer import")
        self.module_attributes.imports.append(import_model)
        return self

    def update_import(
        self, updated_import_model: ImportModel, old_import_model: ImportModel
    ) -> "ModuleModelBuilder":
        """
        Update an import in the imports list.

        Loops through the imports list and replaces the old import with the updated import.

        Args:
            updated_import_model (ImportModel): The updated import model.
            old_import_model

        Returns:
            ModuleModelBuilder: The module model builder instance.

        Raises:
            Exception: If the import to be updated is not found.
        """
        if self.module_attributes.imports:
            import_to_remove: ImportModel | None = None
            for existing_import in self.module_attributes.imports:
                if (
                    existing_import.import_names == old_import_model.import_names
                    and existing_import.imported_from == old_import_model.imported_from
                    and existing_import.import_module_type
                    == old_import_model.import_module_type
                ):
                    import_to_remove = existing_import
                    # if "OpenAISummarizer" in [
                    #     name.name for name in existing_import.import_names
                    # ]:
                    #     print("Updating OpenAISummarizer import")
                    break

            if not import_to_remove:
                # raise Exception(f"Could not find import to remove: {old_import_model}")
                # print(f"Could not find import to remove: {old_import_model}")
                ...
            else:
                self.module_attributes.imports.remove(import_to_remove)
                self.module_attributes.imports.append(updated_import_model)
        else:
            raise Exception(
                f"No imports in the builders imports list: {self.module_attributes.imports}"
            )
        return self

    def _get_module_specific_attributes(self) -> dict[str, Any]:
        """Get the module specific attributes."""
        return self.module_attributes.model_dump()

    @logging_decorator(message="Building module model")
    def build(
        self,
    ) -> tuple[
        ModuleModel, list[ClassModel | FunctionModel | StandaloneCodeBlockModel] | None
    ]:
        """Builds and returns the module model instance after building and setting the children models."""
        self.build_children()
        self.set_children_ids()
        return (
            ModuleModel(
                **self._get_common_attributes(),
                **self._get_module_specific_attributes(),
            ),
            self.child_models,
        )



File: postcode/python_parser/model_builders/function_model_builder.py
----------------------------------------
from typing import Any

from postcode.python_parser.model_builders.base_model_builder import BaseModelBuilder

from postcode.utilities.logger.decorators import logging_decorator
from postcode.models.models import (
    DecoratorModel,
    FunctionModel,
    FunctionSpecificAttributes,
    ParameterListModel,
)
from postcode.models.enums import BlockType


class FunctionModelBuilder(BaseModelBuilder):
    """
    A builder class for constructing a model of a Python function.

    This class extends BaseModelBuilder and specializes in building a detailed model of a Python function, capturing various aspects such as function name, docstring, parameters, decorators, return type, and whether the function is a method or asynchronous.

    Attributes:
        - function_attributes (FunctionSpecificAttributes): An instance containing attributes specific to a function.

    Args:
        - id (str): The unique identifier for the function model.
        - function_name (str): The name of the function.
        - parent_id (str): The identifier of the parent model (e.g., module or class containing this function).
    """

    def __init__(self, id: str, function_name: str, parent_id: str, file_path: str) -> None:
        super().__init__(
            id=id,
            file_path=file_path,
            block_type=BlockType.FUNCTION,
            parent_id=parent_id,
        )
        self.function_attributes = FunctionSpecificAttributes(
            function_name=function_name,
            docstring=None,
            decorators=None,
            parameters=None,
            is_method=False,
            is_async=False,
            returns=None,
        )

    def set_parameters_list(
        self, parameter_list_model: ParameterListModel | None
    ) -> "FunctionModelBuilder":
        """Adds a parameter to the function model."""
        self.function_attributes.parameters = parameter_list_model
        return self

    def set_decorators(
        self, decorators: list[DecoratorModel] | None
    ) -> "FunctionModelBuilder":
        """Adds decorator to the decorators list in the class model."""
        if decorators:
            self.function_attributes.decorators = decorators
        else:
            self.function_attributes.decorators = None
        return self

    def set_docstring(self, docstring: str | None) -> "FunctionModelBuilder":
        """Sets the docstring."""
        self.function_attributes.docstring = docstring
        return self

    def set_return_annotation(self, return_type: str) -> "FunctionModelBuilder":
        """Sets the return type."""
        self.function_attributes.returns = return_type
        return self

    def set_is_method(self, is_method: bool) -> "FunctionModelBuilder":
        """Sets the is_method attribute in the function model."""
        self.function_attributes.is_method = is_method
        return self

    def set_is_async(self, is_async: bool) -> "FunctionModelBuilder":
        """Sets the is_async attribute in the function model."""
        self.function_attributes.is_async = is_async
        return self

    def _get_function_specific_attributes(self) -> dict[str, Any]:
        """
        Gets the function specific attributes from the builder.
        """
        return self.function_attributes.model_dump()

    @logging_decorator(message="Building function model")
    def build(self) -> FunctionModel:
        """Builds and returns the function model instance after building and setting the children models."""
        self.build_children()
        self.set_children_ids()
        return FunctionModel(
            **self._get_common_attributes(),
            **self._get_function_specific_attributes(),
        )



File: postcode/python_parser/model_builders/standalone_block_model_builder.py
----------------------------------------
from typing import Any

from postcode.utilities.logger.decorators import logging_decorator
from postcode.python_parser.model_builders.base_model_builder import BaseModelBuilder
from postcode.models.models import (
    StandaloneCodeBlockModel,
    StandaloneCodeBlockSpecificAttributes,
)
from postcode.models.enums import BlockType


class StandaloneBlockModelBuilder(BaseModelBuilder):
    """
    A builder class for constructing a model of a standalone code block.

    This class extends BaseModelBuilder and specializes in building models of standalone code blocks, which are blocks of code not part of any class or function definitions. It captures details such as variable assignments within the block.

    Attributes:
        - standalone_block_attributes (StandaloneCodeBlockSpecificAttributes): An instance containing attributes specific to a standalone code block, such as variable assignments.

    Args:
        - id (str): The unique identifier for the standalone code block model.
        - parent_id (str): The identifier of the parent model (e.g., module or class containing this standalone block).

    Example:
        ```Python
        standalone_block_builder = StandaloneBlockModelBuilder(id='block1', parent_id='module1')
        standalone_block_builder.set_variable_assignments(['x = 1', 'y = 2'])
        # Configures the builder with variable assignments for the standalone code block.
        ```
    """

    def __init__(self, id: str, parent_id: str, file_path: str) -> None:
        super().__init__(
            id=id,
            block_type=BlockType.STANDALONE_CODE_BLOCK,
            parent_id=parent_id,
            file_path=file_path,
        )

        self.standalone_block_attributes = StandaloneCodeBlockSpecificAttributes(
            variable_assignments=None,
        )

    def set_variable_assignments(
        self, variable_declarations: list[str]
    ) -> "StandaloneBlockModelBuilder":
        """Sets the list of variable declarations to the standalone code block model."""
        self.standalone_block_attributes.variable_assignments = variable_declarations
        return self

    def _get_standalone_block_specific_attributes(self) -> dict[str, Any]:
        """Gets the standalone block specific attributes."""
        return self.standalone_block_attributes.model_dump()

    @logging_decorator(message="Building standalone code block model")
    def build(self) -> StandaloneCodeBlockModel:
        """Creates a StandaloneCodeBlockModel instance after building and setting the children models."""
        return StandaloneCodeBlockModel(
            **self._get_common_attributes(),
            **self._get_standalone_block_specific_attributes(),
        )



File: postcode/python_parser/model_builders/builder_factory.py
----------------------------------------
from typing import Any, Callable, Literal, overload

from postcode.utilities.logger.decorators import logging_decorator

from postcode.python_parser.model_builders.class_model_builder import ClassModelBuilder
from postcode.python_parser.model_builders.function_model_builder import (
    FunctionModelBuilder,
)
from postcode.python_parser.model_builders.module_model_builder import (
    ModuleModelBuilder,
)
from postcode.python_parser.model_builders.standalone_block_model_builder import (
    StandaloneBlockModelBuilder,
)

from postcode.models.enums import BlockType


class BuilderFactory:
    """
    A factory class for creating instances of different types of model builders.

    This class uses a strategy pattern to map each block type to a corresponding builder creation function. Depending on the block type specified, it creates and returns an instance of the appropriate model builder class.

    The factory supports creating builders for modules, classes, functions, and standalone code blocks.

    Attributes:
        - _creation_strategies (dict[BlockType, Callable[..., Any]]): A dictionary mapping block types to their corresponding builder creation functions.

    Example:
        ```Python
        # This example demonstrates how to create a builder instance using the BuilderFactory.
        builder = BuilderFactory.create_builder_instance(
            block_type=BlockType.CLASS,
            id='class1',
            name='MyClass',
            parent_id='module1'
        )
        # This will create an instance of ClassModelBuilder for a class named 'MyClass'.
        ```

    Methods:
        - `@overload create_builder_instance(block_type: Literal[BlockType.MODULE], *, id: str, file_path: str, parent_id: str) -> ModuleModelBuilder`:
            Creates a ModuleModelBuilder instance for building module models.
        - `@overload create_builder_instance(block_type: Literal[BlockType.CLASS], *, id: str, name: str, parent_id: str, file_path: str) -> ClassModelBuilder`:
            Creates a ClassModelBuilder instance for building class models.
        - `@overload create_builder_instance(block_type: Literal[BlockType.FUNCTION], *, id: str, name: str, parent_id: str, file_path: str) -> FunctionModelBuilder`:
            Creates a FunctionModelBuilder instance for building function models.
        - `@overload create_builder_instance(block_type: Literal[BlockType.STANDALONE_CODE_BLOCK], *, id: str, parent_id: str, file_path: str) -> StandaloneBlockModelBuilder`:
            Creates a StandaloneBlockModelBuilder instance for building standalone code block models.
        - `@logging_decorator() @staticmethod create_builder_instance(block_type: BlockType, *, id: str, name: str | None = None, parent_id: str | None = None, file_path: str | None = None) -> Union[ModuleModelBuilder, ClassModelBuilder, FunctionModelBuilder, StandaloneBlockModelBuilder]`:
            Creates and returns an instance of a model builder based on the specified block type.
    """

    _creation_strategies: dict[BlockType, Callable[..., Any]] = {
        BlockType.MODULE: lambda id, file_path, name, parent_id: ModuleModelBuilder(
            id=id,
            file_path=file_path,
            parent_id=parent_id,
        ),
        BlockType.CLASS: lambda id, name, parent_id, file_path: ClassModelBuilder(
            id=id,
            class_name=name,
            parent_id=parent_id,
            file_path=file_path,
        ),
        BlockType.FUNCTION: lambda id, name, parent_id, file_path: FunctionModelBuilder(
            id=id,
            function_name=name,
            parent_id=parent_id,
            file_path=file_path,
        ),
        BlockType.STANDALONE_CODE_BLOCK: lambda id, parent_id, name, file_path: StandaloneBlockModelBuilder(
            id=id,
            parent_id=parent_id,
            file_path=file_path,
        ),
    }

    @staticmethod
    @overload
    def create_builder_instance(
        block_type: Literal[BlockType.MODULE],
        *,
        id: str,
        file_path: str,
        parent_id: str,
    ) -> ModuleModelBuilder:
        """
        Creates a ModuleModelBuilder instance for building module models.

        Args:
            - block_type: Specifies that a ModuleModelBuilder is to be created.
            - id (str): The unique identifier for the module model.
            - file_path (str): The file path of the module.

        Returns:
            - ModuleModelBuilder: An instance of ModuleModelBuilder.
        """
        ...

    @staticmethod
    @overload
    def create_builder_instance(
        block_type: Literal[BlockType.CLASS],
        *,
        id: str,
        name: str,
        parent_id: str,
        file_path: str,
    ) -> ClassModelBuilder:
        """
        Creates a ClassModelBuilder instance for building class models.

        Args:
            - block_type: Specifies that a ClassModelBuilder is to be created.
            - id (str): The unique identifier for the class model.
            - name (str): The name of the class.
            - parent_id (str): The identifier of the parent model.

        Returns:
            - ClassModelBuilder: An instance of ClassModelBuilder.
        """
        ...

    @staticmethod
    @overload
    def create_builder_instance(
        block_type: Literal[BlockType.FUNCTION],
        *,
        id: str,
        name: str,
        parent_id: str,
        file_path: str,
    ) -> FunctionModelBuilder:
        """
        Creates a FunctionModelBuilder instance for building function models.

        Args:
            - block_type: Specifies that a FunctionModelBuilder is to be created.
            - id (str): The unique identifier for the function model.
            - name (str): The name of the function.
            - parent_id (str): The identifier of the parent model.

        Returns:
            - FunctionModelBuilder: An instance of FunctionModelBuilder.
        """
        ...

    @staticmethod
    @overload
    def create_builder_instance(
        block_type: Literal[BlockType.STANDALONE_CODE_BLOCK],
        *,
        id: str,
        parent_id: str,
        file_path: str,
    ) -> StandaloneBlockModelBuilder:
        """
        Creates a StandaloneBlockModelBuilder instance for building standalone code block models.

        Args:
            - block_type: Specifies that a StandaloneBlockModelBuilder is to be created.
            - id (str): The unique identifier for the standalone code block model.
            - parent_id (str): The identifier of the parent model.

        Returns:
            - StandaloneBlockModelBuilder: An instance of StandaloneBlockModelBuilder.
        """
        ...

    @logging_decorator()
    @staticmethod
    def create_builder_instance(
        block_type: BlockType,
        *,
        id: str,
        name: str | None = None,
        parent_id: str | None = None,
        file_path: str | None = None,
    ) -> (
        ModuleModelBuilder
        | ClassModelBuilder
        | FunctionModelBuilder
        | StandaloneBlockModelBuilder
    ):
        """
        Creates and returns an instance of a model builder based on the specified block type.

        Depending on the block type (module, class, function, standalone code block), it creates an instance of the corresponding model builder class.

        Args:
            - block_type (BlockType): The type of code block for which the builder is to be created.
            - id (str): The unique identifier for the builder.
            name (str | None): The name of the code block (relevant for class or function blocks).
            parent_id (str | None): The identifier of the parent model (if applicable).
            file_path (str | None): The file path of the module (relevant for module blocks).

        Returns:
            Union[ModuleModelBuilder, ClassModelBuilder, FunctionModelBuilder, StandaloneBlockModelBuilder]:
            An instance of the appropriate model builder class.

        Raises:
            ValueError: If an unknown block type is provided.

        Example:
            ```Python
            # This example demonstrates how to create a builder instance using the BuilderFactory.
            builder = BuilderFactory.create_builder_instance(
                block_type=BlockType.CLASS,
                id='class1',
                name='MyClass',
                parent_id='module1'
            )
            # This will create an instance of ClassModelBuilder for a class named 'MyClass'.
            ```
        """

        if block_type not in BuilderFactory._creation_strategies:
            raise ValueError(f"Unknown node type: {block_type}")
        return BuilderFactory._creation_strategies[block_type](
            id=id, name=name, parent_id=parent_id, file_path=file_path
        )



File: postcode/python_parser/model_builders/class_model_builder.py
----------------------------------------
from __future__ import annotations
from typing import TYPE_CHECKING, Any

from postcode.utilities.logger.decorators import logging_decorator

from postcode.python_parser.model_builders.base_model_builder import BaseModelBuilder
from postcode.models.models import (
    ClassSpecificAttributes,
    ClassModel,
    FunctionModel,
    StandaloneCodeBlockModel,
)
from postcode.models.enums import BlockType


if TYPE_CHECKING:
    from postcode.models.models import (
        ClassKeywordModel,
        DecoratorModel,
    )


class ClassModelBuilder(BaseModelBuilder):
    """
    A builder class for constructing a model of a Python class.

    This class extends BaseModelBuilder and is specialized for building a model of a Python class, capturing details such as decorators, base classes, documentation strings, class attributes, and class-specific keywords.

    Attributes:
        - class_attributes (ClassSpecificAttributes): An instance containing attributes specific to a class, like name, decorators, bases, etc.

    Args:
        - id (str): The unique identifier for the class model.
        - class_name (str): The name of the class.
        - parent_id (str): The identifier of the parent model (e.g., module or class containing this class).
    """

    def __init__(
        self, id: str, class_name: str, parent_id: str, file_path: str
    ) -> None:
        super().__init__(
            id=id, block_type=BlockType.CLASS, parent_id=parent_id, file_path=file_path
        )

        self.class_attributes = ClassSpecificAttributes(
            class_name=class_name,
            decorators=None,
            bases=None,
            docstring=None,
            keywords=None,
        )

    def set_decorators(
        self, decorators: list[DecoratorModel] | None
    ) -> "ClassModelBuilder":
        """Adds decorator to the decorators list in the class model."""
        if decorators:
            self.class_attributes.decorators = decorators
        else:
            self.class_attributes.decorators = None
        return self

    def set_bases(self, base_classes: list[str] | None) -> "ClassModelBuilder":
        """Sets the list of base classes to the class model."""
        self.class_attributes.bases = base_classes
        return self

    def set_docstring(self, docstring: str | None) -> "ClassModelBuilder":
        """Sets the docstring of the class in the model."""
        self.class_attributes.docstring = docstring
        return self

    # # TODO: Add attribute model
    # def add_attribute(self, attribute) -> "ClassModelBuilder":
    #     """Adds an attribute of the class in the model."""
    #     if not self.class_attributes.attributes:
    #         self.class_attributes.attributes = []
    #     self.class_attributes.attributes.append(attribute)
    #     return self

    def set_keywords(
        self, keyword_list: list[ClassKeywordModel] | None
    ) -> "ClassModelBuilder":
        """Sets the list of keywords to the class model."""
        self.class_attributes.keywords = keyword_list
        return self

    def _get_class_specific_attributes(self) -> dict[str, Any]:
        """Gets the class specific attributes."""
        return self.class_attributes.model_dump()

    @logging_decorator(message="Building ClassModel")
    def build(
        self,
    ) -> ClassModel:
        """Creates a ClassModel instance after building and setting the children models."""
        self.build_children()
        self.set_children_ids()
        return ClassModel(
            **self._get_common_attributes(),
            **self._get_class_specific_attributes(),
        )



File: postcode/python_parser/model_builders/base_model_builder.py
----------------------------------------
from __future__ import annotations

from typing import TYPE_CHECKING, Any, Union
from abc import ABC, abstractmethod

from postcode.models.models import (
    BaseCodeBlockModel,
    ClassModel,
    CommentModel,
    FunctionModel,
    ImportModel,
    DependencyModel,
    BlockType,
    StandaloneCodeBlockModel,
)


if TYPE_CHECKING:
    from postcode.python_parser.model_builders.class_model_builder import (
        ClassModelBuilder,
    )
    from postcode.python_parser.model_builders.function_model_builder import (
        FunctionModelBuilder,
    )
    from postcode.python_parser.model_builders.module_model_builder import (
        ModuleModelBuilder,
    )
    from postcode.python_parser.model_builders.standalone_block_model_builder import (
        StandaloneBlockModelBuilder,
    )


class BaseModelBuilder(ABC):
    """
    Abstract base class for building models of different code blocks.

    This class follows the builder pattern, providing a structured approach to constructing models for various types of code blocks (like modules, classes, functions). It defines common attributes and methods used across all specific model builders.

    Attributes:
        - id (str): The unique identifier for the code block.
        - child_builders (list[Union[ClassModelBuilder, FunctionModelBuilder, StandaloneBlockModelBuilder]]):
            A list of builders for the children code blocks.
        - child_models (list[
            ClassModel | FunctionModel | StandaloneCodeBlockModel
        ] | None): A list of child models built by this builder.
        - common_attributes (BaseCodeBlockModel): An instance containing common attributes shared across different code block models.

    Example:
        ```Python
        # This example demonstrates how a derived builder might be initialized and used.
        class SomeModelBuilder(BaseModelBuilder):
            def build(self):
                # Building logic specific to 'SomeModelBuilder'
                pass
        builder = SomeModelBuilder(id='123', block_type=BlockType.CLASS, parent_id='root')
        builder.set_start_line_num(1).set_end_line_num(10)
        # Sets the start and end line numbers for the code block.
        ```

    Methods:
        - `set_start_line_num(line_num: int) -> Union[...]`: Sets the start line number of the code block model instance.
        - `set_end_line_num(line_num: int) -> Union[...]`: Sets the end line number of the code block model instance.
        - `set_code_content(code_content: str) -> Union[...]`: Adds the string containing the content of the code block to the model instance.
        - `add_important_comment(comment: CommentModel) -> Union[...]`: Adds an important comment to the model instance.
        - `add_summary(summary: str) -> Union[...]`: Adds a summary to the model instance.
        - `add_child_builder(child: Union[...]) -> Union[...]`: Adds a child code block to the model instance.
        - `set_dependencies(dependencies: list[ImportModel | DependencyModel] | None) -> Union[...]`: Sets the dependencies of the model instance.
        - `update_import_dependency(new_import_model: ImportModel, old_import_model: ImportModel) -> Union[...]`: Updates an import in the model instance.
        - `build_children() -> None`: Builds the child models of the code block.
        - `set_children_ids() -> Union[...]`: Sets the children ids of the model instance.
        - `_get_common_attributes() -> dict[str, Any]`: Returns a dictionary containing the attributes common to all code block models.
        - `@abstractmethod build() -> None`: Builds and returns the code block model instance.
    """

    def __init__(
        self, *, id: str, block_type: BlockType, parent_id: str | None, file_path: str
    ) -> None:
        self.id: str = id
        self.child_builders: list[
            ClassModelBuilder | FunctionModelBuilder | StandaloneBlockModelBuilder
        ] = []
        self.child_models: list[
            ClassModel | FunctionModel | StandaloneCodeBlockModel
        ] | None = None

        self.common_attributes = BaseCodeBlockModel(
            id=id,
            file_path=file_path,
            parent_id=parent_id,
            block_type=block_type,
            start_line_num=0,
            end_line_num=0,
            code_content="",
            important_comments=None,
            children_ids=None,
            dependencies=None,
            summary=None,
        )

    def set_start_line_num(
        self, line_num: int
    ) -> Union[
        "BaseModelBuilder",
        "ModuleModelBuilder",
        "ClassModelBuilder",
        "FunctionModelBuilder",
    ]:
        """Sets the start line number of the code block model instance."""
        self.common_attributes.start_line_num = line_num
        return self

    def set_end_line_num(
        self, line_num: int
    ) -> Union[
        "BaseModelBuilder",
        "ModuleModelBuilder",
        "ClassModelBuilder",
        "FunctionModelBuilder",
    ]:
        """Sets the end line number of the code block model instance."""
        self.common_attributes.end_line_num = line_num
        return self

    def set_code_content(
        self, code_content: str
    ) -> Union[
        "BaseModelBuilder",
        "ModuleModelBuilder",
        "ClassModelBuilder",
        "FunctionModelBuilder",
    ]:
        """Adds the string containing the content of the code block to the model instance."""
        self.common_attributes.code_content = code_content
        return self

    def add_important_comment(
        self, comment: CommentModel
    ) -> Union[
        "BaseModelBuilder",
        "ModuleModelBuilder",
        "ClassModelBuilder",
        "FunctionModelBuilder",
    ]:
        """Adds an important comment to the model instance."""
        if not self.common_attributes.important_comments:
            self.common_attributes.important_comments = []
        self.common_attributes.important_comments.append(comment)
        return self

    def add_summary(
        self, summary: str
    ) -> Union[
        "BaseModelBuilder",
        "ModuleModelBuilder",
        "ClassModelBuilder",
        "FunctionModelBuilder",
    ]:
        """Adds a summary to the model instance."""
        self.common_attributes.summary = summary
        # print(f"Added summary to {self.common_attributes.id}")
        return self

    def add_child_builder(
        self,
        child: Union[
            "ClassModelBuilder", "FunctionModelBuilder", StandaloneBlockModelBuilder
        ],
    ) -> Union[
        "BaseModelBuilder",
        "ModuleModelBuilder",
        "ClassModelBuilder",
        "FunctionModelBuilder",
    ]:
        """Adds a child code block to the model instance."""
        self.child_builders.append(child)
        return self

    def set_dependencies(
        self, dependencies: list[ImportModel | DependencyModel] | None
    ) -> Union[
        "BaseModelBuilder",
        "ModuleModelBuilder",
        "ClassModelBuilder",
        "FunctionModelBuilder",
    ]:
        """Sets the dependencies of the model instance."""
        self.common_attributes.dependencies = dependencies
        return self

    def update_import_dependency(
        self,
        new_import_model: ImportModel,
        old_import_model: ImportModel,
    ) -> Union[
        "BaseModelBuilder",
        "ModuleModelBuilder",
        "ClassModelBuilder",
        "FunctionModelBuilder",
    ]:
        """
        Updates an import in the model instance.

        Args:
            - new_import_model (ImportModel): The updated import model.
            - old_import_model

        Returns:
            - BaseModelBuilder: The base model builder instance.
        """

        if self.common_attributes.dependencies:
            import_model_to_remove: ImportModel | None = None
            for existing_import_model in self.common_attributes.dependencies:
                if isinstance(existing_import_model, DependencyModel):
                    continue

                if (
                    existing_import_model.import_names == old_import_model.import_names
                    and existing_import_model.imported_from
                    == old_import_model.imported_from
                    and existing_import_model.import_module_type
                    == old_import_model.import_module_type
                ):
                    import_model_to_remove = existing_import_model
                    break

            if not import_model_to_remove:
                raise Exception(f"Could not find import to remove: {old_import_model}")

            self.common_attributes.dependencies.remove(import_model_to_remove)
            self.common_attributes.dependencies.append(new_import_model)
        else:
            raise Exception(
                f"No imports in the builders imports list: {self.common_attributes.dependencies}"
            )
        return self

    def build_children(
        self,
    ) -> None:
        """Builds the child models of the code block."""
        if self.child_builders:
            self.child_models = []
            for child_builder in self.child_builders:
                self.child_models.append(child_builder.build())
                if child_builder.child_models:
                    self.child_models.extend(child_builder.child_models)

    def set_children_ids(
        self,
    ) -> Union[
        "BaseModelBuilder",
        "ModuleModelBuilder",
        "ClassModelBuilder",
        "FunctionModelBuilder",
    ]:
        """Sets the children ids of the model instance."""
        self.common_attributes.children_ids = [
            child.id for child in self.child_builders
        ]
        return self

    def _get_common_attributes(self) -> dict[str, Any]:
        """
        Returns a dictionary containing the attributes common to all code block models.
        """
        return self.common_attributes.model_dump()

    @abstractmethod
    def build(
        self,
    ) -> None:
        """
        Builds and returns the code block model instance.

        Returns:
            CodeBlockModel: The built code block model instance.
        """
        ...



File: postcode/python_parser/visitor_manager/visitor_manager.py
----------------------------------------
from dataclasses import dataclass
import logging
from pathlib import Path
from typing import Union

from postcode.python_parser.model_builders.module_model_builder import (
    ModuleModelBuilder,
)
from postcode.utilities.logger.decorators import logging_decorator

from postcode.python_parser.parsers.python_parser import PythonParser
from postcode.python_parser.visitor_manager.import_and_dependency_updater import (
    ImportAndDependencyUpdater,
)
from postcode.models.models import (
    ClassModel,
    DirectoryModel,
    FunctionModel,
    ModuleModel,
    StandaloneCodeBlockModel,
)


from postcode.python_parser.model_builders.class_model_builder import (
    ClassModelBuilder,
)
from postcode.python_parser.model_builders.function_model_builder import (
    FunctionModelBuilder,
)
from postcode.python_parser.model_builders.standalone_block_model_builder import (
    StandaloneBlockModelBuilder,
)

from postcode.python_parser.id_generation.id_generation_strategies import (
    ModuleIDGenerationStrategy,
    DirectoryIDGenerationStrategy,
)
from postcode.types.postcode import ModelType


BuilderType = Union[
    ModuleModelBuilder,
    ClassModelBuilder,
    FunctionModelBuilder,
    StandaloneBlockModelBuilder,
]

# ModelType = Union[
#     ModuleModel,
#     ClassModel,
#     FunctionModel,
#     StandaloneCodeBlockModel,
#     DirectoryModel,
# ]

EXCLUDED_DIRECTORIES: set[str] = {".venv", "node_modules", "__pycache__", ".git"}


@dataclass
class VisitorManagerProcessFilesReturn:
    """
    Represents the return value of the VisitorManager.process_files() method.

    Attributes:
        - models_tuple (tuple[ModuleModel, ...]): A tuple of ModuleModel objects representing the parsed modules.
        - directory_modules (dict[str, list[str]]): A dictionary mapping directory paths to lists of module names.
            This is used to keep track of the modules present in each directory.
    """

    models_tuple: tuple[ModelType, ...]
    directory_modules: dict[str, list[str]]


@dataclass
class DirectoryDetails:
    """
    Represents the details of a directory.

    Attributes:
        - directory_name (str): The name of the directory.
        - sub_directories (list[str]): A list of the names of the sub-directories of the directory.
        - module_ids (list[str]): A list of the module ids of the modules in the directory.
    """

    directory_name: str
    sub_directories: list[str]
    module_ids: list[str]


class VisitorManager:
    """
    Manages the visiting and processing of Python files in a given directory.

    This class scans a specified directory, filters for Python files, parses them, and saves the parsed data in a structured JSON format.
    It also maintains a mapping of directories to the Python files they contain.

    Attributes:
        - directory (str): The root directory to scan for Python files.
        - directory_modules (dict[str, list[str]]): A mapping of directories to their contained Python files.

    Example:
        ```Python
        visitor_manager = VisitorManager("/path/to/python/code")
        visitor_manager.process_files()
        # This will process all Python files in /path/to/python/code and save their parsed data in the output directory.
        ```
    """

    @logging_decorator(message="Initializing VisitorManager")
    def __init__(self, directory: str) -> None:
        self.directory: str = directory
        self.directory_modules: dict[str, list[str]] = {}

    def process_files(self) -> VisitorManagerProcessFilesReturn:
        """
        Process the files in the directory and return the module models.

        This function iterates through all the Python files in the directory, processes each file,
        updates the imports, and builds module models for each file. It returns a tuple of module models
        and a dictionary of directory modules.

        Returns:
            - VisitorManagerProcessFilesReturn, a named tuple containing:
                - models_tuple (tuple[ModuleModel, ...]): A tuple of module models.
                - directory_modules (dict[str, ModuleModel]): A dictionary of directory modules.

        Examples:
            ```Python
            visitor_manager = VisitorManager()
            result = visitor_manager.process_files()
            print(result.models_tuple)
            # (ModuleModel(file_path='/path/to/file1.py'), ModuleModel(file_path='/path/to/file2.py'))
            print(result.directory_modules)
            {'/path/to/directory1': ModuleModel(file_path='/path/to/directory1/__init__.py')}
            ```
        """

        logging.info("Processing files")
        python_files: list[str] = self._get_python_files()
        model_builder_list: list[ModuleModelBuilder] = []
        for file_path in python_files:
            if model_builder := self._process_file(file_path):
                model_builder_list.append((model_builder))

        logging.info("File processing completed")
        logging.info("Updating imports")

        model_builder_tuple: tuple[ModuleModelBuilder, ...] = tuple(model_builder_list)

        import_and_dependency_updater = ImportAndDependencyUpdater(model_builder_tuple)
        import_and_dependency_updater.update_imports()
        logging.info("Updated imports")

        models_list: list[
            ModuleModel | ClassModel | FunctionModel | StandaloneCodeBlockModel
        ] = []
        for module_model_builder in model_builder_tuple:
            module_model_return: tuple[
                ModuleModel,
                list[ClassModel | FunctionModel | StandaloneCodeBlockModel] | None,
            ] = self._build_module_model(module_model_builder)
            models_list.append(module_model_return[0])
            if module_model_return[1]:
                models_list.extend(module_model_return[1])

        directory_models_list: list[DirectoryModel] = []
        for directory_path in self.directory_modules.keys():
            directory_model: DirectoryModel = self._build_directory_model(
                directory_path
            )
            directory_models_list.append(directory_model)

        all_models: list[ModelType] = [
            *models_list,
            *directory_models_list,
        ]

        models_tuple: tuple[ModelType, ...] = tuple(all_models)

        return VisitorManagerProcessFilesReturn(
            models_tuple=models_tuple, directory_modules=self.directory_modules
        )

    def _walk_directories(self) -> list[str]:
        """Walks the specified directory and returns a list of all files."""

        all_files: list[str] = []
        for file_path in Path(self.directory).rglob("*"):
            if not any(
                excluded in file_path.parts for excluded in EXCLUDED_DIRECTORIES
            ):
                all_files.append(str(file_path))
        return all_files

    def _filter_python_files(self, files: list[str]) -> list[str]:
        """Filters a list of files to only include Python files."""

        return [file for file in files if file.endswith(".py")]

    @logging_decorator(message="Getting Python files")
    def _get_python_files(self) -> list[str]:
        """Gets all Python files in the specified directory."""

        all_files: list[str] = self._walk_directories()
        return self._filter_python_files(all_files)

    def _process_file(self, file_path: str) -> ModuleModelBuilder | None:
        """Processes a single Python file."""

        file_path_obj = Path(file_path)
        root = str(file_path_obj.parent)
        self.directory_modules.setdefault(root, []).append(file_path_obj.name)
        return self._parse_file(file_path)

    @logging_decorator(message="Processing file")
    def _parse_file(self, file_path: str) -> ModuleModelBuilder | None:
        """Parses a Python file and saves the parsed data as JSON."""

        parser = PythonParser(file_path)
        code: str = parser.open_file()

        parent_id: str | None = self._get_parent_directory_id(file_path)
        if not parent_id:
            parent_id = ""

        module_model_builder: ModuleModelBuilder | None = parser.parse(code, parent_id)

        return module_model_builder if module_model_builder else None

    def _build_module_model(
        self, visitor_stack: ModuleModelBuilder | None
    ) -> tuple[
        ModuleModel, list[ClassModel | FunctionModel | StandaloneCodeBlockModel] | None
    ]:
        """
        Builds a module model from the provided module builder.

        Args:
            - visitor_stack (ModuleModelBuilder): The module builder to build the model from.

        Returns:
            - ModuleModel: A structured module model.
        """

        if not isinstance(visitor_stack, ModuleModelBuilder):
            raise TypeError("Expected the first builder to be a ModuleModelBuilder")

        return visitor_stack.build()

    def _build_directory_model(self, directory_path: str) -> DirectoryModel:
        """Builds a directory model for the given directory path."""

        id: str = DirectoryIDGenerationStrategy().generate_id(directory_path)
        parent_id: str | None = self._get_parent_directory_id(directory_path)

        return DirectoryModel(
            id=id,
            parent_id=parent_id,
            directory_name=self._get_directory_name(directory_path),
            sub_directories_ids=self._get_subdirectory_ids(directory_path),
            children_ids=self._generate_module_ids(directory_path),
        )

    def _get_subdirectory_ids(self, directory_path: str) -> list[str]:
        """Gets the sub-directories of the given directory."""

        subdirectories: list[str] = [
            directory.name
            for directory in Path(directory_path).iterdir()
            if directory.is_dir() and directory.name not in EXCLUDED_DIRECTORIES
        ]

        subdirectory_ids: list[str] = [
            DirectoryIDGenerationStrategy().generate_id(
                str(Path(directory_path) / subdirectory)
            )
            for subdirectory in subdirectories
        ]

        return subdirectory_ids

    def _get_directory_name(self, directory_path: str) -> str:
        """Gets the name of the given directory."""

        return Path(directory_path).name

    def _generate_module_ids(self, directory_path: str) -> list[str]:
        """Generates module ids for the given directory."""

        file_names: list[str] = self.directory_modules.get(directory_path, [])
        python_files: list[str] = self._filter_python_files(file_names)

        return [
            ModuleIDGenerationStrategy.generate_id(str(Path(directory_path) / module))
            for module in python_files
        ]

    def _get_parent_directory_id(self, directory_path: str) -> str | None:
        """Gets the parent id of the given directory."""

        parent_path: str = str(Path(directory_path).parent)
        if parent_path == self.directory:
            return None
        else:
            return DirectoryIDGenerationStrategy().generate_id(parent_path)



File: postcode/python_parser/visitor_manager/import_and_dependency_updater.py
----------------------------------------
# TODO: Add logic to update imports when defined in a StandaloneCodeBlock
# TODO: Add logic to track down the import's definition location
# FIXME: There is still an issue with the imports being updated twice for some reason

from postcode.python_parser.model_builders.module_model_builder import (
    ModuleModelBuilder,
)
from postcode.models.models import (
    DependencyModel,
    ImportModel,
    ImportNameModel,
    ImportModuleType,
)


class ImportAndDependencyUpdater:
    """
    The ImportAndDependencyUpdater class is designed to update import statements and
    dependencies in a set of module model builders. It manages two main tasks: updating
    import statements using an ImportUpdater and updating dependencies using a DependencyUpdater.
    This class ensures that both imports and dependencies are consistent and up-to-date
    across the provided module model builders.

    Attributes:
        - model_builder_tuple (tuple[ModuleModelBuilder, ...]): A tuple of ModuleModelBuilder instances
        to be processed for import and dependency updates.

    Example:
        ```Python
        model_builders = [ModuleModelBuilder(), ModuleModelBuilder()]
        updater = ImportAndDependencyUpdater(model_builders)
        updater.update_imports()
        ```
    """

    def __init__(self, model_builder_tuple: tuple[ModuleModelBuilder, ...]) -> None:
        self.model_builder_tuple: tuple[ModuleModelBuilder, ...] = model_builder_tuple

    def update_imports(self) -> None:
        """
        Processes each module model builder in the model_builder_tuple and updates their import
        statements. This method is the primary entry point for initiating the import update process.

        Example:
            ```Python
            updater = ImportAndDependencyUpdater(model_builders)
            updater.update_imports()
            ```
        """

        for model_builder in self.model_builder_tuple:
            import_updater: ImportUpdater = ImportUpdater(self.model_builder_tuple)
            import_updater.process_builder(model_builder)

            # for model_builder in self.model_builder_tuple:
            ...
        # Track down and add imports for the imports that were defined outside of the module that it is imported from


class ImportUpdater:
    """
    The ImportUpdater class is designed to manage and update import statements across
    a collection of module model builders. It processes each builder in the provided
    list, handling and updating import models as required. This class plays a crucial
    role in ensuring that import statements are correctly managed and updated in response
    to changes in the module models.

    Attributes:
        - model_builder_tuple (tuple[ModuleModelBuilder, ...]): A tuple of ModuleModelBuilder
        instances to be processed for import updates.

    Example:
        ```Python
        model_builders = [ModuleModelBuilder(), ModuleModelBuilder()]
        import_updater = ImportUpdater(model_builders)
        for builder in model_builders:
            import_updater.process_builder(builder)
        ```
    """

    def __init__(self, model_builder_tuple: tuple[ModuleModelBuilder, ...]) -> None:
        self.model_builder_tuple: tuple[ModuleModelBuilder, ...] = model_builder_tuple

    def process_builder(self, builder: ModuleModelBuilder) -> None:
        """
        Processes a single module model builder to update its import statements.

        Args:
            - builder (ModuleModelBuilder): The module model builder to process.
        """

        if module_imports := builder.module_attributes.imports:
            module_imports_tuple = tuple(module_imports)
            self._handle_import_models(builder, module_imports_tuple)
            # print(module_imports_tuple)

    def _handle_import_models(
        self, builder: ModuleModelBuilder, module_imports_tuple: tuple[ImportModel, ...]
    ) -> None:
        """
        Handles the import models for a given builder and updates them as necessary.

        Args:
            - builder (ModuleModelBuilder): The builder whose import models are to be handled.
            - module_imports (tuple[ImportModel]): A tuple of import models to process.
        """

        # module_imports_tuple = tuple(module_imports)
        # # HACK: Converts to tuple in order to prevent missing elements as the list was getting modified during iteration

        for import_model in module_imports_tuple:
            self._update_import_for_builder(builder, import_model)

            DependencyUpdater.update_dependencies(builder)

    def _update_import_for_builder(
        self, builder: ModuleModelBuilder, import_model: ImportModel
    ) -> None:
        """
        Updates a single import model for the given builder. Determines if the import is local,
        and if so, updates the import path and names accordingly.

        Args:
            - builder (ModuleModelBuilder): The builder that owns the import model.
            - import_model (ImportModel): The import model to be updated.

        Example:
            ```Python
            updater = ImportUpdater(model_builder_tuple)
            updater._update_import_for_builder(builder_instance, import_model_instance)
            ```
        """

        if self._is_local_import(import_model):
            import_path: str = self._get_import_path(import_model)
            import_names: list[str] | None = None

            if import_model.imported_from:
                import_names = self._get_import_names(import_model)
            # else:
            #     import_path: str = self._get_import_path(import_model)

            for external_builder in self.model_builder_tuple:
                if self._should_skip_builder(
                    builder, external_builder, import_path, import_model
                ):
                    continue

                self._update_import_model(
                    import_model, import_names, builder, external_builder
                )

    def _is_local_import(self, import_model: ImportModel) -> bool:
        """Returns boolean indicating whether the import is local to the project."""
        return import_model.import_module_type == ImportModuleType.LOCAL

    def _get_import_names(self, import_model: ImportModel) -> list[str]:
        """Returns a list of import names for the given import model."""
        return [name.name for name in import_model.import_names]

    def _get_import_path(self, import_model: ImportModel) -> str:
        """Returns the import path for the given import model."""

        if import_model.imported_from:
            return import_model.imported_from.replace(".", ":")
        else:
            return import_model.import_names[0].name.replace(".", ":")

    def _should_skip_builder(
        self,
        builder: ModuleModelBuilder,
        external_builder: ModuleModelBuilder,
        import_path: str,
        import_model: ImportModel,
    ) -> bool:
        """Returns boolean indicating if the given builder should be skipped."""

        return (
            external_builder.id == builder.id
            or not import_path in external_builder.id
            or import_model.local_module_id is not None
        )

    def _update_import_model(
        self,
        import_model: ImportModel,
        import_names: list[str] | None,
        builder: ModuleModelBuilder,
        external_builder: ModuleModelBuilder,
    ) -> None:
        """
        Updates the import model with new import names and assigns the local module ID to the external builder.

        Args:
            - import_model (ImportModel): The import model to be updated.
            - import_names (list[str] | None): The list of new import names.
            - builder (ModuleModelBuilder): The module model builder.
            - external_builder (ModuleModelBuilder): The external module model builder.

        Returns:
            - None

        Example:
            ```Python
            import_updater._update_import_model(import_model_instance, import_names_list, builder_instance, external_builder_instance)
            ```
        """
        new_import_model: ImportModel = import_model.model_copy()
        new_import_model.local_module_id = external_builder.id

        if not import_model.imported_from:
            builder.update_import(new_import_model, import_model)
            return

        if import_names:
            new_import_name_models: list[
                ImportNameModel
            ] = self._get_new_import_name_models(
                external_builder, import_names, import_model
            )
            # print(f"{len(new_import_name_models)} : {len(import_model.import_names)}")
            if len(new_import_name_models) < len(import_model.import_names):
                # TODO: Add logic to track down the import's definition location

                new_import_name_models = self._add_missing_imports(
                    new_import_name_models, import_model.import_names
                )

            new_import_model.import_names = new_import_name_models
            builder.update_import(new_import_model, import_model)

    def _get_new_import_name_models(
        self,
        external_builder: ModuleModelBuilder,
        import_names: list[str],
        import_model: ImportModel,
    ) -> list[ImportNameModel]:
        """
        Returns a list of new ImportNameModel objects based on the given import names.

        Args:
            - external_builder (ModuleModelBuilder): The external module builder.
            - import_names (list[str]): The list of import names.
            - import_model (ImportModel): The import model.

        Returns:
            - list[ImportNameModel]: The list of new ImportNameModel objects.

        Example:
            ```Python
            new_import_name_models = import_updater._get_new_import_name_models(external_builder_instance, import_names_list, import_model_instance)
            ```
        """

        new_import_name_models: list = []
        for child_builder in external_builder.child_builders:
            for import_name in import_names:
                child_builder_id_split: list[str] = child_builder.id.split("-")

                if import_name == child_builder_id_split[-1]:
                    for import_name_model in import_model.import_names:
                        if import_name_model.name == import_name:
                            new_import_name_model: ImportNameModel = (
                                import_name_model.model_copy()
                            )
                            # if import_name_model.name == "OpenAISummarizer":
                            #     print(f"Found OpenAISummarizer: id")

                            new_import_name_model.local_block_id = child_builder.id
                            new_import_name_models.append(new_import_name_model)
                            break

        return new_import_name_models

    def _add_missing_imports(
        self,
        new_import_name_models: list[ImportNameModel],
        existing_import_names: list[ImportNameModel],
    ) -> list[ImportNameModel]:
        """
        Adds missing import names to the list of new ImportNameModel objects.

        Args:
            - new_import_name_models (list[ImportNameModel]): The list of new ImportNameModel objects.
            - existing_import_names (list[ImportNameModel]): The list of existing ImportNameModel objects.

        Returns:
            - list[ImportNameModel]: The updated list of new ImportNameModel objects.

        Example:
            ```Python
            updated_import_names = import_updater._add_missing_imports(new_import_name_models_list, existing_import_names_list)
            ```
        """

        for import_name_model in existing_import_names:
            if import_name_model.name not in [
                name.name for name in new_import_name_models
            ]:
                new_import_name_models.append(import_name_model)

        return new_import_name_models


class DependencyUpdater:
    """
    Class responsible for updating dependencies in a module.

    Methods:
        - `update_dependencies` (staticmethod): Updates the dependencies in the module.

    Examples:
        ```Python
        model_builder = ModuleModelBuilder()

        DependencyUpdater.update_dependencies(model_builder)
        ```
    """

    @staticmethod
    def update_dependencies(model_builder: ModuleModelBuilder) -> None:
        """
        Updates the dependencies in the module.

        Args:
            - model_builder (ModuleModelBuilder): The module model builder to update the dependencies for.

        Returns:
            - None

        Example:
            ```Python
            model_builder = ModuleModelBuilder()

            DependencyUpdater.update_dependencies(model_builder)
            ```
        """

        import_model_list: list[
            ImportModel
        ] | None = model_builder.module_attributes.imports
        if model_builder.child_builders:
            for child_builder in model_builder.child_builders:
                if (
                    not child_builder.common_attributes.dependencies
                    or not import_model_list
                ):
                    continue

                dependencies_to_process: tuple[
                    ImportModel | DependencyModel, ...
                ] = tuple(child_builder.common_attributes.dependencies)
                imports_to_process: tuple[ImportModel, ...] = tuple(import_model_list)
                for dependency in dependencies_to_process:
                    if isinstance(dependency, DependencyModel):
                        continue

                    dependency_import_names: list[str] = [
                        name.name for name in dependency.import_names
                    ]

                    for import_model in imports_to_process:
                        import_model_import_names: list[str] = [
                            name.name for name in import_model.import_names
                        ]

                        if (
                            dependency_import_names == import_model_import_names
                            and dependency.imported_from == import_model.imported_from
                        ):
                            child_builder.update_import_dependency(
                                import_model, dependency
                            )
                            break



File: postcode/models/enums.py
----------------------------------------
from enum import Enum


class ImportModuleType(str, Enum):
    """Enum of import module types."""

    STANDARD_LIBRARY = "STANDARD_LIBRARY"
    LOCAL = "LOCAL"
    THIRD_PARTY = "THIRD_PARTY"

    def __str__(self) -> str:
        return self.value


class CommentType(str, Enum):
    """Enum representing the different types of important comments."""

    TODO = "TODO"
    FIXME = "FIXME"
    NOTE = "NOTE"
    HACK = "HACK"
    XXX = "XXX"
    REVIEW = "REVIEW"
    OPTIMIZE = "OPTIMIZE"
    CHANGED = "CHANGED"
    QUESTION = "QUESTION"
    Q = "Q"
    DEPRECATED = "@deprecated"
    NOSONAR = "NOSONAR"
    TODO_FIXME = "TODO-FIXME"

    def __str__(self) -> str:
        return self.value


class BlockType(str, Enum):
    """Enum of code block types."""

    STANDALONE_CODE_BLOCK = "STANDALONE_BLOCK"
    CLASS = "CLASS"
    FUNCTION = "FUNCTION"
    MODULE = "MODULE"
    DIRECTORY = "DIRECTORY"

    def __str__(self) -> str:
        return self.value



File: postcode/models/models.py
----------------------------------------
import logging
from pydantic import BaseModel, Field, field_validator

from postcode.models.enums import (
    BlockType,
    ImportModuleType,
    CommentType,
)


class ImportNameModel(BaseModel):
    """Class representing the name of an import."""

    name: str
    as_name: str | None = None
    local_block_id: str | None = None

    @classmethod
    def _build_from_metadata(cls, metadata: dict[str, str]) -> "ImportNameModel":
        """
        Builds an ImportNameModel from a metadata dictionary.

        Args:
            metadata (dict[str, str]): A dictionary containing metadata for an import name.

        Returns:
            ImportNameModel: An instance of ImportNameModel.
        """
        try:
            if not isinstance(metadata, dict):
                raise ValueError("Metadata must be a dictionary.")

            name: str | None = metadata.get("name")
            if not name:
                raise ValueError("Import name must be a string.")

            return cls(
                name=name,
                as_name=metadata.get("as_name"),
                local_block_id=metadata.get("local_block_id"),
            )
        except ValueError as ve:
            logging.error(f"Error building from metadata: {ve}")
            raise ve
        except Exception as e:
            logging.error(f"An unexpected error occurred: {e}")
            raise e


class ImportModel(BaseModel):
    """Class representing an import statement."""

    import_names: list[ImportNameModel]
    imported_from: str | None = None
    import_module_type: ImportModuleType = ImportModuleType.STANDARD_LIBRARY
    local_module_id: str | None = None

    def convert_import_to_metadata(self) -> str:
        """Converts the import to a metadata string."""
        return self.model_dump_json()

    @classmethod
    def _build_from_metadata(
        cls, metadata: dict[str, str | list[dict[str, str]]]
    ) -> "ImportModel":
        """
        Builds an ImportModel from a metadata dictionary.

        Args:
            metadata (dict): A dictionary containing metadata for an import statement.

        Returns:
            ImportModel: An instance of ImportModel.
        """
        try:
            if not isinstance(metadata, dict):
                raise ValueError("Metadata must be a dictionary.")

            import_names_data = metadata.get("import_names", [])
            if not isinstance(import_names_data, list):
                raise ValueError("import_names must be a list.")

            import_names = [
                ImportNameModel._build_from_metadata(name) for name in import_names_data
            ]

            import_from = metadata.get("imported_from")

            if not isinstance(import_from, str):
                raise ValueError("imported_from must be a string.")

            if import_from == "":
                import_from = None

            import_module_type_raw = metadata.get("import_module_type")
            if not isinstance(import_module_type_raw, str):
                raise ValueError("import_module_type must be a string.")

            try:
                import_module_type = ImportModuleType(metadata["import_module_type"])
            except ValueError:
                raise ValueError("Invalid import module type.")

            local_module_id = metadata.get("local_module_id")
            if not isinstance(local_module_id, str):
                raise ValueError("local_module_id must be a string.")

            if not local_module_id:
                raise ValueError("local_module_id cannot be empty.")

            return cls(
                import_names=import_names,
                imported_from=import_from,
                import_module_type=import_module_type,
                local_module_id=local_module_id,
            )
        except ValueError as ve:
            logging.error(f"Error building from metadata: {ve}")
            raise ve
        except Exception as e:
            logging.error(f"An unexpected error occurred: {e}")
            raise e


class DependencyModel(BaseModel):
    """Class representing a module dependency."""

    code_block_id: str

    def convert_dependency_to_metadata(self) -> str:
        """Converts the dependency to a metadata string."""
        return self.model_dump_json()

    @classmethod
    def _build_from_metadata(cls, metadata: dict[str, str]) -> "DependencyModel":
        """Builds a DependencyModel from a metadata dictionary."""

        try:
            if not isinstance(metadata, dict):
                raise ValueError("Metadata must be a dictionary.")

            return cls(
                code_block_id=metadata["code_block_id"],
            )
        except ValueError as ve:
            logging.error(f"Error building from metadata: {ve}")
            raise ve
        except Exception as e:
            logging.error(f"An unexpected error occurred: {e}")
            raise e


class CommentModel(BaseModel):
    """Class representing a comment."""

    content: str
    comment_types: list[CommentType]

    def convert_comment_to_metadata(self) -> str:
        """Converts the comment to a metadata string."""
        return self.model_dump_json()

    @classmethod
    def _build_from_metadata(
        cls, metadata: dict[str, str | list[str]]
    ) -> "CommentModel":
        """Builds a CommentModel from a metadata dictionary."""
        try:
            if not isinstance(metadata, dict):
                raise ValueError("Metadata must be a dictionary.")

            content = metadata.get("content", "")
            if not isinstance(content, str):
                raise ValueError("Content must be a string.")

            comment_types_raw = metadata.get("comment_types", [])
            if not isinstance(comment_types_raw, list):
                raise ValueError("Comment types must be a list.")

            comment_types: list[CommentType] = []
            for comment_type_str in comment_types_raw:
                try:
                    comment_type = CommentType(comment_type_str)
                    comment_types.append(comment_type)
                except ValueError:
                    raise ValueError(f"Invalid comment type: {comment_type_str}")

            return cls(content=content, comment_types=comment_types)
        except ValueError as ve:
            logging.error(f"Error building from metadata: {ve}")
            raise
        except Exception as e:
            logging.error(f"An unexpected error occurred: {e}")
            raise


class DecoratorModel(BaseModel):
    """Class representing a decorator."""

    content: str
    decorator_name: str
    decorator_args: list[str] | None = None

    def convert_decorator_to_metadata(self) -> str:
        """Converts the decorator to a metadata string."""
        return self.model_dump_json()

    @classmethod
    def _build_from_metadata(
        cls, metadata: dict[str, str | list[str] | None]
    ) -> "DecoratorModel":
        """Builds a DecoratorModel from a metadata dictionary."""
        try:
            # Ensure the metadata is a dictionary
            if not isinstance(metadata, dict):
                raise ValueError("Metadata must be a dictionary.")

            content = metadata.get("content", "")
            decorator_name = metadata.get("decorator_name", "")

            if not isinstance(decorator_name, str) and not isinstance(content, str):
                raise ValueError("Decorator name and content must be strings.")

            # Handle decorator_args, ensuring it's a list[str] or None
            decorator_args_raw = metadata.get("decorator_args")
            decorator_args = None  # Default to None
            if isinstance(decorator_args_raw, list):
                # If it's a list, ensure all elements are strings
                if all(isinstance(arg, str) for arg in decorator_args_raw):
                    decorator_args = decorator_args_raw
                else:
                    raise ValueError("All decorator arguments must be strings.")
            elif isinstance(decorator_args_raw, str):
                # If it's a string, wrap it in a list
                decorator_args = [decorator_args_raw]
            elif decorator_args_raw is not None:
                # If it's not a list, string, or None, it's an invalid type
                raise ValueError(
                    "Decorator arguments must be a string, a list of strings, or None."
                )

            return cls(content=content, decorator_name=decorator_name, decorator_args=decorator_args)  # type: ignore # FIXME: fix type hinting error
        except ValueError as ve:
            print(f"Error building from metadata: {ve}")
            raise
        except Exception as e:
            print(f"An unexpected error occurred: {e}")
            raise


class ClassKeywordModel(BaseModel):
    """Class representing a class keyword."""

    content: str
    keyword_name: str
    args: str | None = None

    def convert_class_keyword_to_metadata(self) -> str:
        """Converts the class keyword to a metadata string."""
        return self.model_dump_json()

    @classmethod
    def _build_from_metadata(cls, metadata: dict[str, str]) -> "ClassKeywordModel":
        """Builds a ClassKeywordModel from a metadata dictionary."""

        try:
            if not isinstance(metadata, dict):
                raise ValueError("Metadata must be a dictionary.")

            return cls(
                content=metadata["content"],
                keyword_name=metadata["keyword_name"],
                args=metadata["args"] if "args" in metadata else None,
            )
        except ValueError as ve:
            logging.error(f"Error building from metadata: {ve}")
            raise ve
        except Exception as e:
            logging.error(f"An unexpected error occurred: {e}")
            raise e


class ParameterModel(BaseModel):
    """Class representing a function parameter."""

    content: str


class ParameterListModel(BaseModel):
    """Class representing a list of parameters."""

    params: list[ParameterModel] | None = None
    star_arg: ParameterModel | None = None
    kwonly_params: list[ParameterModel] | None = None
    star_kwarg: ParameterModel | None = None
    posonly_params: list[ParameterModel] | None = None

    def convert_parameters_to_metadata(self) -> str:
        """Converts the parameter list to a metadata string."""
        return self.model_dump_json()

    @classmethod
    def _build_from_metadata(cls, metadata: dict[str, str]) -> "ParameterListModel":
        """Builds a ParameterListModel from a metadata dictionary."""

        try:
            if not isinstance(metadata, dict):
                raise ValueError("Metadata must be a dictionary.")

            params: list[ParameterModel] | None = (
                [ParameterModel(content=param) for param in metadata.get("params", [])]
                if "params" in metadata and isinstance(metadata["params"], list)
                else None
            )
            star_arg: ParameterModel | None = (
                ParameterModel(content=metadata["star_arg"])
                if "star_arg" in metadata and isinstance(metadata["star_arg"], str)
                else None
            )
            kwonly_params: list[ParameterModel] | None = (
                [
                    ParameterModel(content=param)
                    for param in metadata.get("kwonly_params", [])
                ]
                if "kwonly_params" in metadata
                and isinstance(metadata["kwonly_params"], list)
                else None
            )
            star_kwarg: ParameterModel | None = (
                ParameterModel(content=metadata["star_kwarg"])
                if "star_kwarg" in metadata and isinstance(metadata["star_kwarg"], str)
                else None
            )
            posonly_params: list[ParameterModel] | None = (
                [
                    ParameterModel(content=param)
                    for param in metadata.get("posonly_params", [])
                ]
                if "posonly_params" in metadata
                and isinstance(metadata["posonly_params"], list)
                else None
            )

            return cls(
                params=params,
                star_arg=star_arg,
                kwonly_params=kwonly_params,
                star_kwarg=star_kwarg,
                posonly_params=posonly_params,
            )
        except ValueError as ve:
            logging.error(f"Error building from metadata: {ve}")
            raise ve
        except Exception as e:
            logging.error(f"An unexpected error occurred: {e}")
            raise e


class BaseCodeBlockModel(BaseModel):
    """Attributes common to all code block models."""

    id: str
    file_path: str = Field(min_length=1)
    parent_id: str | None = None
    block_type: BlockType
    start_line_num: int
    end_line_num: int
    code_content: str = ""
    important_comments: list[CommentModel] | None = None
    dependencies: list[ImportModel | DependencyModel] | None = None
    summary: str | None = None
    children_ids: list[str] | None = []

    @field_validator("parent_id")
    def check_parent_id(cls, v, values) -> str | None:
        """Validates that parent_id is a non-empty string unless block_type is MODULE."""
        block_type = (
            values.get("block_type")
            if isinstance(values, dict)
            else values.data.get("block_type")
        )

        if block_type and block_type != BlockType.MODULE:
            if v is None or len(v) < 1:
                raise ValueError(
                    "parent_id must be a non-empty string unless block_type is MODULE"
                )
        return v

    def _convert_parent_id_to_metadata(self) -> str:
        """Converts the parent_id to a metadata string."""
        return f"{self.parent_id}" if self.parent_id else ""

    def _convert_block_type_to_metadata(self) -> str:
        """Converts the block_type to a metadata string."""
        return f"{self.block_type.name}"

    def _convert_important_comments_to_metadata(self) -> str:
        """Converts the important comments to a metadata string."""

        important_comments: str = (
            self.model_dump_json() if self.important_comments else ""
        )

        return f"{important_comments}"

    def _convert_dependencies_to_metadata(self) -> str:
        """Converts the dependencies to a metadata string."""

        dependencies_str: str = ""

        if self.dependencies:
            for dependency in self.dependencies:
                if isinstance(dependency, ImportModel):
                    dependencies_str += f"{dependency.convert_import_to_metadata()}\n"
                elif isinstance(dependency, DependencyModel):
                    dependencies_str += (
                        f"{dependency.convert_dependency_to_metadata()}\n"
                    )

        return dependencies_str

    def _convert_summary_to_metadata(self) -> str:
        """Converts the summary to a metadata string."""
        return f"{self.summary}" if self.summary else ""

    def _convert_children_to_metadata(self) -> str:
        """Converts the children to a metadata string."""

        return str(self.children_ids) if self.children_ids else ""

    def _convert_base_attributes_to_metadata_dict(self) -> dict[str, str | int]:
        """Converts the base attributes to a metadata dictionary for ChromaDB."""

        return {
            "id": self.id,
            "file_path": self.file_path,
            "parent_id": self._convert_parent_id_to_metadata(),
            "block_type": self._convert_block_type_to_metadata(),
            "start_line_num": self.start_line_num,
            "end_line_num": self.end_line_num,
            "code_content": self.code_content,
            "important_comments": self._convert_important_comments_to_metadata(),
            "dependencies": self._convert_dependencies_to_metadata(),
            "summary": self._convert_summary_to_metadata(),
            "children": self._convert_children_to_metadata(),
        }

    @classmethod
    def _build_from_metadata(
        cls, metadata: dict[str, str | int | list[str]]
    ) -> "BaseCodeBlockModel":
        """Builds a BaseCodeBlockModel from a metadata dictionary."""
        try:
            if not isinstance(metadata, dict):
                raise ValueError("Metadata must be a dictionary.")

            id = metadata.get("id")
            if not isinstance(id, str):
                raise ValueError("ID must be a string.")

            file_path = metadata.get("file_path")
            if not isinstance(file_path, str):
                raise ValueError("File path must be a string.")

            block_type = metadata.get("block_type")
            if (
                not isinstance(block_type, str)
                or block_type not in BlockType._member_names_
            ):
                raise ValueError("Invalid block type.")

            start_line_num = metadata.get("start_line_num")
            if not isinstance(start_line_num, int):
                raise ValueError("Start line number must be an integer.")

            end_line_num = metadata.get("end_line_num")
            if not isinstance(end_line_num, int):
                raise ValueError("End line number must be an integer.")

            parent_id = metadata.get("parent_id")
            if not isinstance(parent_id, str):
                raise ValueError("Parent ID must be a string.")

            code_content = metadata.get("code_content", "")
            if not isinstance(code_content, str):
                raise ValueError("Code content must be a string.")

            summary = metadata.get("summary")
            if not isinstance(summary, str):
                raise ValueError("Summary must be a string.")

            children_ids = metadata.get("children_ids", [])
            if not isinstance(children_ids, list) or not all(
                isinstance(child_id, str) for child_id in children_ids
            ):
                raise ValueError("Children IDs must be a list of strings.")

            important_comments_data = metadata.get("important_comments", [])
            if not isinstance(important_comments_data, list) or all(
                isinstance(comment, dict) for comment in important_comments_data
            ):
                raise ValueError("Important comments must be a list.")

            important_comments: list[CommentModel] = []
            for comment_data in important_comments_data:
                if not isinstance(comment_data, dict):
                    raise ValueError("Each important comment must be a dictionary.")
                comment: CommentModel = CommentModel._build_from_metadata(comment_data)
                important_comments.append(comment)

            dependencies: list[ImportModel | DependencyModel] = []
            dependencies_data = metadata.get("dependencies", [])
            if isinstance(dependencies_data, list):
                for dependency_data in dependencies_data:
                    if not isinstance(dependency_data, dict):
                        raise ValueError("Each dependency must be a dictionary.")
                    dependency = None
                    if "import_names" in dependency_data:
                        dependency = ImportModel._build_from_metadata(dependency_data)
                    elif "code_block_id" in dependency_data:
                        dependency = DependencyModel._build_from_metadata(
                            dependency_data
                        )
                    if not dependency:
                        raise ValueError("Invalid dependency.")
                    dependencies.append(dependency)
            else:
                raise ValueError("Dependencies must be a list.")

            return cls(
                id=id,
                file_path=file_path,
                parent_id=parent_id,
                block_type=BlockType[block_type],
                start_line_num=start_line_num,
                end_line_num=end_line_num,
                code_content=code_content,
                important_comments=important_comments,
                dependencies=dependencies,
                summary=summary if summary else None,
                children_ids=children_ids,
            )
        except ValueError as ve:
            logging.error(f"Error building from metadata: {ve}")
            raise ve
        except Exception as e:
            logging.error(f"An unexpected error occurred: {e}")
            raise e


class ModuleSpecificAttributes(BaseModel):
    """Module specific attributes."""

    docstring: str | None = None
    header: list[str] | None = None
    footer: list[str] | None = None
    imports: list[ImportModel] | None = None

    def _convert_docstring_to_metadata(self) -> str:
        """Converts the docstring to a metadata string."""
        return f"{self.docstring}"

    def _convert_header_to_metadata(self) -> str:
        """Converts the header and footer to a metadata string."""
        return self.model_dump_json()

    def _convert_footer_to_metadata(self) -> str:
        """Converts the header and footer to a metadata string."""
        return self.model_dump_json()

    def _convert_imports_to_metadata(self) -> str:
        """Converts the imports to a metadata string."""
        imports_str: str = self.model_dump_json() if self.imports else ""
        return f"{imports_str}"

    def _convert_module_attributes_to_metadata_dict(self) -> dict[str, str | int]:
        """Converts the module attributes to a metadata dictionary for ChromaDB."""

        return {
            "docstring": self._convert_docstring_to_metadata(),
            "header": self._convert_header_to_metadata(),
            "footer": self._convert_footer_to_metadata(),
            "imports": self._convert_imports_to_metadata(),
        }

    @classmethod
    def _build_from_meta(
        cls, metadata: dict[str, str | int | list[str]]
    ) -> "ModuleSpecificAttributes":
        """Builds a ModuleSpecificAttributes from a metadata dictionary."""

        try:
            if not isinstance(metadata, dict):
                raise ValueError("Metadata must be a dictionary.")

            docstring = metadata.get("docstring")
            if not isinstance(docstring, str):
                raise ValueError("Docstring must be a string.")

            header = metadata.get("header")
            if not isinstance(header, list):
                raise ValueError("Header must be a list.")

            footer = metadata.get("footer")
            if not isinstance(footer, list):
                raise ValueError("Footer must be a list.")

            imports_data = metadata.get("imports")
            if not isinstance(imports_data, list):
                raise ValueError("Imports must be a list.")

            imports = []
            for import_data in imports_data:
                if not isinstance(import_data, dict):
                    raise ValueError("Each import must be a dictionary.")
                import_model = ImportModel._build_from_metadata(import_data)
                imports.append(import_model)

            return cls(
                docstring=docstring,
                header=header,
                footer=footer,
                imports=imports,
            )
        except ValueError as ve:
            logging.error(f"Error building from metadata: {ve}")
            raise ve
        except Exception as e:
            logging.error(f"An unexpected error occurred: {e}")
            raise e


class ModuleModel(BaseCodeBlockModel, ModuleSpecificAttributes):
    """
    Model for a module.

    Attributes:
        - id (str): The unique identifier for the module.
        - file_path (str): The path to the Python file that the module represents.
        - parent_id (str | None): The identifier of the parent (usually a directory).
        - block_type (BlockType): The type of code block that the module represents.
        - start_line_num (int): The line number of the first line of the module.
        - end_line_num (int): The line number of the last line of the module.
        - code_content (str): The string content of the module.
        - important_comments (list[CommentModel] | None): A list of important comments in the module.
        - dependencies (list[ImportModel | DependencyModel] | None): A list of dependencies for the module.
        - summary (str | None): A summary of the module.
        - children_ids (list[str] | None): A list of the identifiers of the children of the module.
        - docstring (str | None): The docstring of the module.
        - header (list[str] | None): The header of the module.
        - footer (list[str] | None): The footer of the module.
        - imports (list[ImportModel] | None): A list of import statements in the module.

    Methods:
        - `convert_to_metadata() -> dict[str, str | int]`
            - Converts the module model to a metadata dictionary for ChromaDB.
        - `build_from_metadata(metadata_dict: dict[str, str | int | list[str]]) -> ModuleModel`
            - Builds a ModuleModel from a metadata dictionary.
    """

    def convert_to_metadata(self) -> dict[str, str | int]:
        """Converts the module model to a metadata dictionary for ChromaDB."""

        return {
            **self._convert_base_attributes_to_metadata_dict(),
            **self._convert_module_attributes_to_metadata_dict(),
        }

    @classmethod
    def build_from_metadata(
        cls, metadata_dict: dict[str, str | int | list[str]]
    ) -> "ModuleModel":
        """
        Builds a ModuleModel from a metadata dictionary.

        Args:
            - metadata_dict (dict[str, str | int | list[str]]): A dictionary containing metadata for a module.

        Returns:
            ModuleModel: An instance of ModuleModel.

        Raises:
            - ValueError: If the metadata is not a dictionary.
            - ValueError: If the metadata is missing required keys.
            - ValueError: If the metadata contains invalid values.
            - Exception: If an unexpected error occurs.
        """
        try:
            if not isinstance(metadata_dict, dict):
                raise ValueError("Metadata must be a dictionary.")

            module_specific_attributes: ModuleSpecificAttributes = (
                ModuleSpecificAttributes._build_from_meta(metadata_dict)
            )
            base_code_block_model: BaseCodeBlockModel = (
                BaseCodeBlockModel._build_from_metadata(metadata_dict)
            )

            return cls(
                **module_specific_attributes.model_dump(),
                **base_code_block_model.model_dump(),
            )
        except ValueError as ve:
            logging.error(f"Error building from metadata: {ve}")
            raise ve
        except Exception as e:
            logging.error(f"An unexpected error occurred: {e}")
            raise e


class ClassSpecificAttributes(BaseModel):
    """Class specific attributes."""

    class_name: str = Field(min_length=1)
    decorators: list[DecoratorModel] | None = None
    bases: list[str] | None = None
    docstring: str | None = None
    keywords: list[ClassKeywordModel] | None = None
    # attributes: list[dict] | None = None

    def _convert_decorators_to_metadata(self) -> str:
        """Converts the decorators to a metadata string."""
        decorators_str: str = self.model_dump_json() if self.decorators else ""
        return f"{decorators_str}"

    def _convert_bases_to_metadata(self) -> str:
        """Converts the bases to a metadata string."""
        return self.model_dump_json() if self.bases else ""

    def _convert_docstring_to_metadata(self) -> str:
        """Converts the docstring to a metadata string."""
        return f"{self.docstring}" if self.docstring else ""

    def _convert_keywords_to_metadata(self) -> str:
        """Converts the keywords to a metadata string."""
        keywords_str: str = self.model_dump_json() if self.keywords else ""
        return f"{keywords_str}"

    def _convert_class_attributes_to_metadata_dict(self) -> dict[str, str | int]:
        """Converts the class attributes to a metadata dictionary."""

        return {
            "class_name": self.class_name,
            "decorators": self._convert_decorators_to_metadata(),
            "bases": self._convert_bases_to_metadata(),
            "docstring": self._convert_docstring_to_metadata(),
            "keywords": self._convert_keywords_to_metadata(),
        }

    @classmethod
    def _build_from_meta(
        cls, metadata: dict[str, str | int | list[str]]
    ) -> "ClassSpecificAttributes":
        """Builds a ClassSpecificAttributes from a metadata dictionary."""

        try:
            if not isinstance(metadata, dict):
                raise ValueError("Metadata must be a dictionary.")

            class_name = metadata.get("class_name")
            if not isinstance(class_name, str):
                raise ValueError("Class name must be a string.")

            decorators_data = metadata.get("decorators", [])
            if not isinstance(decorators_data, list):
                raise ValueError("Decorators must be a list.")

            decorators: list[DecoratorModel] = []
            for decorator_data in decorators_data:
                if not isinstance(decorator_data, dict):
                    raise ValueError("Each decorator must be a dictionary.")
                decorator: DecoratorModel = DecoratorModel._build_from_metadata(
                    decorator_data
                )
                decorators.append(decorator)

            bases = metadata.get("bases", [])
            if not isinstance(bases, list) or all(
                isinstance(base, str) for base in bases
            ):
                raise ValueError("Bases must be a list.")

            docstring = metadata.get("docstring")
            if not isinstance(docstring, str):
                raise ValueError("Docstring must be a string.")

            keywords_data = metadata.get("keywords", [])
            if not isinstance(keywords_data, list) or all(
                isinstance(keyword, dict) for keyword in keywords_data
            ):
                raise ValueError("Keywords must be a list.")

            keywords: list[ClassKeywordModel] = []
            for keyword_data in keywords_data:
                if not isinstance(keyword_data, dict):
                    raise ValueError("Each keyword must be a dictionary.")
                keyword: ClassKeywordModel = ClassKeywordModel._build_from_metadata(
                    keyword_data
                )
                keywords.append(keyword)

            return cls(
                class_name=class_name,
                decorators=decorators,
                bases=bases,
                docstring=docstring,
                keywords=keywords,
            )
        except ValueError as ve:
            logging.error(f"Error building from metadata: {ve}")
            raise ve
        except Exception as e:
            logging.error(f"An unexpected error occurred: {e}")
            raise e


class ClassModel(BaseCodeBlockModel, ClassSpecificAttributes):
    """
    Model for a class.

    Attributes:
        - id (str): The unique identifier for the class.
        - file_path (str): The path to the Python file that the class represents.
        - parent_id (str | None): The identifier of the parent (usually a module).
        - block_type (BlockType): The type of code block that the class represents.
        - start_line_num (int): The line number of the first line of the class.
        - end_line_num (int): The line number of the last line of the class.
        - code_content (str): The string content of the class.
        - important_comments (list[CommentModel] | None): A list of important comments in the class.
        - dependencies (list[ImportModel | DependencyModel] | None): A list of dependencies for the class.
        - summary (str | None): A summary of the class.
        - children_ids (list[str] | None): A list of the identifiers of the children of the class.
        - class_name (str): The name of the class.
        - decorators (list[DecoratorModel] | None): A list of decorators for the class.
        - bases (list[str] | None): A list of base classes for the class.
        - docstring (str | None): The docstring of the class.
        - keywords (list[ClassKeywordModel] | None): A list of keywords for the class.


    Methods:
        - `convert_to_metadata() -> dict[str, str | int]`
            - Converts the class model to a metadata dictionary for ChromaDB.
        - `build_from_metadata(metadata_dict: dict[str, str | int | list[str]]) -> ClassModel`
            - Builds a ClassModel from a metadata dictionary.
    """

    def convert_to_metadata(self) -> dict[str, str | int]:
        """Converts the class model to a metadata dictionary for ChromaDB."""
        return {
            **self._convert_base_attributes_to_metadata_dict(),
            **self._convert_class_attributes_to_metadata_dict(),
        }

    @classmethod
    def build_from_metadata(
        cls, metadata_dict: dict[str, str | int | list[str]]
    ) -> "ClassModel":
        """
        Builds a ClassModel from a metadata dictionary.

        Args:
            - metadata_dict (dict[str, str | int | list[str]]): A dictionary containing metadata for a class.

        Returns:
            ClassModel: An instance of ClassModel.

        Raises:
            - ValueError: If the metadata is not a dictionary.
            - ValueError: If the metadata is missing required keys.
            - ValueError: If the metadata contains invalid values.
            - Exception: If an unexpected error occurs.
        """
        try:
            if not isinstance(metadata_dict, dict):
                raise ValueError("Metadata must be a dictionary.")

            class_specific_attributes: ClassSpecificAttributes = (
                ClassSpecificAttributes._build_from_meta(metadata_dict)
            )
            base_code_block_model: BaseCodeBlockModel = (
                BaseCodeBlockModel._build_from_metadata(metadata_dict)
            )

            return cls(
                **class_specific_attributes.model_dump(),
                **base_code_block_model.model_dump(),
            )
        except ValueError as ve:
            logging.error(f"Error building from metadata: {ve}")
            raise ve
        except Exception as e:
            logging.error(f"An unexpected error occurred: {e}")
            raise e


class FunctionSpecificAttributes(BaseModel):
    """Function specific attributes."""

    function_name: str = Field(min_length=1)
    docstring: str | None = None
    decorators: list[DecoratorModel] | None = None
    parameters: ParameterListModel | None = None
    returns: str | None = None
    is_method: bool = False
    is_async: bool = False

    def _convert_docstring_to_metadata(self) -> str:
        """Converts the docstring to a metadata string."""
        return f"{self.docstring}" if self.docstring else ""

    def _convert_decorators_to_metadata(self) -> str:
        """Converts the decorators to a metadata string."""
        decorators_str: str = self.model_dump_json() if self.decorators else ""
        return f"{decorators_str}"

    def _convert_parameters_to_metadata(self) -> str:
        """Converts the parameters to a metadata string."""
        return (
            self.parameters.convert_parameters_to_metadata() if self.parameters else ""
        )

    def _convert_returns_to_metadata(self) -> str:
        """Converts the returns to a metadata string."""
        return f"{self.returns}" if self.returns else ""

    def _convert_function_attributes_to_metadata_dict(self) -> dict[str, str | bool]:
        """Converts the function attributes to a metadata dictionary for ChromaDB."""

        return {
            "function_name": self.function_name,
            "docstring": self._convert_docstring_to_metadata(),
            "decorators": self._convert_decorators_to_metadata(),
            "parameters": self._convert_parameters_to_metadata(),
            "returns": self._convert_returns_to_metadata(),
            "is_method": self.is_method,
            "is_async": self.is_async,
        }

    @classmethod
    def _build_from_meta(
        cls, metadata: dict[str, str | bool]
    ) -> "FunctionSpecificAttributes":
        """Builds a FunctionSpecificAttributes from a metadata dictionary."""

        try:
            if not isinstance(metadata, dict):
                raise ValueError("Metadata must be a dictionary.")

            function_name = metadata.get("function_name")
            if not isinstance(function_name, str):
                raise ValueError("Function name must be a string.")

            docstring = metadata.get("docstring")
            if not isinstance(docstring, str):
                raise ValueError("Docstring must be a string.")

            decorators_data = metadata.get("decorators", [])
            if not isinstance(decorators_data, list):
                raise ValueError("Decorators must be a list.")

            decorators: list[DecoratorModel] = []
            for decorator_data in decorators_data:
                if not isinstance(decorator_data, dict):
                    raise ValueError("Each decorator must be a dictionary.")
                decorator: DecoratorModel = DecoratorModel._build_from_metadata(
                    decorator_data
                )
                decorators.append(decorator)

            parameters_data = metadata.get("parameters")
            if not isinstance(parameters_data, dict):
                raise ValueError("Parameters must be a dictionary.")

            parameters: ParameterListModel = ParameterListModel._build_from_metadata(
                parameters_data
            )

            returns = metadata.get("returns")
            if not isinstance(returns, str):
                raise ValueError("Returns must be a string.")

            is_method = metadata.get("is_method")
            if not isinstance(is_method, bool):
                raise ValueError("is_method must be a boolean.")

            is_async = metadata.get("is_async")
            if not isinstance(is_async, bool):
                raise ValueError("is_async must be a boolean.")

            return cls(
                function_name=function_name,
                docstring=docstring,
                decorators=decorators,
                parameters=parameters,
                returns=returns,
                is_method=is_method,
                is_async=is_async,
            )
        except ValueError as ve:
            logging.error(f"Error building from metadata: {ve}")
            raise ve
        except Exception as e:
            logging.error(f"An unexpected error occurred: {e}")
            raise e


class FunctionModel(BaseCodeBlockModel, FunctionSpecificAttributes):
    """
    A model for a function.

    Attributes:
        - id (str): The unique identifier for the function.
        - file_path (str): The path to the Python file that the function represents.
        - parent_id (str | None): The identifier of the parent (usually a module or class).
        - block_type (BlockType): The type of code block that the function represents.
        - start_line_num (int): The line number of the first line of the function.
        - end_line_num (int): The line number of the last line of the function.
        - code_content (str): The string content of the function.
        - important_comments (list[CommentModel] | None): A list of important comments in the function.
        - dependencies (list[ImportModel | DependencyModel] | None): A list of dependencies for the function.
        - summary (str | None): A summary of the function.
        - children_ids (list[str] | None): A list of the identifiers of the children of the function.
        - function_name (str): The name of the function.
        - docstring (str | None): The docstring of the function.
        - decorators (list[DecoratorModel] | None): A list of decorators for the function.
        - parameters (ParameterListModel | None): A model representing the function's parameters.
        - returns (str | None): A string representing the function's return annotation.
        - is_method (bool): True if the function is a method, False otherwise.
        - is_async (bool): True if the function is asynchronous, False otherwise.

    Methods:
        - `convert_to_metadata() -> dict[str, str | int]`
            - Converts the function model to a metadata dictionary for ChromaDB.
        - `build_from_metadata(metadata_dict: dict[str, str | int | list[str]]) -> FunctionModel`
            - Builds a FunctionModel from a metadata dictionary.
    """

    def convert_to_metadata(self) -> dict[str, str | int]:
        """Converts the function model to a metadata dictionary for ChromaDB."""

        return {
            **self._convert_base_attributes_to_metadata_dict(),
            **self._convert_function_attributes_to_metadata_dict(),
        }

    @classmethod
    def build_from_metadata(
        cls, metadata_dict: dict[str, str | int | list[str] | bool]
    ) -> "FunctionModel":
        """
        Builds a FunctionModel from a metadata dictionary.

        Args:
            - metadata_dict (dict[str, str | int | list[str]]): A dictionary containing metadata for a function.

        Returns:
            FunctionModel: An instance of FunctionModel.

        Raises:
            - ValueError: If the metadata is not a dictionary.
            - ValueError: If the metadata is missing required keys.
            - ValueError: If the metadata contains invalid values.
            - Exception: If an unexpected error occurs.
        """
        try:
            if not isinstance(metadata_dict, dict):
                raise ValueError("Metadata must be a dictionary.")

            function_specific_attributes: FunctionSpecificAttributes = (
                FunctionSpecificAttributes._build_from_meta(metadata_dict)  # type: ignore # FIXME: fix type hinting error
            )  # type: ignore # FIXME: fix type hinting error
            base_code_block_model: BaseCodeBlockModel = (
                BaseCodeBlockModel._build_from_metadata(metadata_dict)
            )

            return cls(
                **function_specific_attributes.model_dump(),
                **base_code_block_model.model_dump(),
            )
        except ValueError as ve:
            logging.error(f"Error building from metadata: {ve}")
            raise ve
        except Exception as e:
            logging.error(f"An unexpected error occurred: {e}")
            raise e


class StandaloneCodeBlockSpecificAttributes(BaseModel):
    """Standalone code block specific attributes."""

    variable_assignments: list[str] | None = None

    def _convert_variable_assignments_to_metadata(self) -> str:
        """Converts the variable assignments to a metadata string."""
        return self.model_dump_json() if self.variable_assignments else ""

    def _convert_standalone_block_attributes_to_metadata_dict(
        self,
    ) -> dict[str, str | int]:
        """Converts the standalone code block attributes to a metadata dictionary for ChromaDB."""
        return {
            "variable_assignments": self._convert_variable_assignments_to_metadata(),
        }

    @classmethod
    def _build_from_meta(
        cls, metadata: dict[str, str | int | list[str]]
    ) -> "StandaloneCodeBlockSpecificAttributes":
        """Builds a StandaloneCodeBlockSpecificAttributes from a metadata dictionary."""

        try:
            if not isinstance(metadata, dict):
                raise ValueError("Metadata must be a dictionary.")

            variable_assignments_data = metadata.get("variable_assignments", [])
            if not isinstance(variable_assignments_data, list):
                raise ValueError("Variable assignments must be a list.")

            variable_assignments: list[str] = []
            for variable_assignment_data in variable_assignments_data:
                if not isinstance(variable_assignment_data, str):
                    raise ValueError("Each variable assignment must be a string.")
                variable_assignments.append(variable_assignment_data)

            return cls(
                variable_assignments=variable_assignments,
            )
        except ValueError as ve:
            logging.error(f"Error building from metadata: {ve}")
            raise ve
        except Exception as e:
            logging.error(f"An unexpected error occurred: {e}")
            raise e


class StandaloneCodeBlockModel(
    BaseCodeBlockModel, StandaloneCodeBlockSpecificAttributes
):
    """
    Model for a standalone code block.

    Attributes:
        - id (str): The unique identifier for the standalone code block.
        - file_path (str): The path to the Python file that the standalone code block represents.
        - parent_id (str | None): The identifier of the parent (usually a module or class).
        - block_type (BlockType): The type of code block that the standalone code block represents.
        - start_line_num (int): The line number of the first line of the standalone code block.
        - end_line_num (int): The line number of the last line of the standalone code block.
        - code_content (str): The string content of the standalone code block.
        - important_comments (list[CommentModel] | None): A list of important comments in the standalone code block.
        - dependencies (list[ImportModel | DependencyModel] | None): A list of dependencies for the standalone code block.
        - summary (str | None): A summary of the standalone code block.
        - children_ids (list[str] | None): A list of the identifiers of the children of the standalone code block.
        - variable_assignments (list[str] | None): A list of variable assignments in the standalone code block.

    Methods:
        - `convert_to_metadata() -> dict[str, str | int]`
            - Converts the standalone code block model to a metadata dictionary for ChromaDB.
        - `build_from_metadata(metadata_dict: dict[str, str | int | list[str]]) -> StandaloneCodeBlockModel`
            - Builds a StandaloneCodeBlockModel from a metadata dictionary.
    """

    def convert_to_metadata(self) -> dict[str, str | int]:
        """Converts the standalone code block model to a metadata dictionary for ChromaDB."""

        return {
            **self._convert_base_attributes_to_metadata_dict(),
            **self._convert_standalone_block_attributes_to_metadata_dict(),
        }

    @classmethod
    def _build_from_meta(
        cls, metadata: dict[str, str | int | list[str]]
    ) -> "StandaloneCodeBlockModel":
        """
        Builds a StandaloneCodeBlockModel from a metadata dictionary.

        Args:
            - metadata_dict (dict[str, str | int | list[str]]): A dictionary containing metadata for a standalone code block.

        Returns:
            - StandaloneCodeBlockModel: An instance of StandaloneCodeBlockModel.

        Raises:
            - ValueError: If the metadata is not a dictionary.
            - ValueError: If the metadata is missing required keys.
            - ValueError: If the metadata contains invalid values.
            - Exception: If an unexpected error occurs.
        """

        try:
            if not isinstance(metadata, dict):
                raise ValueError("Metadata must be a dictionary.")

            standalone_code_block_specific_attributes: (
                StandaloneCodeBlockSpecificAttributes
            ) = StandaloneCodeBlockSpecificAttributes._build_from_meta(metadata)
            base_code_block_model: BaseCodeBlockModel = (
                BaseCodeBlockModel._build_from_metadata(metadata)
            )

            return cls(
                **standalone_code_block_specific_attributes.model_dump(),
                **base_code_block_model.model_dump(),
            )
        except ValueError as ve:
            logging.error(f"Error building from metadata: {ve}")
            raise ve
        except Exception as e:
            logging.error(f"An unexpected error occurred: {e}")
            raise e


class DirectoryModel(BaseModel):
    """
    Model for a directory.

    Attributes:
        - id (str): The unique identifier for the directory.
        - block_type (BlockType): The type of code block that the directory represents.
        - directory_name (str): The name of the directory.
        - sub_directories_ids (list[str]): A list of the identifiers of the sub-directories of the directory.
        - children_ids (list[str]): A list of the identifiers of the children of the directory.
        - parent_id (str | None): The identifier of the parent (usually a directory).
        - summary (str | None): A summary of the directory.

    Methods:
        - `convert_to_metadata() -> dict[str, str | int]`:
            Converts the directory model to a metadata dictionary for ChromaDB.
    """

    id: str
    block_type: BlockType = BlockType.DIRECTORY
    directory_name: str
    sub_directories_ids: list[str]
    children_ids: list[str]
    parent_id: str | None
    summary: str | None = None

    def convert_to_metadata(self) -> dict[str, str | int]:
        """Converts the directory model to a metadata dictionary for ChromaDB."""

        return {
            "directory_name": self.directory_name,
            "sub_directories": (
                str(self.sub_directories_ids) if self.sub_directories_ids else ""
            ),
            "children_ids": self.model_dump_json() if self.children_ids else "",
            "parent_id": self.parent_id if self.parent_id else "",
            "summary": self.summary if self.summary else "",
        }

    @classmethod
    def build_from_metadata(
        cls, metadata_dict: dict[str, str | list[str]]
    ) -> "DirectoryModel":
        """
        Builds a DirectoryModel from a metadata dictionary.

        Args:
            - metadata_dict (dict[str, str | int | list[str]]): A dictionary containing metadata for a directory.

        Returns:
            - DirectoryModel: An instance of DirectoryModel.

        Raises:
            - ValueError: If the metadata is not a dictionary.
            - ValueError: If the metadata is missing required keys.
            - ValueError: If the metadata contains invalid values.
            - Exception: If an unexpected error occurs.
        """

        try:
            if not isinstance(metadata_dict, dict):
                raise ValueError("Metadata must be a dictionary.")

            id = metadata_dict.get("id")
            if not isinstance(id, str):
                raise ValueError("ID must be a string.")

            directory_name = metadata_dict.get("directory_name")
            if not isinstance(directory_name, str):
                raise ValueError("Directory name must be a string.")

            sub_directories_ids = metadata_dict.get("sub_directories")
            if not isinstance(sub_directories_ids, list) or not all(
                isinstance(sub_directory_id, str)
                for sub_directory_id in sub_directories_ids
            ):
                raise ValueError("Sub-directories must be a list of strings.")

            children_ids = metadata_dict.get("children_ids")
            if not isinstance(children_ids, list) or not all(
                isinstance(child_id, str) for child_id in children_ids
            ):
                raise ValueError("Children IDs must be a list of strings.")

            parent_id = metadata_dict.get("parent_id")
            if not isinstance(parent_id, str):
                raise ValueError("Parent ID must be a string.")

            summary = metadata_dict.get("summary")
            if not isinstance(summary, str):
                raise ValueError("Summary must be a string.")

            return cls(
                id=id,
                directory_name=directory_name,
                sub_directories_ids=sub_directories_ids,
                children_ids=children_ids,
                parent_id=parent_id if parent_id else None,
                summary=summary if summary else None,
            )

        except ValueError as ve:
            logging.error(f"Error building from metadata: {ve}")
            raise ve
        except Exception as e:
            logging.error(f"An unexpected error occurred: {e}")
            raise e



File: postcode/json_management/json_handler.py
----------------------------------------
import json
import logging
from pathlib import Path
from shutil import rmtree
from typing import Union

from postcode.models.models import (
    ModuleModel,
    ClassModel,
    FunctionModel,
    StandaloneCodeBlockModel,
    DirectoryModel,
)
from postcode.utilities.logger.decorators import logging_decorator

ModelType = Union[
    ModuleModel,
    ClassModel,
    FunctionModel,
    StandaloneCodeBlockModel,
    DirectoryModel,
]


class JSONHandler:
    """
    A class for handling the serialization and storage of parsed code models in JSON format.

    This class provides methods to save parsed code models, such as modules, classes, functions, standalone code blocks, and directory maps, as JSON files. It ensures proper organization and cleanup of the output directory.

    Attributes:
        - directory (str): The base directory of the parsed code.
        - output_directory (str): The directory where JSON output files are stored.
        - directory_modules (dict[str, list[str]]): A mapping of directories to their corresponding Python files.

    Example:
        ```Python
        # This example demonstrates how to use JSONHandler to save a parsed model as JSON.
        handler = JSONHandler(directory="/path/to/code", directory_modules={})
        module_model = ModuleModel(id='module1', file_path='/path/to/code/module1.py')
        handler.save_model_as_json(module_model, file_path='/path/to/code/module1.py')
        ```
    """

    def __init__(
        self,
        directory: str,
        directory_modules: dict[str, list[str]],
        output_directory: str = "output_json",
    ) -> None:
        self.directory: str = directory
        self.output_directory: str = output_directory
        self.directory_modules: dict[str, list[str]] = directory_modules

        self._clean_output_directory()
        self._create_output_directory()

    @logging_decorator(message="Saving model as JSON")
    def save_model_as_json(
        self,
        model: ModelType,
        file_path: str,
    ) -> None:
        """
        Saves a parsed ModelType as JSON.

        Args:
            - model (ModelType): The parsed code model to be saved.
            - file_path (str): The file path of the original Python file.

        Example:
            ```Python
            # This example demonstrates how to use JSONHandler to save a parsed model as JSON.
            handler = JSONHandler(directory="/path/to/code", directory_modules={})
            module_model = ModuleModel(id='module1', file_path='/path/to/code/module1.py')
            handler.save_model_as_json(module_model, file_path='/path/to/code/module1.py')
            ```
        """

        json_output_directory: str = self._create_json_output_directory()
        output_path: str = self._get_json_output_path(file_path, json_output_directory)
        self._write_json_file(model, output_path)

    @logging_decorator(message="Saving visited directories")
    def save_visited_directories(
        self, directory_mape_name: str = "directory_map.json"
    ) -> None:
        """
        Saves a JSON file mapping each visited directory to its Python files.

        The output is saved in a file named 'directory_map.json' within the specified output directory.

        Args:
            - directory_map_name (str, optional): The name of the output file for the directory map. Defaults to "directory_map.json".

        Example:
            ```Python
            # This example demonstrates how to save visited directories as a JSON map.
            handler = JSONHandler(directory="/path/to/code", directory_modules={})
            handler.save_visited_directories(directory_map_name="custom_map.json")
            ```
        """

        output_path: str = self._get_directory_map_output_path(directory_mape_name)
        self._write_json_directory_map(output_path)

    def _create_output_directory(self) -> None:
        """Creates the output directory if it does not already exist."""

        Path(self.output_directory).mkdir(exist_ok=True)

    def _create_json_output_directory(self) -> str:
        """
        Creates the JSON output directory if it does not already exist.

        Returns:
            str: The path to the created JSON output directory.
        """

        json_output_directory: Path = Path(self.output_directory) / "json"
        json_output_directory.mkdir(exist_ok=True)
        return str(json_output_directory)

    def _get_json_output_path(self, file_path: str, json_output_directory: str) -> str:
        """
        Gets the output path for a JSON file.

        Args:
            - file_path (str): The file path of the original Python file.
            - json_output_directory (str): The path to the JSON output directory.

        Returns:
            str: The output path for the JSON file.
        """

        if "DIRECTORY" in file_path:
            safe_file_path: str = file_path.replace("/", ":")
            return str(Path(json_output_directory) / f"{safe_file_path}.json")
        else:
            relative_path: Path = Path(file_path).relative_to(Path(self.directory))
            safe_relative_path: str = str(relative_path).replace("/", ":").rstrip(".py")
            return str(Path(json_output_directory) / f"{safe_relative_path}.json")

    def _write_json_file(
        self,
        module_model: ModelType,
        output_path: str,
    ) -> None:
        """
        Writes a JSON file containing the parsed data from a ModuleModel.

        Args:
            - module_model (ModelType): The parsed code model.
            - output_path (str): The path where the JSON file will be saved.
        """

        parsed_data_json: str = module_model.model_dump_json(indent=4)
        with open(output_path, "w") as json_file:
            json_file.write(parsed_data_json)

    def _get_directory_map_output_path(self, directory_output_name: str) -> str:
        """
        Gets the output path for the directory map JSON file.

        Args:
            - directory_output_name (str): The name of the output file for the directory map.

        Returns:
            str: The output path for the directory map JSON file.
        """

        return str(Path(self.output_directory) / directory_output_name)

    def _write_json_directory_map(self, output_path: str) -> None:
        """Writes the directory map JSON file."""

        with open(output_path, "w") as json_file:
            json.dump(self.directory_modules, json_file, indent=4)

    def _clean_output_directory(self) -> None:
        """Deletes the output directory and all its contents."""

        output_dir = Path(self.output_directory)
        if output_dir.exists() and output_dir.is_dir():
            rmtree(output_dir)



File: postcode/api.py
----------------------------------------
from postcode.updaters.graph_db_updater import GraphDBUpdater
from postcode.databases.chroma.chromadb_collection_manager import (
    ChromaCollectionManager,
)
from postcode.ai_services.openai_configs import ChatCompletionConfigs
from postcode.ai_services.chat.openai_agents import OpenAIChatAgent
from postcode.ai_services.librarians.chroma_librarians import ChromaLibrarian
from postcode.databases.chroma.chroma_setup import setup_chroma
from postcode.utilities.logger.logging_config import setup_logging


class Postcode:
    """
    Main interface for the Postcode package.

    This class provides methods to process a codebase and interact with it through a chat interface.

    Attributes:
        - `updater` (GraphDBUpdater): The updater for the graph database.
            - default: GraphDBUpdater()

    Methods:
        - `process_entire_codebase`(updater: GraphDBUpdater = GraphDBUpdater()): Process the entire codebase using the GraphDBUpdater.
        - `chat`(message: str, chat_config: ChatCompletionConfigs = ChatCompletionConfigs()): Interact with the processed codebase through a chat interface

    Example:
        ```python
        summarizer = OpenAISummarizer()
        updater = GraphDBUpdater("/path/to/project", summarizer=summarizer, output_directory="output_json")
        postcode = Postcode("/path/to/project", output_directory="output_json")

        postcode.process_entire_codebase(summarizer)
        response = postcode.chat("What does the main function do?")
        print(response)
        ```
    """

    def __init__(self) -> None:
        setup_logging()

    def process_codebase(
        self,
        updater: GraphDBUpdater = GraphDBUpdater(),
        num_of_passes: int = 3,
        process_all: bool = False,
    ) -> None:
        """
        Process the entire codebase using the GraphDBUpdater.

        This method initializes the GraphDBUpdater, processes the codebase, and stores the resulting
        ChromaCollectionManager for later use in chat interactions.

        Args:
            - `updater` (GraphDBUpdater): The updater for the graph database.

        Raises:
            - `Exception`: If there's an error during the codebase processing.
        """

        try:
            if process_all:
                self.chroma_collection_manager: ChromaCollectionManager = (
                    updater.update_all(num_of_passes)
                )
            else:
                self.chroma_collection_manager: ChromaCollectionManager = (
                    updater.update_changed(num_of_passes)
                )
            self.chroma_librarian = ChromaLibrarian(self.chroma_collection_manager)
        except Exception as e:
            raise Exception(f"Error processing codebase: {str(e)}")

    def connect_to_vectorstore(self, chromadb_name: str = "postcode") -> None:
        """
        Connect to an existing ChromaDB collection.

        This method initializes the ChromaCollectionManager for the specified collection name
        and stores it for later use in chat interactions.

        Args:
            - `chromadb_name` (str): Name of the ChromaDB collection.

        Raises:
            - `Exception`: If there's an error during the connection.
        """

        try:
            self.chroma_collection_manager: ChromaCollectionManager = setup_chroma(
                chromadb_name
            )
            self.chroma_librarian = ChromaLibrarian(self.chroma_collection_manager)
        except Exception as e:
            raise Exception(f"Error connecting to ChromaDB: {str(e)}")

    def chat(
        self, message: str, chat_config: ChatCompletionConfigs = ChatCompletionConfigs()
    ) -> str:
        """
        Interact with the processed codebase through a chat interface.

        This method uses the stored ChromaCollectionManager to process the user's message
        and return a response.

        Args:
            - `message` (str): The user's input message or question.
            - `chat_config` (ChatCompletionConfigs): Configuration for the chat completion.
                - default: ChatCompletionConfigs().

        Returns:
            - `str`: The AI's response to the user's message.

        Raises:
            - `ValueError`: If the codebase hasn't been processed yet.
        """
        if not self.chroma_librarian:
            raise ValueError(
                "Codebase has not been processed. Call process_codebase() first."
            )
        openai_chat_agent = OpenAIChatAgent(self.chroma_librarian, configs=chat_config)
        response: str | None = openai_chat_agent.get_response(message)
        return response if response else "I'm sorry, I couldn't generate a response."



File: postcode/utilities/logger/logging_config.py
----------------------------------------
import logging

from rich.logging import RichHandler
from rich.syntax import Syntax


def setup_logging(level=logging.INFO) -> None:
    """
    Configures the logging system to use RichSyntaxHandler for output.

    This function sets up logging with a specific log level and format. It utilizes the RichSyntaxHandler to support rich text and syntax highlighting in log outputs.

    Args:
        level (int, optional): The logging level to set for the root logger. Defaults to logging.INFO.

    Example:
        >>> setup_logging(logging.DEBUG)
        # Configures logging at DEBUG level with RichSyntaxHandler.
    """

    format_str = "%(message)s"
    logging.basicConfig(
        level=level,
        format=format_str,
        handlers=[RichHandler(markup=True)],
    )


class RichSyntaxHandler(RichHandler):
    """
    A custom logging handler that extends RichHandler to add syntax highlighting.

    This handler checks if the log record contains a 'syntax_highlight' attribute and, if so, uses 'rich.syntax.Syntax' to render the message with Python syntax highlighting.

    Inherits:
        RichHandler: The base handler provided by the rich library for rich text formatting.
    """

    def emit(self, record) -> None:
        """
        Emits a logging record.

        If the record has the 'syntax_highlight' attribute set to True, it renders the 'content' attribute of the record with syntax highlighting. Otherwise, it falls back to the standard behavior of RichHandler.

        Args:
            record: The logging record to emit.

        Example:
            # Assuming `logger` is a logger instance
            >>> logger.info("Regular log message")
            # Outputs a regular log message.

            >>> logger.info("Highlighted log message", extra={"syntax_highlight": True, "content": "print('Hello, world!')"})
            # Outputs the message with syntax highlighting.
        """

        try:
            if hasattr(record, "syntax_highlight") and getattr(
                record, "syntax_highlight"
            ):
                content: str = getattr(record, "content", "")
                if isinstance(content, str):
                    syntax = Syntax(
                        content, "python", theme="material", line_numbers=True
                    )
                    self.console.print(syntax)
                return

        except Exception as e:
            self.handleError(record)

        super().emit(record)



File: postcode/utilities/logger/decorators.py
----------------------------------------
from functools import wraps
import inspect
from inspect import FrameInfo
import logging
from logging import LogRecord, Logger
from typing import Callable
import libcst


import postcode.python_parser.visitors.node_processing.common_functions as common_functions
from postcode.utilities.processing_context import LoggingCallerInfo, NodeAndPositionData


def logging_decorator(
    level=logging.DEBUG,
    *,
    message: str | None = None,
    syntax_highlighting: bool = False,
) -> Callable:
    """
    A decorator for adding enhanced logging to functions, with optional syntax highlighting.

    This decorator logs the call to the decorated function at the specified logging level. If syntax_highlighting is enabled and the first argument of the function is a libcst.CSTNode, the decorator logs the node's content with syntax highlighting.

    Args:
        level (int): The logging level. Defaults to logging.DEBUG.
        message (str | None): Custom log message. If None, a default message is generated.
        syntax_highlighting (bool): If True, enables syntax highlighting for libcst.CSTNode arguments.

    Returns:
        Callable: The decorated function with enhanced logging capability.

    Example:
        >>> @logging_decorator(level=logging.INFO, message="Function start", syntax_highlighting=True)
        >>> def sample_function(arg1):
        >>>     pass
        # This decorates 'sample_function' with enhanced logging at INFO level.
    """

    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            log_message: str = (
                message if message else (f"Calling function: {func.__name__}")
            )
            frame_info: inspect.FrameInfo = inspect.stack()[1]
            caller_info: LoggingCallerInfo = _get_caller_info(frame_info)
            code_content: str = _gather_code_content(syntax_highlighting, args)
            logger: Logger = _get_logger(caller_info.caller_module_name)

            _handle_logging(
                logger,
                caller_info,
                level,
                log_message,
                syntax_highlighting,
                code_content,
            )

            return func(*args, **kwargs)

        return wrapper

    return decorator


def _gather_log_record_context(
    caller_info: LoggingCallerInfo, level: int, msg: str
) -> logging.LogRecord:
    """Creates and returns a LogRecord with specified context information."""

    return logging.LogRecord(
        name=caller_info.caller_module_name,
        level=level,
        pathname=caller_info.caller_file_path,
        lineno=caller_info.caller_line_no,
        msg=msg,
        args=None,
        exc_info=None,
    )


def _get_caller_info(frame_info: FrameInfo) -> LoggingCallerInfo:
    """Extracts and returns caller information from a frame object."""

    caller_module_name: str = frame_info.filename.split("/")[-1].split(".")[0]
    caller_file_path: str = frame_info.filename
    caller_line_no: int = frame_info.lineno
    return LoggingCallerInfo(caller_module_name, caller_file_path, caller_line_no)


def _get_logger(caller_module_name: str) -> Logger:
    """Retrieves and returns a Logger instance for the specified module name."""

    return logging.getLogger(caller_module_name)


def _gather_code_content(syntax_highlighting: bool, args: tuple) -> str:
    """Gathers and returns code content for logging, if `syntax_highlighting` else returns empty string."""

    if not syntax_highlighting or not args:
        return ""

    arg_0 = args[0]
    content: str = ""

    if isinstance(arg_0, libcst.CSTNode):
        content = common_functions.extract_code_content(arg_0)
    elif isinstance(arg_0, list) and all(
        isinstance(node, libcst.CSTNode) for node in arg_0
    ):
        content = "\n".join(
            common_functions.extract_stripped_code_content(node) for node in arg_0
        )
    elif isinstance(arg_0, NodeAndPositionData):
        content = "\n".join(
            common_functions.extract_stripped_code_content(node) for node in arg_0.nodes
        )

    return content


def _handle_syntax_highlighting(
    syntax_highlighting: bool,
    log_record: logging.LogRecord,
    logger: Logger,
    content: str,
) -> None:
    """Handles syntax highlighting for the log record if enabled."""

    if syntax_highlighting:
        log_record.syntax_highlight = syntax_highlighting
        log_record.content = content
        logger.handle(log_record)


def _handle_logging(
    logger: Logger,
    caller_info: LoggingCallerInfo,
    level: int,
    log_message: str,
    syntax_highlighting: bool,
    code_content: str,
) -> None:
    """Handles the logging process, including the creation and handling of log records."""

    if logger.isEnabledFor(level):
        log_record: LogRecord = _gather_log_record_context(
            caller_info, level, log_message
        )
        logger.handle(log_record)  # Print log message
        _handle_syntax_highlighting(
            syntax_highlighting, log_record, logger, code_content
        )



File: postcode/utilities/processing_context.py
----------------------------------------
from dataclasses import dataclass

import libcst


@dataclass
class PositionData:
    """Positional data for a node in the syntax tree."""

    start: int
    end: int


@dataclass
class NodeAndPositionData:
    """A node in the syntax tree and its positional data."""

    nodes: list[libcst.CSTNode]
    start: int
    end: int


@dataclass
class LoggingCallerInfo:
    """Information about the caller of a function that is being logged. Used for `logging_decorator`."""

    caller_module_name: str
    caller_file_path: str
    caller_line_no: int



File: postcode/updaters/change_detector.py
----------------------------------------
from postcode.databases.arangodb.arangodb_manager import ArangoDBManager
from postcode.models.models import ModuleModel
from postcode.types.postcode import ModelType


class ChangeDetector:
    def __init__(
        self, all_models: tuple[ModelType, ...], arangodb_manager: ArangoDBManager
    ) -> None:
        self.all_models: tuple[ModelType, ...] = all_models
        self.id_to_model: dict[str, ModelType] = {
            model.id: model for model in all_models
        }
        self.arangodb_manager: ArangoDBManager = arangodb_manager

    def get_affected_models(
        self, changed_files: list[str], both_directions: bool = False
    ) -> set[str]:
        affected_models = set()

        for model in self.all_models:
            if isinstance(model, ModuleModel) and model.file_path in changed_files:
                affected_models.add(model.id)
                affected_models.update(
                    self._get_connected_models(model.id, both_directions)
                )

        return affected_models

    def _get_connected_models(self, model_id: str, both_directions: bool) -> set[str]:
        connected_models = set()

        # Get outbound models (dependencies and children)
        outbound_models: list[ModelType] | None = (
            self.arangodb_manager.get_outbound_models(model_id)
        )
        if outbound_models:
            connected_models.update(model.id for model in outbound_models)

        if both_directions:
            # Get inbound models (dependents and parents)
            inbound_models: list[ModelType] | None = (
                self.arangodb_manager.get_inbound_models(model_id)
            )
            if inbound_models:
                connected_models.update(model.id for model in inbound_models)

        return connected_models



File: postcode/updaters/graph_db_updater.py
----------------------------------------
import json
import logging
import os

from postcode.ai_services.summarizer.graph_db_summarization_manager import (
    GraphDBSummarizationManager,
)
from postcode.ai_services.summarizer.openai_summarizer import OpenAISummarizer
from postcode.ai_services.summarizer.summarization_mapper import SummarizationMapper
from postcode.databases.arangodb.arangodb_connector import ArangoDBConnector

from postcode.databases.arangodb.arangodb_manager import ArangoDBManager
from postcode.databases.chroma.chromadb_collection_manager import (
    ChromaCollectionManager,
)
import postcode.databases.chroma.chroma_setup as chroma_setup
from postcode.json_management.json_handler import JSONHandler
from postcode.models.models import (
    DirectoryModel,
    ModuleModel,
)
from postcode.python_parser.visitor_manager.visitor_manager import (
    VisitorManager,
    VisitorManagerProcessFilesReturn,
)
from postcode.types.postcode import ModelType
from postcode.updaters.change_detector import ChangeDetector
import postcode.updaters.git_updater as git_updater


class GraphDBUpdater:
    """
    Graph DB based updater supporting multi-pass summarization.

    Updates, parses the files in a directory, saves the models as JSON, in the graph database, and in a ChromaDB collection.

    Args:
        - `directory` (str): The directory of the project to update.
            default: "."
        - `summarizer` (OpenAISummarizer): The OpenAI summarizer to use for summarizing the code.
        - `output_directory` (str): The directory to save the JSON files.
            - default: "pc_output_json"
        - `graph_connector` (ArangoDBConnector): The ArangoDB connector to use for connecting to the graph database.
            - default: ArangoDBConnector() - instantiates a new ArangoDBConnector with its default values

    Example:
        ```Python
        from postcode.databases.arangodb.arangodb_connector import ArangoDBConnector
        from postcode.updaters.graph_db_updater import GraphDBUpdater

        # Create the ArangoDB connector.
        arango_connector = ArangoDBConnector()

        # Create the GraphDBUpdater.
        graph_updater = GraphDBUpdater(directory, output_directory, arango_connector)

        # Update all the models for the project and setup Chroma.
        chroma_collection_manager = graph_updater.update_all()
        ```
    """

    def __init__(
        self,
        directory: str = ".",
        *,
        summarizer: OpenAISummarizer = OpenAISummarizer(),
        output_directory: str = "pc_output_json",
        graph_connector: ArangoDBConnector = ArangoDBConnector(),
    ) -> None:
        self.directory: str = directory
        self.summarizer: OpenAISummarizer = summarizer
        self.output_directory: str = output_directory
        self.graph_connector: ArangoDBConnector = graph_connector

        self.graph_manager = ArangoDBManager(graph_connector)
        self.last_commit_file = os.path.join(self.output_directory, "last_commit.json")

    def update_changed(self, num_passes: int = 1) -> ChromaCollectionManager:
        """
        Updates only the changed files and their connected code blocks since the last update.

        Args:
            last_commit_hash (str): The commit hash of the last update.
            num_passes (int): Number of summarization passes to perform. Must be either 1 or 3. Default is 1.

        Returns:
            ChromaCollectionManager: The updated ChromaDB collection manager.
        """
        if num_passes not in [1, 3]:
            raise ValueError("Number of passes must be either 1 or 3")

        last_commit_hash: str = self._get_last_commit_hash()
        changed_files: list[str] = git_updater.get_changed_files_since_last_update(
            last_commit_hash
        )

        # Parse all files (we need the full structure to detect connections)
        process_files_return = self._visit_and_parse_files(self.directory)
        all_models = process_files_return.models_tuple

        # Detect affected models
        change_detector = ChangeDetector(
            all_models,
            self.graph_manager,
        )
        affected_model_ids: set[str] = change_detector.get_affected_models(
            changed_files, both_directions=True if num_passes == 3 else False
        )

        # Filter models to only affected ones
        affected_models = [
            model for model in all_models if model.id in affected_model_ids
        ]
        affected_models = tuple(affected_models)

        # Update graph DB with all models (to ensure structure is up-to-date)
        self._upsert_models_to_graph_db(all_models)

        # Summarize and update only affected models
        finalized_models = self._map_and_summarize_models(affected_models, num_passes)

        if not finalized_models:
            raise Exception("No finalized models returned from summarization.")

        # Update databases with finalized models
        self._upsert_models_to_graph_db(tuple(finalized_models))
        chroma_manager = chroma_setup.setup_chroma_with_update(finalized_models)

        current_commit_hash = git_updater.get_current_commit_hash()
        self._save_last_commit_hash(current_commit_hash)

        return chroma_manager

    def _save_last_commit_hash(self, commit_hash: str) -> None:
        """
        Saves the last commit hash to a file.

        Args:
            commit_hash (str): The commit hash to save.
        """
        os.makedirs(os.path.dirname(self.last_commit_file), exist_ok=True)
        with open(self.last_commit_file, "w") as f:
            json.dump({"last_commit": commit_hash}, f)

    def _get_last_commit_hash(self) -> str:
        """
        Retrieves the last commit hash from the file.

        Returns:
            str: The last commit hash, or an empty string if the file doesn't exist.
        """
        if not os.path.exists(self.last_commit_file):
            return ""
        with open(self.last_commit_file, "r") as f:
            data = json.load(f)
            return data.get("last_commit", "")

    def update_all(self, num_passes: int = 1) -> ChromaCollectionManager:
        """
        Updates all the models for a project using the graph database with multi-pass summarization support.

        Args:
            - num_passes (int): Number of summarization passes to perform. Must be either 1 or 3. Default is 1.

        Note:
            This method will delete all the existing collections in the graph database, summarize every code block in the project,
            and save the new models in the graph database and as JSON. Use with caution as it is expensive with respect to time, resources,
            and money.

        Returns:
            - `chroma_collection_manager` (ChromaDBCollectionManager): The ChromaDB collection manager.

        Raises:
            - `Exception`: If no finalized models are returned from summarization.
            - `ValueError`: If num_passes is not 1 or 3.

        Example:
            ```Python
            graph_updater = GraphDBUpdater(directory, output_directory)

            # Update all the models for the project with multi-pass summarization and setup Chroma.
            chroma_manager = graph_updater.update_all(num_passes=3)
            ```
        """
        if num_passes not in [1, 3]:
            raise ValueError("Number of passes must be either 1 or 3")

        self.graph_connector.delete_all_collections()
        self.graph_connector.ensure_collections()

        process_files_return: VisitorManagerProcessFilesReturn = (
            self._visit_and_parse_files(self.directory)
        )
        models_tuple: tuple[ModelType, ...] = process_files_return.models_tuple

        self._upsert_models_to_graph_db(models_tuple)

        finalized_models: list[ModelType] | None = self._map_and_summarize_models(
            models_tuple, num_passes
        )

        if not finalized_models:
            raise Exception("No finalized models returned from summarization.")

        json_manager = JSONHandler(
            self.directory,
            process_files_return.directory_modules,
            self.output_directory,
        )
        self._save_json(finalized_models, json_manager)
        self._upsert_models_to_graph_db(tuple(finalized_models))

        current_commit_hash: str = git_updater.get_current_commit_hash()
        self._save_last_commit_hash(current_commit_hash)

        return chroma_setup.setup_chroma_with_update(finalized_models)

    def _visit_and_parse_files(
        self, directory: str
    ) -> VisitorManagerProcessFilesReturn:
        """Visits and parses the files in the directory."""

        logging.info("Starting the directory parsing.")
        visitor_manager = VisitorManager(directory)

        return visitor_manager.process_files()

    def _get_module_ids(self, models_tuple: tuple[ModelType, ...]) -> list[str]:
        """Returns a list of module IDs from the models tuple."""

        return [model.id for model in models_tuple if isinstance(model, ModuleModel)]

    def _upsert_models_to_graph_db(self, models_tuple: tuple[ModelType, ...]) -> None:
        """Upserts the models to the graph database."""

        self.graph_manager.upsert_models(
            list(models_tuple)
        ).process_imports_and_dependencies().get_or_create_graph()

    def _save_json(self, models: list[ModelType], json_manager: JSONHandler) -> None:
        """Saves the models as JSON."""

        logging.info("Saving models as JSON")
        for model in models:
            if isinstance(model, DirectoryModel):
                output_path: str = model.id

            else:
                output_path: str = model.file_path + model.id
            json_manager.save_model_as_json(model, output_path)

        json_manager.save_visited_directories()
        logging.info("JSON save complete")

    def _map_and_summarize_models(
        self,
        models_tuple: tuple[ModelType, ...],
        num_passes: int,
    ) -> list[ModelType] | None:
        """Maps and summarizes the models using multi-pass summarization."""

        module_ids: list[str] = self._get_module_ids(models_tuple)
        summarization_mapper = SummarizationMapper(
            module_ids, models_tuple, self.graph_manager
        )
        summarization_manager = GraphDBSummarizationManager(
            models_tuple, summarization_mapper, self.summarizer, self.graph_manager
        )

        finalized_models: list[ModelType] | None = (
            summarization_manager.create_summaries_and_return_updated_models(num_passes)
        )
        logging.info(f"Multi-pass summarization complete (passes: {num_passes})")

        return finalized_models if finalized_models else None



File: postcode/updaters/git_updater.py
----------------------------------------
import subprocess


def get_changed_files_since_last_update(last_commit_hash: str) -> list[str]:
    """
    Returns a list of Python files that have been changed since the last update.

    Args:
        `last_commit_hash` (str): The commit hash of the last update.

    Returns:
        `list[str]`: A list of changed Python file paths.
    """
    git_command = f"git diff --name-only {last_commit_hash} HEAD"

    result = subprocess.run(git_command, shell=True, capture_output=True, text=True)
    if result.returncode != 0:
        raise Exception(f"Git command failed: {result.stderr}")

    changed_files = result.stdout.strip().split("\n")
    return [file for file in changed_files if file.endswith(".py")]


def get_current_commit_hash() -> str:
    """
    Retrieves the current commit hash.

    Returns:
        `str`: The current commit hash.
    """
    git_command = "git rev-parse HEAD"

    result = subprocess.run(git_command, shell=True, capture_output=True, text=True)
    if result.returncode != 0:
        raise Exception(f"Git command failed: {result.stderr}")

    return result.stdout.strip()



File: postcode/cli_app.py
----------------------------------------
import logging
import typer
from typing import Annotated, Literal, Optional, Any
from pathlib import Path
from postcode import Postcode
from postcode.updaters.graph_db_updater import GraphDBUpdater
from rich import print
from postcode.utilities.logger.logging_config import setup_logging

app = typer.Typer()

postcode_instance: Optional[Postcode] = None


def process_codebase(
    path: Path,
    postcode_instance: Postcode,
    num_of_passes: int = 3,
    process_all: bool = False,
) -> None:
    """
    Process the codebase at the given path.
    """
    try:
        updater = GraphDBUpdater(str(path))
        postcode_instance.process_codebase(updater, num_of_passes, process_all)
        typer.echo("Codebase processing complete.")
    except Exception as e:
        logging.exception("Error processing codebase")
        typer.echo(f"Error processing codebase: {e}")
        raise typer.Exit(1)


def connect_to_vectorstore(postcode_instance: Postcode) -> None:
    """
    Connect to an existing vectorstore.
    """
    try:
        postcode_instance.connect_to_vectorstore()
        typer.echo("Connected to existing vectorstore.")
    except Exception as e:
        logging.exception("Error connecting to vectorstore")
        typer.echo(f"Error connecting to vectorstore: {e}")
        raise typer.Exit(1)


def chat_loop() -> None:
    """
    Start a chat session with Postcode.
    """
    if not postcode_instance:
        typer.echo(
            "Error: Codebase has not been processed. Please process the codebase first."
        )
        raise typer.Exit(1)

    print(
        "[blue]Chat[/blue] session started. Type [magenta]'exit'[/magenta] to end the chat."
    )
    while True:
        user_input = typer.prompt("You")
        if user_input.lower() == "exit":
            break
        try:
            response = postcode_instance.chat(user_input)
            typer.echo(f"AI: {response}")
        except Exception as e:
            logging.exception("Error during chat")
            typer.echo(f"Error during chat: {e}")
            break


def get_path_from_option(option_value: Any) -> Path:
    if hasattr(option_value, "default"):
        # If it's an OptionInfo object, use its default value
        path_str = str(option_value.default)
    else:
        # Otherwise, assume it's already a string
        path_str = str(option_value)

    path: Path = Path(path_str).resolve()
    if not path.exists():
        raise typer.BadParameter(f"The path '{path}' does not exist.")
    return path


@app.command()
def main(
    path: Annotated[
        str, typer.Argument(help="The path to the directory containing the codebase")
    ] = ".",
    update: Annotated[
        bool,
        typer.Argument(
            help="Whether to update the summaries and databases with the code that has changed since the last git commit"
        ),
    ] = False,
    update_all: Annotated[
        bool,
        typer.Argument(
            help="Whether to update the summaries and databases for the whole project, `update` must be False"
        ),
    ] = False,
    chat: Annotated[
        bool,
        typer.Argument(
            help="Whether to start a chat session with Postcode, if updating it will run after processing the codebase"
        ),
    ] = True,
    passes: Annotated[
        int,
        typer.Argument(
            help="The number of passes the summarizer will take, 1 is bottom-up, 3 is bottom-up, top-down, then bottom-up again"
        ),
    ] = 3,
) -> None:
    """
    Process the codebase and start a chat session with Postcode.
    """
    setup_logging()

    try:
        resolved_path: Path = Path(path).resolve()

        if passes not in {1, 3}:
            raise typer.BadParameter("Number of passes must be 1 or 3")

        global postcode_instance
        postcode_instance = Postcode()

        if update:
            print(
                f"[bold blue]POSTCODE[/bold blue]\n\nProcessing codebase at path: '{resolved_path}'"
            )
            process_codebase(resolved_path, postcode_instance, passes, update_all)
        else:
            print("[blue]POSTCODE[/blue]\n\nConnecting to existing vectorstore")
            connect_to_vectorstore(postcode_instance)
        if chat:
            chat_loop()
    except typer.BadParameter as e:
        logging.error(f"Invalid parameter: {e}")
        typer.echo(str(e))
        raise typer.Exit(1)
    except typer.Exit:
        logging.error("Codebase processing failed")
        raise
    except Exception as e:
        logging.exception("An unexpected error occurred")
        typer.echo(f"An unexpected error occurred: {e}")
        raise typer.Exit(1)


if __name__ == "__main__":
    app()



File: aggregate_files.sh
----------------------------------------
#!/bin/bash

# Set the output file name
output_file="aggregated_contents.txt"

# Remove the output file if it already exists
rm -f "$output_file"

# Function to process each file
process_file() {
    local file="$1"
    local rel_path="${file#./}"
    # Append file path and contents to the output file
    echo "File: $rel_path" >> "$output_file"
    echo "----------------------------------------" >> "$output_file"
    cat "$file" >> "$output_file"
    echo -e "\n\n" >> "$output_file"
}

# Variable to keep track of the last printed directory
last_dir=""

# Function to print directory name
print_directory() {
    local dir=$(dirname "$1")
    if [ "$dir" != "$last_dir" ]; then
        echo "Entering directory: $dir"
        last_dir="$dir"
    fi
}

# Find all files, excluding specific directories and files
find . -type f \
    ! -path "*/.git/*" \
    ! -path "*/.pytest_cache/*" \
    ! -path "*/__pycache__/*" \
    ! -path "*/.venv/*" \
    ! -path "*/node_modules/*" \
    ! -path "*/chroma/*" \
    ! -path "*/output_json/*" \
    ! -name ".gitignore" \
    ! -name "LICENSE" \
    ! -name "$output_file" \
    ! -name "*.pyc" \
    ! -name ".DS_Store" \
    ! -name "*.log" \
    ! -name "*.sqlite3" \
    ! -name "*.db" \
    ! -name "poetry.lock" \
    ! -name "Pipfile.lock" \
    ! -name "package-lock.json" \
    ! -name "yarn.lock" \
    ! -name "Gemfile.lock" \
    ! -name "composer.lock" \
    ! -name "*.env" \
    ! -name ".env.*" \
    ! -name "*.cfg" \
    ! -name "*.ini" \
    ! -name "*.toml" \
    ! -name "*.yaml" \
    ! -name "*.yml" \
    -print0 | while IFS= read -r -d '' file; do
    print_directory "$file"
    process_file "$file"
done

echo "File aggregation complete. Output saved to $output_file"


File: TODO.md
----------------------------------------
# TODO List

## ArangoDB Docker Setup

-   docker pull arangodb/arangodb:3.11.6
-   docker run -e ARANGO_ROOT_PASSWORD=openSesame -p 8529:8529 -d arangodb/arangodb:3.11.6

## Things to do before showing

-   [x] Create simple chat agent
-   [x] Update docstrings
-   [ ] Add logic to construct dbs from json
-   [x] Finish `StandardUpdater`, only the `update_all` method, class to replace `main.py` for parsing, summarization, and DB insertion as an interface

    -   `update_all` wipes and updates the summaries and databases for the whole project

-   [x] Create AI tools to retrieve from ChromaDB
-   [ ] Add chatbot interface
-   [ ] Add summarization logic for the directory models
-   [ ] Create 3-4 more simple agents to show off capabilities

    -   [ ] Starting with general 'agent', question answering

-   [ ] Add logic to reverse create models from ChromaDB
-   [ ] Complete version control updater
-   [ ] Add readme
-   [ ] Add test coverage
-   [ ] Move to new repo
-   [ ] Add issues
-   [ ] Create media to share

## Roadmap

-   [ ] Add tests and improve error handling
-   [ ] Make into pypi package
-   [ ] Update summaries and DB's based on version control
-   [ ] Add logic to track down where an import is defined and update import and dependency models
-   [x] Add logic to log summary count, eg. 'Summarizing k of n files'
-   [ ] Add tests for summarization
-   [ ] Add logic to get BottomUp and TopDown summary mapping to allow for multidirectional summary creation (if desired by user)
-   [ ] Fix parsing error, trying to update an import after it was updated
-   [ ] Add query logic for ArangoDB
-   [ ] Complete CRUD for chromadb
-   [ ] Complete CRUD logic for ArangoDB
-   [ ] Add tests for ArangoDB
-   [ ] Add load project from GitHub logic
-   [ ] Add MethodModel Class that overrides FunctionModel when function is a method
-   [ ] Class Attribute logic



File: README.md
----------------------------------------
# Postcode

This project is designed to parse a Python codebase and generate summaries for each code block and its dependencies. The goal is to enhance an AI's capability to engage in meaningful conversations with the codebase. The goal is to create a python package that others can use with their own projects.

## Installation

Ensure you have Poetry installed. If not, install it by following the instructions in the [Poetry Documentation](https://python-poetry.org/docs/).

Clone the repository and install the dependencies:

```bash
git clone https://github.com/evanmschultz/postcode.git
cd postcode
poetry install
```

## Usage

To simple chat with the Postcode Project as is, run the following command:

```bash
python main.py
```

-   This will create a simple CLI app to chat with an AI using the ChromaDB database saved in version control.

The project allows for use of a Graph Database and currently requires ArangoDB. To use the database, you must have ArangoDB installed and running. You can install ArangoDB in a docker container by following the instructions in the [ArangoDB Documentation](https://hub.docker.com/_/arangodb/) or by following the commands below:

```bash
docker pull arangodb/arangodb:3.11.6
docker run -e ARANGO_ROOT_PASSWORD=openSesame -p 8529:8529 -d arangodb/arangodb:3.11.6
```

## Configuration

Add configuration logic and update readme.

## Contributing

If you find issues or have suggestions for improvement, feel free to open an issue or submit a pull request. Contributions are greatly welcome!

## Philosophical Question

-   Does an an AI chatbot work better with knowledge of what code does or why it does it?

    -   A bottom up approach while summarizing a codebase helps with the what
    -   A top down approach while summarizing a codebase helps with the why
    -   A combination, where summaries are built from bottom-up then redone from top-down would be expensive, yet likely improve results, but by how much?
        -   Also, how many iterations of that process would it take to get diminishing returns?

-   Chain of density summarization doesn't work for code bases. Update summary prompt to create larger more diverse summaries as they will help with RAG.
-   Maybe add the top level summary / project summary to (logic to be added) to the librarian and agent prompt would help.

<!-- ## License

This project is licensed under the [MIT License](LICENSE). -->



File: py.typed
----------------------------------------



