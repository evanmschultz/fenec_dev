{
    "function_name": "get_response",
    "docstring": "Generates a response to the user's question using the OpenAI API.\n\nArgs:\n    - user_question (str): The user's question.\n    - prompt_template (str, optional): The template for formatting the prompt.\n        Defaults to DEFAULT_PROMPT_TEMPLATE.\n\nReturns:\n    - str | None: The generated response or None if the response could not be generated.\n\nRaises:\n    - ValueError: If user_question is empty.\n    - RuntimeError: If there is an issue with the OpenAI API request.\n    - KeyError: If the prompt template is missing required keys.\n\nExample:\n    ```python\n    agent = OpenAIChatAgent(chroma_librarian, model=\"gpt-4-1106-preview\")\n    try:\n        response = agent.get_response(\"What is the capital of France?\")\n        print(response)\n    except ValueError as ve:\n        print(f\"ValueError: {ve}\")\n    except RuntimeError as re:\n        print(f\"RuntimeError: {re}\")\n    except KeyError as ke:\n        print(f\"KeyError: {ke}\")\n    ```",
    "decorators": null,
    "parameters": null,
    "returns": "str | None",
    "is_method": true,
    "is_async": false,
    "id": "postcode:ai_services:chat:openai_agents.py__*__MODULE__*__CLASS-OpenAIChatAgent__*__FUNCTION-get_response",
    "file_path": "postcode/ai_services/chat/openai_agents.py",
    "parent_id": "postcode:ai_services:chat:openai_agents.py__*__MODULE__*__CLASS-OpenAIChatAgent",
    "block_type": "FUNCTION",
    "start_line_num": 44,
    "end_line_num": 115,
    "code_content": "\ndef get_response(\n    self, user_question: str, prompt_template: str = DEFAULT_PROMPT_TEMPLATE\n) -> str | None:\n    \"\"\"\n        Generates a response to the user's question using the OpenAI API.\n\n        Args:\n            - user_question (str): The user's question.\n            - prompt_template (str, optional): The template for formatting the prompt.\n                Defaults to DEFAULT_PROMPT_TEMPLATE.\n\n        Returns:\n            - str | None: The generated response or None if the response could not be generated.\n\n        Raises:\n            - ValueError: If user_question is empty.\n            - RuntimeError: If there is an issue with the OpenAI API request.\n            - KeyError: If the prompt template is missing required keys.\n\n        Example:\n            ```python\n            agent = OpenAIChatAgent(chroma_librarian, model=\"gpt-4-1106-preview\")\n            try:\n                response = agent.get_response(\"What is the capital of France?\")\n                print(response)\n            except ValueError as ve:\n                print(f\"ValueError: {ve}\")\n            except RuntimeError as re:\n                print(f\"RuntimeError: {re}\")\n            except KeyError as ke:\n                print(f\"KeyError: {ke}\")\n            ```\n        \"\"\"\n    if not user_question:\n        raise ValueError(\"User question cannot be empty.\")\n\n    try:\n        chroma_results: chroma_types.QueryResult | None = (\n            self.chroma_librarian.query_chroma(user_question)\n        )\n\n        if not chroma_results:\n            return \"I don't know how to answer that question.\"\n\n        documents: list[list[str]] | None = chroma_results[\"documents\"]\n\n        if not documents:\n            return \"I don't know how to answer that question.\"\n\n        context: str = \"\"\n        for document in documents:\n            context += \"\\n\".join(document) + \"\\n\"\n\n        prompt: str = self._format_prompt(context, user_question, prompt_template)\n\n        messages: Sequence[dict[str, str]] = [\n            {\"role\": \"system\", \"content\": DEFAULT_SYSTEM_PROMPT},\n            {\"role\": \"user\", \"content\": prompt},\n        ]\n\n        response: openai_types.ChatCompletion = self.client.chat.completions.create(\n            model=self.model,\n            messages=messages,  # type: ignore # FIXME: fix type hinting error\n            temperature=0.1,\n            # response_format={\"type\": \"json_object\"},\n        )\n        return response.choices[0].message.content\n\n    except Exception as e:\n        raise RuntimeError(f\"Error interacting with OpenAI API: {e}\") from e\n",
    "important_comments": [
        {
            "content": "# type: ignore # FIXME: fix type hinting error",
            "comment_types": [
                "FIXME"
            ]
        }
    ],
    "dependencies": null,
    "summary": "\nThe `get_response` method retrieves documents related to a user's question via `chroma_librarian.query_chroma`, constructs a context, and formats a prompt to request a response from the OpenAI API, returning a fallback message if no documents are found. It extracts the response from the API's structured output, handling exceptions by raising `ValueError` for empty input, `RuntimeError` for API interaction errors, and `KeyError` for prompt template issues, while also noting a type hinting error to be fixed.",
    "children_ids": []
}