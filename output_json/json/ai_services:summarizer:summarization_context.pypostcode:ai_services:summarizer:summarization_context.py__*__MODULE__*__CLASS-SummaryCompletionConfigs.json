{
    "class_name": "SummaryCompletionConfigs",
    "decorators": null,
    "bases": [
        "BaseModel"
    ],
    "docstring": "Configs for the summarization completion.\n\nUsed to set the chat completion parameters for the OpenAI chat completions method call.\n\nArgs:\n    - system_message (str): The system message used for chat completion.\n    - model (str): The model to use for the completion. Default is \"gpt-4-1106-preview\".\n    - max_tokens (int | None): The maximum number of tokens to generate. 'None' implies no limit. Default is None.\n    - stream (bool): Whether to stream back partial progress. Default is False.\n    - temperature (float): Sampling temperature to use. Default is 0.0.\n\nNotes:\n    - model must be a valid OpenAI model name.\n\nExamples:\n    ```Python\n    system_message = \"Summarize the following code.\"\n    summary_completion_configs = SummaryCompletionConfigs(\n        system_message=system_message,\n        model=\"gpt-4-1106-preview\",\n        max_tokens=100,\n        presence_penalty=0.0,\n        stream=False,\n        temperature=0.0,\n    )\n    ```",
    "keywords": null,
    "id": "postcode:ai_services:summarizer:summarization_context.py__*__MODULE__*__CLASS-SummaryCompletionConfigs",
    "file_path": "postcode/ai_services/summarizer/summarization_context.py",
    "parent_id": "postcode:ai_services:summarizer:summarization_context.py__*__MODULE",
    "block_type": "CLASS",
    "start_line_num": 7,
    "end_line_num": 59,
    "code_content": "\n\nclass SummaryCompletionConfigs(BaseModel):\n    \"\"\"\n    Configs for the summarization completion.\n\n    Used to set the chat completion parameters for the OpenAI chat completions method call.\n\n    Args:\n        - system_message (str): The system message used for chat completion.\n        - model (str): The model to use for the completion. Default is \"gpt-4-1106-preview\".\n        - max_tokens (int | None): The maximum number of tokens to generate. 'None' implies no limit. Default is None.\n        - stream (bool): Whether to stream back partial progress. Default is False.\n        - temperature (float): Sampling temperature to use. Default is 0.0.\n\n    Notes:\n        - model must be a valid OpenAI model name.\n\n    Examples:\n        ```Python\n        system_message = \"Summarize the following code.\"\n        summary_completion_configs = SummaryCompletionConfigs(\n            system_message=system_message,\n            model=\"gpt-4-1106-preview\",\n            max_tokens=100,\n            presence_penalty=0.0,\n            stream=False,\n            temperature=0.0,\n        )\n        ```\n    \"\"\"\n\n    system_message: str = summarization_prompts.SUMMARIZER_DEFAULT_INSTRUCTIONS\n    model: Literal[\n        \"gpt-4-1106-preview\",\n        \"gpt-4-vision-preview\",\n        \"gpt-4\",\n        \"gpt-4-0314\",\n        \"gpt-4-0613\",\n        \"gpt-4-32k\",\n        \"gpt-4-32k-0314\",\n        \"gpt-4-32k-0613\",\n        \"gpt-3.5-turbo-1106\",\n        \"gpt-3.5-turbo\",\n        \"gpt-3.5-turbo-16k\",\n        \"gpt-3.5-turbo-0301\",\n        \"gpt-3.5-turbo-0613\",\n        \"gpt-3.5-turbo-16k-0613\",\n    ] = \"gpt-4-1106-preview\"\n    max_tokens: int | None = None\n    stream: bool = False\n    temperature: float = 0.0\n",
    "important_comments": null,
    "dependencies": [
        {
            "import_names": [
                {
                    "name": "Literal",
                    "as_name": null,
                    "local_block_id": null
                },
                {
                    "name": "Protocol",
                    "as_name": null,
                    "local_block_id": null
                }
            ],
            "imported_from": "typing",
            "import_module_type": "STANDARD_LIBRARY",
            "local_module_id": null
        },
        {
            "import_names": [
                {
                    "name": "BaseModel",
                    "as_name": null,
                    "local_block_id": null
                }
            ],
            "imported_from": "pydantic",
            "import_module_type": "THIRD_PARTY",
            "local_module_id": null
        },
        {
            "import_names": [
                {
                    "name": "summarization_prompts",
                    "as_name": null,
                    "local_block_id": null
                }
            ],
            "imported_from": "postcode.ai_services.summarizer.prompts",
            "import_module_type": "LOCAL",
            "local_module_id": "postcode:ai_services:summarizer:prompts:summarization_prompts.py__*__MODULE"
        }
    ],
    "summary": null,
    "children_ids": []
}