rn.directory_modules\\n        self.graph_manager.upsert_models(\\n            list(module_models_tuple)\\n        ).process_imports_and_dependencies().get_or_create_graph()\\n        summarization_mapper = SummarizationMapper(\\n            module_ids, module_models_tuple, self.graph_manager\\n        )\\n        client = OpenAI(max_retries=4)\\n        summarizer = OpenAISummarizer(client=client)\\n        summarization_manager = GraphDBSummarizationManager(\\n            module_models_tuple, summarization_mapper, summarizer, self.graph_manager\\n        )\\n        finalized_module_models: list[\\n            ModuleModel\\n        ] | None = summarization_manager.create_summaries_and_return_updated_models()\\n        logger.info(\\\"Summarization complete\\\")\\n\\n        logger.info(\\\"Saving models as JSON\\\")\\n        json_manager = JSONHandler(directory, directory_modules, output_directory)\\n\\n        for module_model in module_models_tuple:\\n            json_manager.save_model_as_json(module_model, module_model.file_path)\\n\\n        json_manager.save_visited_directories()\\n        logger.info(\\\"JSON save complete\\\")\\n\\n        logger.info(\\\"Directory parsing completed.\\\")\\n\\n        # self.graph_manager.upsert_models(\\n        #     list(finalized_module_models)\\n        # ).process_imports_and_dependencies().get_or_create_graph()\\n\\n        if finalized_module_models:\\n            chroma_context: ChromaSetupReturnContext = setup_chroma(\\n                finalized_module_models, logger\\n            )\\n        else:\\n            raise Exception(\\\"No finalized models returned from summarization.\\\")\\n\\n        return chroma_context\\n\\n, \\nImported code block (postcode:ai_services:summarizer:graph_db_summarization_manager.py__*__MODULE) code content:\\n# FIXME: This file is not currently being used. It is a work in progress as the summarization mapper isn't getting returning all of the project models.\\n\\nimport logging\\nfrom pprint import pprint\\nfrom typing import Union\\n\\nfrom postcode.ai_services.summarizer.summarization_context import (\\n    Summarizer,\\n    OpenAIReturnContext,\\n)\\nfrom postcode.ai_services.summarizer.summarization_mapper import SummarizationMapper\\nfrom postcode.databases.arangodb.arangodb_manager import ArangoDBManager\\n\\n# from postcode.types.postcode import ModelType\\n\\nfrom postcode.models.models import (\\n    ClassModel,\\n    DependencyModel,\\n    FunctionModel,\\n    ImportModel,\\n    ModuleModel,\\n    StandaloneCodeBlockModel,\\n)\\n\\nModelType = Union[\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n]\\n\\n\\nclass GraphDBSummarizationManager:\\n    def __init__(\\n        self,\\n        module_models_tuple: tuple[ModuleModel, ...],\\n        summarization_mapper: SummarizationMapper,\\n        summarizer: Summarizer,\\n        graph_manager: ArangoDBManager,\\n    ) -> None:\\n        self.module_models_tuple: tuple[ModuleModel, ...] = module_models_tuple\\n        self.summarization_mapper: SummarizationMapper = summarization_mapper\\n        self.summarizer: Summarizer = summarizer\\n        self.summarized_code_block_ids: set[str] = set()\\n        self.prompt_tokens: int = 0\\n        self.completion_tokens: int = 0\\n        self.graph_manager: ArangoDBManager = graph_manager\\n\\n    @property\\n    def total_cost(self) -> float:\\n        \\\"\\\"\\\"Provides the total cost of the summarization process.\\\"\\\"\\\"\\n        prompt_cost: int = self.prompt_tokens * 1  # Costs 1 cent per 1,000 tokens\\n        completion_cost: int = (\\n            self.completion_tokens * 3\\n        )  # Costs 3 cents per 1,000 tokens\\n        return (prompt_cost + completion_cost) / 100_000  # Convert to dollars\\n\\n    def create_summaries_and_return_updated_models(self) -> list[ModuleModel] | None:\\n        summarization_map: list[\\n            ModelType\\n        ] = self.summarization_mapper.create_summarization_map()\\n        models_to_summarize_count: int = len(summarization_map)\\n        models_summarized_count: int = 0\\n\\n        for model in summarization_map:\\n            children_summaries: str | None = None\\n            dependency_summaries: str | None = None\\n            import_details: str | None = None\\n\\n            if model.children:\\n                children_summaries: str | None = self._stringify_children_summaries(\\n                    self._get_child_summaries(model)\\n                )\\n            if isinstance(model, ModuleModel):\\n                if model.imports:\\n                    dependency_summaries = self._get_dependencies_summaries(model)\\n                    import_details = \\\"\\\"\\n                    for _import in model.imports:\\n                        if import_summary := self._get_import_details(_import):\\n                            import_details += f\\\"\\\\n{import_summary}\\\"\\n            else:\\n                if model.dependencies:\\n                    dependency_summaries = self._get_dependencies_summaries(model)\\n                    import_details = \\\"\\\"\\n                    for dependency in model.dependencies:\\n                        if isinstance(dependency, DependencyModel):\\n                            continue\\n                        if import_summary := self._get_import_details(dependency):\\n                            import_details += f\\\"\\\\n{import_summary}\\\"\\n\\n            models_summarized_count += 1\\n            logging.info(\\n                f\\\"Summarizing model {models_summarized_count} out of {models_to_summarize_count}; {model.id}.\\\"\\n            )\\n\\n            summary_return_context: OpenAIReturnContext | None = (\\n                self.summarizer.test_summarize_code(\\n                    model.code_content,\\n                    model_id=model.id,\\n                    children_summaries=children_summaries,\\n                    dependency_summaries=dependency_summaries,\\n                    import_details=import_details,\\n                )\\n            )\\n            if summary_return_context:\\n                if summary_return_context.summary:\\n                    self.graph_manager.update_vertex_by_id(\\n                        model.id, summary_return_context.summary\\n                    )\\n                self.prompt_tokens += summary_return_context.prompt_tokens\\n                self.completion_tokens += summary_return_context.completion_tokens\\n\\n                # for module_model in self.module_models_tuple:\\n                #     if isinstance(model, ModuleModel):\\n                #         if module_model.id == model.id:\\n                #             module_model.summary = model.summary\\n                #             break\\n                #         else:\\n                #             continue\\n                #     else:\\n                #         module_id_for_model: str = model.id.split(\\\"MODULE\\\")[0]\\n                #         if (\\n                #             module_model.children\\n                #             and module_id_for_model in module_model.id\\n                #         ):\\n                #             for child_model in module_model.children:\\n                #                 if child_model.id == model.id:\\n                #                     # child_model.summary = model.summary\\n                #                     break\\n                #         else:\\n                #             continue\\n\\n        pprint([model.id for model in summarization_map[::-1]])\\n        print(len(summarization_map))\\n\\n        return self.graph_manager.get_all_modules() if self.graph_manager else None\\n\\n    def _get_child_summaries(self, model: ModelType) -> list[str]:\\n        \\\"\\\"\\\"Gathers summaries of child models.\\\"\\\"\\\"\\n        child_summary_list: list[str] = []\\n        if model.children:\\n            for child in model.children:\\n                if child.summary:\\n                    child_summary: str = child.summary\\n                else:\\n                    child_summary = (\\n                        f\\\"Child ({child.id}) code content:\\\\n{child.code_content}\\\\n\\\"\\n                    )\\n                child_summary_list.append(child_summary)\\n        return child_summary_list\\n\\n    def _stringify_children_summaries(self, children_summary_list: list[str]) -> str:\\n        \\\"\\\"\\\"Converts all of the child summaries to a single string to be used in the prompt.\\\"\\\"\\\"\\n\\n        children_summaries: str = \\\"\\\"\\n        for child_summary in children_summary_list:\\n            children_summaries += f\\\"\\\\n{child_summary}\\\"\\n        return children_summaries\\n\\n    def _get_dependencies_summaries(self, model: ModelType) -> str | None:\\n        dependency_list: list[ImportModel | DependencyModel] | list[ImportModel] = []\\n        dependency_summary_list: list[str] = []\\n\\n        if isinstance(model, ModuleModel):\\n            if not model.imports:\\n                return None\\n\\n            dependency_list = model.imports\\n        else:\\n            if not model.dependencies:\\n                return None\\n\\n            dependency_list = model.dependencies\\n        for dependency in dependency_list:\\n            if isinstance(dependency, DependencyModel) and dependency.code_block_id:\\n                if module_local_dependency_summary := self._get_local_dependency_summary(\\n                    dependency, model\\n                ):\\n                    dependency_summary_list.append(module_local_dependency_summary)\\n\\n            elif isinstance(dependency, ImportModel):\\n                if dependency.import_module_type == \\\"LOCAL\\\":\\n                    if not dependency.import_names:\\n                        if module_import_dependency := self._get_local_import_summary(\\n                            dependency\\n                        ):\\n                            dependency_summary_list.append(module_import_dependency)\\n                    else:\\n                        if import_from_dependency := self._get_local_import_from_summary(\\n                            dependency\\n                        ):\\n                            dependency_summary_list.append(import_from_dependency)\\n\\n        dependency_summaries = self._stringify_dependencies_summaries(\\n            dependency_summary_list\\n        )\\n\\n        return dependency_summaries\\n\\n    # def _get_import_details_for_dependencies(\\n    #     self, dependencies: list[ImportModel | DependencyModel]\\n    # ) -> str | None:\\n    #     import_details: str | None = None\\n    #     for dependency in dependencies:\\n    #         if isinstance(dependency, ImportModel):\\n    #             if dependency.import_module_type == \\\"LOCAL\\\":\\n    #                 continue\\n    #             else:\\n    #                 import_detail: str | None = self._get_import_details(dependency)\\n    #                 if not import_detail:\\n    #                     continue\\n    #                 if not import_details:\\n    #                     import_details = \\\"\\\"\\n    #                 import_details += f\\\"\\\\n{import_detail}\\\"\\n    #     return import_details\\n\\n    def _get_local_dependency_summary(\\n        self,\\n        dependency: DependencyModel,\\n        model: ModelType,\\n    ) -> str | None:\\n        \\\"\\\"\\\"Gets a summary for a dependency local to the module.\\\"\\\"\\\"\\n        if not model.children:\\n            return None\\n\\n        for child_model in model.children:\\n            if child_model.id == dependency.code_block_id:\\n                child_summary: str | None = None\\n\\n                if child_model.summary:\\n                    child_summary = child_model.summary\\n                else:\\n                    child_summary = f\\\"Dependency ({dependency.code_block_id}) code content:\\\\n{child_model.code_content}\\\\n\\\"\\n\\n                return child_summary\\n        return None\\n\\n    def _stringify_dependencies_summaries(\\n        self, dependencies_summary_list: list[str] | None\\n    ) -> str | None:\\n        \\\"\\\"\\\"Converts all of the dependency summaries to a single string to be used in the prompt.\\\"\\\"\\\"\\n        if not dependencies_summary_list:\\n            return None\\n\\n        dependency_summaries: str = \\\"\\\"\\n        for dependency_summary in dependencies_summary_list:\\n            dependency_summaries += f\\\"\\\\n{dependency_summary}\\\"\\n        return dependency_summaries\\n\\n    def _get_local_import_summary(self, dependency: ImportModel) -> str | None:\\n        for module_model in self.module_models_tuple:\\n            if module_model.id == dependency.local_module_id:\\n                import_summary: str | None = None\\n                if module_model.summary:\\n                    import_summary = module_model.summary\\n                else:\\n                    import_summary = f\\\"Imported module ({dependency.local_module_id}) code content:\\\\n{module_model.code_content}\\\\n\\\"\\n                return import_summary\\n        return None\\n\\n    def _get_local_import_from_summary(self, dependency: ImportModel) -> str | None:\\n        for import_name in dependency.import_names:\\n            for module_model in self.module_models_tuple:\\n                if module_model.id == dependency.local_module_id:\\n                    if module_model.children:\\n                        for child_model in module_model.children:\\n                            if (\\n                                child_model.id == import_name.local_block_id\\n                                and child_model.id\\n                            ):\\n                                import_summary: str | None = None\\n                                if child_model.summary:\\n                                    import_summary = child_model.summary\\n                                else:\\n                                    import_summary = f\\\"Imported code block ({dependency.local_module_id}) code content:\\\\n{module_model.code_content}\\\\n\\\"\\n                                return import_summary\\n        return None\\n\\n    def _get_import_details(self, import_model: ImportModel) -> str | None:\\n        \\\"\\\"\\\"Retrieves details of import statements to be used in the prompt.\\\"\\\"\\\"\\n        if import_model.import_module_type == \\\"LOCAL\\\" or not import_model.import_names:\\n            return None\\n\\n        import_names_list: list[str] = []\\n        for import_name in import_model.import_names:\\n            if import_name.as_name:\\n                import_names_list.append(f\\\"{import_name.name} as {import_name.as_name}\\\")\\n            else:\\n                import_names_list.append(f\\\"{import_name.name}\\\")\\n\\n        if import_model.imported_from:\\n            import_details: str = f\\\"from {import_model.imported_from} import {', '.join(import_names_list)}\\\"\\n        else:\\n            import_details = f\\\"import {', '.join(import_names_list)}\\\"\\n\\n        return import_details\\n\\n\\nImported code block (postcode:ai_services:summarizer:openai_summarizer.py__*__MODULE) code content:\\nimport logging\\n\\nfrom openai import OpenAI\\nfrom openai.types.chat.chat_completion_system_message_param import (\\n    ChatCompletionSystemMessageParam,\\n)\\nfrom openai.types.chat.chat_completion_user_message_param import (\\n    ChatCompletionUserMessageParam,\\n)\\nfrom openai.types.chat.chat_completion_message_param import ChatCompletionMessageParam\\nfrom openai.types.chat.chat_completion import ChatCompletion\\n\\nfrom postcode.ai_services.summarizer.prompts.prompt_creator import PromptCreator\\nfrom postcode.ai_services.summarizer.summarization_context import (\\n    OpenAIReturnContext,\\n    SummaryCompletionConfigs,\\n)\\n\\n# from postcode.ai_services.summarizer.temp import code_example\\n\\n\\nclass OpenAISummarizer:\\n    \\\"\\\"\\\"\\n    A class for summarizing code snippets using the OpenAI API.\\n\\n    Args:\\n        - client (OpenAI): The OpenAI client used for making API requests.\\n\\n    Attributes:\\n        - client (OpenAI): The OpenAI client used for making API requests.\\n        - prompt_list (list[str]): A list of summary prompts.\\n        - default_prompt (str): The default summary prompt.\\n\\n    Methods:\\n        - `summarize_code`: Summarizes the provided code snippet using the OpenAI API.\\n\\n    Examples:\\n        ```Python\\n        client = OpenAI()\\n\\n        # Create a summarizer instance with the OpenAI client\\n        summarizer = Summarizer(client=client)\\n        code_example = \\\"print('Hello, world')\\\"\\n\\n        # Summarize the code snippet\\n        summary = summarizer.summarize_code(code_example)\\n        print(summary)\\n        ```\\n    \\\"\\\"\\\"\\n\\n    def __init__(\\n        self,\\n        client: OpenAI,\\n        # *, summary_prompt_list: list[str] = summary_prompt_list\\n    ) -> None:\\n        self.client: OpenAI = client\\n        # self.prompt_list: list[str] = summary_prompt_list\\n        # self.default_prompt: str = self.prompt_list[0]\\n\\n    def _create_system_message(self, content: str) -> ChatCompletionSystemMessageParam:\\n        \\\"\\\"\\\"Creates a system message for chat completion using OpenAi's ChatCompletionSystemMessageParam class.\\\"\\\"\\\"\\n        return ChatCompletionSystemMessageParam(content=content, role=\\\"system\\\")\\n\\n    def _create_user_message(self, content: str) -> ChatCompletionUserMessageParam:\\n        \\\"\\\"\\\"Creates a user message for chat completion using OpenAi's ChatCompletionUserMessageParam class.\\\"\\\"\\\"\\n        return ChatCompletionUserMessageParam(content=content, role=\\\"user\\\")\\n\\n    def _create_messages_list(\\n        self,\\n        system_message: str,\\n        user_message: str,\\n    ) -> list[ChatCompletionMessageParam]:\\n        \\\"\\\"\\\"\\n        Creates a list of messages for chat completion, including both system and user messages.\\n\\n        Args:\\n            - system_message (str): The system message content.\\n            - user_message (str): The user message content.\\n\\n        Returns:\\n            - list[ChatCompletionMessageParam]: A list containing the system and user messages as OpenAI's\\n                ChatCompletionMessageParam classes.\\n        \\\"\\\"\\\"\\n\\n        return [\\n            self._create_system_message(system_message),\\n            self._create_user_message(user_message),\\n        ]\\n\\n    def _create_prompt(\\n        self,\\n        code: str,\\n        children_summaries: str | None,\\n        dependency_summaries: str | None,\\n        import_details: str | None,\\n    ) -> str:\\n        prompt_creator: PromptCreator = PromptCreator()\\n        prompt: str | None = prompt_creator.create_prompt(\\n            code,\\n            children_summaries,\\n            dependency_summaries,\\n            import_details,\\n        )\\n\\n        if prompt:\\n            return prompt\\n        else:\\n            raise Exception(\\\"Prompt creation failed.\\\")\\n\\n    def _get_summary(\\n        self,\\n        messages: list[ChatCompletionMessageParam],\\n        *,\\n        configs: SummaryCompletionConfigs,\\n    ) -> OpenAIReturnContext | None:\\n        \\\"\\\"\\\"\\n        Retrieves the summary from the OpenAI API based on the provided messages and configuration settings.\\n\\n        Args:\\n            - messages (list[ChatCompletionMessageParam]): A list of messages for chat completion.\\n            - configs (SummaryCompletionConfigs): Configuration settings for the summarization completion.\\n\\n        Returns:\\n            str | None: The summary generated by the OpenAI API, or None if no summary is found.\\n        \\\"\\\"\\\"\\n\\n        try:\\n            response: ChatCompletion = self.client.chat.completions.create(\\n                messages=messages,\\n                model=configs.model,\\n                max_tokens=configs.max_tokens,\\n                temperature=configs.temperature,\\n            )\\n            prompt_tokens: int = 0\\n            completion_tokens: int = 0\\n            summary: str | None = response.choices[0].message.content\\n            if response.usage:\\n                prompt_tokens = response.usage.prompt_tokens\\n                completion_tokens = response.usage.completion_tokens\\n\\n            return OpenAIReturnContext(\\n                prompt_tokens=prompt_tokens,\\n                completion_tokens=completion_tokens,\\n                summary=summary,\\n            )\\n\\n        except Exception as e:\\n            logging.error(e)\\n            return None\\n\\n    def summarize_code(\\n        self,\\n        code: str,\\n        *,\\n        model_id: str,\\n        children_summaries: str | None,\\n        dependency_summaries: str | None,\\n        import_details: str | None,\\n        configs: SummaryCompletionConfigs = SummaryCompletionConfigs(),\\n    ) -> OpenAIReturnContext | None:\\n        \\\"\\\"\\\"\\n        Summarizes the provided code snippet using the OpenAI API.\\n\\n        Args:\\n            - code (str): The code snippet to summarize.\\n            - configs (SummaryCompletionConfigs, optional): Configuration settings for the summarization.\\n                Defaults to SummaryCompletionConfigs().\\n\\n        Returns:\\n            - str: The summary of the provided code snippet.\\n\\n        Examples:\\n            ```Python\\n            client = OpenAI()\\n\\n            # Create a summarizer instance with the OpenAI client\\n            summarizer = Summarizer(client=client)\\n            code_example = \\\"print('Hello, world')\\\"\\n\\n            # Summarize the code snippet\\n            summary = summarizer.summarize_code(code_example)\\n            print(summary)\\n            ```\\n        \\\"\\\"\\\"\\n\\n        logging.info(f\\\"Summarizing code for model: {model_id}\\\")\\n        prompt: str = self._create_prompt(\\n            code, children_summaries, dependency_summaries, import_details\\n        )\\n        messages: list[ChatCompletionMessageParam] = self._create_messages_list(\\n            system_message=configs.system_message, user_message=prompt\\n        )\\n\\n        if summary_return_context := self._get_summary(messages, configs=configs):\\n            if summary_return_context:\\n                if summary_return_context.summary:\\n                    summary_return_context.summary = (\\n                        summary_return_context.summary.split(\\\"FINAL SUMMARY:\\\")[-1]\\n                    )\\n                    return summary_return_context\\n        return None\\n\\n    def test_summarize_code(\\n        self,\\n        code: str,\\n        *,\\n        model_id: str,\\n        children_summaries: str | None,\\n        dependency_summaries: str | None,\\n        import_details: str | None,\\n        configs: SummaryCompletionConfigs = SummaryCompletionConfigs(),\\n    ) -> OpenAIReturnContext | None:\\n        \\\"\\\"\\\"\\n        Summarizes the provided code snippet using the OpenAI API.\\n\\n        Args:\\n            - code (str): The code snippet to summarize.\\n            - configs (SummaryCompletionConfigs, optional): Configuration settings for the summarization.\\n                Defaults to SummaryCompletionConfigs().\\n\\n        Returns:\\n            - str: The summary of the provided code snippet.\\n        \\\"\\\"\\\"\\n\\n        summary = f\\\"\\\"\\\"\\\\nSummary:\\\\n\\n        {model_id}\\\\n\\n        {children_summaries}, {dependency_summaries}, {import_details}\\n        \\\"\\\"\\\"\\n        summary_context = OpenAIReturnContext(\\n            summary=summary,\\n            prompt_tokens=1,\\n            completion_tokens=1,\\n        )\\n\\n        return summary_context\\n\\n\\n# if __name__ == \\\"__main__\\\":\\n#     client = OpenAI()\\n#     summarizer = OpenAISummarizer(client=client)\\n#     children_summaries = \\\"\\\"\\n#     dependency_summaries = \\\"\\\"\\n#     summary = summarizer.summarize_code(\\n#         code_example,\\n#         model_id=\\\"test\\\",\\n#         children_summaries=children_summaries,\\n#         dependency_summaries=dependency_summaries,\\n#         import_details=None,\\n#     )\\n#     print(summary)\\n\\n\\nImported code block (postcode:ai_services:summarizer:summarization_mapper.py__*__MODULE) code content:\\nimport logging\\nfrom pprint import pprint\\nfrom typing import Union\\nfrom postcode.databases.arangodb.arangodb_manager import ArangoDBManager\\nfrom postcode.models.models import (\\n    ClassModel,\\n    FunctionModel,\\n    ModuleModel,\\n    StandaloneCodeBlockModel,\\n)\\n\\n# from postcode.types.postcode import ModelType\\n\\nModelType = Union[\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n]\\n\\n\\nclass SummarizationMapper:\\n    def __init__(\\n        self,\\n        module_ids_to_update: list[str],\\n        module_models: tuple[ModuleModel, ...],\\n        arangodb_manager: ArangoDBManager,\\n    ) -> None:\\n        self.module_ids_to_update: list[str] = module_ids_to_update\\n        self.module_models: tuple[ModuleModel, ...] = module_models\\n        self.arangodb_manager: ArangoDBManager = arangodb_manager\\n        self.models_to_update: list[ModelType] = []\\n        self.model_visited_in_db: set[str] = set()\\n        self.summarization_map: list[ModelType] = []\\n        self.temp_map: list[ModelType] = []\\n\\n    def _set_child_models_to_update(self, model: ModelType) -> None:\\n        if model.children:\\n            for child in model.children:\\n                # logging.info(f\\\"Setting child model to update: {child.id}\\\")\\n                self._set_child_models_to_update(child)\\n                child.summary = None\\n                self.models_to_update.append(child)\\n            self.models_to_update.append(model)\\n\\n    def _set_models_to_update(self) -> None:\\n        for model in self.module_models:\\n            if model.id in self.module_ids_to_update:\\n                if model.children:\\n                    for child in model.children:\\n                        self._set_child_models_to_update(child)\\n\\n                model.summary = None\\n                self.models_to_update.append(model)\\n\\n    def _set_inbound_models_in_summarization_map(self, model_id: str) -> None:\\n        if model_id in self.model_visited_in_db:\\n            return\\n        self.model_visited_in_db.add(model_id)\\n        if inbound_models := self.arangodb_manager.get_inbound_models(model_id):\\n            for model in inbound_models:\\n                # logging.info(f\\\"Setting inbound models in summarization map: {model.id}\\\")\\n                self.model_visited_in_db.add(model_id)\\n                self._set_inbound_models_in_summarization_map(model.id)\\n\\n                self.temp_map.append(model)\\n\\n    def _set_outbound_models_in_summarization_map(self, model_id: str) -> None:\\n        if model_id in self.model_visited_in_db:\\n            return\\n\\n        if outbound_models := self.arangodb_manager.get_outbound_models(model_id):\\n            for model in outbound_models[::-1]:\\n                # logging.info(\\n                #     f\\\"Setting outbound models in summarization map: {model.id}\\\"\\n                # )\\n                self.model_visited_in_db.add(model_id)\\n                # self._set_outbound_models_in_summarization_map(model.id)``\\n\\n                if model.id in self.models_to_update:\\n                    model.summary = None\\n                self.temp_map.append(model)\\n\\n    def create_summarization_map(self) -> list[ModelType]:\\n        self._set_models_to_update()\\n        logging.info(\\\"Set models to update\\\")\\n\\n        # pprint([model.id for model in self.models_to_update])\\n\\n        for model in self.models_to_update:\\n            # self.model_visited_in_db = set()\\n            # logging.info(f\\\"Setting inbound models in summarization map: {model.id}\\\")\\n            self._set_inbound_models_in_summarization_map(model.id)\\n            self.temp_map.append(model)\\n\\n            self.model_visited_in_db.remove(model.id)\\n            # logging.info(f\\\"Setting outbound models in summarization map: {model.id}\\\")\\n            # self._set_outbound_models_in_summarization_map(model.id)\\n            self.summarization_map.extend(self.temp_map)\\n            self.temp_map = []\\n\\n        for model in self.models_to_update:\\n            self.model_visited_in_db = set()\\n            # logging.info(f\\\"Setting outbound models in summarization map: {model.id}\\\")\\n            self._set_outbound_models_in_summarization_map(model.id)\\n            self.summarization_map.extend(self.temp_map)\\n            self.temp_map = []\\n\\n        logging.info(\\\"Created summarization map\\\")\\n        summary_ids: set[str] = set()\\n        summary_map: list[ModelType] = []\\n        for model in self.summarization_map[::-1]:\\n            if model.id not in summary_ids:\\n                summary_map.append(model)\\n                summary_ids.add(model.id)\\n\\n        # return summary_map[::-1]\\n        pprint([model.id for model in summary_map[::-1]])\\n        return summary_map[::-1]\\n\\n    # def old_create_summarization_map(self) -> list[list[ModelType]]:\\n    #     for module_id in self.module_ids_to_update:\\n    #         models_to_update: list[ModelType] = []\\n\\n    #         upstream_models: list[\\n    #             ModelType\\n    #         ] | None = self.arangodb_manager.get_all_upstream_vertices(module_id)\\n    #         downstream_models: list[\\n    #             ModelType\\n    #         ] | None = self.arangodb_manager.get_all_downstream_vertices(module_id)\\n\\n    #         ids_from_db: list[str] = []\\n    #         if upstream_models:\\n    #             upstream_ids_to_update: list[str] = [\\n    #                 model.id for model in upstream_models\\n    #             ]\\n    #             ids_from_db.extend(upstream_ids_to_update)\\n\\n    #         ids_from_db.append(module_id)\\n\\n    #         if downstream_models:\\n    #             downstream_ids_to_update: list[str] = [\\n    #                 model.id for model in downstream_models\\n    #             ]\\n    #             ids_from_db.extend(downstream_ids_to_update)\\n\\n    #         for id in ids_from_db:\\n    #             for model in self.module_models:\\n    #                 if model.id == id:\\n    #                     models_to_update.append(model)\\n    #                 elif model.children:\\n    #                     for child in model.children:\\n    #                         if child.id == id:\\n    #                             models_to_update.append(child)\\n\\n    #         self.summarization_map.append(models_to_update)\\n\\n    #     return self.summarization_map\\n\\n\\nImported code block (postcode:databases:arangodb:arangodb_connector.py__*__MODULE) code content:\\nimport logging\\nfrom typing import Any\\nfrom arango.client import ArangoClient\\nfrom arango.database import StandardDatabase\\nfrom arango.result import Result\\nfrom arango.typings import Jsons, Json\\n\\nimport postcode.databases.arangodb.helper_functions as helper_functions\\n\\n# from postcode.models import (\\n#     ModuleModel,\\n#     ClassModel,\\n#     FunctionModel,\\n#     StandaloneCodeBlockModel,\\n# )\\n\\n\\n# test = ArangoClient(hosts=\\\"http://localhost:8529\\\")\\nclass ArangoDBConnector:\\n    def __init__(\\n        self,\\n        url: str = \\\"http://localhost:8529\\\",\\n        username: str = \\\"root\\\",\\n        password: str = \\\"openSesame\\\",\\n        db_name: str = \\\"postcode\\\",\\n    ) -> None:\\n        self.client = ArangoClient(hosts=url)\\n        self.username: str = username\\n        self.password: str = password\\n        self.db_name: str = db_name\\n        self.db: StandardDatabase = self._ensure_database()\\n\\n    def _ensure_database(self) -> StandardDatabase:\\n        sys_db: StandardDatabase = self.client.db(\\n            \\\"_system\\\", username=self.username, password=self.password\\n        )\\n        if not sys_db.has_database(self.db_name):\\n            sys_db.create_database(self.db_name)\\n        return self.client.db(\\n            self.db_name, username=self.username, password=self.password\\n        )\\n\\n    # def _ensure_vertex_collections(self, vertex_collections: list[str]) -> None:\\n    #     for collection in vertex_collections:\\n    #         if not self.db.has_collection(collection):\\n    #             self.db.create_collection(collection)\\n\\n    def _get_current_schema(self, collection_name: str) -> dict:\\n        collection = self.db.collection(collection_name)\\n        try:\\n            properties: Result[Json] = collection.properties()\\n            return properties.get(\\\"schema\\\", {})  # type: ignore # FIXME: Fix type error\\n        except Exception as e:\\n            logging.error(f\\\"Error retrieving current schema for {collection_name}: {e}\\\")\\n            return {}\\n\\n    def ensure_collection(\\n        self, collection_name: str, schema: dict[str, Any] | None = None\\n    ) -> None:\\n        if not self.db.has_collection(collection_name) and not schema:\\n            self.db.create_collection(collection_name)\\n            logging.info(f\\\"Created collection: {collection_name}\\\")\\n        # else:\\n        #     current_schema = self._get_current_schema(collection_name)\\n        #     self.db.collection(collection_name)\\n        # if current_schema != schema:\\n        #     collection = self.db.collection(collection_name)\\n        #     try:\\n        #         collection.configure(schema=schema)\\n        #         logging.info(f\\\"Updated schema for collection: {collection_name}\\\")\\n        #     except Exception as e:\\n        #         logging.error(f\\\"Error updating schema for {collection_name}: {e}\\\")\\n\\n    def ensure_edge_collection(self, collection_name: str) -> None:\\n        if not self.db.has_collection(collection_name):\\n            self.db.create_collection(collection_name, edge=True)\\n            logging.info(f\\\"Created edge collection: {collection_name}\\\")\\n\\n    def delete_all_collections(self) -> None:\\n        collections: Result[Jsons] = self.db.collections()\\n\\n        for collection in collections:  # type: ignore # FIXME: Fix type error\\n            if not collection[\\\"name\\\"].startswith(\\\"_\\\"):  # Skip system collections\\n                self.db.delete_collection(collection[\\\"name\\\"])\\n                logging.info(f\\\"Deleted collection: {collection['name']}\\\")\\n\\n    def ensure_collections(self) -> None:\\n        # model_schemas: dict[str, dict[str, Any]] = self._get_model_schemas()\\n        required_collections: list[\\n            str\\n        ] = helper_functions.pluralized_and_lowered_block_types()\\n\\n        for collection_name in required_collections:\\n            # schema: dict[str, Any] = model_schemas[collection_name]\\n            # self.ensure_collection(collection_name, schema)\\n            self.ensure_collection(collection_name)\\n\\n        self.ensure_edge_collection(\\\"code_edges\\\")\\n\\n    # def _get_model_schemas(self) -> dict[str, dict[str, Any]]:\\n    #     return {\\n    #         \\\"modules\\\": ModuleModel.model_json_schema(),\\n    #         \\\"classes\\\": ClassModel.model_json_schema(),\\n    #         \\\"functions\\\": FunctionModel.model_json_schema(),\\n    #         \\\"standalone_blocks\\\": StandaloneCodeBlockModel.model_json_schema(),\\n    #     }\\n\\n\\nImported code block (postcode:databases:arangodb:arangodb_manager.py__*__MODULE) code content:\\nimport logging\\nfrom typing import Any, Callable, Union\\n\\nfrom arango.result import Result\\nfrom arango.cursor import Cursor\\nfrom arango.graph import Graph\\nfrom arango.collection import StandardCollection\\nfrom arango.typings import Json\\n\\nfrom postcode.databases.arangodb.arangodb_connector import ArangoDBConnector\\n\\n# from postcode.types.postcode import ModelType\\nfrom postcode.models.models import (\\n    ClassModel,\\n    FunctionModel,\\n    ModuleModel,\\n    StandaloneCodeBlockModel,\\n)\\nimport postcode.databases.arangodb.helper_functions as helper_functions\\n\\nModelType = Union[\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n]\\n\\n# NOTE: Remember, when adding logic to connect dependencies, the `from` the external dependency `to` the internal definition using it\\n\\n\\nclass ArangoDBManager:\\n    def __init__(\\n        self,\\n        db_connector: ArangoDBConnector,\\n        default_graph_name: str = \\\"codebase_graph\\\",\\n    ) -> None:\\n        self.db_connector: ArangoDBConnector = db_connector\\n\\n        self.processed_id_set = set()\\n        self.default_graph_name: str = default_graph_name\\n\\n    def upsert_models(self, module_models: list[ModuleModel]) -> \\\"ArangoDBManager\\\":\\n        for model in module_models:\\n            self._upsert_model(model)\\n        return self\\n\\n    def _upsert_model(self, module_model: ModuleModel) -> None:\\n        self._upsert_vertex(module_model, \\\"modules\\\")\\n        self._process_children(module_model)\\n\\n    def _process_children(self, parent_model: ModelType) -> None:\\n        if not parent_model.children:\\n            return None\\n\\n        for child in parent_model.children:\\n            # if child.id in self.processed_id_set:\\n            #     continue\\n\\n            self.processed_id_set.add(child.id)\\n            self._upsert_vertex(\\n                child, helper_functions.pluralize_block_type(child.block_type)\\n            )\\n\\n            if child.children:\\n                self._process_children(child)\\n\\n    def _upsert_vertex(self, model: ModelType, collection_name: str) -> None:\\n        model_data: dict[str, Any] = model.model_dump()\\n        model_data[\\\"_key\\\"] = model.id\\n\\n        try:\\n            self.db_connector.ensure_collection(\\n                collection_name, model.model_json_schema()\\n            )\\n            query: str = f\\\"\\\"\\\"\\n            UPSERT {{_key: @key}}\\n            INSERT @doc\\n            UPDATE @doc\\n            IN {collection_name}\\n            \\\"\\\"\\\"\\n            bind_vars: dict[str, Any] = {\\\"key\\\": model.id, \\\"doc\\\": model_data}\\n            self.db_connector.db.aql.execute(query, bind_vars=bind_vars)\\n\\n            if not isinstance(model, ModuleModel) and model.parent_id:\\n                parent_type: str = self._get_collection_from_id(model.parent_id)\\n                self._upsert_edge(\\n                    model.id, model.parent_id, collection_name, parent_type\\n                )\\n        except Exception as e:\\n            logging.error(f\\\"Error upserting {collection_name} vertex (ArangoDB): {e}\\\")\\n\\n    def _upsert_edge(\\n        self, from_key: str, to_key: str, source_type: str, target_type: str\\n    ) -> None:\\n        source_string: str = f\\\"{source_type}/{from_key}\\\"\\n        target_string: str = f\\\"{target_type}/{to_key}\\\"\\n\\n        edge_data: dict[str, str] = {\\n            \\\"_from\\\": source_string,\\n            \\\"_to\\\": target_string,\\n            \\\"source_type\\\": source_type,\\n            \\\"target_type\\\": target_type,\\n        }\\n\\n        try:\\n            self.db_connector.ensure_edge_collection(\\\"code_edges\\\")\\n            query = f\\\"\\\"\\\"\\n            UPSERT {{_from: @from, _to: @to}}\\n            INSERT @doc\\n            UPDATE @doc\\n            IN code_edges\\n            \\\"\\\"\\\"\\n            bind_vars = {\\n                \\\"from\\\": edge_data[\\\"_from\\\"],\\n                \\\"to\\\": edge_data[\\\"_to\\\"],\\n                \\\"doc\\\": edge_data,\\n            }\\n            self.db_connector.db.aql.execute(query, bind_vars=bind_vars)\\n        except Exception as e:\\n            logging.error(f\\\"Error upserting edge (ArangoDB): {e}\\\")\\n\\n    def _get_collection_from_id(self, block_id: str) -> str:\\n        block_id_parts: list[str] = block_id.split(\\\"__*__\\\")\\n        block_type_part: str = block_id_parts[-1]\\n\\n        block_type_functions: dict[str, Callable[..., str]] = {\\n            \\\"MODULE\\\": lambda: \\\"modules\\\",\\n            \\\"CLASS\\\": lambda: \\\"classes\\\",\\n            \\\"FUNCTION\\\": lambda: \\\"functions\\\",\\n            \\\"STANDALONE_BLOCK\\\": lambda: \\\"standalone_blocks\\\",\\n        }\\n\\n        for key, func in block_type_functions.items():\\n            if block_type_part.startswith(key):\\n                return func()\\n\\n        return \\\"unknown\\\"\\n\\n    def process_imports_and_dependencies(self) -> \\\"ArangoDBManager\\\":\\n        for vertex_collection in helper_functions.pluralized_and_lowered_block_types():\\n            cursor: Result[Cursor] = self.db_connector.db.collection(\\n                vertex_collection\\n            ).all()\\n            if isinstance(cursor, Cursor):\\n                for vertex in cursor:\\n                    vertex_key = vertex[\\\"_key\\\"]\\n                    if vertex_collection == \\\"modules\\\":\\n                        self._create_edges_for_imports(\\n                            vertex_key, vertex.get(\\\"imports\\\", [])\\n                        )\\n                    else:\\n                        self._create_edges_for_dependencies(\\n                            vertex_key, vertex.get(\\\"dependencies\\\", [])\\n                        )\\n            else:\\n                logging.error(\\n                    f\\\"Error getting cursor for vertex collection: {vertex_collection}\\\"\\n                )\\n        return self\\n\\n    def _create_edges_for_imports(\\n        self, module_key: str, imports: list[dict[str, Any]]\\n    ) -> None:\\n        if not imports:\\n            # logging.debug(f\\\"No imports found for module {module_key}\\\")\\n            return\\n\\n        # logging.info(f\\\"Processing imports for module {module_key}\\\")\\n\\n        for _import in imports:\\n            import_names: list[dict[str, str]] = _import.get(\\\"import_names\\\", [])\\n            if not import_names:\\n                # logging.debug(f\\\"No import names found in import {_import}\\\")\\n                continue\\n\\n            for import_name in import_names:\\n                local_block_id: str | None = import_name.get(\\\"local_block_id\\\")\\n\\n                if local_block_id:\\n                    target_type = self._get_collection_from_id(local_block_id)\\n                    try:\\n                        self._upsert_edge(\\n                            local_block_id, module_key, target_type, \\\"modules\\\"\\n                        )\\n\\n                        # logging.info(\\n                        #     f\\\"Upserted edge for import {module_key} to {local_block_id}\\\"\\n                        # )\\n                    except Exception as e:\\n                        logging.error(\\n                            f\\\"Error creating edge for import {module_key} to {local_block_id}: {e}\\\"\\n                        )\\n                else:\\n                    # logging.warning(\\n                    #     f\\\"Skipped import {import_name} in module {module_key}\\\"\\n                    # )\\n                    ...\\n\\n    def _create_edges_for_dependencies(\\n        self, block_key: str, dependencies: list[dict[str, Any]]\\n    ) -> None:\\n        if not dependencies:\\n            return\\n\\n        for dependency in dependencies:\\n            code_block_id: str | None = dependency.get(\\\"code_block_id\\\")\\n            if code_block_id:\\n                source_type: str = self._get_collection_from_id(code_block_id)\\n                target_type: str = self._get_collection_from_id(block_key)\\n                try:\\n                    self._upsert_edge(\\n                        code_block_id, block_key, source_type, target_type\\n                    )\\n                    # logging.info(\\n                    #     f\\\"Upserted edge for dependency {block_key} to {code_block_id}\\\"\\n                    # )\\n                except Exception as e:\\n                    logging.error(\\n                        f\\\"Error creating edge for dependency {block_key} to {code_block_id}: {e}\\\"\\n                    )\\n\\n    def delete_vertex_by_id(\\n        self, vertex_key: str, graph_name: str | None = None\\n    ) -> None:\\n        collection_name: str = self._get_collection_from_id(vertex_key)\\n        if collection_name == \\\"unknown\\\":\\n            logging.error(f\\\"Unknown vertex type for key: {vertex_key}\\\")\\n            return None\\n\\n        if not graph_name:\\n            graph_name = self.default_graph_name\\n\\n        try:\\n            vertex_coll = self.db_connector.db.graph(graph_name).vertex_collection(\\n                collection_name\\n            )\\n\\n            vertex_coll.delete(vertex_key)\\n\\n            # logging.info(\\n            #     f\\\"Vertex '{vertex_key}' from collection '{collection_name}' was successfully deleted.\\\"\\n            # )\\n\\n        except Exception as e:\\n            logging.error(\\n                f\\\"Error deleting vertex '{vertex_key}' from collection '{collection_name}': {e}\\\"\\n            )\\n\\n    def get_graph(self, graph_name: str | None = None) -> Graph | None:\\n        if not graph_name:\\n            graph_name = self.default_graph_name\\n        try:\\n            return self.db_connector.db.graph(self.default_graph_name)\\n        except Exception as e:\\n            logging.error(f\\\"Error getting graph '{self.default_graph_name}': {e}\\\")\\n            return None\\n\\n    def get_or_create_graph(self, graph_name: str | None = None) -> Result[Graph]:\\n        if not graph_name:\\n            graph_name = self.default_graph_name\\n\\n        try:\\n            if not self.db_connector.db.has_graph(graph_name):\\n                edge_definitions: list[dict[str, str | list[str]]] = [\\n                    {\\n                        \\\"edge_collection\\\": \\\"code_edges\\\",\\n                        \\\"from_vertex_collections\\\": helper_functions.pluralized_and_lowered_block_types(),\\n                        \\\"to_vertex_collections\\\": helper_functions.pluralized_and_lowered_block_types(),\\n                    }\\n                ]\\n\\n                # logging.info(f\\\"Graph '{graph_name}' created successfully.\\\")\\n                return self.db_connector.db.create_graph(\\n                    graph_name, edge_definitions=edge_definitions\\n                )\\n\\n            else:\\n                return self.get_graph()\\n\\n        except Exception as e:\\n            logging.error(f\\\"Error creating graph '{graph_name}': {e}\\\")\\n\\n    def delete_graph(self, graph_name: str | None = None) -> None:\\n        if not graph_name:\\n            graph_name = self.default_graph_name\\n        try:\\n            self.db_connector.db.delete_graph(graph_name)\\n            logging.info(f\\\"Graph '{graph_name}' deleted successfully.\\\")\\n        except Exception as e:\\n            logging.error(f\\\"Error deleting graph '{graph_name}': {e}\\\")\\n\\n    def get_outbound_models(self, start_key: str) -> list[ModelType] | None:\\n        vertex_type: str = self._get_collection_from_id(start_key)\\n\\n        query: str = f\\\"\\\"\\\"\\n        FOR v, e, p IN 1..100 OUTBOUND '{vertex_type}/{start_key}' GRAPH '{self.default_graph_name}'\\n        RETURN DISTINCT v\\n        \\\"\\\"\\\"\\n        # query: str = f\\\"\\\"\\\"\\n        # FOR v, e, p IN 1..100 OUTBOUND '{vertex_type}/{start_key}' GRAPH '{self.default_graph_name}'\\n        # FILTER LENGTH(p.edges[* FILTER CURRENT != e]) == 0\\n        # RETURN DISTINCT v\\n        # \\\"\\\"\\\"\\n        # query: str = f\\\"\\\"\\\"\\n        # FOR v, e, p IN 1..100 OUTBOUND '{vertex_type}/{start_key}' GRAPH '{self.default_graph_name}'\\n        # FILTER LENGTH(p.edges[* FILTER CURRENT != e]) == 0\\n        #     AND p.edges[*].distance ALL == 1\\n        # RETURN DISTINCT v\\n        # \\\"\\\"\\\"\\n\\n        try:\\n            cursor = self.db_connector.db.aql.execute(query)\\n            if isinstance(cursor, Cursor):\\n                return [\\n                    helper_functions.create_model_from_vertex(doc) for doc in cursor\\n                ]\\n            else:\\n                logging.error(f\\\"Error getting cursor for query: {query}\\\")\\n                return None\\n        except Exception as e:\\n            logging.error(f\\\"Error in get_all_downstream_vertices: {e}\\\")\\n            return None\\n\\n    def get_inbound_models(self, end_key: str) -> list[ModelType] | None:\\n        vertex_type: str = self._get_collection_from_id(end_key)\\n\\n        query: str = f\\\"\\\"\\\"\\n        FOR v, e, p IN 1..100 INBOUND '{vertex_type}/{end_key}' GRAPH '{self.default_graph_name}'\\n        RETURN DISTINCT v\\n        \\\"\\\"\\\"\\n\\n        # query: str = f\\\"\\\"\\\"\\n        # FOR v, e, p IN 1..100 INBOUND '{vertex_type}/{end_key}' GRAPH '{self.default_graph_name}'\\n        # FILTER LENGTH(p.edges[* FILTER CURRENT != e]) == 0\\n        # RETURN DISTINCT v\\n        # \\\"\\\"\\\"\\n\\n        try:\\n            cursor: Result[Cursor] = self.db_connector.db.aql.execute(query)\\n            if isinstance(cursor, Cursor):\\n                return [\\n                    helper_functions.create_model_from_vertex(doc) for doc in cursor\\n                ]\\n            else:\\n                logging.error(f\\\"Error getting cursor for query: {query}\\\")\\n                return None\\n        except Exception as e:\\n            logging.error(f\\\"Error in get_all_upstream_vertices: {e}\\\")\\n            return None\\n\\n    def update_vertex_by_id(self, id: str, new_summary: str) -> None:\\n        try:\\n            collection_name: str = self._get_collection_from_id(id)\\n            if collection_name == \\\"unknown\\\":\\n                logging.error(f\\\"Unknown vertex type for id: {id}\\\")\\n                return\\n\\n            vertex_collection: StandardCollection = self.db_connector.db.collection(\\n                collection_name\\n            )\\n            vertex_result: Result[Json | None] = vertex_collection.get(id)\\n\\n            if not vertex_result:\\n                logging.error(f\\\"Vertex with id {id} not found.\\\")\\n                return\\n\\n            if isinstance(vertex_result, dict):\\n                vertex = vertex_result\\n            else:\\n                logging.error(\\\"Retrieved vertex is not in a mutable format.\\\")\\n                return None\\n\\n            vertex[\\\"summary\\\"] = new_summary\\n\\n            vertex_collection.update(vertex)\\n            logging.info(f\\\"Vertex with id {id} updated successfully.\\\")\\n\\n        except Exception as e:\\n            logging.error(f\\\"Error in `update_vertex_by_id`: {e}\\\")\\n\\n    def get_all_modules(self) -> list[ModuleModel] | None:\\n        try:\\n            # Define the collection name for modules.\\n            collection_name = \\\"modules\\\"\\n            module_collection: StandardCollection = self.db_connector.db.collection(\\n                collection_name\\n            )\\n\\n            # Retrieve all documents from the modules collection.\\n            cursor: Result[Cursor] = module_collection.all()\\n\\n            # Convert each document to a ModuleModel instance.\\n            modules: list[ModuleModel] = []\\n            for doc in cursor:  # type: ignore # FIXME: Fix type error\\n                # Ensure the document is a dictionary.\\n                try:\\n                    # Convert the document to a ModuleModel instance and add it to the list.\\n                    module = ModuleModel(**doc)\\n                    modules.append(module)\\n                except Exception as e:\\n                    logging.error(f\\\"Retrieved document is not in a valid format: {e}\\\")\\n                    continue\\n\\n            return modules\\n\\n        except Exception as e:\\n            logging.error(f\\\"Error in get_all_modules: {e}\\\")\\n            return None\\n\\n\\nImported code block (postcode:databases:chroma:setup_chroma.py__*__MODULE) code content:\\nfrom dataclasses import dataclass\\nfrom logging import Logger\\n\\nimport chromadb\\nfrom postcode.databases.chroma.chromadb_client_manager import ChromaDBClientManager\\n\\nfrom postcode.databases.chroma.chromadb_collection_manager import (\\n    ChromaDBCollectionManager,\\n)\\n\\nfrom chromadb.config import DEFAULT_DATABASE, DEFAULT_TENANT, Settings\\nfrom chromadb.api import ClientAPI\\nfrom chromadb.api.types import (\\n    DataLoader,\\n    CollectionMetadata,\\n    GetResult,\\n    QueryResult,\\n    Where,\\n    WhereDocument,\\n    Include,\\n    URIs,\\n    Loadable,\\n    Metadata,\\n    Embedding,\\n)\\nfrom chromadb import Collection\\nfrom chromadb import EmbeddingFunction\\n\\nfrom postcode.models.models import ModuleModel\\n\\n\\n@dataclass\\nclass ChromaSetupReturnContext:\\n    \\\"\\\"\\\"\\n    Represents the return value of the ChromaDB setup method.\\n\\n    Attributes:\\n        - chroma_collection_manager (ChromaDBCollectionManager): The ChromaDB collection manager.\\n        - chroma_collection (Collection): The ChromaDB collection.\\n    \\\"\\\"\\\"\\n\\n    chroma_collection_manager: ChromaDBCollectionManager\\n    chroma_collection: Collection\\n\\n\\ndef setup_chroma(\\n    module_models: list[ModuleModel], logger: Logger\\n) -> ChromaSetupReturnContext:\\n    chroma_settings = Settings(allow_reset=True)\\n    chroma_client: ClientAPI = chromadb.PersistentClient(settings=chroma_settings)\\n    chroma_client_manager = ChromaDBClientManager(chroma_client)\\n\\n    logger.debug(f\\\"Resetting Chroma client\\\")\\n    if chroma_client_manager.reset_client():\\n        logger.debug(\\\"Client reset\\\")\\n\\n    chroma_collection: Collection = chroma_client_manager.get_or_create_collection(\\n        \\\"postcode\\\"\\n    )\\n\\n    chroma_collection_manager = ChromaDBCollectionManager(chroma_collection)\\n    chroma_collection_manager.upsert_models(tuple(module_models))\\n\\n    return ChromaSetupReturnContext(chroma_collection_manager, chroma_collection)\\n\\n\\nImported code block (postcode:json_management:json_handler.py__*__MODULE) code content:\\nimport json\\nfrom pathlib import Path\\n\\nfrom postcode.models.models import ModuleModel\\nfrom postcode.utilities.logger.decorators import logging_decorator\\n\\n\\nclass JSONHandler:\\n    def __init__(\\n        self,\\n        directory: str,\\n        directory_modules: dict[str, list[str]],\\n        output_directory: str = \\\"../output\\\",\\n    ) -> None:\\n        self.directory: str = directory\\n        self.output_directory: str = output_directory\\n        self.directory_modules: dict[str, list[str]] = directory_modules\\n\\n        self._create_output_directory()\\n\\n    @logging_decorator(message=\\\"Saving model as JSON\\\")\\n    def save_model_as_json(self, module_model: ModuleModel, file_path: str) -> None:\\n        \\\"\\\"\\\"Saves a parsed ModuleModel as JSON.\\\"\\\"\\\"\\n\\n        json_output_directory: str = self._create_json_output_directory()\\n        output_path: str = self._get_json_output_path(file_path, json_output_directory)\\n        self._write_json_file(module_model, output_path)\\n\\n    @logging_decorator(message=\\\"Saving visited directories\\\")\\n    def save_visited_directories(\\n        self, directory_mape_name: str = \\\"directory_map.json\\\"\\n    ) -> None:\\n        \\\"\\\"\\\"\\n        Saves a JSON file mapping each visited directory to its Python files.\\n\\n        The output is saved in a file named '00_directory_module_map.json' within the specified output directory.\\n\\n        Args:\\n            directory_mape_name (str): The name of the output file for the directory map.\\n\\n        Example:\\n            >>> visitor_manager.save_visited_directories(\\\"directory_map.json\\\")\\n            # Saves a mapping of directories to Python files as JSON.\\n        \\\"\\\"\\\"\\n\\n        output_path: str = self._get_directory_map_output_path(directory_mape_name)\\n        self._write_json_directory_map(output_path)\\n\\n    def _create_output_directory(self) -> None:\\n        \\\"\\\"\\\"Creates the output directory if it does not already exist.\\\"\\\"\\\"\\n\\n        Path(self.output_directory).mkdir(exist_ok=True)\\n\\n    def _create_json_output_directory(self) -> str:\\n        \\\"\\\"\\\"Creates the JSON output directory if it does not already exist.\\\"\\\"\\\"\\n\\n        json_output_directory: Path = Path(self.output_directory) / \\\"json\\\"\\n        json_output_directory.mkdir(exist_ok=True)\\n        return str(json_output_directory)\\n\\n    def _get_json_output_path(self, file_path: str, json_output_directory: str) -> str:\\n        \\\"\\\"\\\"Gets the output path for a JSON file.\\\"\\\"\\\"\\n\\n        relative_path: Path = Path(file_path).relative_to(Path(self.directory))\\n        safe_relative_path: str = str(relative_path).replace(\\\"/\\\", \\\":\\\").rstrip(\\\".py\\\")\\n        return str(Path(json_output_directory) / f\\\"{safe_relative_path}.json\\\")\\n\\n    def _write_json_file(self, module_model: ModuleModel, output_path: str) -> None:\\n        \\\"\\\"\\\"Writes a JSON file containing the parsed data from a ModuleModel.\\\"\\\"\\\"\\n\\n        parsed_data_json: str = module_model.model_dump_json(indent=4)\\n        with open(output_path, \\\"w\\\") as json_file:\\n            json_file.write(parsed_data_json)\\n\\n    def _get_directory_map_output_path(self, directory_output_name: str) -> str:\\n        \\\"\\\"\\\"Gets the output path for the directory map JSON file.\\\"\\\"\\\"\\n\\n        return str(Path(self.output_directory) / directory_output_name)\\n\\n    def _write_json_directory_map(self, output_path: str) -> None:\\n        \\\"\\\"\\\"Writes the directory map JSON file.\\\"\\\"\\\"\\n\\n        with open(output_path, \\\"w\\\") as json_file:\\n            json.dump(self.directory_modules, json_file, indent=4)\\n\\n\\nImported code block (postcode:models:models.py__*__MODULE) code content:\\nfrom typing import Union\\nfrom pydantic import BaseModel, Field, validator\\n\\nfrom postcode.models.enums import (\\n    BlockType,\\n    ImportModuleType,\\n    CommentType,\\n)\\n\\n\\nclass ImportNameModel(BaseModel):\\n    \\\"\\\"\\\"Class representing the name of an import.\\\"\\\"\\\"\\n\\n    name: str\\n    as_name: str | None = None\\n    local_block_id: str | None = None\\n\\n    # def convert_import_names_to_metadata(self) -> str:\\n    #     \\\"\\\"\\\"Converts the import name to a metadata string.\\\"\\\"\\\"\\n\\n    #     return self.model_dump_json()\\n\\n\\nclass ImportModel(BaseModel):\\n    \\\"\\\"\\\"Class representing an import statement.\\\"\\\"\\\"\\n\\n    import_names: list[ImportNameModel]\\n    imported_from: str | None = None\\n    import_module_type: ImportModuleType = ImportModuleType.STANDARD_LIBRARY\\n    local_module_id: str | None = None\\n\\n    def convert_import_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the import to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass DependencyModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a module dependency.\\\"\\\"\\\"\\n\\n    code_block_id: str\\n\\n    def convert_dependency_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the dependency to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass CommentModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a comment.\\\"\\\"\\\"\\n\\n    content: str\\n    comment_types: list[CommentType]\\n\\n    def convert_comment_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the comment to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass DecoratorModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a decorator.\\\"\\\"\\\"\\n\\n    content: str\\n    decorator_name: str\\n    decorator_args: list[str] | None = None\\n\\n    def convert_decorator_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the decorator to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass ClassKeywordModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a class keyword.\\\"\\\"\\\"\\n\\n    content: str\\n    keyword_name: str\\n    args: str | None = None\\n\\n    def convert_class_keyword_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the class keyword to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass ParameterModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a function parameter.\\\"\\\"\\\"\\n\\n    content: str\\n\\n\\nclass ParameterListModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a list of parameters.\\\"\\\"\\\"\\n\\n    params: list[ParameterModel] | None = None\\n    star_arg: ParameterModel | None = None\\n    kwonly_params: list[ParameterModel] | None = None\\n    star_kwarg: ParameterModel | None = None\\n    posonly_params: list[ParameterModel] | None = None\\n\\n    def convert_parameters_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the parameter list to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass BaseCodeBlockModel(BaseModel):\\n    \\\"\\\"\\\"Attributes common to all code block models.\\\"\\\"\\\"\\n\\n    id: str\\n    parent_id: str | None = None\\n    block_type: BlockType\\n    start_line_num: int\\n    end_line_num: int\\n    code_content: str = \\\"\\\"\\n    important_comments: list[CommentModel] | None = None\\n    dependencies: list[ImportModel | DependencyModel] | None = None\\n    summary: str | None = None\\n    children: list[\\n        Union[\\n            \\\"ClassModel\\\",\\n            \\\"FunctionModel\\\",\\n            \\\"StandaloneCodeBlockModel\\\",\\n        ]\\n    ] | None = []\\n\\n    @validator(\\\"parent_id\\\", always=True)\\n    def check_parent_id(cls, v, values, **kwargs) -> str | None:\\n        \\\"\\\"\\\"Validates that parent_id is a non-empty string unless block_type is MODULE.\\\"\\\"\\\"\\n\\n        if \\\"block_type\\\" in values and values[\\\"block_type\\\"] != BlockType.MODULE:\\n            if len(v) < 1:\\n                raise ValueError(\\\"parent_id is required!\\\")\\n        return v\\n\\n    def _convert_parent_id_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the parent_id to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.parent_id}\\\" if self.parent_id else \\\"\\\"\\n\\n    def _convert_block_type_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the block_type to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.block_type.name}\\\"\\n\\n    def _convert_important_comments_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the important comments to a metadata string.\\\"\\\"\\\"\\n\\n        important_comments: str = (\\n            self.model_dump_json() if self.important_comments else \\\"\\\"\\n        )\\n\\n        return f\\\"{important_comments}\\\"\\n\\n    def _convert_dependencies_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the dependencies to a metadata string.\\\"\\\"\\\"\\n\\n        dependencies_str: str = \\\"\\\"\\n\\n        if self.dependencies:\\n            for dependency in self.dependencies:\\n                if isinstance(dependency, ImportModel):\\n                    dependencies_str += f\\\"{dependency.convert_import_to_metadata()}\\\\n\\\"\\n                elif isinstance(dependency, DependencyModel):\\n                    dependencies_str += (\\n                        f\\\"{dependency.convert_dependency_to_metadata()}\\\\n\\\"\\n                    )\\n\\n        return dependencies_str\\n\\n    def _convert_summary_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the summary to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.summary}\\\" if self.summary else \\\"\\\"\\n\\n    def _convert_children_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the children to a metadata string.\\\"\\\"\\\"\\n\\n        children_str: str = \\\"\\\"\\n\\n        if self.children:\\n            for child in self.children:\\n                children_str += f\\\"{child.id}\\\\n\\\"\\n\\n        return children_str\\n\\n    def _convert_base_attributes_to_metadata_dict(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the base attributes to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            \\\"id\\\": self.id,\\n            \\\"parent_id\\\": self._convert_parent_id_to_metadata(),\\n            \\\"block_type\\\": self._convert_block_type_to_metadata(),\\n            \\\"start_line_num\\\": self.start_line_num,\\n            \\\"end_line_num\\\": self.end_line_num,\\n            \\\"code_content\\\": self.code_content,\\n            \\\"important_comments\\\": self._convert_important_comments_to_metadata(),\\n            \\\"dependencies\\\": self._convert_dependencies_to_metadata(),\\n            \\\"summary\\\": self._convert_summary_to_metadata(),\\n            \\\"children\\\": self._convert_children_to_metadata(),\\n        }\\n\\n\\nclass ModuleSpecificAttributes(BaseModel):\\n    \\\"\\\"\\\"Module specific attributes.\\\"\\\"\\\"\\n\\n    file_path: str = Field(min_length=1)\\n    docstring: str | None = None\\n    header: list[str] | None = None\\n    footer: list[str] | None = None\\n    imports: list[ImportModel] | None = None\\n\\n    def _convert_docstring_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the docstring to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.docstring}\\\"\\n\\n    def _convert_header_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the header and footer to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n    def _convert_footer_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the header and footer to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n    def _convert_imports_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the imports to a metadata string.\\\"\\\"\\\"\\n        imports_str: str = self.model_dump_json() if self.imports else \\\"\\\"\\n        return f\\\"{imports_str}\\\"\\n\\n    def _convert_module_attributes_to_metadata_dict(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the module attributes to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            \\\"file_path\\\": self.file_path,\\n            \\\"docstring\\\": self._convert_docstring_to_metadata(),\\n            \\\"header\\\": self._convert_header_to_metadata(),\\n            \\\"footer\\\": self._convert_footer_to_metadata(),\\n            \\\"imports\\\": self._convert_imports_to_metadata(),\\n        }\\n\\n\\nclass ModuleModel(BaseCodeBlockModel, ModuleSpecificAttributes):\\n    \\\"\\\"\\\"Model for a module.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the module model to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_module_attributes_to_metadata_dict(),\\n        }\\n\\n\\nclass ClassSpecificAttributes(BaseModel):\\n    \\\"\\\"\\\"Class specific attributes.\\\"\\\"\\\"\\n\\n    class_name: str = Field(min_length=1)\\n    decorators: list[DecoratorModel] | None = None\\n    bases: list[str] | None = None\\n    docstring: str | None = None\\n    keywords: list[ClassKeywordModel] | None = None\\n    # attributes: list[dict] | None = None\\n\\n    def _convert_decorators_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the decorators to a metadata string.\\\"\\\"\\\"\\n        decorators_str: str = self.model_dump_json() if self.decorators else \\\"\\\"\\n        return f\\\"{decorators_str}\\\"\\n\\n    def _convert_bases_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the bases to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json() if self.bases else \\\"\\\"\\n\\n    def _convert_docstring_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the docstring to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.docstring}\\\" if self.docstring else \\\"\\\"\\n\\n    def _convert_keywords_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the keywords to a metadata string.\\\"\\\"\\\"\\n        keywords_str: str = self.model_dump_json() if self.keywords else \\\"\\\"\\n        return f\\\"{keywords_str}\\\"\\n\\n    def _convert_class_attributes_to_metadata_dict(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the class attributes to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            \\\"class_name\\\": self.class_name,\\n            \\\"decorators\\\": self._convert_decorators_to_metadata(),\\n            \\\"bases\\\": self._convert_bases_to_metadata(),\\n            \\\"docstring\\\": self._convert_docstring_to_metadata(),\\n            \\\"keywords\\\": self._convert_keywords_to_metadata(),\\n        }\\n\\n\\nclass ClassModel(BaseCodeBlockModel, ClassSpecificAttributes):\\n    \\\"\\\"\\\"Model for a class.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the class model to a metadata dictionary.\\\"\\\"\\\"\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_class_attributes_to_metadata_dict(),\\n        }\\n\\n\\nclass FunctionSpecificAttributes(BaseModel):\\n    \\\"\\\"\\\"Function specific attributes.\\\"\\\"\\\"\\n\\n    function_name: str = Field(min_length=1)\\n    docstring: str | None = None\\n    decorators: list[DecoratorModel] | None = None\\n    parameters: ParameterListModel | None = None\\n    returns: str | None = None\\n    is_method: bool = False\\n    is_async: bool = False\\n\\n    def _convert_docstring_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the docstring to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.docstring}\\\" if self.docstring else \\\"\\\"\\n\\n    def _convert_decorators_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the decorators to a metadata string.\\\"\\\"\\\"\\n        decorators_str: str = self.model_dump_json() if self.decorators else \\\"\\\"\\n        return f\\\"{decorators_str}\\\"\\n\\n    def _convert_parameters_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the parameters to a metadata string.\\\"\\\"\\\"\\n        return (\\n            self.parameters.convert_parameters_to_metadata() if self.parameters else \\\"\\\"\\n        )\\n\\n    def _convert_returns_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the returns to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.returns}\\\" if self.returns else \\\"\\\"\\n\\n    def _convert_function_attributes_to_metadata_dict(self) -> dict[str, str | bool]:\\n        \\\"\\\"\\\"Converts the function attributes to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            \\\"function_name\\\": self.function_name,\\n            \\\"docstring\\\": self._convert_docstring_to_metadata(),\\n            \\\"decorators\\\": self._convert_decorators_to_metadata(),\\n            \\\"parameters\\\": self._convert_parameters_to_metadata(),\\n            \\\"returns\\\": self._convert_returns_to_metadata(),\\n            \\\"is_method\\\": self.is_method,\\n            \\\"is_async\\\": self.is_async,\\n        }\\n\\n\\nclass FunctionModel(BaseCodeBlockModel, FunctionSpecificAttributes):\\n    \\\"\\\"\\\"Model for a function.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the function model to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_function_attributes_to_metadata_dict(),\\n        }\\n\\n\\nclass StandaloneCodeBlockSpecificAttributes(BaseModel):\\n    \\\"\\\"\\\"Standalone code block specific attributes.\\\"\\\"\\\"\\n\\n    variable_assignments: list[str] | None = None\\n\\n    def _convert_variable_assignments_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the variable assignments to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json() if self.variable_assignments else \\\"\\\"\\n\\n    def _convert_standalone_block_attributes_to_metadata_dict(\\n        self,\\n    ) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the standalone code block attributes to a metadata dictionary.\\\"\\\"\\\"\\n        return {\\n            \\\"variable_assignments\\\": self._convert_variable_assignments_to_metadata(),\\n        }\\n\\n\\nclass StandaloneCodeBlockModel(\\n    BaseCodeBlockModel, StandaloneCodeBlockSpecificAttributes\\n):\\n    \\\"\\\"\\\"Model for a standalone code block.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the standalone code block model to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_standalone_block_attributes_to_metadata_dict(),\\n        }\\n\\n\\nImported code block (postcode:python_parser:visitor_manager:visitor_manager.py__*__MODULE) code content:\\nfrom dataclasses import dataclass\\nimport logging\\nfrom pathlib import Path\\n\\nfrom postcode.python_parser.model_builders.module_model_builder import (\\n    ModuleModelBuilder,\\n)\\nfrom postcode.utilities.logger.decorators import logging_decorator\\n\\nfrom postcode.python_parser.parsers.python_parser import PythonParser\\nfrom postcode.python_parser.visitor_manager.import_and_dependency_updater import (\\n    ImportAndDependencyUpdater,\\n)\\nfrom postcode.models.models import ModuleModel\\n\\nfrom postcode.ai_services.summarizer.summarization_context import Summarizer\\n\\nEXCLUDED_DIRECTORIES: set[str] = {\\\".venv\\\", \\\"node_modules\\\", \\\"__pycache__\\\", \\\".git\\\"}\\n\\n\\n@dataclass\\nclass VisitorManagerProcessFilesReturn:\\n    \\\"\\\"\\\"\\n    Represents the return value of the VisitorManager.process_files() method.\\n\\n    Attributes:\\n        - models_tuple (tuple[ModuleModel, ...]): A tuple of ModuleModel objects representing the parsed modules.\\n        - directory_modules (dict[str, list[str]]): A dictionary mapping directory paths to lists of module names.\\n            This is used to keep track of the modules present in each directory.\\n    \\\"\\\"\\\"\\n\\n    models_tuple: tuple[ModuleModel, ...]\\n    directory_modules: dict[str, list[str]]\\n\\n\\nclass VisitorManager:\\n    \\\"\\\"\\\"\\n    Manages the visiting and processing of Python files in a given directory.\\n\\n    This class scans a specified directory, filters for Python files, parses them, and saves the parsed data in a structured JSON format. It also maintains a mapping of directories to the Python files they contain.\\n\\n    Attributes:\\n        directory (str): The root directory to scan for Python files.\\n        output_directory (str): The directory where output JSON files will be saved.\\n        directory_modules (dict): A mapping of directories to their contained Python files.\\n\\n    Example:\\n        >>> visitor_manager = VisitorManager(\\\"/path/to/python/code\\\", \\\"output\\\")\\n        >>> visitor_manager.process_files()\\n        # This will process all Python files in /path/to/python/code and save their parsed data in the output directory.\\n    \\\"\\\"\\\"\\n\\n    @logging_decorator(message=\\\"Initializing VisitorManager\\\")\\n    def __init__(self, directory: str, output_directory: str = \\\"output_json\\\") -> None:\\n        self.directory: str = directory\\n        self.output_directory: str = output_directory\\n        self.directory_modules: dict[str, list[str]] = {}\\n\\n    def process_files(self) -> VisitorManagerProcessFilesReturn:\\n        \\\"\\\"\\\"\\n        Process the files in the directory and return the module models.\\n\\n        This function iterates through all the Python files in the directory, processes each file,\\n        updates the imports, and builds module models for each file. It returns a tuple of module models\\n        and a dictionary of directory modules.\\n\\n        Returns:\\n            A named tuple (VisitorManagerProcessFilesReturn) containing:\\n            - models_tuple (tuple[ModuleModel, ...]): A tuple of module models.\\n            - directory_modules (dict[str, ModuleModel]): A dictionary of directory modules.\\n\\n        Examples:\\n            >>> visitor_manager = VisitorManager()\\n            >>> result = visitor_manager.process_files()\\n            >>> print(result.models_tuple)\\n            (ModuleModel(file_path='/path/to/file1.py'), ModuleModel(file_path='/path/to/file2.py'))\\n            >>> print(result.directory_modules)\\n            {'/path/to/directory1': ModuleModel(file_path='/path/to/directory1/__init__.py')}\\n        \\\"\\\"\\\"\\n\\n        logging.info(\\\"Processing files\\\")\\n        python_files: list[str] = self._get_python_files()\\n        model_builder_list: list[ModuleModelBuilder] = []\\n        for file_path in python_files:\\n            if model_builder := self._process_file(file_path):\\n                model_builder_list.append((model_builder))\\n\\n        logging.info(\\\"File processing completed\\\")\\n        logging.info(\\\"Updating imports\\\")\\n\\n        # TODO: Test making this a tuple of tuples, see if that solves the double update import issue\\n        model_builder_tuple: tuple[ModuleModelBuilder, ...] = tuple(model_builder_list)\\n\\n        import_and_dependency_updater = ImportAndDependencyUpdater(model_builder_tuple)\\n        import_and_dependency_updater.update_imports()\\n        logging.info(\\\"Updated imports\\\")\\n\\n        module_models_list: list[ModuleModel] = []\\n        for module_model_builder in model_builder_tuple:\\n            module_model: ModuleModel = self._build_module_model(module_model_builder)\\n            module_models_list.append(module_model)\\n\\n        module_models_tuple: tuple[ModuleModel, ...] = tuple(module_models_list)\\n\\n        return VisitorManagerProcessFilesReturn(\\n            models_tuple=module_models_tuple, directory_modules=self.directory_modules\\n        )\\n\\n    def _walk_directories(self) -> list[str]:\\n        \\\"\\\"\\\"Walks the specified directory and returns a list of all files.\\\"\\\"\\\"\\n\\n        all_files: list[str] = []\\n        for file_path in Path(self.directory).rglob(\\\"*\\\"):\\n            if not any(\\n                excluded in file_path.parts for excluded in EXCLUDED_DIRECTORIES\\n            ):\\n                all_files.append(str(file_path))\\n        return all_files\\n\\n    def _filter_python_files(self, files: list[str]) -> list[str]:\\n        \\\"\\\"\\\"Filters a list of files to only include Python files.\\\"\\\"\\\"\\n\\n        return [file for file in files if file.endswith(\\\".py\\\")]\\n\\n    @logging_decorator(message=\\\"Getting Python files\\\")\\n    def _get_python_files(self) -> list[str]:\\n        \\\"\\\"\\\"Gets all Python files in the specified directory.\\\"\\\"\\\"\\n\\n        all_files: list[str] = self._walk_directories()\\n        return self._filter_python_files(all_files)\\n\\n    def _process_file(self, file_path: str) -> ModuleModelBuilder | None:\\n        \\\"\\\"\\\"Processes a single Python file.\\\"\\\"\\\"\\n\\n        file_path_obj = Path(file_path)\\n        root = str(file_path_obj.parent)\\n        self.directory_modules.setdefault(root, []).append(file_path_obj.name)\\n        return self._parse_file(file_path)\\n\\n    @logging_decorator(message=\\\"Processing file\\\")\\n    def _parse_file(self, file_path: str) -> ModuleModelBuilder | None:\\n        \\\"\\\"\\\"Parses a Python file and saves the parsed data as JSON.\\\"\\\"\\\"\\n\\n        parser = PythonParser(file_path)\\n        code: str = parser.open_file()\\n        module_model_builder: ModuleModelBuilder | None = parser.parse(code)\\n\\n        return module_model_builder\\n\\n    def _build_module_model(\\n        self, visitor_stack: ModuleModelBuilder | None\\n    ) -> ModuleModel:\\n        \\\"\\\"\\\"\\n        Builds a module model from the provided module builder.\\n\\n        Args:\\n            visitor_stack (ModuleModelBuilder): The module builder to build the model from.\\n\\n        Returns:\\n            ModuleModel: A structured module model.\\n\\n        Example:\\n            >>> module_model = python_parser.build_module_model(visitor_stack)\\n            # Builds a module model from the provided module builder.\\n        \\\"\\\"\\\"\\n\\n        if not isinstance(visitor_stack, ModuleModelBuilder):\\n            raise TypeError(\\\"Expected the first builder to be a ModuleModelBuilder\\\")\\n\\n        return visitor_stack.build()\\n\\n, \\nfrom logging import Logger\\nfrom openai import OpenAI\\n        \",\"children\":[{\"class_name\":\"GraphDBUpdater\",\"decorators\":null,\"bases\":null,\"docstring\":null,\"keywords\":null,\"id\":\"postcode:updaters:graph_db_updater.py__*__MODULE__*__CLASS-GraphDBUpdater\",\"parent_id\":\"postcode:updaters:graph_db_updater.py__*__MODULE\",\"block_type\":\"CLASS\",\"start_line_num\":22,\"end_line_num\":96,\"code_content\":\"\\n\\nclass GraphDBUpdater:\\n    def __init__(\\n        self,\\n        directory: str,\\n        output_directory: str,\\n        logger: Logger,\\n        arango_connector: ArangoDBConnector = ArangoDBConnector(),\\n    ) -> None:\\n        self.directory: str = directory\\n        self.output_directory: str = output_directory\\n        self.logger: Logger = logger\\n        self.arango_connector: ArangoDBConnector = arango_connector\\n\\n        self.arango_connector.delete_all_collections()\\n        self.arango_connector.ensure_collections()\\n        self.graph_manager = ArangoDBManager(arango_connector)\\n\\n    def update_all(\\n        self,\\n        directory: str,\\n        output_directory: str,\\n        logger: Logger,\\n    ) -> ChromaSetupReturnContext:\\n        logger.info(\\\"Starting the directory parsing.\\\")\\n\\n        visitor_manager = VisitorManager(directory, output_directory)\\n        process_files_return: VisitorManagerProcessFilesReturn = (\\n            visitor_manager.process_files()\\n        )\\n\\n        module_models_tuple: tuple[ModuleModel, ...] = process_files_return.models_tuple\\n        module_ids: list[str] = [model.id for model in module_models_tuple]\\n        directory_modules: dict[str, list[str]] = process_files_return.directory_modules\\n        self.graph_manager.upsert_models(\\n            list(module_models_tuple)\\n        ).process_imports_and_dependencies().get_or_create_graph()\\n        summarization_mapper = SummarizationMapper(\\n            module_ids, module_models_tuple, self.graph_manager\\n        )\\n        client = OpenAI(max_retries=4)\\n        summarizer = OpenAISummarizer(client=client)\\n        summarization_manager = GraphDBSummarizationManager(\\n            module_models_tuple, summarization_mapper, summarizer, self.graph_manager\\n        )\\n        finalized_module_models: list[\\n            ModuleModel\\n        ] | None = summarization_manager.create_summaries_and_return_updated_models()\\n        logger.info(\\\"Summarization complete\\\")\\n\\n        logger.info(\\\"Saving models as JSON\\\")\\n        json_manager = JSONHandler(directory, directory_modules, output_directory)\\n\\n        for module_model in module_models_tuple:\\n            json_manager.save_model_as_json(module_model, module_model.file_path)\\n\\n        json_manager.save_visited_directories()\\n        logger.info(\\\"JSON save complete\\\")\\n\\n        logger.info(\\\"Directory parsing completed.\\\")\\n\\n        # self.graph_manager.upsert_models(\\n        #     list(finalized_module_models)\\n        # ).process_imports_and_dependencies().get_or_create_graph()\\n\\n        if finalized_module_models:\\n            chroma_context: ChromaSetupReturnContext = setup_chroma(\\n                finalized_module_models, logger\\n            )\\n        else:\\n            raise Exception(\\\"No finalized models returned from summarization.\\\")\\n\\n        return chroma_context\\n\",\"important_comments\":null,\"dependencies\":[{\"import_names\":[{\"name\":\"VisitorManager\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"VisitorManagerProcessFilesReturn\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"postcode.python_parser.visitor_manager.visitor_manager\",\"import_module_type\":\"LOCAL\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"VisitorManager\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"VisitorManagerProcessFilesReturn\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"postcode.python_parser.visitor_manager.visitor_manager\",\"import_module_type\":\"LOCAL\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"Logger\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"logging\",\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"OpenAI\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"openai\",\"import_module_type\":\"THIRD_PARTY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"GraphDBSummarizationManager\",\"as_name\":null,\"local_block_id\":\"postcode:ai_services:summarizer:graph_db_summarization_manager.py__*__MODULE__*__CLASS-GraphDBSummarizationManager\"}],\"imported_from\":\"postcode.ai_services.summarizer.graph_db_summarization_manager\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:ai_services:summarizer:graph_db_summarization_manager.py__*__MODULE\"},{\"import_names\":[{\"name\":\"OpenAISummarizer\",\"as_name\":null,\"local_block_id\":\"postcode:ai_services:summarizer:openai_summarizer.py__*__MODULE__*__CLASS-OpenAISummarizer\"}],\"imported_from\":\"postcode.ai_services.summarizer.openai_summarizer\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:ai_services:summarizer:openai_summarizer.py__*__MODULE\"},{\"import_names\":[{\"name\":\"SummarizationMapper\",\"as_name\":null,\"local_block_id\":\"postcode:ai_services:summarizer:summarization_mapper.py__*__MODULE__*__CLASS-SummarizationMapper\"}],\"imported_from\":\"postcode.ai_services.summarizer.summarization_mapper\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:ai_services:summarizer:summarization_mapper.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ArangoDBConnector\",\"as_name\":null,\"local_block_id\":\"postcode:databases:arangodb:arangodb_connector.py__*__MODULE__*__CLASS-ArangoDBConnector\"}],\"imported_from\":\"postcode.databases.arangodb.arangodb_connector\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:databases:arangodb:arangodb_connector.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ArangoDBManager\",\"as_name\":null,\"local_block_id\":\"postcode:databases:arangodb:arangodb_manager.py__*__MODULE__*__CLASS-ArangoDBManager\"}],\"imported_from\":\"postcode.databases.arangodb.arangodb_manager\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:databases:arangodb:arangodb_manager.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ChromaSetupReturnContext\",\"as_name\":null,\"local_block_id\":\"postcode:databases:chroma:setup_chroma.py__*__MODULE__*__CLASS-ChromaSetupReturnContext\"},{\"name\":\"setup_chroma\",\"as_name\":null,\"local_block_id\":\"postcode:databases:chroma:setup_chroma.py__*__MODULE__*__FUNCTION-setup_chroma\"}],\"imported_from\":\"postcode.databases.chroma.setup_chroma\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:databases:chroma:setup_chroma.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ChromaSetupReturnContext\",\"as_name\":null,\"local_block_id\":\"postcode:databases:chroma:setup_chroma.py__*__MODULE__*__CLASS-ChromaSetupReturnContext\"},{\"name\":\"setup_chroma\",\"as_name\":null,\"local_block_id\":\"postcode:databases:chroma:setup_chroma.py__*__MODULE__*__FUNCTION-setup_chroma\"}],\"imported_from\":\"postcode.databases.chroma.setup_chroma\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:databases:chroma:setup_chroma.py__*__MODULE\"},{\"import_names\":[{\"name\":\"JSONHandler\",\"as_name\":null,\"local_block_id\":\"postcode:json_management:json_handler.py__*__MODULE__*__CLASS-JSONHandler\"}],\"imported_from\":\"postcode.json_management.json_handler\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:json_management:json_handler.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"}],\"summary\":null,\"children\":[{\"function_name\":\"__init__\",\"docstring\":null,\"decorators\":null,\"parameters\":null,\"returns\":\"None\",\"is_method\":true,\"is_async\":false,\"id\":\"postcode:updaters:graph_db_updater.py__*__MODULE__*__CLASS-GraphDBUpdater__*__FUNCTION-__init__\",\"parent_id\":\"postcode:updaters:graph_db_updater.py__*__MODULE__*__CLASS-GraphDBUpdater\",\"block_type\":\"FUNCTION\",\"start_line_num\":25,\"end_line_num\":40,\"code_content\":\"def __init__(\\n    self,\\n    directory: str,\\n    output_directory: str,\\n    logger: Logger,\\n    arango_connector: ArangoDBConnector = ArangoDBConnector(),\\n) -> None:\\n    self.directory: str = directory\\n    self.output_directory: str = output_directory\\n    self.logger: Logger = logger\\n    self.arango_connector: ArangoDBConnector = arango_connector\\n\\n    self.arango_connector.delete_all_collections()\\n    self.arango_connector.ensure_collections()\\n    self.graph_manager = ArangoDBManager(arango_connector)\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":null,\"children\":null},{\"function_name\":\"update_all\",\"docstring\":null,\"decorators\":null,\"parameters\":null,\"returns\":\"ChromaSetupReturnContext\",\"is_method\":true,\"is_async\":false,\"id\":\"postcode:updaters:graph_db_updater.py__*__MODULE__*__CLASS-GraphDBUpdater__*__FUNCTION-update_all\",\"parent_id\":\"postcode:updaters:graph_db_updater.py__*__MODULE__*__CLASS-GraphDBUpdater\",\"block_type\":\"FUNCTION\",\"start_line_num\":40,\"end_line_num\":96,\"code_content\":\"\\ndef update_all(\\n    self,\\n    directory: str,\\n    output_directory: str,\\n    logger: Logger,\\n) -> ChromaSetupReturnContext:\\n    logger.info(\\\"Starting the directory parsing.\\\")\\n\\n    visitor_manager = VisitorManager(directory, output_directory)\\n    process_files_return: VisitorManagerProcessFilesReturn = (\\n        visitor_manager.process_files()\\n    )\\n\\n    module_models_tuple: tuple[ModuleModel, ...] = process_files_return.models_tuple\\n    module_ids: list[str] = [model.id for model in module_models_tuple]\\n    directory_modules: dict[str, list[str]] = process_files_return.directory_modules\\n    self.graph_manager.upsert_models(\\n        list(module_models_tuple)\\n    ).process_imports_and_dependencies().get_or_create_graph()\\n    summarization_mapper = SummarizationMapper(\\n        module_ids, module_models_tuple, self.graph_manager\\n    )\\n    client = OpenAI(max_retries=4)\\n    summarizer = OpenAISummarizer(client=client)\\n    summarization_manager = GraphDBSummarizationManager(\\n        module_models_tuple, summarization_mapper, summarizer, self.graph_manager\\n    )\\n    finalized_module_models: list[\\n        ModuleModel\\n    ] | None = summarization_manager.create_summaries_and_return_updated_models()\\n    logger.info(\\\"Summarization complete\\\")\\n\\n    logger.info(\\\"Saving models as JSON\\\")\\n    json_manager = JSONHandler(directory, directory_modules, output_directory)\\n\\n    for module_model in module_models_tuple:\\n        json_manager.save_model_as_json(module_model, module_model.file_path)\\n\\n    json_manager.save_visited_directories()\\n    logger.info(\\\"JSON save complete\\\")\\n\\n    logger.info(\\\"Directory parsing completed.\\\")\\n\\n    # self.graph_manager.upsert_models(\\n    #     list(finalized_module_models)\\n    # ).process_imports_and_dependencies().get_or_create_graph()\\n\\n    if finalized_module_models:\\n        chroma_context: ChromaSetupReturnContext = setup_chroma(\\n            finalized_module_models, logger\\n        )\\n    else:\\n        raise Exception(\\\"No finalized models returned from summarization.\\\")\\n\\n    return chroma_context\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":null,\"children\":null}]}]}", "imports": "{\"file_path\":\"postcode/updaters/graph_db_updater.py\",\"docstring\":null,\"header\":[],\"footer\":[],\"imports\":[{\"import_names\":[{\"name\":\"Logger\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"logging\",\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"OpenAI\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"openai\",\"import_module_type\":\"THIRD_PARTY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"GraphDBSummarizationManager\",\"as_name\":null,\"local_block_id\":\"postcode:ai_services:summarizer:graph_db_summarization_manager.py__*__MODULE__*__CLASS-GraphDBSummarizationManager\"}],\"imported_from\":\"postcode.ai_services.summarizer.graph_db_summarization_manager\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:ai_services:summarizer:graph_db_summarization_manager.py__*__MODULE\"},{\"import_names\":[{\"name\":\"OpenAISummarizer\",\"as_name\":null,\"local_block_id\":\"postcode:ai_services:summarizer:openai_summarizer.py__*__MODULE__*__CLASS-OpenAISummarizer\"}],\"imported_from\":\"postcode.ai_services.summarizer.openai_summarizer\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:ai_services:summarizer:openai_summarizer.py__*__MODULE\"},{\"import_names\":[{\"name\":\"SummarizationMapper\",\"as_name\":null,\"local_block_id\":\"postcode:ai_services:summarizer:summarization_mapper.py__*__MODULE__*__CLASS-SummarizationMapper\"}],\"imported_from\":\"postcode.ai_services.summarizer.summarization_mapper\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:ai_services:summarizer:summarization_mapper.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ArangoDBConnector\",\"as_name\":null,\"local_block_id\":\"postcode:databases:arangodb:arangodb_connector.py__*__MODULE__*__CLASS-ArangoDBConnector\"}],\"imported_from\":\"postcode.databases.arangodb.arangodb_connector\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:databases:arangodb:arangodb_connector.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ArangoDBManager\",\"as_name\":null,\"local_block_id\":\"postcode:databases:arangodb:arangodb_manager.py__*__MODULE__*__CLASS-ArangoDBManager\"}],\"imported_from\":\"postcode.databases.arangodb.arangodb_manager\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:databases:arangodb:arangodb_manager.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ChromaSetupReturnContext\",\"as_name\":null,\"local_block_id\":\"postcode:databases:chroma:setup_chroma.py__*__MODULE__*__CLASS-ChromaSetupReturnContext\"},{\"name\":\"setup_chroma\",\"as_name\":null,\"local_block_id\":\"postcode:databases:chroma:setup_chroma.py__*__MODULE__*__FUNCTION-setup_chroma\"}],\"imported_from\":\"postcode.databases.chroma.setup_chroma\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:databases:chroma:setup_chroma.py__*__MODULE\"},{\"import_names\":[{\"name\":\"JSONHandler\",\"as_name\":null,\"local_block_id\":\"postcode:json_management:json_handler.py__*__MODULE__*__CLASS-JSONHandler\"}],\"imported_from\":\"postcode.json_management.json_handler\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:json_management:json_handler.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"},{\"import_names\":[{\"name\":\"VisitorManagerProcessFilesReturn\",\"as_name\":null,\"local_block_id\":\"postcode:python_parser:visitor_manager:visitor_manager.py__*__MODULE__*__CLASS-VisitorManagerProcessFilesReturn\"},{\"name\":\"VisitorManager\",\"as_name\":null,\"local_block_id\":\"postcode:python_parser:visitor_manager:visitor_manager.py__*__MODULE__*__CLASS-VisitorManager\"}],\"imported_from\":\"postcode.python_parser.visitor_manager.visitor_manager\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:python_parser:visitor_manager:visitor_manager.py__*__MODULE\"}],\"id\":\"postcode:updaters:graph_db_updater.py__*__MODULE\",\"parent_id\":null,\"block_type\":\"MODULE\",\"start_line_num\":1,\"end_line_num\":96,\"code_content\":\"from logging import Logger\\n\\nfrom openai import OpenAI\\nfrom postcode.ai_services.summarizer.graph_db_summarization_manager import (\\n    GraphDBSummarizationManager,\\n)\\nfrom postcode.ai_services.summarizer.openai_summarizer import OpenAISummarizer\\nfrom postcode.ai_services.summarizer.summarization_mapper import SummarizationMapper\\nfrom postcode.databases.arangodb.arangodb_connector import ArangoDBConnector\\n\\nfrom postcode.databases.arangodb.arangodb_manager import ArangoDBManager\\nfrom postcode.databases.chroma.setup_chroma import (\\n    ChromaSetupReturnContext,\\n    setup_chroma,\\n)\\nfrom postcode.json_management.json_handler import JSONHandler\\nfrom postcode.models.models import ModuleModel\\nfrom postcode.python_parser.visitor_manager.visitor_manager import (\\n    VisitorManager,\\n    VisitorManagerProcessFilesReturn,\\n)\\n\\n\\nclass GraphDBUpdater:\\n    def __init__(\\n        self,\\n        directory: str,\\n        output_directory: str,\\n        logger: Logger,\\n        arango_connector: ArangoDBConnector = ArangoDBConnector(),\\n    ) -> None:\\n        self.directory: str = directory\\n        self.output_directory: str = output_directory\\n        self.logger: Logger = logger\\n        self.arango_connector: ArangoDBConnector = arango_connector\\n\\n        self.arango_connector.delete_all_collections()\\n        self.arango_connector.ensure_collections()\\n        self.graph_manager = ArangoDBManager(arango_connector)\\n\\n    def update_all(\\n        self,\\n        directory: str,\\n        output_directory: str,\\n        logger: Logger,\\n    ) -> ChromaSetupReturnContext:\\n        logger.info(\\\"Starting the directory parsing.\\\")\\n\\n        visitor_manager = VisitorManager(directory, output_directory)\\n        process_files_return: VisitorManagerProcessFilesReturn = (\\n            visitor_manager.process_files()\\n        )\\n\\n        module_models_tuple: tuple[ModuleModel, ...] = process_files_return.models_tuple\\n        module_ids: list[str] = [model.id for model in module_models_tuple]\\n        directory_modules: dict[str, list[str]] = process_files_return.directory_modules\\n        self.graph_manager.upsert_models(\\n            list(module_models_tuple)\\n        ).process_imports_and_dependencies().get_or_create_graph()\\n        summarization_mapper = SummarizationMapper(\\n            module_ids, module_models_tuple, self.graph_manager\\n        )\\n        client = OpenAI(max_retries=4)\\n        summarizer = OpenAISummarizer(client=client)\\n        summarization_manager = GraphDBSummarizationManager(\\n            module_models_tuple, summarization_mapper, summarizer, self.graph_manager\\n        )\\n        finalized_module_models: list[\\n            ModuleModel\\n        ] | None = summarization_manager.create_summaries_and_return_updated_models()\\n        logger.info(\\\"Summarization complete\\\")\\n\\n        logger.info(\\\"Saving models as JSON\\\")\\n        json_manager = JSONHandler(directory, directory_modules, output_directory)\\n\\n        for module_model in module_models_tuple:\\n            json_manager.save_model_as_json(module_model, module_model.file_path)\\n\\n        json_manager.save_visited_directories()\\n        logger.info(\\\"JSON save complete\\\")\\n\\n        logger.info(\\\"Directory parsing completed.\\\")\\n\\n        # self.graph_manager.upsert_models(\\n        #     list(finalized_module_models)\\n        # ).process_imports_and_dependencies().get_or_create_graph()\\n\\n        if finalized_module_models:\\n            chroma_context: ChromaSetupReturnContext = setup_chroma(\\n                finalized_module_models, logger\\n            )\\n        else:\\n            raise Exception(\\\"No finalized models returned from summarization.\\\")\\n\\n        return chroma_context\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":\"\\nSummary:\\n\\n        postcode:updaters:graph_db_updater.py__*__MODULE\\n\\n        \\nChild (postcode:updaters:graph_db_updater.py__*__MODULE__*__CLASS-GraphDBUpdater) code content:\\n\\n\\nclass GraphDBUpdater:\\n    def __init__(\\n        self,\\n        directory: str,\\n        output_directory: str,\\n        logger: Logger,\\n        arango_connector: ArangoDBConnector = ArangoDBConnector(),\\n    ) -> None:\\n        self.directory: str = directory\\n        self.output_directory: str = output_directory\\n        self.logger: Logger = logger\\n        self.arango_connector: ArangoDBConnector = arango_connector\\n\\n        self.arango_connector.delete_all_collections()\\n        self.arango_connector.ensure_collections()\\n        self.graph_manager = ArangoDBManager(arango_connector)\\n\\n    def update_all(\\n        self,\\n        directory: str,\\n        output_directory: str,\\n        logger: Logger,\\n    ) -> ChromaSetupReturnContext:\\n        logger.info(\\\"Starting the directory parsing.\\\")\\n\\n        visitor_manager = VisitorManager(directory, output_directory)\\n        process_files_return: VisitorManagerProcessFilesReturn = (\\n            visitor_manager.process_files()\\n        )\\n\\n        module_models_tuple: tuple[ModuleModel, ...] = process_files_return.models_tuple\\n        module_ids: list[str] = [model.id for model in module_models_tuple]\\n        directory_modules: dict[str, list[str]] = process_files_return.directory_modules\\n        self.graph_manager.upsert_models(\\n            list(module_models_tuple)\\n        ).process_imports_and_dependencies().get_or_create_graph()\\n        summarization_mapper = SummarizationMapper(\\n            module_ids, module_models_tuple, self.graph_manager\\n        )\\n        client = OpenAI(max_retries=4)\\n        summarizer = OpenAISummarizer(client=client)\\n        summarization_manager = GraphDBSummarizationManager(\\n            module_models_tuple, summarization_mapper, summarizer, self.graph_manager\\n        )\\n        finalized_module_models: list[\\n            ModuleModel\\n        ] | None = summarization_manager.create_summaries_and_return_updated_models()\\n        logger.info(\\\"Summarization complete\\\")\\n\\n        logger.info(\\\"Saving models as JSON\\\")\\n        json_manager = JSONHandler(directory, directory_modules, output_directory)\\n\\n        for module_model in module_models_tuple:\\n            json_manager.save_model_as_json(module_model, module_model.file_path)\\n\\n        json_manager.save_visited_directories()\\n        logger.info(\\\"JSON save complete\\\")\\n\\n        logger.info(\\\"Directory parsing completed.\\\")\\n\\n        # self.graph_manager.upsert_models(\\n        #     list(finalized_module_models)\\n        # ).process_imports_and_dependencies().get_or_create_graph()\\n\\n        if finalized_module_models:\\n            chroma_context: ChromaSetupReturnContext = setup_chroma(\\n                finalized_module_models, logger\\n            )\\n        else:\\n            raise Exception(\\\"No finalized models returned from summarization.\\\")\\n\\n        return chroma_context\\n\\n, \\nImported code block (postcode:ai_services:summarizer:graph_db_summarization_manager.py__*__MODULE) code content:\\n# FIXME: This file is not currently being used. It is a work in progress as the summarization mapper isn't getting returning all of the project models.\\n\\nimport logging\\nfrom pprint import pprint\\nfrom typing import Union\\n\\nfrom postcode.ai_services.summarizer.summarization_context import (\\n    Summarizer,\\n    OpenAIReturnContext,\\n)\\nfrom postcode.ai_services.summarizer.summarization_mapper import SummarizationMapper\\nfrom postcode.databases.arangodb.arangodb_manager import ArangoDBManager\\n\\n# from postcode.types.postcode import ModelType\\n\\nfrom postcode.models.models import (\\n    ClassModel,\\n    DependencyModel,\\n    FunctionModel,\\n    ImportModel,\\n    ModuleModel,\\n    StandaloneCodeBlockModel,\\n)\\n\\nModelType = Union[\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n]\\n\\n\\nclass GraphDBSummarizationManager:\\n    def __init__(\\n        self,\\n        module_models_tuple: tuple[ModuleModel, ...],\\n        summarization_mapper: SummarizationMapper,\\n        summarizer: Summarizer,\\n        graph_manager: ArangoDBManager,\\n    ) -> None:\\n        self.module_models_tuple: tuple[ModuleModel, ...] = module_models_tuple\\n        self.summarization_mapper: SummarizationMapper = summarization_mapper\\n        self.summarizer: Summarizer = summarizer\\n        self.summarized_code_block_ids: set[str] = set()\\n        self.prompt_tokens: int = 0\\n        self.completion_tokens: int = 0\\n        self.graph_manager: ArangoDBManager = graph_manager\\n\\n    @property\\n    def total_cost(self) -> float:\\n        \\\"\\\"\\\"Provides the total cost of the summarization process.\\\"\\\"\\\"\\n        prompt_cost: int = self.prompt_tokens * 1  # Costs 1 cent per 1,000 tokens\\n        completion_cost: int = (\\n            self.completion_tokens * 3\\n        )  # Costs 3 cents per 1,000 tokens\\n        return (prompt_cost + completion_cost) / 100_000  # Convert to dollars\\n\\n    def create_summaries_and_return_updated_models(self) -> list[ModuleModel] | None:\\n        summarization_map: list[\\n            ModelType\\n        ] = self.summarization_mapper.create_summarization_map()\\n        models_to_summarize_count: int = len(summarization_map)\\n        models_summarized_count: int = 0\\n\\n        for model in summarization_map:\\n            children_summaries: str | None = None\\n            dependency_summaries: str | None = None\\n            import_details: str | None = None\\n\\n            if model.children:\\n                children_summaries: str | None = self._stringify_children_summaries(\\n                    self._get_child_summaries(model)\\n                )\\n            if isinstance(model, ModuleModel):\\n                if model.imports:\\n                    dependency_summaries = self._get_dependencies_summaries(model)\\n                    import_details = \\\"\\\"\\n                    for _import in model.imports:\\n                        if import_summary := self._get_import_details(_import):\\n                            import_details += f\\\"\\\\n{import_summary}\\\"\\n            else:\\n                if model.dependencies:\\n                    dependency_summaries = self._get_dependencies_summaries(model)\\n                    import_details = \\\"\\\"\\n                    for dependency in model.dependencies:\\n                        if isinstance(dependency, DependencyModel):\\n                            continue\\n                        if import_summary := self._get_import_details(dependency):\\n                            import_details += f\\\"\\\\n{import_summary}\\\"\\n\\n            models_summarized_count += 1\\n            logging.info(\\n                f\\\"Summarizing model {models_summarized_count} out of {models_to_summarize_count}; {model.id}.\\\"\\n            )\\n\\n            summary_return_context: OpenAIReturnContext | None = (\\n                self.summarizer.test_summarize_code(\\n                    model.code_content,\\n                    model_id=model.id,\\n                    children_summaries=children_summaries,\\n                    dependency_summaries=dependency_summaries,\\n                    import_details=import_details,\\n                )\\n            )\\n            if summary_return_context:\\n                if summary_return_context.summary:\\n                    self.graph_manager.update_vertex_by_id(\\n                        model.id, summary_return_context.summary\\n                    )\\n                self.prompt_tokens += summary_return_context.prompt_tokens\\n                self.completion_tokens += summary_return_context.completion_tokens\\n\\n                # for module_model in self.module_models_tuple:\\n                #     if isinstance(model, ModuleModel):\\n                #         if module_model.id == model.id:\\n                #             module_model.summary = model.summary\\n                #             break\\n                #         else:\\n                #             continue\\n                #     else:\\n                #         module_id_for_model: str = model.id.split(\\\"MODULE\\\")[0]\\n                #         if (\\n                #             module_model.children\\n                #             and module_id_for_model in module_model.id\\n                #         ):\\n                #             for child_model in module_model.children:\\n                #                 if child_model.id == model.id:\\n                #                     # child_model.summary = model.summary\\n                #                     break\\n                #         else:\\n                #             continue\\n\\n        pprint([model.id for model in summarization_map[::-1]])\\n        print(len(summarization_map))\\n\\n        return self.graph_manager.get_all_modules() if self.graph_manager else None\\n\\n    def _get_child_summaries(self, model: ModelType) -> list[str]:\\n        \\\"\\\"\\\"Gathers summaries of child models.\\\"\\\"\\\"\\n        child_summary_list: list[str] = []\\n        if model.children:\\n            for child in model.children:\\n                if child.summary:\\n                    child_summary: str = child.summary\\n                else:\\n                    child_summary = (\\n                        f\\\"Child ({child.id}) code content:\\\\n{child.code_content}\\\\n\\\"\\n                    )\\n                child_summary_list.append(child_summary)\\n        return child_summary_list\\n\\n    def _stringify_children_summaries(self, children_summary_list: list[str]) -> str:\\n        \\\"\\\"\\\"Converts all of the child summaries to a single string to be used in the prompt.\\\"\\\"\\\"\\n\\n        children_summaries: str = \\\"\\\"\\n        for child_summary in children_summary_list:\\n            children_summaries += f\\\"\\\\n{child_summary}\\\"\\n        return children_summaries\\n\\n    def _get_dependencies_summaries(self, model: ModelType) -> str | None:\\n        dependency_list: list[ImportModel | DependencyModel] | list[ImportModel] = []\\n        dependency_summary_list: list[str] = []\\n\\n        if isinstance(model, ModuleModel):\\n            if not model.imports:\\n                return None\\n\\n            dependency_list = model.imports\\n        else:\\n            if not model.dependencies:\\n                return None\\n\\n            dependency_list = model.dependencies\\n        for dependency in dependency_list:\\n            if isinstance(dependency, DependencyModel) and dependency.code_block_id:\\n                if module_local_dependency_summary := self._get_local_dependency_summary(\\n                    dependency, model\\n                ):\\n                    dependency_summary_list.append(module_local_dependency_summary)\\n\\n            elif isinstance(dependency, ImportModel):\\n                if dependency.import_module_type == \\\"LOCAL\\\":\\n                    if not dependency.import_names:\\n                        if module_import_dependency := self._get_local_import_summary(\\n                            dependency\\n                        ):\\n                            dependency_summary_list.append(module_import_dependency)\\n                    else:\\n                        if import_from_dependency := self._get_local_import_from_summary(\\n                            dependency\\n                        ):\\n                            dependency_summary_list.append(import_from_dependency)\\n\\n        dependency_summaries = self._stringify_dependencies_summaries(\\n            dependency_summary_list\\n        )\\n\\n        return dependency_summaries\\n\\n    # def _get_import_details_for_dependencies(\\n    #     self, dependencies: list[ImportModel | DependencyModel]\\n    # ) -> str | None:\\n    #     import_details: str | None = None\\n    #     for dependency in dependencies:\\n    #         if isinstance(dependency, ImportModel):\\n    #             if dependency.import_module_type == \\\"LOCAL\\\":\\n    #                 continue\\n    #             else:\\n    #                 import_detail: str | None = self._get_import_details(dependency)\\n    #                 if not import_detail:\\n    #                     continue\\n    #                 if not import_details:\\n    #                     import_details = \\\"\\\"\\n    #                 import_details += f\\\"\\\\n{import_detail}\\\"\\n    #     return import_details\\n\\n    def _get_local_dependency_summary(\\n        self,\\n        dependency: DependencyModel,\\n        model: ModelType,\\n    ) -> str | None:\\n        \\\"\\\"\\\"Gets a summary for a dependency local to the module.\\\"\\\"\\\"\\n        if not model.children:\\n            return None\\n\\n        for child_model in model.children:\\n            if child_model.id == dependency.code_block_id:\\n                child_summary: str | None = None\\n\\n                if child_model.summary:\\n                    child_summary = child_model.summary\\n                else:\\n                    child_summary = f\\\"Dependency ({dependency.code_block_id}) code content:\\\\n{child_model.code_content}\\\\n\\\"\\n\\n                return child_summary\\n        return None\\n\\n    def _stringify_dependencies_summaries(\\n        self, dependencies_summary_list: list[str] | None\\n    ) -> str | None:\\n        \\\"\\\"\\\"Converts all of the dependency summaries to a single string to be used in the prompt.\\\"\\\"\\\"\\n        if not dependencies_summary_list:\\n            return None\\n\\n        dependency_summaries: str = \\\"\\\"\\n        for dependency_summary in dependencies_summary_list:\\n            dependency_summaries += f\\\"\\\\n{dependency_summary}\\\"\\n        return dependency_summaries\\n\\n    def _get_local_import_summary(self, dependency: ImportModel) -> str | None:\\n        for module_model in self.module_models_tuple:\\n            if module_model.id == dependency.local_module_id:\\n                import_summary: str | None = None\\n                if module_model.summary:\\n                    import_summary = module_model.summary\\n                else:\\n                    import_summary = f\\\"Imported module ({dependency.local_module_id}) code content:\\\\n{module_model.code_content}\\\\n\\\"\\n                return import_summary\\n        return None\\n\\n    def _get_local_import_from_summary(self, dependency: ImportModel) -> str | None:\\n        for import_name in dependency.import_names:\\n            for module_model in self.module_models_tuple:\\n                if module_model.id == dependency.local_module_id:\\n                    if module_model.children:\\n                        for child_model in module_model.children:\\n                            if (\\n                                child_model.id == import_name.local_block_id\\n                                and child_model.id\\n                            ):\\n                                import_summary: str | None = None\\n                                if child_model.summary:\\n                                    import_summary = child_model.summary\\n                                else:\\n                                    import_summary = f\\\"Imported code block ({dependency.local_module_id}) code content:\\\\n{module_model.code_content}\\\\n\\\"\\n                                return import_summary\\n        return None\\n\\n    def _get_import_details(self, import_model: ImportModel) -> str | None:\\n        \\\"\\\"\\\"Retrieves details of import statements to be used in the prompt.\\\"\\\"\\\"\\n        if import_model.import_module_type == \\\"LOCAL\\\" or not import_model.import_names:\\n            return None\\n\\n        import_names_list: list[str] = []\\n        for import_name in import_model.import_names:\\n            if import_name.as_name:\\n                import_names_list.append(f\\\"{import_name.name} as {import_name.as_name}\\\")\\n            else:\\n                import_names_list.append(f\\\"{import_name.name}\\\")\\n\\n        if import_model.imported_from:\\n            import_details: str = f\\\"from {import_model.imported_from} import {', '.join(import_names_list)}\\\"\\n        else:\\n            import_details = f\\\"import {', '.join(import_names_list)}\\\"\\n\\n        return import_details\\n\\n\\nImported code block (postcode:ai_services:summarizer:openai_summarizer.py__*__MODULE) code content:\\nimport logging\\n\\nfrom openai import OpenAI\\nfrom openai.types.chat.chat_completion_system_message_param import (\\n    ChatCompletionSystemMessageParam,\\n)\\nfrom openai.types.chat.chat_completion_user_message_param import (\\n    ChatCompletionUserMessageParam,\\n)\\nfrom openai.types.chat.chat_completion_message_param import ChatCompletionMessageParam\\nfrom openai.types.chat.chat_completion import ChatCompletion\\n\\nfrom postcode.ai_services.summarizer.prompts.prompt_creator import PromptCreator\\nfrom postcode.ai_services.summarizer.summarization_context import (\\n    OpenAIReturnContext,\\n    SummaryCompletionConfigs,\\n)\\n\\n# from postcode.ai_services.summarizer.temp import code_example\\n\\n\\nclass OpenAISummarizer:\\n    \\\"\\\"\\\"\\n    A class for summarizing code snippets using the OpenAI API.\\n\\n    Args:\\n        - client (OpenAI): The OpenAI client used for making API requests.\\n\\n    Attributes:\\n        - client (OpenAI): The OpenAI client used for making API requests.\\n        - prompt_list (list[str]): A list of summary prompts.\\n        - default_prompt (str): The default summary prompt.\\n\\n    Methods:\\n        - `summarize_code`: Summarizes the provided code snippet using the OpenAI API.\\n\\n    Examples:\\n        ```Python\\n        client = OpenAI()\\n\\n        # Create a summarizer instance with the OpenAI client\\n        summarizer = Summarizer(client=client)\\n        code_example = \\\"print('Hello, world')\\\"\\n\\n        # Summarize the code snippet\\n        summary = summarizer.summarize_code(code_example)\\n        print(summary)\\n        ```\\n    \\\"\\\"\\\"\\n\\n    def __init__(\\n        self,\\n        client: OpenAI,\\n        # *, summary_prompt_list: list[str] = summary_prompt_list\\n    ) -> None:\\n        self.client: OpenAI = client\\n        # self.prompt_list: list[str] = summary_prompt_list\\n        # self.default_prompt: str = self.prompt_list[0]\\n\\n    def _create_system_message(self, content: str) -> ChatCompletionSystemMessageParam:\\n        \\\"\\\"\\\"Creates a system message for chat completion using OpenAi's ChatCompletionSystemMessageParam class.\\\"\\\"\\\"\\n        return ChatCompletionSystemMessageParam(content=content, role=\\\"system\\\")\\n\\n    def _create_user_message(self, content: str) -> ChatCompletionUserMessageParam:\\n        \\\"\\\"\\\"Creates a user message for chat completion using OpenAi's ChatCompletionUserMessageParam class.\\\"\\\"\\\"\\n        return ChatCompletionUserMessageParam(content=content, role=\\\"user\\\")\\n\\n    def _create_messages_list(\\n        self,\\n        system_message: str,\\n        user_message: str,\\n    ) -> list[ChatCompletionMessageParam]:\\n        \\\"\\\"\\\"\\n        Creates a list of messages for chat completion, including both system and user messages.\\n\\n        Args:\\n            - system_message (str): The system message content.\\n            - user_message (str): The user message content.\\n\\n        Returns:\\n            - list[ChatCompletionMessageParam]: A list containing the system and user messages as OpenAI's\\n                ChatCompletionMessageParam classes.\\n        \\\"\\\"\\\"\\n\\n        return [\\n            self._create_system_message(system_message),\\n            self._create_user_message(user_message),\\n        ]\\n\\n    def _create_prompt(\\n        self,\\n        code: str,\\n        children_summaries: str | None,\\n        dependency_summaries: str | None,\\n        import_details: str | None,\\n    ) -> str:\\n        prompt_creator: PromptCreator = PromptCreator()\\n        prompt: str | None = prompt_creator.create_prompt(\\n            code,\\n            children_summaries,\\n            dependency_summaries,\\n            import_details,\\n        )\\n\\n        if prompt:\\n            return prompt\\n        else:\\n            raise Exception(\\\"Prompt creation failed.\\\")\\n\\n    def _get_summary(\\n        self,\\n        messages: list[ChatCompletionMessageParam],\\n        *,\\n        configs: SummaryCompletionConfigs,\\n    ) -> OpenAIReturnContext | None:\\n        \\\"\\\"\\\"\\n        Retrieves the summary from the OpenAI API based on the provided messages and configuration settings.\\n\\n        Args:\\n            - messages (list[ChatCompletionMessageParam]): A list of messages for chat completion.\\n            - configs (SummaryCompletionConfigs): Configuration settings for the summarization completion.\\n\\n        Returns:\\n            str | None: The summary generated by the OpenAI API, or None if no summary is found.\\n        \\\"\\\"\\\"\\n\\n        try:\\n            response: ChatCompletion = self.client.chat.completions.create(\\n                messages=messages,\\n                model=configs.model,\\n                max_tokens=configs.max_tokens,\\n                temperature=configs.temperature,\\n            )\\n            prompt_tokens: int = 0\\n            completion_tokens: int = 0\\n            summary: str | None = response.choices[0].message.content\\n            if response.usage:\\n                prompt_tokens = response.usage.prompt_tokens\\n                completion_tokens = response.usage.completion_tokens\\n\\n            return OpenAIReturnContext(\\n                prompt_tokens=prompt_tokens,\\n                completion_tokens=completion_tokens,\\n                summary=summary,\\n            )\\n\\n        except Exception as e:\\n            logging.error(e)\\n            return None\\n\\n    def summarize_code(\\n        self,\\n        code: str,\\n        *,\\n        model_id: str,\\n        children_summaries: str | None,\\n        dependency_summaries: str | None,\\n        import_details: str | None,\\n        configs: SummaryCompletionConfigs = SummaryCompletionConfigs(),\\n    ) -> OpenAIReturnContext | None:\\n        \\\"\\\"\\\"\\n        Summarizes the provided code snippet using the OpenAI API.\\n\\n        Args:\\n            - code (str): The code snippet to summarize.\\n            - configs (SummaryCompletionConfigs, optional): Configuration settings for the summarization.\\n                Defaults to SummaryCompletionConfigs().\\n\\n        Returns:\\n            - str: The summary of the provided code snippet.\\n\\n        Examples:\\n            ```Python\\n            client = OpenAI()\\n\\n            # Create a summarizer instance with the OpenAI client\\n            summarizer = Summarizer(client=client)\\n            code_example = \\\"print('Hello, world')\\\"\\n\\n            # Summarize the code snippet\\n            summary = summarizer.summarize_code(code_example)\\n            print(summary)\\n            ```\\n        \\\"\\\"\\\"\\n\\n        logging.info(f\\\"Summarizing code for model: {model_id}\\\")\\n        prompt: str = self._create_prompt(\\n            code, children_summaries, dependency_summaries, import_details\\n        )\\n        messages: list[ChatCompletionMessageParam] = self._create_messages_list(\\n            system_message=configs.system_message, user_message=prompt\\n        )\\n\\n        if summary_return_context := self._get_summary(messages, configs=configs):\\n            if summary_return_context:\\n                if summary_return_context.summary:\\n                    summary_return_context.summary = (\\n                        summary_return_context.summary.split(\\\"FINAL SUMMARY:\\\")[-1]\\n                    )\\n                    return summary_return_context\\n        return None\\n\\n    def test_summarize_code(\\n        self,\\n        code: str,\\n        *,\\n        model_id: str,\\n        children_summaries: str | None,\\n        dependency_summaries: str | None,\\n        import_details: str | None,\\n        configs: SummaryCompletionConfigs = SummaryCompletionConfigs(),\\n    ) -> OpenAIReturnContext | None:\\n        \\\"\\\"\\\"\\n        Summarizes the provided code snippet using the OpenAI API.\\n\\n        Args:\\n            - code (str): The code snippet to summarize.\\n            - configs (SummaryCompletionConfigs, optional): Configuration settings for the summarization.\\n                Defaults to SummaryCompletionConfigs().\\n\\n        Returns:\\n            - str: The summary of the provided code snippet.\\n        \\\"\\\"\\\"\\n\\n        summary = f\\\"\\\"\\\"\\\\nSummary:\\\\n\\n        {model_id}\\\\n\\n        {children_summaries}, {dependency_summaries}, {import_details}\\n        \\\"\\\"\\\"\\n        summary_context = OpenAIReturnContext(\\n            summary=summary,\\n            prompt_tokens=1,\\n            completion_tokens=1,\\n        )\\n\\n        return summary_context\\n\\n\\n# if __name__ == \\\"__main__\\\":\\n#     client = OpenAI()\\n#     summarizer = OpenAISummarizer(client=client)\\n#     children_summaries = \\\"\\\"\\n#     dependency_summaries = \\\"\\\"\\n#     summary = summarizer.summarize_code(\\n#         code_example,\\n#         model_id=\\\"test\\\",\\n#         children_summaries=children_summaries,\\n#         dependency_summaries=dependency_summaries,\\n#         import_details=None,\\n#     )\\n#     print(summary)\\n\\n\\nImported code block (postcode:ai_services:summarizer:summarization_mapper.py__*__MODULE) code content:\\nimport logging\\nfrom pprint import pprint\\nfrom typing import Union\\nfrom postcode.databases.arangodb.arangodb_manager import ArangoDBManager\\nfrom postcode.models.models import (\\n    ClassModel,\\n    FunctionModel,\\n    ModuleModel,\\n    StandaloneCodeBlockModel,\\n)\\n\\n# from postcode.types.postcode import ModelType\\n\\nModelType = Union[\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n]\\n\\n\\nclass SummarizationMapper:\\n    def __init__(\\n        self,\\n        module_ids_to_update: list[str],\\n        module_models: tuple[ModuleModel, ...],\\n        arangodb_manager: ArangoDBManager,\\n    ) -> None:\\n        self.module_ids_to_update: list[str] = module_ids_to_update\\n        self.module_models: tuple[ModuleModel, ...] = module_models\\n        self.arangodb_manager: ArangoDBManager = arangodb_manager\\n        self.models_to_update: list[ModelType] = []\\n        self.model_visited_in_db: set[str] = set()\\n        self.summarization_map: list[ModelType] = []\\n        self.temp_map: list[ModelType] = []\\n\\n    def _set_child_models_to_update(self, model: ModelType) -> None:\\n        if model.children:\\n            for child in model.children:\\n                # logging.info(f\\\"Setting child model to update: {child.id}\\\")\\n                self._set_child_models_to_update(child)\\n                child.summary = None\\n                self.models_to_update.append(child)\\n            self.models_to_update.append(model)\\n\\n    def _set_models_to_update(self) -> None:\\n        for model in self.module_models:\\n            if model.id in self.module_ids_to_update:\\n                if model.children:\\n                    for child in model.children:\\n                        self._set_child_models_to_update(child)\\n\\n                model.summary = None\\n                self.models_to_update.append(model)\\n\\n    def _set_inbound_models_in_summarization_map(self, model_id: str) -> None:\\n        if model_id in self.model_visited_in_db:\\n            return\\n        self.model_visited_in_db.add(model_id)\\n        if inbound_models := self.arangodb_manager.get_inbound_models(model_id):\\n            for model in inbound_models:\\n                # logging.info(f\\\"Setting inbound models in summarization map: {model.id}\\\")\\n                self.model_visited_in_db.add(model_id)\\n                self._set_inbound_models_in_summarization_map(model.id)\\n\\n                self.temp_map.append(model)\\n\\n    def _set_outbound_models_in_summarization_map(self, model_id: str) -> None:\\n        if model_id in self.model_visited_in_db:\\n            return\\n\\n        if outbound_models := self.arangodb_manager.get_outbound_models(model_id):\\n            for model in outbound_models[::-1]:\\n                # logging.info(\\n                #     f\\\"Setting outbound models in summarization map: {model.id}\\\"\\n                # )\\n                self.model_visited_in_db.add(model_id)\\n                # self._set_outbound_models_in_summarization_map(model.id)``\\n\\n                if model.id in self.models_to_update:\\n                    model.summary = None\\n                self.temp_map.append(model)\\n\\n    def create_summarization_map(self) -> list[ModelType]:\\n        self._set_models_to_update()\\n        logging.info(\\\"Set models to update\\\")\\n\\n        # pprint([model.id for model in self.models_to_update])\\n\\n        for model in self.models_to_update:\\n            # self.model_visited_in_db = set()\\n            # logging.info(f\\\"Setting inbound models in summarization map: {model.id}\\\")\\n            self._set_inbound_models_in_summarization_map(model.id)\\n            self.temp_map.append(model)\\n\\n            self.model_visited_in_db.remove(model.id)\\n            # logging.info(f\\\"Setting outbound models in summarization map: {model.id}\\\")\\n            # self._set_outbound_models_in_summarization_map(model.id)\\n            self.summarization_map.extend(self.temp_map)\\n            self.temp_map = []\\n\\n        for model in self.models_to_update:\\n            self.model_visited_in_db = set()\\n            # logging.info(f\\\"Setting outbound models in summarization map: {model.id}\\\")\\n            self._set_outbound_models_in_summarization_map(model.id)\\n            self.summarization_map.extend(self.temp_map)\\n            self.temp_map = []\\n\\n        logging.info(\\\"Created summarization map\\\")\\n        summary_ids: set[str] = set()\\n        summary_map: list[ModelType] = []\\n        for model in self.summarization_map[::-1]:\\n            if model.id not in summary_ids:\\n                summary_map.append(model)\\n                summary_ids.add(model.id)\\n\\n        # return summary_map[::-1]\\n        pprint([model.id for model in summary_map[::-1]])\\n        return summary_map[::-1]\\n\\n    # def old_create_summarization_map(self) -> list[list[ModelType]]:\\n    #     for module_id in self.module_ids_to_update:\\n    #         models_to_update: list[ModelType] = []\\n\\n    #         upstream_models: list[\\n    #             ModelType\\n    #         ] | None = self.arangodb_manager.get_all_upstream_vertices(module_id)\\n    #         downstream_models: list[\\n    #             ModelType\\n    #         ] | None = self.arangodb_manager.get_all_downstream_vertices(module_id)\\n\\n    #         ids_from_db: list[str] = []\\n    #         if upstream_models:\\n    #             upstream_ids_to_update: list[str] = [\\n    #                 model.id for model in upstream_models\\n    #             ]\\n    #             ids_from_db.extend(upstream_ids_to_update)\\n\\n    #         ids_from_db.append(module_id)\\n\\n    #         if downstream_models:\\n    #             downstream_ids_to_update: list[str] = [\\n    #                 model.id for model in downstream_models\\n    #             ]\\n    #             ids_from_db.extend(downstream_ids_to_update)\\n\\n    #         for id in ids_from_db:\\n    #             for model in self.module_models:\\n    #                 if model.id == id:\\n    #                     models_to_update.append(model)\\n    #                 elif model.children:\\n    #                     for child in model.children:\\n    #                         if child.id == id:\\n    #                             models_to_update.append(child)\\n\\n    #         self.summarization_map.append(models_to_update)\\n\\n    #     return self.summarization_map\\n\\n\\nImported code block (postcode:databases:arangodb:arangodb_connector.py__*__MODULE) code content:\\nimport logging\\nfrom typing import Any\\nfrom arango.client import ArangoClient\\nfrom arango.database import StandardDatabase\\nfrom arango.result import Result\\nfrom arango.typings import Jsons, Json\\n\\nimport postcode.databases.arangodb.helper_functions as helper_functions\\n\\n# from postcode.models import (\\n#     ModuleModel,\\n#     ClassModel,\\n#     FunctionModel,\\n#     StandaloneCodeBlockModel,\\n# )\\n\\n\\n# test = ArangoClient(hosts=\\\"http://localhost:8529\\\")\\nclass ArangoDBConnector:\\n    def __init__(\\n        self,\\n        url: str = \\\"http://localhost:8529\\\",\\n        username: str = \\\"root\\\",\\n        password: str = \\\"openSesame\\\",\\n        db_name: str = \\\"postcode\\\",\\n    ) -> None:\\n        self.client = ArangoClient(hosts=url)\\n        self.username: str = username\\n        self.password: str = password\\n        self.db_name: str = db_name\\n        self.db: StandardDatabase = self._ensure_database()\\n\\n    def _ensure_database(self) -> StandardDatabase:\\n        sys_db: StandardDatabase = self.client.db(\\n            \\\"_system\\\", username=self.username, password=self.password\\n        )\\n        if not sys_db.has_database(self.db_name):\\n            sys_db.create_database(self.db_name)\\n        return self.client.db(\\n            self.db_name, username=self.username, password=self.password\\n        )\\n\\n    # def _ensure_vertex_collections(self, vertex_collections: list[str]) -> None:\\n    #     for collection in vertex_collections:\\n    #         if not self.db.has_collection(collection):\\n    #             self.db.create_collection(collection)\\n\\n    def _get_current_schema(self, collection_name: str) -> dict:\\n        collection = self.db.collection(collection_name)\\n        try:\\n            properties: Result[Json] = collection.properties()\\n            return properties.get(\\\"schema\\\", {})  # type: ignore # FIXME: Fix type error\\n        except Exception as e:\\n            logging.error(f\\\"Error retrieving current schema for {collection_name}: {e}\\\")\\n            return {}\\n\\n    def ensure_collection(\\n        self, collection_name: str, schema: dict[str, Any] | None = None\\n    ) -> None:\\n        if not self.db.has_collection(collection_name) and not schema:\\n            self.db.create_collection(collection_name)\\n            logging.info(f\\\"Created collection: {collection_name}\\\")\\n        # else:\\n        #     current_schema = self._get_current_schema(collection_name)\\n        #     self.db.collection(collection_name)\\n        # if current_schema != schema:\\n        #     collection = self.db.collection(collection_name)\\n        #     try:\\n        #         collection.configure(schema=schema)\\n        #         logging.info(f\\\"Updated schema for collection: {collection_name}\\\")\\n        #     except Exception as e:\\n        #         logging.error(f\\\"Error updating schema for {collection_name}: {e}\\\")\\n\\n    def ensure_edge_collection(self, collection_name: str) -> None:\\n        if not self.db.has_collection(collection_name):\\n            self.db.create_collection(collection_name, edge=True)\\n            logging.info(f\\\"Created edge collection: {collection_name}\\\")\\n\\n    def delete_all_collections(self) -> None:\\n        collections: Result[Jsons] = self.db.collections()\\n\\n        for collection in collections:  # type: ignore # FIXME: Fix type error\\n            if not collection[\\\"name\\\"].startswith(\\\"_\\\"):  # Skip system collections\\n                self.db.delete_collection(collection[\\\"name\\\"])\\n                logging.info(f\\\"Deleted collection: {collection['name']}\\\")\\n\\n    def ensure_collections(self) -> None:\\n        # model_schemas: dict[str, dict[str, Any]] = self._get_model_schemas()\\n        required_collections: list[\\n            str\\n        ] = helper_functions.pluralized_and_lowered_block_types()\\n\\n        for collection_name in required_collections:\\n            # schema: dict[str, Any] = model_schemas[collection_name]\\n            # self.ensure_collection(collection_name, schema)\\n            self.ensure_collection(collection_name)\\n\\n        self.ensure_edge_collection(\\\"code_edges\\\")\\n\\n    # def _get_model_schemas(self) -> dict[str, dict[str, Any]]:\\n    #     return {\\n    #         \\\"modules\\\": ModuleModel.model_json_schema(),\\n    #         \\\"classes\\\": ClassModel.model_json_schema(),\\n    #         \\\"functions\\\": FunctionModel.model_json_schema(),\\n    #         \\\"standalone_blocks\\\": StandaloneCodeBlockModel.model_json_schema(),\\n    #     }\\n\\n\\nImported code block (postcode:databases:arangodb:arangodb_manager.py__*__MODULE) code content:\\nimport logging\\nfrom typing import Any, Callable, Union\\n\\nfrom arango.result import Result\\nfrom arango.cursor import Cursor\\nfrom arango.graph import Graph\\nfrom arango.collection import StandardCollection\\nfrom arango.typings import Json\\n\\nfrom postcode.databases.arangodb.arangodb_connector import ArangoDBConnector\\n\\n# from postcode.types.postcode import ModelType\\nfrom postcode.models.models import (\\n    ClassModel,\\n    FunctionModel,\\n    ModuleModel,\\n    StandaloneCodeBlockModel,\\n)\\nimport postcode.databases.arangodb.helper_functions as helper_functions\\n\\nModelType = Union[\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n]\\n\\n# NOTE: Remember, when adding logic to connect dependencies, the `from` the external dependency `to` the internal definition using it\\n\\n\\nclass ArangoDBManager:\\n    def __init__(\\n        self,\\n        db_connector: ArangoDBConnector,\\n        default_graph_name: str = \\\"codebase_graph\\\",\\n    ) -> None:\\n        self.db_connector: ArangoDBConnector = db_connector\\n\\n        self.processed_id_set = set()\\n        self.default_graph_name: str = default_graph_name\\n\\n    def upsert_models(self, module_models: list[ModuleModel]) -> \\\"ArangoDBManager\\\":\\n        for model in module_models:\\n            self._upsert_model(model)\\n        return self\\n\\n    def _upsert_model(self, module_model: ModuleModel) -> None:\\n        self._upsert_vertex(module_model, \\\"modules\\\")\\n        self._process_children(module_model)\\n\\n    def _process_children(self, parent_model: ModelType) -> None:\\n        if not parent_model.children:\\n            return None\\n\\n        for child in parent_model.children:\\n            # if child.id in self.processed_id_set:\\n            #     continue\\n\\n            self.processed_id_set.add(child.id)\\n            self._upsert_vertex(\\n                child, helper_functions.pluralize_block_type(child.block_type)\\n            )\\n\\n            if child.children:\\n                self._process_children(child)\\n\\n    def _upsert_vertex(self, model: ModelType, collection_name: str) -> None:\\n        model_data: dict[str, Any] = model.model_dump()\\n        model_data[\\\"_key\\\"] = model.id\\n\\n        try:\\n            self.db_connector.ensure_collection(\\n                collection_name, model.model_json_schema()\\n            )\\n            query: str = f\\\"\\\"\\\"\\n            UPSERT {{_key: @key}}\\n            INSERT @doc\\n            UPDATE @doc\\n            IN {collection_name}\\n            \\\"\\\"\\\"\\n            bind_vars: dict[str, Any] = {\\\"key\\\": model.id, \\\"doc\\\": model_data}\\n            self.db_connector.db.aql.execute(query, bind_vars=bind_vars)\\n\\n            if not isinstance(model, ModuleModel) and model.parent_id:\\n                parent_type: str = self._get_collection_from_id(model.parent_id)\\n                self._upsert_edge(\\n                    model.id, model.parent_id, collection_name, parent_type\\n                )\\n        except Exception as e:\\n            logging.error(f\\\"Error upserting {collection_name} vertex (ArangoDB): {e}\\\")\\n\\n    def _upsert_edge(\\n        self, from_key: str, to_key: str, source_type: str, target_type: str\\n    ) -> None:\\n        source_string: str = f\\\"{source_type}/{from_key}\\\"\\n        target_string: str = f\\\"{target_type}/{to_key}\\\"\\n\\n        edge_data: dict[str, str] = {\\n            \\\"_from\\\": source_string,\\n            \\\"_to\\\": target_string,\\n            \\\"source_type\\\": source_type,\\n            \\\"target_type\\\": target_type,\\n        }\\n\\n        try:\\n            self.db_connector.ensure_edge_collection(\\\"code_edges\\\")\\n            query = f\\\"\\\"\\\"\\n            UPSERT {{_from: @from, _to: @to}}\\n            INSERT @doc\\n            UPDATE @doc\\n            IN code_edges\\n            \\\"\\\"\\\"\\n            bind_vars = {\\n                \\\"from\\\": edge_data[\\\"_from\\\"],\\n                \\\"to\\\": edge_data[\\\"_to\\\"],\\n                \\\"doc\\\": edge_data,\\n            }\\n            self.db_connector.db.aql.execute(query, bind_vars=bind_vars)\\n        except Exception as e:\\n            logging.error(f\\\"Error upserting edge (ArangoDB): {e}\\\")\\n\\n    def _get_collection_from_id(self, block_id: str) -> str:\\n        block_id_parts: list[str] = block_id.split(\\\"__*__\\\")\\n        block_type_part: str = block_id_parts[-1]\\n\\n        block_type_functions: dict[str, Callable[..., str]] = {\\n            \\\"MODULE\\\": lambda: \\\"modules\\\",\\n            \\\"CLASS\\\": lambda: \\\"classes\\\",\\n            \\\"FUNCTION\\\": lambda: \\\"functions\\\",\\n            \\\"STANDALONE_BLOCK\\\": lambda: \\\"standalone_blocks\\\",\\n        }\\n\\n        for key, func in block_type_functions.items():\\n            if block_type_part.startswith(key):\\n                return func()\\n\\n        return \\\"unknown\\\"\\n\\n    def process_imports_and_dependencies(self) -> \\\"ArangoDBManager\\\":\\n        for vertex_collection in helper_functions.pluralized_and_lowered_block_types():\\n            cursor: Result[Cursor] = self.db_connector.db.collection(\\n                vertex_collection\\n            ).all()\\n            if isinstance(cursor, Cursor):\\n                for vertex in cursor:\\n                    vertex_key = vertex[\\\"_key\\\"]\\n                    if vertex_collection == \\\"modules\\\":\\n                        self._create_edges_for_imports(\\n                            vertex_key, vertex.get(\\\"imports\\\", [])\\n                        )\\n                    else:\\n                        self._create_edges_for_dependencies(\\n                            vertex_key, vertex.get(\\\"dependencies\\\", [])\\n                        )\\n            else:\\n                logging.error(\\n                    f\\\"Error getting cursor for vertex collection: {vertex_collection}\\\"\\n                )\\n        return self\\n\\n    def _create_edges_for_imports(\\n        self, module_key: str, imports: list[dict[str, Any]]\\n    ) -> None:\\n        if not imports:\\n            # logging.debug(f\\\"No imports found for module {module_key}\\\")\\n            return\\n\\n        # logging.info(f\\\"Processing imports for module {module_key}\\\")\\n\\n        for _import in imports:\\n            import_names: list[dict[str, str]] = _import.get(\\\"import_names\\\", [])\\n            if not import_names:\\n                # logging.debug(f\\\"No import names found in import {_import}\\\")\\n                continue\\n\\n            for import_name in import_names:\\n                local_block_id: str | None = import_name.get(\\\"local_block_id\\\")\\n\\n                if local_block_id:\\n                    target_type = self._get_collection_from_id(local_block_id)\\n                    try:\\n                        self._upsert_edge(\\n                            local_block_id, module_key, target_type, \\\"modules\\\"\\n                        )\\n\\n                        # logging.info(\\n                        #     f\\\"Upserted edge for import {module_key} to {local_block_id}\\\"\\n                        # )\\n                    except Exception as e:\\n                        logging.error(\\n                            f\\\"Error creating edge for import {module_key} to {local_block_id}: {e}\\\"\\n                        )\\n                else:\\n                    # logging.warning(\\n                    #     f\\\"Skipped import {import_name} in module {module_key}\\\"\\n                    # )\\n                    ...\\n\\n    def _create_edges_for_dependencies(\\n        self, block_key: str, dependencies: list[dict[str, Any]]\\n    ) -> None:\\n        if not dependencies:\\n            return\\n\\n        for dependency in dependencies:\\n            code_block_id: str | None = dependency.get(\\\"code_block_id\\\")\\n            if code_block_id:\\n                source_type: str = self._get_collection_from_id(code_block_id)\\n                target_type: str = self._get_collection_from_id(block_key)\\n                try:\\n                    self._upsert_edge(\\n                        code_block_id, block_key, source_type, target_type\\n                    )\\n                    # logging.info(\\n                    #     f\\\"Upserted edge for dependency {block_key} to {code_block_id}\\\"\\n                    # )\\n                except Exception as e:\\n                    logging.error(\\n                        f\\\"Error creating edge for dependency {block_key} to {code_block_id}: {e}\\\"\\n                    )\\n\\n    def delete_vertex_by_id(\\n        self, vertex_key: str, graph_name: str | None = None\\n    ) -> None:\\n        collection_name: str = self._get_collection_from_id(vertex_key)\\n        if collection_name == \\\"unknown\\\":\\n            logging.error(f\\\"Unknown vertex type for key: {vertex_key}\\\")\\n            return None\\n\\n        if not graph_name:\\n            graph_name = self.default_graph_name\\n\\n        try:\\n            vertex_coll = self.db_connector.db.graph(graph_name).vertex_collection(\\n                collection_name\\n            )\\n\\n            vertex_coll.delete(vertex_key)\\n\\n            # logging.info(\\n            #     f\\\"Vertex '{vertex_key}' from collection '{collection_name}' was successfully deleted.\\\"\\n            # )\\n\\n        except Exception as e:\\n            logging.error(\\n                f\\\"Error deleting vertex '{vertex_key}' from collection '{collection_name}': {e}\\\"\\n            )\\n\\n    def get_graph(self, graph_name: str | None = None) -> Graph | None:\\n        if not graph_name:\\n            graph_name = self.default_graph_name\\n        try:\\n            return self.db_connector.db.graph(self.default_graph_name)\\n        except Exception as e:\\n            logging.error(f\\\"Error getting graph '{self.default_graph_name}': {e}\\\")\\n            return None\\n\\n    def get_or_create_graph(self, graph_name: str | None = None) -> Result[Graph]:\\n        if not graph_name:\\n            graph_name = self.default_graph_name\\n\\n        try:\\n            if not self.db_connector.db.has_graph(graph_name):\\n                edge_definitions: list[dict[str, str | list[str]]] = [\\n                    {\\n                        \\\"edge_collection\\\": \\\"code_edges\\\",\\n                        \\\"from_vertex_collections\\\": helper_functions.pluralized_and_lowered_block_types(),\\n                        \\\"to_vertex_collections\\\": helper_functions.pluralized_and_lowered_block_types(),\\n                    }\\n                ]\\n\\n                # logging.info(f\\\"Graph '{graph_name}' created successfully.\\\")\\n                return self.db_connector.db.create_graph(\\n                    graph_name, edge_definitions=edge_definitions\\n                )\\n\\n            else:\\n                return self.get_graph()\\n\\n        except Exception as e:\\n            logging.error(f\\\"Error creating graph '{graph_name}': {e}\\\")\\n\\n    def delete_graph(self, graph_name: str | None = None) -> None:\\n        if not graph_name:\\n            graph_name = self.default_graph_name\\n        try:\\n            self.db_connector.db.delete_graph(graph_name)\\n            logging.info(f\\\"Graph '{graph_name}' deleted successfully.\\\")\\n        except Exception as e:\\n            logging.error(f\\\"Error deleting graph '{graph_name}': {e}\\\")\\n\\n    def get_outbound_models(self, start_key: str) -> list[ModelType] | None:\\n        vertex_type: str = self._get_collection_from_id(start_key)\\n\\n        query: str = f\\\"\\\"\\\"\\n        FOR v, e, p IN 1..100 OUTBOUND '{vertex_type}/{start_key}' GRAPH '{self.default_graph_name}'\\n        RETURN DISTINCT v\\n        \\\"\\\"\\\"\\n        # query: str = f\\\"\\\"\\\"\\n        # FOR v, e, p IN 1..100 OUTBOUND '{vertex_type}/{start_key}' GRAPH '{self.default_graph_name}'\\n        # FILTER LENGTH(p.edges[* FILTER CURRENT != e]) == 0\\n        # RETURN DISTINCT v\\n        # \\\"\\\"\\\"\\n        # query: str = f\\\"\\\"\\\"\\n        # FOR v, e, p IN 1..100 OUTBOUND '{vertex_type}/{start_key}' GRAPH '{self.default_graph_name}'\\n        # FILTER LENGTH(p.edges[* FILTER CURRENT != e]) == 0\\n        #     AND p.edges[*].distance ALL == 1\\n        # RETURN DISTINCT v\\n        # \\\"\\\"\\\"\\n\\n        try:\\n            cursor = self.db_connector.db.aql.execute(query)\\n            if isinstance(cursor, Cursor):\\n                return [\\n                    helper_functions.create_model_from_vertex(doc) for doc in cursor\\n                ]\\n            else:\\n                logging.error(f\\\"Error getting cursor for query: {query}\\\")\\n                return None\\n        except Exception as e:\\n            logging.error(f\\\"Error in get_all_downstream_vertices: {e}\\\")\\n            return None\\n\\n    def get_inbound_models(self, end_key: str) -> list[ModelType] | None:\\n        vertex_type: str = self._get_collection_from_id(end_key)\\n\\n        query: str = f\\\"\\\"\\\"\\n        FOR v, e, p IN 1..100 INBOUND '{vertex_type}/{end_key}' GRAPH '{self.default_graph_name}'\\n        RETURN DISTINCT v\\n        \\\"\\\"\\\"\\n\\n        # query: str = f\\\"\\\"\\\"\\n        # FOR v, e, p IN 1..100 INBOUND '{vertex_type}/{end_key}' GRAPH '{self.default_graph_name}'\\n        # FILTER LENGTH(p.edges[* FILTER CURRENT != e]) == 0\\n        # RETURN DISTINCT v\\n        # \\\"\\\"\\\"\\n\\n        try:\\n            cursor: Result[Cursor] = self.db_connector.db.aql.execute(query)\\n            if isinstance(cursor, Cursor):\\n                return [\\n                    helper_functions.create_model_from_vertex(doc) for doc in cursor\\n                ]\\n            else:\\n                logging.error(f\\\"Error getting cursor for query: {query}\\\")\\n                return None\\n        except Exception as e:\\n            logging.error(f\\\"Error in get_all_upstream_vertices: {e}\\\")\\n            return None\\n\\n    def update_vertex_by_id(self, id: str, new_summary: str) -> None:\\n        try:\\n            collection_name: str = self._get_collection_from_id(id)\\n            if collection_name == \\\"unknown\\\":\\n                logging.error(f\\\"Unknown vertex type for id: {id}\\\")\\n                return\\n\\n            vertex_collection: StandardCollection = self.db_connector.db.collection(\\n                collection_name\\n            )\\n            vertex_result: Result[Json | None] = vertex_collection.get(id)\\n\\n            if not vertex_result:\\n                logging.error(f\\\"Vertex with id {id} not found.\\\")\\n                return\\n\\n            if isinstance(vertex_result, dict):\\n                vertex = vertex_result\\n            else:\\n                logging.error(\\\"Retrieved vertex is not in a mutable format.\\\")\\n                return None\\n\\n            vertex[\\\"summary\\\"] = new_summary\\n\\n            vertex_collection.update(vertex)\\n            logging.info(f\\\"Vertex with id {id} updated successfully.\\\")\\n\\n        except Exception as e:\\n            logging.error(f\\\"Error in `update_vertex_by_id`: {e}\\\")\\n\\n    def get_all_modules(self) -> list[ModuleModel] | None:\\n        try:\\n            # Define the collection name for modules.\\n            collection_name = \\\"modules\\\"\\n            module_collection: StandardCollection = self.db_connector.db.collection(\\n                collection_name\\n            )\\n\\n            # Retrieve all documents from the modules collection.\\n            cursor: Result[Cursor] = module_collection.all()\\n\\n            # Convert each document to a ModuleModel instance.\\n            modules: list[ModuleModel] = []\\n            for doc in cursor:  # type: ignore # FIXME: Fix type error\\n                # Ensure the document is a dictionary.\\n                try:\\n                    # Convert the document to a ModuleModel instance and add it to the list.\\n                    module = ModuleModel(**doc)\\n                    modules.append(module)\\n                except Exception as e:\\n                    logging.error(f\\\"Retrieved document is not in a valid format: {e}\\\")\\n                    continue\\n\\n            return modules\\n\\n        except Exception as e:\\n            logging.error(f\\\"Error in get_all_modules: {e}\\\")\\n            return None\\n\\n\\nImported code block (postcode:databases:chroma:setup_chroma.py__*__MODULE) code content:\\nfrom dataclasses import dataclass\\nfrom logging import Logger\\n\\nimport chromadb\\nfrom postcode.databases.chroma.chromadb_client_manager import ChromaDBClientManager\\n\\nfrom postcode.databases.chroma.chromadb_collection_manager import (\\n    ChromaDBCollectionManager,\\n)\\n\\nfrom chromadb.config import DEFAULT_DATABASE, DEFAULT_TENANT, Settings\\nfrom chromadb.api import ClientAPI\\nfrom chromadb.api.types import (\\n    DataLoader,\\n    CollectionMetadata,\\n    GetResult,\\n    QueryResult,\\n    Where,\\n    WhereDocument,\\n    Include,\\n    URIs,\\n    Loadable,\\n    Metadata,\\n    Embedding,\\n)\\nfrom chromadb import Collection\\nfrom chromadb import EmbeddingFunction\\n\\nfrom postcode.models.models import ModuleModel\\n\\n\\n@dataclass\\nclass ChromaSetupReturnContext:\\n    \\\"\\\"\\\"\\n    Represents the return value of the ChromaDB setup method.\\n\\n    Attributes:\\n        - chroma_collection_manager (ChromaDBCollectionManager): The ChromaDB collection manager.\\n        - chroma_collection (Collection): The ChromaDB collection.\\n    \\\"\\\"\\\"\\n\\n    chroma_collection_manager: ChromaDBCollectionManager\\n    chroma_collection: Collection\\n\\n\\ndef setup_chroma(\\n    module_models: list[ModuleModel], logger: Logger\\n) -> ChromaSetupReturnContext:\\n    chroma_settings = Settings(allow_reset=True)\\n    chroma_client: ClientAPI = chromadb.PersistentClient(settings=chroma_settings)\\n    chroma_client_manager = ChromaDBClientManager(chroma_client)\\n\\n    logger.debug(f\\\"Resetting Chroma client\\\")\\n    if chroma_client_manager.reset_client():\\n        logger.debug(\\\"Client reset\\\")\\n\\n    chroma_collection: Collection = chroma_client_manager.get_or_create_collection(\\n        \\\"postcode\\\"\\n    )\\n\\n    chroma_collection_manager = ChromaDBCollectionManager(chroma_collection)\\n    chroma_collection_manager.upsert_models(tuple(module_models))\\n\\n    return ChromaSetupReturnContext(chroma_collection_manager, chroma_collection)\\n\\n\\nImported code block (postcode:json_management:json_handler.py__*__MODULE) code content:\\nimport json\\nfrom pathlib import Path\\n\\nfrom postcode.models.models import ModuleModel\\nfrom postcode.utilities.logger.decorators import logging_decorator\\n\\n\\nclass JSONHandler:\\n    def __init__(\\n        self,\\n        directory: str,\\n        directory_modules: dict[str, list[str]],\\n        output_directory: str = \\\"../output\\\",\\n    ) -> None:\\n        self.directory: str = directory\\n        self.output_directory: str = output_directory\\n        self.directory_modules: dict[str, list[str]] = directory_modules\\n\\n        self._create_output_directory()\\n\\n    @logging_decorator(message=\\\"Saving model as JSON\\\")\\n    def save_model_as_json(self, module_model: ModuleModel, file_path: str) -> None:\\n        \\\"\\\"\\\"Saves a parsed ModuleModel as JSON.\\\"\\\"\\\"\\n\\n        json_output_directory: str = self._create_json_output_directory()\\n        output_path: str = self._get_json_output_path(file_path, json_output_directory)\\n        self._write_json_file(module_model, output_path)\\n\\n    @logging_decorator(message=\\\"Saving visited directories\\\")\\n    def save_visited_directories(\\n        self, directory_mape_name: str = \\\"directory_map.json\\\"\\n    ) -> None:\\n        \\\"\\\"\\\"\\n        Saves a JSON file mapping each visited directory to its Python files.\\n\\n        The output is saved in a file named '00_directory_module_map.json' within the specified output directory.\\n\\n        Args:\\n            directory_mape_name (str): The name of the output file for the directory map.\\n\\n        Example:\\n            >>> visitor_manager.save_visited_directories(\\\"directory_map.json\\\")\\n            # Saves a mapping of directories to Python files as JSON.\\n        \\\"\\\"\\\"\\n\\n        output_path: str = self._get_directory_map_output_path(directory_mape_name)\\n        self._write_json_directory_map(output_path)\\n\\n    def _create_output_directory(self) -> None:\\n        \\\"\\\"\\\"Creates the output directory if it does not already exist.\\\"\\\"\\\"\\n\\n        Path(self.output_directory).mkdir(exist_ok=True)\\n\\n    def _create_json_output_directory(self) -> str:\\n        \\\"\\\"\\\"Creates the JSON output directory if it does not already exist.\\\"\\\"\\\"\\n\\n        json_output_directory: Path = Path(self.output_directory) / \\\"json\\\"\\n        json_output_directory.mkdir(exist_ok=True)\\n        return str(json_output_directory)\\n\\n    def _get_json_output_path(self, file_path: str, json_output_directory: str) -> str:\\n        \\\"\\\"\\\"Gets the output path for a JSON file.\\\"\\\"\\\"\\n\\n        relative_path: Path = Path(file_path).relative_to(Path(self.directory))\\n        safe_relative_path: str = str(relative_path).replace(\\\"/\\\", \\\":\\\").rstrip(\\\".py\\\")\\n        return str(Path(json_output_directory) / f\\\"{safe_relative_path}.json\\\")\\n\\n    def _write_json_file(self, module_model: ModuleModel, output_path: str) -> None:\\n        \\\"\\\"\\\"Writes a JSON file containing the parsed data from a ModuleModel.\\\"\\\"\\\"\\n\\n        parsed_data_json: str = module_model.model_dump_json(indent=4)\\n        with open(output_path, \\\"w\\\") as json_file:\\n            json_file.write(parsed_data_json)\\n\\n    def _get_directory_map_output_path(self, directory_output_name: str) -> str:\\n        \\\"\\\"\\\"Gets the output path for the directory map JSON file.\\\"\\\"\\\"\\n\\n        return str(Path(self.output_directory) / directory_output_name)\\n\\n    def _write_json_directory_map(self, output_path: str) -> None:\\n        \\\"\\\"\\\"Writes the directory map JSON file.\\\"\\\"\\\"\\n\\n        with open(output_path, \\\"w\\\") as json_file:\\n            json.dump(self.directory_modules, json_file, indent=4)\\n\\n\\nImported code block (postcode:models:models.py__*__MODULE) code content:\\nfrom typing import Union\\nfrom pydantic import BaseModel, Field, validator\\n\\nfrom postcode.models.enums import (\\n    BlockType,\\n    ImportModuleType,\\n    CommentType,\\n)\\n\\n\\nclass ImportNameModel(BaseModel):\\n    \\\"\\\"\\\"Class representing the name of an import.\\\"\\\"\\\"\\n\\n    name: str\\n    as_name: str | None = None\\n    local_block_id: str | None = None\\n\\n    # def convert_import_names_to_metadata(self) -> str:\\n    #     \\\"\\\"\\\"Converts the import name to a metadata string.\\\"\\\"\\\"\\n\\n    #     return self.model_dump_json()\\n\\n\\nclass ImportModel(BaseModel):\\n    \\\"\\\"\\\"Class representing an import statement.\\\"\\\"\\\"\\n\\n    import_names: list[ImportNameModel]\\n    imported_from: str | None = None\\n    import_module_type: ImportModuleType = ImportModuleType.STANDARD_LIBRARY\\n    local_module_id: str | None = None\\n\\n    def convert_import_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the import to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass DependencyModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a module dependency.\\\"\\\"\\\"\\n\\n    code_block_id: str\\n\\n    def convert_dependency_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the dependency to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass CommentModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a comment.\\\"\\\"\\\"\\n\\n    content: str\\n    comment_types: list[CommentType]\\n\\n    def convert_comment_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the comment to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass DecoratorModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a decorator.\\\"\\\"\\\"\\n\\n    content: str\\n    decorator_name: str\\n    decorator_args: list[str] | None = None\\n\\n    def convert_decorator_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the decorator to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass ClassKeywordModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a class keyword.\\\"\\\"\\\"\\n\\n    content: str\\n    keyword_name: str\\n    args: str | None = None\\n\\n    def convert_class_keyword_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the class keyword to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass ParameterModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a function parameter.\\\"\\\"\\\"\\n\\n    content: str\\n\\n\\nclass ParameterListModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a list of parameters.\\\"\\\"\\\"\\n\\n    params: list[ParameterModel] | None = None\\n    star_arg: ParameterModel | None = None\\n    kwonly_params: list[ParameterModel] | None = None\\n    star_kwarg: ParameterModel | None = None\\n    posonly_params: list[ParameterModel] | None = None\\n\\n    def convert_parameters_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the parameter list to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass BaseCodeBlockModel(BaseModel):\\n    \\\"\\\"\\\"Attributes common to all code block models.\\\"\\\"\\\"\\n\\n    id: str\\n    parent_id: str | None = None\\n    block_type: BlockType\\n    start_line_num: int\\n    end_line_num: int\\n    code_content: str = \\\"\\\"\\n    important_comments: list[CommentModel] | None = None\\n    dependencies: list[ImportModel | DependencyModel] | None = None\\n    summary: str | None = None\\n    children: list[\\n        Union[\\n            \\\"ClassModel\\\",\\n            \\\"FunctionModel\\\",\\n            \\\"StandaloneCodeBlockModel\\\",\\n        ]\\n    ] | None = []\\n\\n    @validator(\\\"parent_id\\\", always=True)\\n    def check_parent_id(cls, v, values, **kwargs) -> str | None:\\n        \\\"\\\"\\\"Validates that parent_id is a non-empty string unless block_type is MODULE.\\\"\\\"\\\"\\n\\n        if \\\"block_type\\\" in values and values[\\\"block_type\\\"] != BlockType.MODULE:\\n            if len(v) < 1:\\n                raise ValueError(\\\"parent_id is required!\\\")\\n        return v\\n\\n    def _convert_parent_id_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the parent_id to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.parent_id}\\\" if self.parent_id else \\\"\\\"\\n\\n    def _convert_block_type_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the block_type to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.block_type.name}\\\"\\n\\n    def _convert_important_comments_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the important comments to a metadata string.\\\"\\\"\\\"\\n\\n        important_comments: str = (\\n            self.model_dump_json() if self.important_comments else \\\"\\\"\\n        )\\n\\n        return f\\\"{important_comments}\\\"\\n\\n    def _convert_dependencies_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the dependencies to a metadata string.\\\"\\\"\\\"\\n\\n        dependencies_str: str = \\\"\\\"\\n\\n        if self.dependencies:\\n            for dependency in self.dependencies:\\n                if isinstance(dependency, ImportModel):\\n                    dependencies_str += f\\\"{dependency.convert_import_to_metadata()}\\\\n\\\"\\n                elif isinstance(dependency, DependencyModel):\\n                    dependencies_str += (\\n                        f\\\"{dependency.convert_dependency_to_metadata()}\\\\n\\\"\\n                    )\\n\\n        return dependencies_str\\n\\n    def _convert_summary_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the summary to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.summary}\\\" if self.summary else \\\"\\\"\\n\\n    def _convert_children_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the children to a metadata string.\\\"\\\"\\\"\\n\\n        children_str: str = \\\"\\\"\\n\\n        if self.children:\\n            for child in self.children:\\n                children_str += f\\\"{child.id}\\\\n\\\"\\n\\n        return children_str\\n\\n    def _convert_base_attributes_to_metadata_dict(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the base attributes to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            \\\"id\\\": self.id,\\n            \\\"parent_id\\\": self._convert_parent_id_to_metadata(),\\n            \\\"block_type\\\": self._convert_block_type_to_metadata(),\\n            \\\"start_line_num\\\": self.start_line_num,\\n            \\\"end_line_num\\\": self.end_line_num,\\n            \\\"code_content\\\": self.code_content,\\n            \\\"important_comments\\\": self._convert_important_comments_to_metadata(),\\n            \\\"dependencies\\\": self._convert_dependencies_to_metadata(),\\n            \\\"summary\\\": self._convert_summary_to_metadata(),\\n            \\\"children\\\": self._convert_children_to_metadata(),\\n        }\\n\\n\\nclass ModuleSpecificAttributes(BaseModel):\\n    \\\"\\\"\\\"Module specific attributes.\\\"\\\"\\\"\\n\\n    file_path: str = Field(min_length=1)\\n    docstring: str | None = None\\n    header: list[str] | None = None\\n    footer: list[str] | None = None\\n    imports: list[ImportModel] | None = None\\n\\n    def _convert_docstring_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the docstring to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.docstring}\\\"\\n\\n    def _convert_header_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the header and footer to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n    def _convert_footer_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the header and footer to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n    def _convert_imports_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the imports to a metadata string.\\\"\\\"\\\"\\n        imports_str: str = self.model_dump_json() if self.imports else \\\"\\\"\\n        return f\\\"{imports_str}\\\"\\n\\n    def _convert_module_attributes_to_metadata_dict(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the module attributes to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            \\\"file_path\\\": self.file_path,\\n            \\\"docstring\\\": self._convert_docstring_to_metadata(),\\n            \\\"header\\\": self._convert_header_to_metadata(),\\n            \\\"footer\\\": self._convert_footer_to_metadata(),\\n            \\\"imports\\\": self._convert_imports_to_metadata(),\\n        }\\n\\n\\nclass ModuleModel(BaseCodeBlockModel, ModuleSpecificAttributes):\\n    \\\"\\\"\\\"Model for a module.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the module model to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_module_attributes_to_metadata_dict(),\\n        }\\n\\n\\nclass ClassSpecificAttributes(BaseModel):\\n    \\\"\\\"\\\"Class specific attributes.\\\"\\\"\\\"\\n\\n    class_name: str = Field(min_length=1)\\n    decorators: list[DecoratorModel] | None = None\\n    bases: list[str] | None = None\\n    docstring: str | None = None\\n    keywords: list[ClassKeywordModel] | None = None\\n    # attributes: list[dict] | None = None\\n\\n    def _convert_decorators_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the decorators to a metadata string.\\\"\\\"\\\"\\n        decorators_str: str = self.model_dump_json() if self.decorators else \\\"\\\"\\n        return f\\\"{decorators_str}\\\"\\n\\n    def _convert_bases_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the bases to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json() if self.bases else \\\"\\\"\\n\\n    def _convert_docstring_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the docstring to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.docstring}\\\" if self.docstring else \\\"\\\"\\n\\n    def _convert_keywords_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the keywords to a metadata string.\\\"\\\"\\\"\\n        keywords_str: str = self.model_dump_json() if self.keywords else \\\"\\\"\\n        return f\\\"{keywords_str}\\\"\\n\\n    def _convert_class_attributes_to_metadata_dict(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the class attributes to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            \\\"class_name\\\": self.class_name,\\n            \\\"decorators\\\": self._convert_decorators_to_metadata(),\\n            \\\"bases\\\": self._convert_bases_to_metadata(),\\n            \\\"docstring\\\": self._convert_docstring_to_metadata(),\\n            \\\"keywords\\\": self._convert_keywords_to_metadata(),\\n        }\\n\\n\\nclass ClassModel(BaseCodeBlockModel, ClassSpecificAttributes):\\n    \\\"\\\"\\\"Model for a class.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the class model to a metadata dictionary.\\\"\\\"\\\"\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_class_attributes_to_metadata_dict(),\\n        }\\n\\n\\nclass FunctionSpecificAttributes(BaseModel):\\n    \\\"\\\"\\\"Function specific attributes.\\\"\\\"\\\"\\n\\n    function_name: str = Field(min_length=1)\\n    docstring: str | None = None\\n    decorators: list[DecoratorModel] | None = None\\n    parameters: ParameterListModel | None = None\\n    returns: str | None = None\\n    is_method: bool = False\\n    is_async: bool = False\\n\\n    def _convert_docstring_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the docstring to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.docstring}\\\" if self.docstring else \\\"\\\"\\n\\n    def _convert_decorators_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the decorators to a metadata string.\\\"\\\"\\\"\\n        decorators_str: str = self.model_dump_json() if self.decorators else \\\"\\\"\\n        return f\\\"{decorators_str}\\\"\\n\\n    def _convert_parameters_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the parameters to a metadata string.\\\"\\\"\\\"\\n        return (\\n            self.parameters.convert_parameters_to_metadata() if self.parameters else \\\"\\\"\\n        )\\n\\n    def _convert_returns_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the returns to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.returns}\\\" if self.returns else \\\"\\\"\\n\\n    def _convert_function_attributes_to_metadata_dict(self) -> dict[str, str | bool]:\\n        \\\"\\\"\\\"Converts the function attributes to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            \\\"function_name\\\": self.function_name,\\n            \\\"docstring\\\": self._convert_docstring_to_metadata(),\\n            \\\"decorators\\\": self._convert_decorators_to_metadata(),\\n            \\\"parameters\\\": self._convert_parameters_to_metadata(),\\n            \\\"returns\\\": self._convert_returns_to_metadata(),\\n            \\\"is_method\\\": self.is_method,\\n            \\\"is_async\\\": self.is_async,\\n        }\\n\\n\\nclass FunctionModel(BaseCodeBlockModel, FunctionSpecificAttributes):\\n    \\\"\\\"\\\"Model for a function.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the function model to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_function_attributes_to_metadata_dict(),\\n        }\\n\\n\\nclass StandaloneCodeBlockSpecificAttributes(BaseModel):\\n    \\\"\\\"\\\"Standalone code block specific attributes.\\\"\\\"\\\"\\n\\n    variable_assignments: list[str] | None = None\\n\\n    def _convert_variable_assignments_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the variable assignments to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json() if self.variable_assignments else \\\"\\\"\\n\\n    def _convert_standalone_block_attributes_to_metadata_dict(\\n        self,\\n    ) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the standalone code block attributes to a metadata dictionary.\\\"\\\"\\\"\\n        return {\\n            \\\"variable_assignments\\\": self._convert_variable_assignments_to_metadata(),\\n        }\\n\\n\\nclass StandaloneCodeBlockModel(\\n    BaseCodeBlockModel, StandaloneCodeBlockSpecificAttributes\\n):\\n    \\\"\\\"\\\"Model for a standalone code block.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the standalone code block model to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_standalone_block_attributes_to_metadata_dict(),\\n        }\\n\\n\\nImported code block (postcode:python_parser:visitor_manager:visitor_manager.py__*__MODULE) code content:\\nfrom dataclasses import dataclass\\nimport logging\\nfrom pathlib import Path\\n\\nfrom postcode.python_parser.model_builders.module_model_builder import (\\n    ModuleModelBuilder,\\n)\\nfrom postcode.utilities.logger.decorators import logging_decorator\\n\\nfrom postcode.python_parser.parsers.python_parser import PythonParser\\nfrom postcode.python_parser.visitor_manager.import_and_dependency_updater import (\\n    ImportAndDependencyUpdater,\\n)\\nfrom postcode.models.models import ModuleModel\\n\\nfrom postcode.ai_services.summarizer.summarization_context import Summarizer\\n\\nEXCLUDED_DIRECTORIES: set[str] = {\\\".venv\\\", \\\"node_modules\\\", \\\"__pycache__\\\", \\\".git\\\"}\\n\\n\\n@dataclass\\nclass VisitorManagerProcessFilesReturn:\\n    \\\"\\\"\\\"\\n    Represents the return value of the VisitorManager.process_files() method.\\n\\n    Attributes:\\n        - models_tuple (tuple[ModuleModel, ...]): A tuple of ModuleModel objects representing the parsed modules.\\n        - directory_modules (dict[str, list[str]]): A dictionary mapping directory paths to lists of module names.\\n            This is used to keep track of the modules present in each directory.\\n    \\\"\\\"\\\"\\n\\n    models_tuple: tuple[ModuleModel, ...]\\n    directory_modules: dict[str, list[str]]\\n\\n\\nclass VisitorManager:\\n    \\\"\\\"\\\"\\n    Manages the visiting and processing of Python files in a given directory.\\n\\n    This class scans a specified directory, filters for Python files, parses them, and saves the parsed data in a structured JSON format. It also maintains a mapping of directories to the Python files they contain.\\n\\n    Attributes:\\n        directory (str): The root directory to scan for Python files.\\n        output_directory (str): The directory where output JSON files will be saved.\\n        directory_modules (dict): A mapping of directories to their contained Python files.\\n\\n    Example:\\n        >>> visitor_manager = VisitorManager(\\\"/path/to/python/code\\\", \\\"output\\\")\\n        >>> visitor_manager.process_files()\\n        # This will process all Python files in /path/to/python/code and save their parsed data in the output directory.\\n    \\\"\\\"\\\"\\n\\n    @logging_decorator(message=\\\"Initializing VisitorManager\\\")\\n    def __init__(self, directory: str, output_directory: str = \\\"output_json\\\") -> None:\\n        self.directory: str = directory\\n        self.output_directory: str = output_directory\\n        self.directory_modules: dict[str, list[str]] = {}\\n\\n    def process_files(self) -> VisitorManagerProcessFilesReturn:\\n        \\\"\\\"\\\"\\n        Process the files in the directory and return the module models.\\n\\n        This function iterates through all the Python files in the directory, processes each file,\\n        updates the imports, and builds module models for each file. It returns a tuple of module models\\n        and a dictionary of directory modules.\\n\\n        Returns:\\n            A named tuple (VisitorManagerProcessFilesReturn) containing:\\n            - models_tuple (tuple[ModuleModel, ...]): A tuple of module models.\\n            - directory_modules (dict[str, ModuleModel]): A dictionary of directory modules.\\n\\n        Examples:\\n            >>> visitor_manager = VisitorManager()\\n            >>> result = visitor_manager.process_files()\\n            >>> print(result.models_tuple)\\n            (ModuleModel(file_path='/path/to/file1.py'), ModuleModel(file_path='/path/to/file2.py'))\\n            >>> print(result.directory_modules)\\n            {'/path/to/directory1': ModuleModel(file_path='/path/to/directory1/__init__.py')}\\n        \\\"\\\"\\\"\\n\\n        logging.info(\\\"Processing files\\\")\\n        python_files: list[str] = self._get_python_files()\\n        model_builder_list: list[ModuleModelBuilder] = []\\n        for file_path in python_files:\\n            if model_builder := self._process_file(file_path):\\n                model_builder_list.append((model_builder))\\n\\n        logging.info(\\\"File processing completed\\\")\\n        logging.info(\\\"Updating imports\\\")\\n\\n        # TODO: Test making this a tuple of tuples, see if that solves the double update import issue\\n        model_builder_tuple: tuple[ModuleModelBuilder, ...] = tuple(model_builder_list)\\n\\n        import_and_dependency_updater = ImportAndDependencyUpdater(model_builder_tuple)\\n        import_and_dependency_updater.update_imports()\\n        logging.info(\\\"Updated imports\\\")\\n\\n        module_models_list: list[ModuleModel] = []\\n        for module_model_builder in model_builder_tuple:\\n            module_model: ModuleModel = self._build_module_model(module_model_builder)\\n            module_models_list.append(module_model)\\n\\n        module_models_tuple: tuple[ModuleModel, ...] = tuple(module_models_list)\\n\\n        return VisitorManagerProcessFilesReturn(\\n            models_tuple=module_models_tuple, directory_modules=self.directory_modules\\n        )\\n\\n    def _walk_directories(self) -> list[str]:\\n        \\\"\\\"\\\"Walks the specified directory and returns a list of all files.\\\"\\\"\\\"\\n\\n        all_files: list[str] = []\\n        for file_path in Path(self.directory).rglob(\\\"*\\\"):\\n            if not any(\\n                excluded in file_path.parts for excluded in EXCLUDED_DIRECTORIES\\n            ):\\n                all_files.append(str(file_path))\\n        return all_files\\n\\n    def _filter_python_files(self, files: list[str]) -> list[str]:\\n        \\\"\\\"\\\"Filters a list of files to only include Python files.\\\"\\\"\\\"\\n\\n        return [file for file in files if file.endswith(\\\".py\\\")]\\n\\n    @logging_decorator(message=\\\"Getting Python files\\\")\\n    def _get_python_files(self) -> list[str]:\\n        \\\"\\\"\\\"Gets all Python files in the specified directory.\\\"\\\"\\\"\\n\\n        all_files: list[str] = self._walk_directories()\\n        return self._filter_python_files(all_files)\\n\\n    def _process_file(self, file_path: str) -> ModuleModelBuilder | None:\\n        \\\"\\\"\\\"Processes a single Python file.\\\"\\\"\\\"\\n\\n        file_path_obj = Path(file_path)\\n        root = str(file_path_obj.parent)\\n        self.directory_modules.setdefault(root, []).append(file_path_obj.name)\\n        return self._parse_file(file_path)\\n\\n    @logging_decorator(message=\\\"Processing file\\\")\\n    def _parse_file(self, file_path: str) -> ModuleModelBuilder | None:\\n        \\\"\\\"\\\"Parses a Python file and saves the parsed data as JSON.\\\"\\\"\\\"\\n\\n        parser = PythonParser(file_path)\\n        code: str = parser.open_file()\\n        module_model_builder: ModuleModelBuilder | None = parser.parse(code)\\n\\n        return module_model_builder\\n\\n    def _build_module_model(\\n        self, visitor_stack: ModuleModelBuilder | None\\n    ) -> ModuleModel:\\n        \\\"\\\"\\\"\\n        Builds a module model from the provided module builder.\\n\\n        Args:\\n            visitor_stack (ModuleModelBuilder): The module builder to build the model from.\\n\\n        Returns:\\n            ModuleModel: A structured module model.\\n\\n        Example:\\n            >>> module_model = python_parser.build_module_model(visitor_stack)\\n            # Builds a module model from the provided module builder.\\n        \\\"\\\"\\\"\\n\\n        if not isinstance(visitor_stack, ModuleModelBuilder):\\n            raise TypeError(\\\"Expected the first builder to be a ModuleModelBuilder\\\")\\n\\n        return visitor_stack.build()\\n\\n, \\nfrom logging import Logger\\nfrom openai import OpenAI\\n        \",\"children\":[{\"class_name\":\"GraphDBUpdater\",\"decorators\":null,\"bases\":null,\"docstring\":null,\"keywords\":null,\"id\":\"postcode:updaters:graph_db_updater.py__*__MODULE__*__CLASS-GraphDBUpdater\",\"parent_id\":\"postcode:updaters:graph_db_updater.py__*__MODULE\",\"block_type\":\"CLASS\",\"start_line_num\":22,\"end_line_num\":96,\"code_content\":\"\\n\\nclass GraphDBUpdater:\\n    def __init__(\\n        self,\\n        directory: str,\\n        output_directory: str,\\n        logger: Logger,\\n        arango_connector: ArangoDBConnector = ArangoDBConnector(),\\n    ) -> None:\\n        self.directory: str = directory\\n        self.output_directory: str = output_directory\\n        self.logger: Logger = logger\\n        self.arango_connector: ArangoDBConnector = arango_connector\\n\\n        self.arango_connector.delete_all_collections()\\n        self.arango_connector.ensure_collections()\\n        self.graph_manager = ArangoDBManager(arango_connector)\\n\\n    def update_all(\\n        self,\\n        directory: str,\\n        output_directory: str,\\n        logger: Logger,\\n    ) -> ChromaSetupReturnContext:\\n        logger.info(\\\"Starting the directory parsing.\\\")\\n\\n        visitor_manager = VisitorManager(directory, output_directory)\\n        process_files_return: VisitorManagerProcessFilesReturn = (\\n            visitor_manager.process_files()\\n        )\\n\\n        module_models_tuple: tuple[ModuleModel, ...] = process_files_return.models_tuple\\n        module_ids: list[str] = [model.id for model in module_models_tuple]\\n        directory_modules: dict[str, list[str]] = process_files_return.directory_modules\\n        self.graph_manager.upsert_models(\\n            list(module_models_tuple)\\n        ).process_imports_and_dependencies().get_or_create_graph()\\n        summarization_mapper = SummarizationMapper(\\n            module_ids, module_models_tuple, self.graph_manager\\n        )\\n        client = OpenAI(max_retries=4)\\n        summarizer = OpenAISummarizer(client=client)\\n        summarization_manager = GraphDBSummarizationManager(\\n            module_models_tuple, summarization_mapper, summarizer, self.graph_manager\\n        )\\n        finalized_module_models: list[\\n            ModuleModel\\n        ] | None = summarization_manager.create_summaries_and_return_updated_models()\\n        logger.info(\\\"Summarization complete\\\")\\n\\n        logger.info(\\\"Saving models as JSON\\\")\\n        json_manager = JSONHandler(directory, directory_modules, output_directory)\\n\\n        for module_model in module_models_tuple:\\n            json_manager.save_model_as_json(module_model, module_model.file_path)\\n\\n        json_manager.save_visited_directories()\\n        logger.info(\\\"JSON save complete\\\")\\n\\n        logger.info(\\\"Directory parsing completed.\\\")\\n\\n        # self.graph_manager.upsert_models(\\n        #     list(finalized_module_models)\\n        # ).process_imports_and_dependencies().get_or_create_graph()\\n\\n        if finalized_module_models:\\n            chroma_context: ChromaSetupReturnContext = setup_chroma(\\n                finalized_module_models, logger\\n            )\\n        else:\\n            raise Exception(\\\"No finalized models returned from summarization.\\\")\\n\\n        return chroma_context\\n\",\"important_comments\":null,\"dependencies\":[{\"import_names\":[{\"name\":\"VisitorManager\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"VisitorManagerProcessFilesReturn\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"postcode.python_parser.visitor_manager.visitor_manager\",\"import_module_type\":\"LOCAL\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"VisitorManager\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"VisitorManagerProcessFilesReturn\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"postcode.python_parser.visitor_manager.visitor_manager\",\"import_module_type\":\"LOCAL\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"Logger\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"logging\",\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"OpenAI\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"openai\",\"import_module_type\":\"THIRD_PARTY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"GraphDBSummarizationManager\",\"as_name\":null,\"local_block_id\":\"postcode:ai_services:summarizer:graph_db_summarization_manager.py__*__MODULE__*__CLASS-GraphDBSummarizationManager\"}],\"imported_from\":\"postcode.ai_services.summarizer.graph_db_summarization_manager\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:ai_services:summarizer:graph_db_summarization_manager.py__*__MODULE\"},{\"import_names\":[{\"name\":\"OpenAISummarizer\",\"as_name\":null,\"local_block_id\":\"postcode:ai_services:summarizer:openai_summarizer.py__*__MODULE__*__CLASS-OpenAISummarizer\"}],\"imported_from\":\"postcode.ai_services.summarizer.openai_summarizer\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:ai_services:summarizer:openai_summarizer.py__*__MODULE\"},{\"import_names\":[{\"name\":\"SummarizationMapper\",\"as_name\":null,\"local_block_id\":\"postcode:ai_services:summarizer:summarization_mapper.py__*__MODULE__*__CLASS-SummarizationMapper\"}],\"imported_from\":\"postcode.ai_services.summarizer.summarization_mapper\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:ai_services:summarizer:summarization_mapper.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ArangoDBConnector\",\"as_name\":null,\"local_block_id\":\"postcode:databases:arangodb:arangodb_connector.py__*__MODULE__*__CLASS-ArangoDBConnector\"}],\"imported_from\":\"postcode.databases.arangodb.arangodb_connector\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:databases:arangodb:arangodb_connector.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ArangoDBManager\",\"as_name\":null,\"local_block_id\":\"postcode:databases:arangodb:arangodb_manager.py__*__MODULE__*__CLASS-ArangoDBManager\"}],\"imported_from\":\"postcode.databases.arangodb.arangodb_manager\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:databases:arangodb:arangodb_manager.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ChromaSetupReturnContext\",\"as_name\":null,\"local_block_id\":\"postcode:databases:chroma:setup_chroma.py__*__MODULE__*__CLASS-ChromaSetupReturnContext\"},{\"name\":\"setup_chroma\",\"as_name\":null,\"local_block_id\":\"postcode:databases:chroma:setup_chroma.py__*__MODULE__*__FUNCTION-setup_chroma\"}],\"imported_from\":\"postcode.databases.chroma.setup_chroma\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:databases:chroma:setup_chroma.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ChromaSetupReturnContext\",\"as_name\":null,\"local_block_id\":\"postcode:databases:chroma:setup_chroma.py__*__MODULE__*__CLASS-ChromaSetupReturnContext\"},{\"name\":\"setup_chroma\",\"as_name\":null,\"local_block_id\":\"postcode:databases:chroma:setup_chroma.py__*__MODULE__*__FUNCTION-setup_chroma\"}],\"imported_from\":\"postcode.databases.chroma.setup_chroma\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:databases:chroma:setup_chroma.py__*__MODULE\"},{\"import_names\":[{\"name\":\"JSONHandler\",\"as_name\":null,\"local_block_id\":\"postcode:json_management:json_handler.py__*__MODULE__*__CLASS-JSONHandler\"}],\"imported_from\":\"postcode.json_management.json_handler\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:json_management:json_handler.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"}],\"summary\":null,\"children\":[{\"function_name\":\"__init__\",\"docstring\":null,\"decorators\":null,\"parameters\":null,\"returns\":\"None\",\"is_method\":true,\"is_async\":false,\"id\":\"postcode:updaters:graph_db_updater.py__*__MODULE__*__CLASS-GraphDBUpdater__*__FUNCTION-__init__\",\"parent_id\":\"postcode:updaters:graph_db_updater.py__*__MODULE__*__CLASS-GraphDBUpdater\",\"block_type\":\"FUNCTION\",\"start_line_num\":25,\"end_line_num\":40,\"code_content\":\"def __init__(\\n    self,\\n    directory: str,\\n    output_directory: str,\\n    logger: Logger,\\n    arango_connector: ArangoDBConnector = ArangoDBConnector(),\\n) -> None:\\n    self.directory: str = directory\\n    self.output_directory: str = output_directory\\n    self.logger: Logger = logger\\n    self.arango_connector: ArangoDBConnector = arango_connector\\n\\n    self.arango_connector.delete_all_collections()\\n    self.arango_connector.ensure_collections()\\n    self.graph_manager = ArangoDBManager(arango_connector)\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":null,\"children\":null},{\"function_name\":\"update_all\",\"docstring\":null,\"decorators\":null,\"parameters\":null,\"returns\":\"ChromaSetupReturnContext\",\"is_method\":true,\"is_async\":false,\"id\":\"postcode:updaters:graph_db_updater.py__*__MODULE__*__CLASS-GraphDBUpdater__*__FUNCTION-update_all\",\"parent_id\":\"postcode:updaters:graph_db_updater.py__*__MODULE__*__CLASS-GraphDBUpdater\",\"block_type\":\"FUNCTION\",\"start_line_num\":40,\"end_line_num\":96,\"code_content\":\"\\ndef update_all(\\n    self,\\n    directory: str,\\n    output_directory: str,\\n    logger: Logger,\\n) -> ChromaSetupReturnContext:\\n    logger.info(\\\"Starting the directory parsing.\\\")\\n\\n    visitor_manager = VisitorManager(directory, output_directory)\\n    process_files_return: VisitorManagerProcessFilesReturn = (\\n        visitor_manager.process_files()\\n    )\\n\\n    module_models_tuple: tuple[ModuleModel, ...] = process_files_return.models_tuple\\n    module_ids: list[str] = [model.id for model in module_models_tuple]\\n    directory_modules: dict[str, list[str]] = process_files_return.directory_modules\\n    self.graph_manager.upsert_models(\\n        list(module_models_tuple)\\n    ).process_imports_and_dependencies().get_or_create_graph()\\n    summarization_mapper = SummarizationMapper(\\n        module_ids, module_models_tuple, self.graph_manager\\n    )\\n    client = OpenAI(max_retries=4)\\n    summarizer = OpenAISummarizer(client=client)\\n    summarization_manager = GraphDBSummarizationManager(\\n        module_models_tuple, summarization_mapper, summarizer, self.graph_manager\\n    )\\n    finalized_module_models: list[\\n        ModuleModel\\n    ] | None = summarization_manager.create_summaries_and_return_updated_models()\\n    logger.info(\\\"Summarization complete\\\")\\n\\n    logger.info(\\\"Saving models as JSON\\\")\\n    json_manager = JSONHandler(directory, directory_modules, output_directory)\\n\\n    for module_model in module_models_tuple:\\n        json_manager.save_model_as_json(module_model, module_model.file_path)\\n\\n    json_manager.save_visited_directories()\\n    logger.info(\\\"JSON save complete\\\")\\n\\n    logger.info(\\\"Directory parsing completed.\\\")\\n\\n    # self.graph_manager.upsert_models(\\n    #     list(finalized_module_models)\\n    # ).process_imports_and_dependencies().get_or_create_graph()\\n\\n    if finalized_module_models:\\n        chroma_context: ChromaSetupReturnContext = setup_chroma(\\n            finalized_module_models, logger\\n        )\\n    else:\\n        raise Exception(\\\"No finalized models returned from summarization.\\\")\\n\\n    return chroma_context\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":null,\"children\":null}]}]}", "chroma:document": "\nSummary:\n\n        postcode:updaters:graph_db_updater.py__*__MODULE\n\n        \nChild (postcode:updaters:graph_db_updater.py__*__MODULE__*__CLASS-GraphDBUpdater) code content:\n\n\nclass GraphDBUpdater:\n    def __init__(\n        self,\n        directory: str,\n        output_directory: str,\n        logger: Logger,\n        arango_connector: ArangoDBConnector = ArangoDBConnector(),\n    ) -> None:\n        self.directory: str = directory\n        self.output_directory: str = output_directory\n        self.logger: Logger = logger\n        self.arango_connector: ArangoDBConnector = arango_connector\n\n        self.arango_connector.delete_all_collections()\n        self.arango_connector.ensure_collections()\n        self.graph_manager = ArangoDBManager(arango_connector)\n\n    def update_all(\n        self,\n        directory: str,\n        output_directory: str,\n        logger: Logger,\n    ) -> ChromaSetupReturnContext:\n        logger.info(\"Starting the directory parsing.\")\n\n        visitor_manager = VisitorManager(directory, output_directory)\n        process_files_return: VisitorManagerProcessFilesReturn = (\n            visitor_manager.process_files()\n        )\n\n        module_models_tuple: tuple[ModuleModel, ...] = process_files_return.models_tuple\n        module_ids: list[str] = [model.id for model in module_models_tuple]\n        directory_modules: dict[str, list[str]] = process_files_return.directory_modules\n        self.graph_manager.upsert_models(\n            list(module_models_tuple)\n        ).process_imports_and_dependencies().get_or_create_graph()\n        summarization_mapper = SummarizationMapper(\n            module_ids, module_models_tuple, self.graph_manager\n        )\n        client = OpenAI(max_retries=4)\n        summarizer = OpenAISummarizer(client=client)\n        summarization_manager = GraphDBSummarizationManager(\n            module_models_tuple, summarization_mapper, summarizer, self.graph_manager\n        )\n        finalized_module_models: list[\n            ModuleModel\n        ] | None = summarization_manager.create_summaries_and_return_updated_models()\n        logger.info(\"Summarization complete\")\n\n        logger.info(\"Saving models as JSON\")\n        json_manager = JSONHandler(directory, directory_modules, output_directory)\n\n        for module_model in module_models_tuple:\n            json_manager.save_model_as_json(module_model, module_model.file_path)\n\n        json_manager.save_visited_directories()\n        logger.info(\"JSON save complete\")\n\n        logger.info(\"Directory parsing completed.\")\n\n        # self.graph_manager.upsert_models(\n        #     list(finalized_module_models)\n        # ).process_imports_and_dependencies().get_or_create_graph()\n\n        if finalized_module_models:\n            chroma_context: ChromaSetupReturnContext = setup_chroma(\n                finalized_module_models, logger\n            )\n        else:\n            raise Exception(\"No finalized models returned from summarization.\")\n\n        return chroma_context\n\n, \nImported code block (postcode:ai_services:summarizer:graph_db_summarization_manager.py__*__MODULE) code content:\n# FIXME: This file is not currently being used. It is a work in progress as the summarization mapper isn't getting returning all of the project models.\n\nimport logging\nfrom pprint import pprint\nfrom typing import Union\n\nfrom postcode.ai_services.summarizer.summarization_context import (\n    Summarizer,\n    OpenAIReturnContext,\n)\nfrom postcode.ai_services.summarizer.summarization_mapper import SummarizationMapper\nfrom postcode.databases.arangodb.arangodb_manager import ArangoDBManager\n\n# from postcode.types.postcode import ModelType\n\nfrom postcode.models.models import (\n    ClassModel,\n    DependencyModel,\n    FunctionModel,\n    ImportModel,\n    ModuleModel,\n    StandaloneCodeBlockModel,\n)\n\nModelType = Union[\n    ModuleModel,\n    ClassModel,\n    FunctionModel,\n    StandaloneCodeBlockModel,\n]\n\n\nclass GraphDBSummarizationManager:\n    def __init__(\n        self,\n        module_models_tuple: tuple[ModuleModel, ...],\n        summarization_mapper: SummarizationMapper,\n        summarizer: Summarizer,\n        graph_manager: ArangoDBManager,\n    ) -> None:\n        self.module_models_tuple: tuple[ModuleModel, ...] = module_models_tuple\n        self.summarization_mapper: SummarizationMapper = summarization_mapper\n        self.summarizer: Summarizer = summarizer\n        self.summarized_code_block_ids: set[str] = set()\n        self.prompt_tokens: int = 0\n        self.completion_tokens: int = 0\n        self.graph_manager: ArangoDBManager = graph_manager\n\n    @property\n    def total_cost(self) -> float:\n        \"\"\"Provides the total cost of the summarization process.\"\"\"\n        prompt_cost: int = self.prompt_tokens * 1  # Costs 1 cent per 1,000 tokens\n        completion_cost: int = (\n            self.completion_tokens * 3\n        )  # Costs 3 cents per 1,000 tokens\n        return (prompt_cost + completion_cost) / 100_000  # Convert to dollars\n\n    def create_summaries_and_return_updated_models(self) -> list[ModuleModel] | None:\n        summarization_map: list[\n            ModelType\n        ] = self.summarization_mapper.create_summarization_map()\n        models_to_summarize_count: int = len(summarization_map)\n        models_summarized_count: int = 0\n\n        for model in summarization_map:\n            children_summaries: str | None = None\n            dependency_summaries: str | None = None\n            import_details: str | None = None\n\n            if model.children:\n                children_summaries: str | None = self._stringify_children_summaries(\n                    self._get_child_summaries(model)\n                )\n            if isinstance(model, ModuleModel):\n                if model.imports:\n                    dependency_summaries = self._get_dependencies_summaries(model)\n                    import_details = \"\"\n                    for _import in model.imports:\n                        if import_summary := self._get_import_details(_import):\n                            import_details += f\"\\n{import_summary}\"\n            else:\n                if model.dependencies:\n                    dependency_summaries = self._get_dependencies_summaries(model)\n                    import_details = \"\"\n                    for dependency in model.dependencies:\n                        if isinstance(dependency, DependencyModel):\n                            continue\n                        if import_summary := self._get_import_details(dependency):\n                            import_details += f\"\\n{import_summary}\"\n\n            models_summarized_count += 1\n            logging.info(\n                f\"Summarizing model {models_summarized_count} out of {models_to_summarize_count}; {model.id}.\"\n            )\n\n            summary_return_context: OpenAIReturnContext | None = (\n                self.summarizer.test_summarize_code(\n                    model.code_content,\n                    model_id=model.id,\n                    children_summaries=children_summaries,\n                    dependency_summaries=dependency_summaries,\n                    import_details=import_details,\n                )\n            )\n            if summary_return_context:\n                if summary_return_context.summary:\n                    self.graph_manager.update_vertex_by_id(\n                        model.id, summary_return_context.summary\n                    )\n                self.prompt_tokens += summary_return_context.prompt_tokens\n                self.completion_tokens += summary_return_context.completion_tokens\n\n                # for module_model in self.module_models_tuple:\n                #     if isinstance(model, ModuleModel):\n                #         if module_model.id == model.id:\n                #             module_model.summary = model.summary\n                #             break\n                #         else:\n                #             continue\n                #     else:\n                #         module_id_for_model: str = model.id.split(\"MODULE\")[0]\n                #         if (\n                #             module_model.children\n                #             and module_id_for_model in module_model.id\n                #         ):\n                #             for child_model in module_model.children:\n                #                 if child_model.id == model.id:\n                #                     # child_model.summary = model.summary\n                #                     break\n                #         else:\n                #             continue\n\n        pprint([model.id for model in summarization_map[::-1]])\n        print(len(summarization_map))\n\n        return self.graph_manager.get_all_modules() if self.graph_manager else None\n\n    def _get_child_summaries(self, model: ModelType) -> list[str]:\n        \"\"\"Gathers summaries of child models.\"\"\"\n        child_summary_list: list[str] = []\n        if model.children:\n            for child in model.children:\n                if child.summary:\n                    child_summary: str = child.summary\n                else:\n                    child_summary = (\n                        f\"Child ({child.id}) code content:\\n{child.code_content}\\n\"\n                    )\n                child_summary_list.append(child_summary)\n        return child_summary_list\n\n    def _stringify_children_summaries(self, children_summary_list: list[str]) -> str:\n        \"\"\"Converts all of the child summaries to a single string to be used in the prompt.\"\"\"\n\n        children_summaries: str = \"\"\n        for child_summary in children_summary_list:\n            children_summaries += f\"\\n{child_summary}\"\n        return children_summaries\n\n    def _get_dependencies_summaries(self, model: ModelType) -> str | None:\n        dependency_list: list[ImportModel | DependencyModel] | list[ImportModel] = []\n        dependency_summary_list: list[str] = []\n\n        if isinstance(model, ModuleModel):\n            if not model.imports:\n                return None\n\n            dependency_list = model.imports\n        else:\n            if not model.dependencies:\n                return None\n\n            dependency_list = model.dependencies\n        for dependency in dependency_list:\n            if isinstance(dependency, DependencyModel) and dependency.code_block_id:\n                if module_local_dependency_summary := self._get_local_dependency_summary(\n                    dependency, model\n                ):\n                    dependency_summary_list.append(module_local_dependency_summary)\n\n            elif isinstance(dependency, ImportModel):\n                if dependency.import_module_type == \"LOCAL\":\n                    if not dependency.import_names:\n                        if module_import_dependency := self._get_local_import_summary(\n                            dependency\n                        ):\n                            dependency_summary_list.append(module_import_dependency)\n                    else:\n                        if import_from_dependency := self._get_local_import_from_summary(\n                            dependency\n                        ):\n                            dependency_summary_list.append(import_from_dependency)\n\n        dependency_summaries = self._stringify_dependencies_summaries(\n            dependency_summary_list\n        )\n\n        return dependency_summaries\n\n    # def _get_import_details_for_dependencies(\n    #     self, dependencies: list[ImportModel | DependencyModel]\n    # ) -> str | None:\n    #     import_details: str | None = None\n    #     for dependency in dependencies:\n    #         if isinstance(dependency, ImportModel):\n    #             if dependency.import_module_type == \"LOCAL\":\n    #                 continue\n    #             else:\n    #                 import_detail: str | None = self._get_import_details(dependency)\n    #                 if not import_detail:\n    #                     continue\n    #                 if not import_details:\n    #                     import_details = \"\"\n    #                 import_details += f\"\\n{import_detail}\"\n    #     return import_details\n\n    def _get_local_dependency_summary(\n        self,\n        dependency: DependencyModel,\n        model: ModelType,\n    ) -> str | None:\n        \"\"\"Gets a summary for a dependency local to the module.\"\"\"\n        if not model.children:\n            return None\n\n        for child_model in model.children:\n            if child_model.id == dependency.code_block_id:\n                child_summary: str | None = None\n\n                if child_model.summary:\n                    child_summary = child_model.summary\n                else:\n                    child_summary = f\"Dependency ({dependency.code_block_id}) code content:\\n{child_model.code_content}\\n\"\n\n                return child_summary\n        return None\n\n    def _stringify_dependencies_summaries(\n        self, dependencies_summary_list: list[str] | None\n    ) -> str | None:\n        \"\"\"Converts all of the dependency summaries to a single string to be used in the prompt.\"\"\"\n        if not dependencies_summary_list:\n            return None\n\n        dependency_summaries: str = \"\"\n        for dependency_summary in dependencies_summary_list:\n            dependency_summaries += f\"\\n{dependency_summary}\"\n        return dependency_summaries\n\n    def _get_local_import_summary(self, dependency: ImportModel) -> str | None:\n        for module_model in self.module_models_tuple:\n            if module_model.id == dependency.local_module_id:\n                import_summary: str | None = None\n                if module_model.summary:\n                    import_summary = module_model.summary\n                else:\n                    import_summary = f\"Imported module ({dependency.local_module_id}) code content:\\n{module_model.code_content}\\n\"\n                return import_summary\n        return None\n\n    def _get_local_import_from_summary(self, dependency: ImportModel) -> str | None:\n        for import_name in dependency.import_names:\n            for module_model in self.module_models_tuple:\n                if module_model.id == dependency.local_module_id:\n                    if module_model.children:\n                        for child_model in module_model.children:\n                            if (\n                                child_model.id == import_name.local_block_id\n                                and child_model.id\n                            ):\n                                import_summary: str | None = None\n                                if child_model.summary:\n                                    import_summary = child_model.summary\n                                else:\n                                    import_summary = f\"Imported code block ({dependency.local_module_id}) code content:\\n{module_model.code_content}\\n\"\n                                return import_summary\n        return None\n\n    def _get_import_details(self, import_model: ImportModel) -> str | None:\n        \"\"\"Retrieves details of import statements to be used in the prompt.\"\"\"\n        if import_model.import_module_type == \"LOCAL\" or not import_model.import_names:\n            return None\n\n        import_names_list: list[str] = []\n        for import_name in import_model.import_names:\n            if import_name.as_name:\n                import_names_list.append(f\"{import_name.name} as {import_name.as_name}\")\n            else:\n                import_names_list.append(f\"{import_name.name}\")\n\n        if import_model.imported_from:\n            import_details: str = f\"from {import_model.imported_from} import {', '.join(import_names_list)}\"\n        else:\n            import_details = f\"import {', '.join(import_names_list)}\"\n\n        return import_details\n\n\nImported code block (postcode:ai_services:summarizer:openai_summarizer.py__*__MODULE) code content:\nimport logging\n\nfrom openai import OpenAI\nfrom openai.types.chat.chat_completion_system_message_param import (\n    ChatCompletionSystemMessageParam,\n)\nfrom openai.types.chat.chat_completion_user_message_param import (\n    ChatCompletionUserMessageParam,\n)\nfrom openai.types.chat.chat_completion_message_param import ChatCompletionMessageParam\nfrom openai.types.chat.chat_completion import ChatCompletion\n\nfrom postcode.ai_services.summarizer.prompts.prompt_creator import PromptCreator\nfrom postcode.ai_services.summarizer.summarization_context import (\n    OpenAIReturnContext,\n    SummaryCompletionConfigs,\n)\n\n# from postcode.ai_services.summarizer.temp import code_example\n\n\nclass OpenAISummarizer:\n    \"\"\"\n    A class for summarizing code snippets using the OpenAI API.\n\n    Args:\n        - client (OpenAI): The OpenAI client used for making API requests.\n\n    Attributes:\n        - client (OpenAI): The OpenAI client used for making API requests.\n        - prompt_list (list[str]): A list of summary prompts.\n        - default_prompt (str): The default summary prompt.\n\n    Methods:\n        - `summarize_code`: Summarizes the provided code snippet using the OpenAI API.\n\n    Examples:\n        ```Python\n        client = OpenAI()\n\n        # Create a summarizer instance with the OpenAI client\n        summarizer = Summarizer(client=client)\n        code_example = \"print('Hello, world')\"\n\n        # Summarize the code snippet\n        summary = summarizer.summarize_code(code_example)\n        print(summary)\n        ```\n    \"\"\"\n\n    def __init__(\n        self,\n        client: OpenAI,\n        # *, summary_prompt_list: list[str] = summary_prompt_list\n    ) -> None:\n        self.client: OpenAI = client\n        # self.prompt_list: list[str] = summary_prompt_list\n        # self.default_prompt: str = self.prompt_list[0]\n\n    def _create_system_message(self, content: str) -> ChatCompletionSystemMessageParam:\n        \"\"\"Creates a system message for chat completion using OpenAi's ChatCompletionSystemMessageParam class.\"\"\"\n        return ChatCompletionSystemMessageParam(content=content, role=\"system\")\n\n    def _create_user_message(self, content: str) -> ChatCompletionUserMessageParam:\n        \"\"\"Creates a user message for chat completion using OpenAi's ChatCompletionUserMessageParam class.\"\"\"\n        return ChatCompletionUserMessageParam(content=content, role=\"user\")\n\n    def _create_messages_list(\n        self,\n        system_message: str,\n        user_message: str,\n    ) -> list[ChatCompletionMessageParam]:\n        \"\"\"\n        Creates a list of messages for chat completion, including both system and user messages.\n\n        Args:\n            - system_message (str): The system message content.\n            - user_message (str): The user message content.\n\n        Returns:\n            - list[ChatCompletionMessageParam]: A list containing the system and user messages as OpenAI's\n                ChatCompletionMessageParam classes.\n        \"\"\"\n\n        return [\n            self._create_system_message(system_message),\n            self._create_user_message(user_message),\n        ]\n\n    def _create_prompt(\n        self,\n        code: str,\n        children_summaries: str | None,\n        dependency_summaries: str | None,\n        import_details: str | None,\n    ) -> str:\n        prompt_creator: PromptCreator = PromptCreator()\n        prompt: str | None = prompt_creator.create_prompt(\n            code,\n            children_summaries,\n            dependency_summaries,\n            import_details,\n        )\n\n        if prompt:\n            return prompt\n        else:\n            raise Exception(\"Prompt creation failed.\")\n\n    def _get_summary(\n        self,\n        messages: list[ChatCompletionMessageParam],\n        *,\n        configs: SummaryCompletionConfigs,\n    ) -> OpenAIReturnContext | None:\n        \"\"\"\n        Retrieves the summary from the OpenAI API based on the provided messages and configuration settings.\n\n        Args:\n            - messages (list[ChatCompletionMessageParam]): A list of messages for chat completion.\n            - configs (SummaryCompletionConfigs): Configuration settings for the summarization completion.\n\n        Returns:\n            str | None: The summary generated by the OpenAI API, or None if no summary is found.\n        \"\"\"\n\n        try:\n            response: ChatCompletion = self.client.chat.completions.create(\n                messages=messages,\n                model=configs.model,\n                max_tokens=configs.max_tokens,\n                temperature=configs.temperature,\n            )\n            prompt_tokens: int = 0\n            completion_tokens: int = 0\n            summary: str | None = response.choices[0].message.content\n            if response.usage:\n                prompt_tokens = response.usage.prompt_tokens\n                completion_tokens = response.usage.completion_tokens\n\n            return OpenAIReturnContext(\n                prompt_tokens=prompt_tokens,\n                completion_tokens=completion_tokens,\n                summary=summary,\n            )\n\n        except Exception as e:\n            logging.error(e)\n            return None\n\n    def summarize_code(\n        self,\n        code: str,\n        *,\n        model_id: str,\n        children_summaries: str | None,\n        dependency_summaries: str | None,\n        import_details: str | None,\n        configs: SummaryCompletionConfigs = SummaryCompletionConfigs(),\n    ) -> OpenAIReturnContext | None:\n        \"\"\"\n        Summarizes the provided code snippet using the OpenAI API.\n\n        Args:\n            - code (str): The code snippet to summarize.\n            - configs (SummaryCompletionConfigs, optional): Configuration settings for the summarization.\n                Defaults to SummaryCompletionConfigs().\n\n        Returns:\n            - str: The summary of the provided code snippet.\n\n        Examples:\n            ```Python\n            client = OpenAI()\n\n            # Create a summarizer instance with the OpenAI client\n            summarizer = Summarizer(client=client)\n            code_example = \"print('Hello, world')\"\n\n            # Summarize the code snippet\n            summary = summarizer.summarize_code(code_example)\n            print(summary)\n            ```\n        \"\"\"\n\n        logging.info(f\"Summarizing code for model: {model_id}\")\n        prompt: str = self._create_prompt(\n            code, children_summaries, dependency_summaries, import_details\n        )\n        messages: list[ChatCompletionMessageParam] = self._create_messages_list(\n            system_message=configs.system_message, user_message=prompt\n        )\n\n        if summary_return_context := self._get_summary(messages, configs=configs):\n            if summary_return_context:\n                if summary_return_context.summary:\n                    summary_return_context.summary = (\n                        summary_return_context.summary.split(\"FINAL SUMMARY:\")[-1]\n                    )\n                    return summary_return_context\n        return None\n\n    def test_summarize_code(\n        self,\n        code: str,\n        *,\n        model_id: str,\n        children_summaries: str | None,\n        dependency_summaries: str | None,\n        import_details: str | None,\n        configs: SummaryCompletionConfigs = SummaryCompletionConfigs(),\n    ) -> OpenAIReturnContext | None:\n        \"\"\"\n        Summarizes the provided code snippet using the OpenAI API.\n\n        Args:\n            - code (str): The code snippet to summarize.\n            - configs (SummaryCompletionConfigs, optional): Configuration settings for the summarization.\n                Defaults to SummaryCompletionConfigs().\n\n        Returns:\n            - str: The summary of the provided code snippet.\n        \"\"\"\n\n        summary = f\"\"\"\\nSummary:\\n\n        {model_id}\\n\n        {children_summaries}, {dependency_summaries}, {import_details}\n        \"\"\"\n        summary_context = OpenAIReturnContext(\n            summary=summary,\n            prompt_tokens=1,\n            completion_tokens=1,\n        )\n\n        return summary_context\n\n\n# if __name__ == \"__main__\":\n#     client = OpenAI()\n#     summarizer = OpenAISummarizer(client=client)\n#     children_summaries = \"\"\n#     dependency_summaries = \"\"\n#     summary = summarizer.summarize_code(\n#         code_example,\n#         model_id=\"test\",\n#         children_summaries=children_summaries,\n#         dependency_summaries=dependency_summaries,\n#         import_details=None,\n#     )\n#     print(summary)\n\n\nImported code block (postcode:ai_services:summarizer:summarization_mapper.py__*__MODULE) code content:\nimport logging\nfrom pprint import pprint\nfrom typing import Union\nfrom postcode.databases.arangodb.arangodb_manager import ArangoDBManager\nfrom postcode.models.models import (\n    ClassModel,\n    FunctionModel,\n    ModuleModel,\n    StandaloneCodeBlockModel,\n)\n\n# from postcode.types.postcode import ModelType\n\nModelType = Union[\n    ModuleModel,\n    ClassModel,\n    FunctionModel,\n    StandaloneCodeBlockModel,\n]\n\n\nclass SummarizationMapper:\n    def __init__(\n        self,\n        module_ids_to_update: list[str],\n        module_models: tuple[ModuleModel, ...],\n        arangodb_manager: ArangoDBManager,\n    ) -> None:\n        self.module_ids_to_update: list[str] = module_ids_to_update\n        self.module_models: tuple[ModuleModel, ...] = module_models\n        self.arangodb_manager: ArangoDBManager = arangodb_manager\n        self.models_to_update: list[ModelType] = []\n        self.model_visited_in_db: set[str] = set()\n        self.summarization_map: list[ModelType] = []\n        self.temp_map: list[ModelType] = []\n\n    def _set_child_models_to_update(self, model: ModelType) -> None:\n        if model.children:\n            for child in model.children:\n                # logging.info(f\"Setting child model to update: {child.id}\")\n                self._set_child_models_to_update(child)\n                child.summary = None\n                self.models_to_update.append(child)\n            self.models_to_update.append(model)\n\n    def _set_models_to_update(self) -> None:\n        for model in self.module_models:\n            if model.id in self.module_ids_to_update:\n                if model.children:\n                    for child in model.children:\n                        self._set_child_models_to_update(child)\n\n                model.summary = None\n                self.models_to_update.append(model)\n\n    def _set_inbound_models_in_summarization_map(self, model_id: str) -> None:\n        if model_id in self.model_visited_in_db:\n            return\n        self.model_visited_in_db.add(model_id)\n        if inbound_models := self.arangodb_manager.get_inbound_models(model_id):\n            for model in inbound_models:\n                # logging.info(f\"Setting inbound models in summarization map: {model.id}\")\n                self.model_visited_in_db.add(model_id)\n                self._set_inbound_models_in_summarization_map(model.id)\n\n                self.temp_map.append(model)\n\n    def _set_outbound_models_in_summarization_map(self, model_id: str) -> None:\n        if model_id in self.model_visited_in_db:\n            return\n\n        if outbound_models := self.arangodb_manager.get_outbound_models(model_id):\n            for model in outbound_models[::-1]:\n                # logging.info(\n                #     f\"Setting outbound models in summarization map: {model.id}\"\n                # )\n                self.model_visited_in_db.add(model_id)\n                # self._set_outbound_models_in_summarization_map(model.id)``\n\n                if model.id in self.models_to_update:\n                    model.summary = None\n                self.temp_map.append(model)\n\n    def create_summarization_map(self) -> list[ModelType]:\n        self._set_models_to_update()\n        logging.info(\"Set models to update\")\n\n        # pprint([model.id for model in self.models_to_update])\n\n        for model in self.models_to_update:\n            # self.model_visited_in_db = set()\n            # logging.info(f\"Setting inbound models in summarization map: {model.id}\")\n            self._set_inbound_models_in_summarization_map(model.id)\n            self.temp_map.append(model)\n\n            self.model_visited_in_db.remove(model.id)\n            # logging.info(f\"Setting outbound models in summarization map: {model.id}\")\n            # self._set_outbound_models_in_summarization_map(model.id)\n            self.summarization_map.extend(self.temp_map)\n            self.temp_map = []\n\n        for model in self.models_to_update:\n            self.model_visited_in_db = set()\n            # logging.info(f\"Setting outbound models in summarization map: {model.id}\")\n            self._set_outbound_models_in_summarization_map(model.id)\n            self.summarization_map.extend(self.temp_map)\n            self.temp_map = []\n\n        logging.info(\"Created summarization map\")\n        summary_ids: set[str] = set()\n        summary_map: list[ModelType] = []\n        for model in self.summarization_map[::-1]:\n            if model.id not in summary_ids:\n                summary_map.append(model)\n                summary_ids.add(model.id)\n\n        # return summary_map[::-1]\n        pprint([model.id for model in summary_map[::-1]])\n        return summary_map[::-1]\n\n    # def old_create_summarization_map(self) -> list[list[ModelType]]:\n    #     for module_id in self.module_ids_to_update:\n    #         models_to_update: list[ModelType] = []\n\n    #         upstream_models: list[\n    #             ModelType\n    #         ] | None = self.arangodb_manager.get_all_upstream_vertices(module_id)\n    #         downstream_models: list[\n    #             ModelType\n    #         ] | None = self.arangodb_manager.get_all_downstream_vertices(module_id)\n\n    #         ids_from_db: list[str] = []\n    #         if upstream_models:\n    #             upstream_ids_to_update: list[str] = [\n    #                 model.id for model in upstream_models\n    #             ]\n    #             ids_from_db.extend(upstream_ids_to_update)\n\n    #         ids_from_db.append(module_id)\n\n    #         if downstream_models:\n    #             downstream_ids_to_update: list[str] = [\n    #                 model.id for model in downstream_models\n    #             ]\n    #             ids_from_db.extend(downstream_ids_to_update)\n\n    #         for id in ids_from_db:\n    #             for model in self.module_models:\n    #                 if model.id == id:\n    #                     models_to_update.append(model)\n    #                 elif model.children:\n    #                     for child in model.children:\n    #                         if child.id == id:\n    #                             models_to_update.append(child)\n\n    #         self.summarization_map.append(models_to_update)\n\n    #     return self.summarization_map\n\n\nImported code block (postcode:databases:arangodb:arangodb_connector.py__*__MODULE) code content:\nimport logging\nfrom typing import Any\nfrom arango.client import ArangoClient\nfrom arango.database import StandardDatabase\nfrom arango.result import Result\nfrom arango.typings import Jsons, Json\n\nimport postcode.databases.arangodb.helper_functions as helper_functions\n\n# from postcode.models import (\n#     ModuleModel,\n#     ClassModel,\n#     FunctionModel,\n#     StandaloneCodeBlockModel,\n# )\n\n\n# test = ArangoClient(hosts=\"http://localhost:8529\")\nclass ArangoDBConnector:\n    def __init__(\n        self,\n        url: str = \"http://localhost:8529\",\n        username: str = \"root\",\n        password: str = \"openSesame\",\n        db_name: str = \"postcode\",\n    ) -> None:\n        self.client = ArangoClient(hosts=url)\n        self.username: str = username\n        self.password: str = password\n        self.db_name: str = db_name\n        self.db: StandardDatabase = self._ensure_database()\n\n    def _ensure_database(self) -> StandardDatabase:\n        sys_db: StandardDatabase = self.client.db(\n            \"_system\", username=self.username, password=self.password\n        )\n        if not sys_db.has_database(self.db_name):\n            sys_db.create_database(self.db_name)\n        return self.client.db(\n            self.db_name, username=self.username, password=self.password\n        )\n\n    # def _ensure_vertex_collections(self, vertex_collections: list[str]) -> None:\n    #     for collection in vertex_collections:\n    #         if not self.db.has_collection(collection):\n    #             self.db.create_collection(collection)\n\n    def _get_current_schema(self, collection_name: str) -> dict:\n        collection = self.db.collection(collection_name)\n        try:\n            properties: Result[Json] = collection.properties()\n            return properties.get(\"schema\", {})  # type: ignore # FIXME: Fix type error\n        except Exception as e:\n            logging.error(f\"Error retrieving current schema for {collection_name}: {e}\")\n            return {}\n\n    def ensure_collection(\n        self, collection_name: str, schema: dict[str, Any] | None = None\n    ) -> None:\n        if not self.db.has_collection(collection_name) and not schema:\n            self.db.create_collection(collection_name)\n            logging.info(f\"Created collection: {collection_name}\")\n        # else:\n        #     current_schema = self._get_current_schema(collection_name)\n        #     self.db.collection(collection_name)\n        # if current_schema != schema:\n        #     collection = self.db.collection(collection_name)\n        #     try:\n        #         collection.configure(schema=schema)\n        #         logging.info(f\"Updated schema for collection: {collection_name}\")\n        #     except Exception as e:\n        #         logging.error(f\"Error updating schema for {collection_name}: {e}\")\n\n    def ensure_edge_collection(self, collection_name: str) -> None:\n        if not self.db.has_collection(collection_name):\n            self.db.create_collection(collection_name, edge=True)\n            logging.info(f\"Created edge collection: {collection_name}\")\n\n    def delete_all_collections(self) -> None:\n        collections: Result[Jsons] = self.db.collections()\n\n        for collection in collections:  # type: ignore # FIXME: Fix type error\n            if not collection[\"name\"].startswith(\"_\"):  # Skip system collections\n                self.db.delete_collection(collection[\"name\"])\n                logging.info(f\"Deleted collection: {collection['name']}\")\n\n    def ensure_collections(self) -> None:\n        # model_schemas: dict[str, dict[str, Any]] = self._get_model_schemas()\n        required_collections: list[\n            str\n        ] = helper_functions.pluralized_and_lowered_block_types()\n\n        for collection_name in required_collections:\n            # schema: dict[str, Any] = model_schemas[collection_name]\n            # self.ensure_collection(collection_name, schema)\n            self.ensure_collection(collection_name)\n\n        self.ensure_edge_collection(\"code_edges\")\n\n    # def _get_model_schemas(self) -> dict[str, dict[str, Any]]:\n    #     return {\n    #         \"modules\": ModuleModel.model_json_schema(),\n    #         \"classes\": ClassModel.model_json_schema(),\n    #         \"functions\": FunctionModel.model_json_schema(),\n    #         \"standalone_blocks\": StandaloneCodeBlockModel.model_json_schema(),\n    #     }\n\n\nImported code block (postcode:databases:arangodb:arangodb_manager.py__*__MODULE) code content:\nimport logging\nfrom typing import Any, Callable, Union\n\nfrom arango.result import Result\nfrom arango.cursor import Cursor\nfrom arango.graph import Graph\nfrom arango.collection import StandardCollection\nfrom arango.typings import Json\n\nfrom postcode.databases.arangodb.arangodb_connector import ArangoDBConnector\n\n# from postcode.types.postcode import ModelType\nfrom postcode.models.models import (\n    ClassModel,\n    FunctionModel,\n    ModuleModel,\n    StandaloneCodeBlockModel,\n)\nimport postcode.databases.arangodb.helper_functions as helper_functions\n\nModelType = Union[\n    ModuleModel,\n    ClassModel,\n    FunctionModel,\n    StandaloneCodeBlockModel,\n]\n\n# NOTE: Remember, when adding logic to connect dependencies, the `from` the external dependency `to` the internal definition using it\n\n\nclass ArangoDBManager:\n    def __init__(\n        self,\n        db_connector: ArangoDBConnector,\n        default_graph_name: str = \"codebase_graph\",\n    ) -> None:\n        self.db_connector: ArangoDBConnector = db_connector\n\n        self.processed_id_set = set()\n        self.default_graph_name: str = default_graph_name\n\n    def upsert_models(self, module_models: list[ModuleModel]) -> \"ArangoDBManager\":\n        for model in module_models:\n            self._upsert_model(model)\n        return self\n\n    def _upsert_model(self, module_model: ModuleModel) -> None:\n        self._upsert_vertex(module_model, \"modules\")\n        self._process_children(module_model)\n\n    def _process_children(self, parent_model: ModelType) -> None:\n        if not parent_model.children:\n            return None\n\n        for child in parent_model.children:\n            # if child.id in self.processed_id_set:\n            #     continue\n\n            self.processed_id_set.add(child.id)\n            self._upsert_vertex(\n                child, helper_functions.pluralize_block_type(child.block_type)\n            )\n\n            if child.children:\n                self._process_children(child)\n\n    def _upsert_vertex(self, model: ModelType, collection_name: str) -> None:\n        model_data: dict[str, Any] = model.model_dump()\n        model_data[\"_key\"] = model.id\n\n        try:\n            self.db_connector.ensure_collection(\n                collection_name, model.model_json_schema()\n            )\n            query: str = f\"\"\"\n            UPSERT {{_key: @key}}\n            INSERT @doc\n            UPDATE @doc\n            IN {collection_name}\n            \"\"\"\n            bind_vars: dict[str, Any] = {\"key\": model.id, \"doc\": model_data}\n            self.db_connector.db.aql.execute(query, bind_vars=bind_vars)\n\n            if not isinstance(model, ModuleModel) and model.parent_id:\n                parent_type: str = self._get_collection_from_id(model.parent_id)\n                self._upsert_edge(\n                    model.id, model.parent_id, collection_name, parent_type\n                )\n        except Exception as e:\n            logging.error(f\"Error upserting {collection_name} vertex (ArangoDB): {e}\")\n\n    def _upsert_edge(\n        self, from_key: str, to_key: str, source_type: str, target_type: str\n    ) -> None:\n        source_string: str = f\"{source_type}/{from_key}\"\n        target_string: str = f\"{target_type}/{to_key}\"\n\n        edge_data: dict[str, str] = {\n            \"_from\": source_string,\n            \"_to\": target_string,\n            \"source_type\": source_type,\n            \"target_type\": target_type,\n        }\n\n        try:\n            self.db_connector.ensure_edge_collection(\"code_edges\")\n            query = f\"\"\"\n            UPSERT {{_from: @from, _to: @to}}\n            INSERT @doc\n            UPDATE @doc\n            IN code_edges\n            \"\"\"\n            bind_vars = {\n                \"from\": edge_data[\"_from\"],\n                \"to\": edge_data[\"_to\"],\n                \"doc\": edge_data,\n            }\n            self.db_connector.db.aql.execute(query, bind_vars=bind_vars)\n        except Exception as e:\n            logging.error(f\"Error upserting edge (ArangoDB): {e}\")\n\n    def _get_collection_from_id(self, block_id: str) -> str:\n        block_id_parts: list[str] = block_id.split(\"__*__\")\n        block_type_part: str = block_id_parts[-1]\n\n        block_type_functions: dict[str, Callable[..., str]] = {\n            \"MODULE\": lambda: \"modules\",\n            \"CLASS\": lambda: \"classes\",\n            \"FUNCTION\": lambda: \"functions\",\n            \"STANDALONE_BLOCK\": lambda: \"standalone_blocks\",\n        }\n\n        for key, func in block_type_functions.items():\n            if block_type_part.startswith(key):\n                return func()\n\n        return \"unknown\"\n\n    def process_imports_and_dependencies(self) -> \"ArangoDBManager\":\n        for vertex_collection in helper_functions.pluralized_and_lowered_block_types():\n            cursor: Result[Cursor] = self.db_connector.db.collection(\n                vertex_collection\n            ).all()\n            if isinstance(cursor, Cursor):\n                for vertex in cursor:\n                    vertex_key = vertex[\"_key\"]\n                    if vertex_collection == \"modules\":\n                        self._create_edges_for_imports(\n                            vertex_key, vertex.get(\"imports\", [])\n                        )\n                    else:\n                        self._create_edges_for_dependencies(\n                            vertex_key, vertex.get(\"dependencies\", [])\n                        )\n            else:\n                logging.error(\n                    f\"Error getting cursor for vertex collection: {vertex_collection}\"\n                )\n        return self\n\n    def _create_edges_for_imports(\n        self, module_key: str, imports: list[dict[str, Any]]\n    ) -> None:\n        if not imports:\n            # logging.debug(f\"No imports found for module {module_key}\")\n            return\n\n        # logging.info(f\"Processing imports for module {module_key}\")\n\n        for _import in imports:\n            import_names: list[dict[str, str]] = _import.get(\"import_names\", [])\n            if not import_names:\n                # logging.debug(f\"No import names found in import {_import}\")\n                continue\n\n            for import_name in import_names:\n                local_block_id: str | None = import_name.get(\"local_block_id\")\n\n                if local_block_id:\n                    target_type = self._get_collection_from_id(local_block_id)\n                    try:\n                        self._upsert_edge(\n                            local_block_id, module_key, target_type, \"modules\"\n                        )\n\n                        # logging.info(\n                        #     f\"Upserted edge for import {module_key} to {local_block_id}\"\n                        # )\n                    except Exception as e:\n                        logging.error(\n                            f\"Error creating edge for import {module_key} to {local_block_id}: {e}\"\n                        )\n                else:\n                    # logging.warning(\n                    #     f\"Skipped import {import_name} in module {module_key}\"\n                    # )\n                    ...\n\n    def _create_edges_for_dependencies(\n        self, block_key: str, dependencies: list[dict[str, Any]]\n    ) -> None:\n        if not dependencies:\n            return\n\n        for dependency in dependencies:\n            code_block_id: str | None = dependency.get(\"code_block_id\")\n            if code_block_id:\n                source_type: str = self._get_collection_from_id(code_block_id)\n                target_type: str = self._get_collection_from_id(block_key)\n                try:\n                    self._upsert_edge(\n                        code_block_id, block_key, source_type, target_type\n                    )\n                    # logging.info(\n                    #     f\"Upserted edge for dependency {block_key} to {code_block_id}\"\n                    # )\n                except Exception as e:\n                    logging.error(\n                        f\"Error creating edge for dependency {block_key} to {code_block_id}: {e}\"\n                    )\n\n    def delete_vertex_by_id(\n        self, vertex_key: str, graph_name: str | None = None\n    ) -> None:\n        collection_name: str = self._get_collection_from_id(vertex_key)\n        if collection_name == \"unknown\":\n            logging.error(f\"Unknown vertex type for key: {vertex_key}\")\n            return None\n\n        if not graph_name:\n            graph_name = self.default_graph_name\n\n        try:\n            vertex_coll = self.db_connector.db.graph(graph_name).vertex_collection(\n                collection_name\n            )\n\n            vertex_coll.delete(vertex_key)\n\n            # logging.info(\n            #     f\"Vertex '{vertex_key}' from collection '{collection_name}' was successfully deleted.\"\n            # )\n\n        except Exception as e:\n            logging.error(\n                f\"Error deleting vertex '{vertex_key}' from collection '{collection_name}': {e}\"\n            )\n\n    def get_graph(self, graph_name: str | None = None) -> Graph | None:\n        if not graph_name:\n            graph_name = self.default_graph_name\n        try:\n            return self.db_connector.db.graph(self.default_graph_name)\n        except Exception as e:\n            logging.error(f\"Error getting graph '{self.default_graph_name}': {e}\")\n            return None\n\n    def get_or_create_graph(self, graph_name: str | None = None) -> Result[Graph]:\n        if not graph_name:\n            graph_name = self.default_graph_name\n\n        try:\n            if not self.db_connector.db.has_graph(graph_name):\n                edge_definitions: list[dict[str, str | list[str]]] = [\n                    {\n                        \"edge_collection\": \"code_edges\",\n                        \"from_vertex_collections\": helper_functions.pluralized_and_lowered_block_types(),\n                        \"to_vertex_collections\": helper_functions.pluralized_and_lowered_block_types(),\n                    }\n                ]\n\n                # logging.info(f\"Graph '{graph_name}' created successfully.\")\n                return self.db_connector.db.create_graph(\n                    graph_name, edge_definitions=edge_definitions\n                )\n\n            else:\n                return self.get_graph()\n\n        except Exception as e:\n            logging.error(f\"Error creating graph '{graph_name}': {e}\")\n\n    def delete_graph(self, graph_name: str | None = None) -> None:\n        if not graph_name:\n            graph_name = self.default_graph_name\n        try:\n            self.db_connector.db.delete_graph(graph_name)\n            logging.info(f\"Graph '{graph_name}' deleted successfully.\")\n        except Exception as e:\n            logging.error(f\"Error deleting graph '{graph_name}': {e}\")\n\n    def get_outbound_models(self, start_key: str) -> list[ModelType] | None:\n        vertex_type: str = self._get_collection_from_id(start_key)\n\n        query: str = f\"\"\"\n        FOR v, e, p IN 1..100 OUTBOUND '{vertex_type}/{start_key}' GRAPH '{self.default_graph_name}'\n        RETURN DISTINCT v\n        \"\"\"\n        # query: str = f\"\"\"\n        # FOR v, e, p IN 1..100 OUTBOUND '{vertex_type}/{start_key}' GRAPH '{self.default_graph_name}'\n        # FILTER LENGTH(p.edges[* FILTER CURRENT != e]) == 0\n        # RETURN DISTINCT v\n        # \"\"\"\n        # query: str = f\"\"\"\n        # FOR v, e, p IN 1..100 OUTBOUND '{vertex_type}/{start_key}' GRAPH '{self.default_graph_name}'\n        # FILTER LENGTH(p.edges[* FILTER CURRENT != e]) == 0\n        #     AND p.edges[*].distance ALL == 1\n        # RETURN DISTINCT v\n        # \"\"\"\n\n        try:\n            cursor = self.db_connector.db.aql.execute(query)\n            if isinstance(cursor, Cursor):\n                return [\n                    helper_functions.create_model_from_vertex(doc) for doc in cursor\n                ]\n            else:\n                logging.error(f\"Error getting cursor for query: {query}\")\n                return None\n        except Exception as e:\n            logging.error(f\"Error in get_all_downstream_vertices: {e}\")\n            return None\n\n    def get_inbound_models(self, end_key: str) -> list[ModelType] | None:\n        vertex_type: str = self._get_collection_from_id(end_key)\n\n        query: str = f\"\"\"\n        FOR v, e, p IN 1..100 INBOUND '{vertex_type}/{end_key}' GRAPH '{self.default_graph_name}'\n        RETURN DISTINCT v\n        \"\"\"\n\n        # query: str = f\"\"\"\n        # FOR v, e, p IN 1..100 INBOUND '{vertex_type}/{end_key}' GRAPH '{self.default_graph_name}'\n        # FILTER LENGTH(p.edges[* FILTER CURRENT != e]) == 0\n        # RETURN DISTINCT v\n        # \"\"\"\n\n        try:\n            cursor: Result[Cursor] = self.db_connector.db.aql.execute(query)\n            if isinstance(cursor, Cursor):\n                return [\n                    helper_functions.create_model_from_vertex(doc) for doc in cursor\n                ]\n            else:\n                logging.error(f\"Error getting cursor for query: {query}\")\n                return None\n        except Exception as e:\n            logging.error(f\"Error in get_all_upstream_vertices: {e}\")\n            return None\n\n    def update_vertex_by_id(self, id: str, new_summary: str) -> None:\n        try:\n            collection_name: str = self._get_collection_from_id(id)\n            if collection_name == \"unknown\":\n                logging.error(f\"Unknown vertex type for id: {id}\")\n                return\n\n            vertex_collection: StandardCollection = self.db_connector.db.collection(\n                collection_name\n            )\n            vertex_result: Result[Json | None] = vertex_collection.get(id)\n\n            if not vertex_result:\n                logging.error(f\"Vertex with id {id} not found.\")\n                return\n\n            if isinstance(vertex_result, dict):\n                vertex = vertex_result\n            else:\n                logging.error(\"Retrieved vertex is not in a mutable format.\")\n                return None\n\n            vertex[\"summary\"] = new_summary\n\n            vertex_collection.update(vertex)\n            logging.info(f\"Vertex with id {id} updated successfully.\")\n\n        except Exception as e:\n            logging.error(f\"Error in `update_vertex_by_id`: {e}\")\n\n    def get_all_modules(self) -> list[ModuleModel] | None:\n        try:\n            # Define the collection name for modules.\n            collection_name = \"modules\"\n            module_collection: StandardCollection = self.db_connector.db.collection(\n                collection_name\n            )\n\n            # Retrieve all documents from the modules collection.\n            cursor: Result[Cursor] = module_collection.all()\n\n            # Convert each document to a ModuleModel instance.\n            modules: list[ModuleModel] = []\n            for doc in cursor:  # type: ignore # FIXME: Fix type error\n                # Ensure the document is a dictionary.\n                try:\n                    # Convert the document to a ModuleModel instance and add it to the list.\n                    module = ModuleModel(**doc)\n                    modules.append(module)\n                except Exception as e:\n                    logging.error(f\"Retrieved document is not in a valid format: {e}\")\n                    continue\n\n            return modules\n\n        except Exception as e:\n            logging.error(f\"Error in get_all_modules: {e}\")\n            return None\n\n\nImported code block (postcode:databases:chroma:setup_chroma.py__*__MODULE) code content:\nfrom dataclasses import dataclass\nfrom logging import Logger\n\nimport chromadb\nfrom postcode.databases.chroma.chromadb_client_manager import ChromaDBClientManager\n\nfrom postcode.databases.chroma.chromadb_collection_manager import (\n    ChromaDBCollectionManager,\n)\n\nfrom chromadb.config import DEFAULT_DATABASE, DEFAULT_TENANT, Settings\nfrom chromadb.api import ClientAPI\nfrom chromadb.api.types import (\n    DataLoader,\n    CollectionMetadata,\n    GetResult,\n    QueryResult,\n    Where,\n    WhereDocument,\n    Include,\n    URIs,\n    Loadable,\n    Metadata,\n    Embedding,\n)\nfrom chromadb import Collection\nfrom chromadb import EmbeddingFunction\n\nfrom postcode.models.models import ModuleModel\n\n\n@dataclass\nclass ChromaSetupReturnContext:\n    \"\"\"\n    Represents the return value of the ChromaDB setup method.\n\n    Attributes:\n        - chroma_collection_manager (ChromaDBCollectionManager): The ChromaDB collection manager.\n        - chroma_collection (Collection): The ChromaDB collection.\n    \"\"\"\n\n    chroma_collection_manager: ChromaDBCollectionManager\n    chroma_collection: Collection\n\n\ndef setup_chroma(\n    module_models: list[ModuleModel], logger: Logger\n) -> ChromaSetupReturnContext:\n    chroma_settings = Settings(allow_reset=True)\n    chroma_client: ClientAPI = chromadb.PersistentClient(settings=chroma_settings)\n    chroma_client_manager = ChromaDBClientManager(chroma_client)\n\n    logger.debug(f\"Resetting Chroma client\")\n    if chroma_client_manager.reset_client():\n        logger.debug(\"Client reset\")\n\n    chroma_collection: Collection = chroma_client_manager.get_or_create_collection(\n        \"postcode\"\n    )\n\n    chroma_collection_manager = ChromaDBCollectionManager(chroma_collection)\n    chroma_collection_manager.upsert_models(tuple(module_models))\n\n    return ChromaSetupReturnContext(chroma_collection_manager, chroma_collection)\n\n\nImported code block (postcode:json_management:json_handler.py__*__MODULE) code content:\nimport json\nfrom pathlib import Path\n\nfrom postcode.models.models import ModuleModel\nfrom postcode.utilities.logger.decorators import logging_decorator\n\n\nclass JSONHandler:\n    def __init__(\n        self,\n        directory: str,\n        directory_modules: dict[str, list[str]],\n        output_directory: str = \"../output\",\n    ) -> None:\n        self.directory: str = directory\n        self.output_directory: str = output_directory\n        self.directory_modules: dict[str, list[str]] = directory_modules\n\n        self._create_output_directory()\n\n    @logging_decorator(message=\"Saving model as JSON\")\n    def save_model_as_json(self, module_model: ModuleModel, file_path: str) -> None:\n        \"\"\"Saves a parsed ModuleModel as JSON.\"\"\"\n\n        json_output_directory: str = self._create_json_output_directory()\n        output_path: str = self._get_json_output_path(file_path, json_output_directory)\n        self._write_json_file(module_model, output_path)\n\n    @logging_decorator(message=\"Saving visited directories\")\n    def save_visited_directories(\n        self, directory_mape_name: str = \"directory_map.json\"\n    ) -> None:\n        \"\"\"\n        Saves a JSON file mapping each visited directory to its Python files.\n\n        The output is saved in a file named '00_directory_module_map.json' within the specified output directory.\n\n        Args:\n            directory_mape_name (str): The name of the output file for the directory map.\n\n        Example:\n            >>> visitor_manager.save_visited_directories(\"directory_map.json\")\n            # Saves a mapping of directories to Python files as JSON.\n        \"\"\"\n\n        output_path: str = self._get_directory_map_output_path(directory_mape_name)\n        self._write_json_directory_map(output_path)\n\n    def _create_output_directory(self) -> None:\n        \"\"\"Creates the output directory if it does not already exist.\"\"\"\n\n        Path(self.output_directory).mkdir(exist_ok=True)\n\n    def _create_json_output_directory(self) -> str:\n        \"\"\"Creates the JSON output directory if it does not already exist.\"\"\"\n\n        json_output_directory: Path = Path(self.output_directory) / \"json\"\n        json_output_directory.mkdir(exist_ok=True)\n        return str(json_output_directory)\n\n    def _get_json_output_path(self, file_path: str, json_output_directory: str) -> str:\n        \"\"\"Gets the output path for a JSON file.\"\"\"\n\n        relative_path: Path = Path(file_path).relative_to(Path(self.directory))\n        safe_relative_path: str = str(relative_path).replace(\"/\", \":\").rstrip(\".py\")\n        return str(Path(json_output_directory) / f\"{safe_relative_path}.json\")\n\n    def _write_json_file(self, module_model: ModuleModel, output_path: str) -> None:\n        \"\"\"Writes a JSON file containing the parsed data from a ModuleModel.\"\"\"\n\n        parsed_data_json: str = module_model.model_dump_json(indent=4)\n        with open(output_path, \"w\") as json_file:\n            json_file.write(parsed_data_json)\n\n    def _get_directory_map_output_path(self, directory_output_name: str) -> str:\n        \"\"\"Gets the output path for the directory map JSON file.\"\"\"\n\n        return str(Path(self.output_directory) / directory_output_name)\n\n    def _write_json_directory_map(self, output_path: str) -> None:\n        \"\"\"Writes the directory map JSON file.\"\"\"\n\n        with open(output_path, \"w\") as json_file:\n            json.dump(self.directory_modules, json_file, indent=4)\n\n\nImported code block (postcode:models:models.py__*__MODULE) code content:\nfrom typing import Union\nfrom pydantic import BaseModel, Field, validator\n\nfrom postcode.models.enums import (\n    BlockType,\n    ImportModuleType,\n    CommentType,\n)\n\n\nclass ImportNameModel(BaseModel):\n    \"\"\"Class representing the name of an import.\"\"\"\n\n    name: str\n    as_name: str | None = None\n    local_block_id: str | None = None\n\n    # def convert_import_names_to_metadata(self) -> str:\n    #     \"\"\"Converts the import name to a metadata string.\"\"\"\n\n    #     return self.model_dump_json()\n\n\nclass ImportModel(BaseModel):\n    \"\"\"Class representing an import statement.\"\"\"\n\n    import_names: list[ImportNameModel]\n    imported_from: str | None = None\n    import_module_type: ImportModuleType = ImportModuleType.STANDARD_LIBRARY\n    local_module_id: str | None = None\n\n    def convert_import_to_metadata(self) -> str:\n        \"\"\"Converts the import to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass DependencyModel(BaseModel):\n    \"\"\"Class representing a module dependency.\"\"\"\n\n    code_block_id: str\n\n    def convert_dependency_to_metadata(self) -> str:\n        \"\"\"Converts the dependency to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass CommentModel(BaseModel):\n    \"\"\"Class representing a comment.\"\"\"\n\n    content: str\n    comment_types: list[CommentType]\n\n    def convert_comment_to_metadata(self) -> str:\n        \"\"\"Converts the comment to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass DecoratorModel(BaseModel):\n    \"\"\"Class representing a decorator.\"\"\"\n\n    content: str\n    decorator_name: str\n    decorator_args: list[str] | None = None\n\n    def convert_decorator_to_metadata(self) -> str:\n        \"\"\"Converts the decorator to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass ClassKeywordModel(BaseModel):\n    \"\"\"Class representing a class keyword.\"\"\"\n\n    content: str\n    keyword_name: str\n    args: str | None = None\n\n    def convert_class_keyword_to_metadata(self) -> str:\n        \"\"\"Converts the class keyword to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass ParameterModel(BaseModel):\n    \"\"\"Class representing a function parameter.\"\"\"\n\n    content: str\n\n\nclass ParameterListModel(BaseModel):\n    \"\"\"Class representing a list of parameters.\"\"\"\n\n    params: list[ParameterModel] | None = None\n    star_arg: ParameterModel | None = None\n    kwonly_params: list[ParameterModel] | None = None\n    star_kwarg: ParameterModel | None = None\n    posonly_params: list[ParameterModel] | None = None\n\n    def convert_parameters_to_metadata(self) -> str:\n        \"\"\"Converts the parameter list to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass BaseCodeBlockModel(BaseModel):\n    \"\"\"Attributes common to all code block models.\"\"\"\n\n    id: str\n    parent_id: str | None = None\n    block_type: BlockType\n    start_line_num: int\n    end_line_num: int\n    code_content: str = \"\"\n    important_comments: list[CommentModel] | None = None\n    dependencies: list[ImportModel | DependencyModel] | None = None\n    summary: str | None = None\n    children: list[\n        Union[\n            \"ClassModel\",\n            \"FunctionModel\",\n            \"StandaloneCodeBlockModel\",\n        ]\n    ] | None = []\n\n    @validator(\"parent_id\", always=True)\n    def check_parent_id(cls, v, values, **kwargs) -> str | None:\n        \"\"\"Validates that parent_id is a non-empty string unless block_type is MODULE.\"\"\"\n\n        if \"block_type\" in values and values[\"block_type\"] != BlockType.MODULE:\n            if len(v) < 1:\n                raise ValueError(\"parent_id is required!\")\n        return v\n\n    def _convert_parent_id_to_metadata(self) -> str:\n        \"\"\"Converts the parent_id to a metadata string.\"\"\"\n        return f\"{self.parent_id}\" if self.parent_id else \"\"\n\n    def _convert_block_type_to_metadata(self) -> str:\n        \"\"\"Converts the block_type to a metadata string.\"\"\"\n        return f\"{self.block_type.name}\"\n\n    def _convert_important_comments_to_metadata(self) -> str:\n        \"\"\"Converts the important comments to a metadata string.\"\"\"\n\n        important_comments: str = (\n            self.model_dump_json() if self.important_comments else \"\"\n        )\n\n        return f\"{important_comments}\"\n\n    def _convert_dependencies_to_metadata(self) -> str:\n        \"\"\"Converts the dependencies to a metadata string.\"\"\"\n\n        dependencies_str: str = \"\"\n\n        if self.dependencies:\n            for dependency in self.dependencies:\n                if isinstance(dependency, ImportModel):\n                    dependencies_str += f\"{dependency.convert_import_to_metadata()}\\n\"\n                elif isinstance(dependency, DependencyModel):\n                    dependencies_str += (\n                        f\"{dependency.convert_dependency_to_metadata()}\\n\"\n                    )\n\n        return dependencies_str\n\n    def _convert_summary_to_metadata(self) -> str:\n        \"\"\"Converts the summary to a metadata string.\"\"\"\n        return f\"{self.summary}\" if self.summary else \"\"\n\n    def _convert_children_to_metadata(self) -> str:\n        \"\"\"Converts the children to a metadata string.\"\"\"\n\n        children_str: str = \"\"\n\n        if self.children:\n            for child in self.children:\n                children_str += f\"{child.id}\\n\"\n\n        return children_str\n\n    def _convert_base_attributes_to_metadata_dict(self) -> dict[str, str | int]:\n        \"\"\"Converts the base attributes to a metadata dictionary.\"\"\"\n\n        return {\n            \"id\": self.id,\n            \"parent_id\": self._convert_parent_id_to_metadata(),\n            \"block_type\": self._convert_block_type_to_metadata(),\n            \"start_line_num\": self.start_line_num,\n            \"end_line_num\": self.end_line_num,\n            \"code_content\": self.code_content,\n            \"important_comments\": self._convert_important_comments_to_metadata(),\n            \"dependencies\": self._convert_dependencies_to_metadata(),\n            \"summary\": self._convert_summary_to_metadata(),\n            \"children\": self._convert_children_to_metadata(),\n        }\n\n\nclass ModuleSpecificAttributes(BaseModel):\n    \"\"\"Module specific attributes.\"\"\"\n\n    file_path: str = Field(min_length=1)\n    docstring: str | None = None\n    header: list[str] | None = None\n    footer: list[str] | None = None\n    imports: list[ImportModel] | None = None\n\n    def _convert_docstring_to_metadata(self) -> str:\n        \"\"\"Converts the docstring to a metadata string.\"\"\"\n        return f\"{self.docstring}\"\n\n    def _convert_header_to_metadata(self) -> str:\n        \"\"\"Converts the header and footer to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n    def _convert_footer_to_metadata(self) -> str:\n        \"\"\"Converts the header and footer to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n    def _convert_imports_to_metadata(self) -> str:\n        \"\"\"Converts the imports to a metadata string.\"\"\"\n        imports_str: str = self.model_dump_json() if self.imports else \"\"\n        return f\"{imports_str}\"\n\n    def _convert_module_attributes_to_metadata_dict(self) -> dict[str, str | int]:\n        \"\"\"Converts the module attributes to a metadata dictionary.\"\"\"\n\n        return {\n            \"file_path\": self.file_path,\n            \"docstring\": self._convert_docstring_to_metadata(),\n            \"header\": self._convert_header_to_metadata(),\n            \"footer\": self._convert_footer_to_metadata(),\n            \"imports\": self._convert_imports_to_metadata(),\n        }\n\n\nclass ModuleModel(BaseCodeBlockModel, ModuleSpecificAttributes):\n    \"\"\"Model for a module.\"\"\"\n\n    def convert_to_metadata(self) -> dict[str, str | int]:\n        \"\"\"Converts the module model to a metadata dictionary.\"\"\"\n\n        return {\n            **self._convert_base_attributes_to_metadata_dict(),\n            **self._convert_module_attributes_to_metadata_dict(),\n        }\n\n\nclass ClassSpecificAttributes(BaseModel):\n    \"\"\"Class specific attributes.\"\"\"\n\n    class_name: str = Field(min_length=1)\n    decorators: list[DecoratorModel] | None = None\n    bases: list[str] | None = None\n    docstring: str | None = None\n    keywords: list[ClassKeywordModel] | None = None\n    # attributes: list[dict] | None = None\n\n    def _convert_decorators_to_metadata(self) -> str:\n        \"\"\"Converts the decorators to a metadata string.\"\"\"\n        decorators_str: str = self.model_dump_json() if self.decorators else \"\"\n        return f\"{decorators_str}\"\n\n    def _convert_bases_to_metadata(self) -> str:\n        \"\"\"Converts the bases to a metadata string.\"\"\"\n        return self.model_dump_json() if self.bases else \"\"\n\n    def _convert_docstring_to_metadata(self) -> str:\n        \"\"\"Converts the docstring to a metadata string.\"\"\"\n        return f\"{self.docstring}\" if self.docstring else \"\"\n\n    def _convert_keywords_to_metadata(self) -> str:\n        \"\"\"Converts the keywords to a metadata string.\"\"\"\n        keywords_str: str = self.model_dump_json() if self.keywords else \"\"\n        return f\"{keywords_str}\"\n\n    def _convert_class_attributes_to_metadata_dict(self) -> dict[str, str | int]:\n        \"\"\"Converts the class attributes to a metadata dictionary.\"\"\"\n\n        return {\n            \"class_name\": self.class_name,\n            \"decorators\": self._convert_decorators_to_metadata(),\n            \"bases\": self._convert_bases_to_metadata(),\n            \"docstring\": self._convert_docstring_to_metadata(),\n            \"keywords\": self._convert_keywords_to_metadata(),\n        }\n\n\nclass ClassModel(BaseCodeBlockModel, ClassSpecificAttributes):\n    \"\"\"Model for a class.\"\"\"\n\n    def convert_to_metadata(self) -> dict[str, str | int]:\n        \"\"\"Converts the class model to a metadata dictionary.\"\"\"\n        return {\n            **self._convert_base_attributes_to_metadata_dict(),\n            **self._convert_class_attributes_to_metadata_dict(),\n        }\n\n\nclass FunctionSpecificAttributes(BaseModel):\n    \"\"\"Function specific attributes.\"\"\"\n\n    function_name: str = Field(min_length=1)\n    docstring: str | None = None\n    decorators: list[DecoratorModel] | None = None\n    parameters: ParameterListModel | None = None\n    returns: str | None = None\n    is_method: bool = False\n    is_async: bool = False\n\n    def _convert_docstring_to_metadata(self) -> str:\n        \"\"\"Converts the docstring to a metadata string.\"\"\"\n        return f\"{self.docstring}\" if self.docstring else \"\"\n\n    def _convert_decorators_to_metadata(self) -> str:\n        \"\"\"Converts the decorators to a metadata string.\"\"\"\n        decorators_str: str = self.model_dump_json() if self.decorators else \"\"\n        return f\"{decorators_str}\"\n\n    def _convert_parameters_to_metadata(self) -> str:\n        \"\"\"Converts the parameters to a metadata string.\"\"\"\n        return (\n            self.parameters.convert_parameters_to_metadata() if self.parameters else \"\"\n        )\n\n    def _convert_returns_to_metadata(self) -> str:\n        \"\"\"Converts the returns to a metadata string.\"\"\"\n        return f\"{self.returns}\" if self.returns else \"\"\n\n    def _convert_function_attributes_to_metadata_dict(self) -> dict[str, str | bool]:\n        \"\"\"Converts the function attributes to a metadata dictionary.\"\"\"\n\n        return {\n            \"function_name\": self.function_name,\n            \"docstring\": self._convert_docstring_to_metadata(),\n            \"decorators\": self._convert_decorators_to_metadata(),\n            \"parameters\": self._convert_parameters_to_metadata(),\n            \"returns\": self._convert_returns_to_metadata(),\n            \"is_method\": self.is_method,\n            \"is_async\": self.is_async,\n        }\n\n\nclass FunctionModel(BaseCodeBlockModel, FunctionSpecificAttributes):\n    \"\"\"Model for a function.\"\"\"\n\n    def convert_to_metadata(self) -> dict[str, str | int]:\n        \"\"\"Converts the function model to a metadata dictionary.\"\"\"\n\n        return {\n            **self._convert_base_attributes_to_metadata_dict(),\n            **self._convert_function_attributes_to_metadata_dict(),\n        }\n\n\nclass StandaloneCodeBlockSpecificAttributes(BaseModel):\n    \"\"\"Standalone code block specific attributes.\"\"\"\n\n    variable_assignments: list[str] | None = None\n\n    def _convert_variable_assignments_to_metadata(self) -> str:\n        \"\"\"Converts the variable assignments to a metadata string.\"\"\"\n        return self.model_dump_json() if self.variable_assignments else \"\"\n\n    def _convert_standalone_block_attributes_to_metadata_dict(\n        self,\n    ) -> dict[str, str | int]:\n        \"\"\"Converts the standalone code block attributes to a metadata dictionary.\"\"\"\n        return {\n            \"variable_assignments\": self._convert_variable_assignments_to_metadata(),\n        }\n\n\nclass StandaloneCodeBlockModel(\n    BaseCodeBlockModel, StandaloneCodeBlockSpecificAttributes\n):\n    \"\"\"Model for a standalone code block.\"\"\"\n\n    def convert_to_metadata(self) -> dict[str, str | int]:\n        \"\"\"Converts the standalone code block model to a metadata dictionary.\"\"\"\n\n        return {\n            **self._convert_base_attributes_to_metadata_dict(),\n            **self._convert_standalone_block_attributes_to_metadata_dict(),\n        }\n\n\nImported code block (postcode:python_parser:visitor_manager:visitor_manager.py__*__MODULE) code content:\nfrom dataclasses import dataclass\nimport logging\nfrom pathlib import Path\n\nfrom postcode.python_parser.model_builders.module_model_builder import (\n    ModuleModelBuilder,\n)\nfrom postcode.utilities.logger.decorators import logging_decorator\n\nfrom postcode.python_parser.parsers.python_parser import PythonParser\nfrom postcode.python_parser.visitor_manager.import_and_dependency_updater import (\n    ImportAndDependencyUpdater,\n)\nfrom postcode.models.models import ModuleModel\n\nfrom postcode.ai_services.summarizer.summarization_context import Summarizer\n\nEXCLUDED_DIRECTORIES: set[str] = {\".venv\", \"node_modules\", \"__pycache__\", \".git\"}\n\n\n@dataclass\nclass VisitorManagerProcessFilesReturn:\n    \"\"\"\n    Represents the return value of the VisitorManager.process_files() method.\n\n    Attributes:\n        - models_tuple (tuple[ModuleModel, ...]): A tuple of ModuleModel objects representing the parsed modules.\n        - directory_modules (dict[str, list[str]]): A dictionary mapping directory paths to lists of module names.\n            This is used to keep track of the modules present in each directory.\n    \"\"\"\n\n    models_tuple: tuple[ModuleModel, ...]\n    directory_modules: dict[str, list[str]]\n\n\nclass VisitorManager:\n    \"\"\"\n    Manages the visiting and processing of Python files in a given directory.\n\n    This class scans a specified directory, filters for Python files, parses them, and saves the parsed data in a structured JSON format. It also maintains a mapping of directories to the Python files they contain.\n\n    Attributes:\n        directory (str): The root directory to scan for Python files.\n        output_directory (str): The directory where output JSON files will be saved.\n        directory_modules (dict): A mapping of directories to their contained Python files.\n\n    Example:\n        >>> visitor_manager = VisitorManager(\"/path/to/python/code\", \"output\")\n        >>> visitor_manager.process_files()\n        # This will process all Python files in /path/to/python/code and save their parsed data in the output directory.\n    \"\"\"\n\n    @logging_decorator(message=\"Initializing VisitorManager\")\n    def __init__(self, directory: str, output_directory: str = \"output_json\") -> None:\n        self.directory: str = directory\n        self.output_directory: str = output_directory\n        self.directory_modules: dict[str, list[str]] = {}\n\n    def process_files(self) -> VisitorManagerProcessFilesReturn:\n        \"\"\"\n        Process the files in the directory and return the module models.\n\n        This function iterates through all the Python files in the directory, processes each file,\n        updates the imports, and builds module models for each file. It returns a tuple of module models\n        and a dictionary of directory modules.\n\n        Returns:\n            A named tuple (VisitorManagerProcessFilesReturn) containing:\n            - models_tuple (tuple[ModuleModel, ...]): A tuple of module models.\n            - directory_modules (dict[str, ModuleModel]): A dictionary of directory modules.\n\n        Examples:\n            >>> visitor_manager = VisitorManager()\n            >>> result = visitor_manager.process_files()\n            >>> print(result.models_tuple)\n            (ModuleModel(file_path='/path/to/file1.py'), ModuleModel(file_path='/path/to/file2.py'))\n            >>> print(result.directory_modules)\n            {'/path/to/directory1': ModuleModel(file_path='/path/to/directory1/__init__.py')}\n        \"\"\"\n\n        logging.info(\"Processing files\")\n        python_files: list[str] = self._get_python_files()\n        model_builder_list: list[ModuleModelBuilder] = []\n        for file_path in python_files:\n            if model_builder := self._process_file(file_path):\n                model_builder_list.append((model_builder))\n\n        logging.info(\"File processing completed\")\n        logging.info(\"Updating imports\")\n\n        # TODO: Test making this a tuple of tuples, see if that solves the double update import issue\n        model_builder_tuple: tuple[ModuleModelBuilder, ...] = tuple(model_builder_list)\n\n        import_and_dependency_updater = ImportAndDependencyUpdater(model_builder_tuple)\n        import_and_dependency_updater.update_imports()\n        logging.info(\"Updated imports\")\n\n        module_models_list: list[ModuleModel] = []\n        for module_model_builder in model_builder_tuple:\n            module_model: ModuleModel = self._build_module_model(module_model_builder)\n            module_models_list.append(module_model)\n\n        module_models_tuple: tuple[ModuleModel, ...] = tuple(module_models_list)\n\n        return VisitorManagerProcessFilesReturn(\n            models_tuple=module_models_tuple, directory_modules=self.directory_modules\n        )\n\n    def _walk_directories(self) -> list[str]:\n        \"\"\"Walks the specified directory and returns a list of all files.\"\"\"\n\n        all_files: list[str] = []\n        for file_path in Path(self.directory).rglob(\"*\"):\n            if not any(\n                excluded in file_path.parts for excluded in EXCLUDED_DIRECTORIES\n            ):\n                all_files.append(str(file_path))\n        return all_files\n\n    def _filter_python_files(self, files: list[str]) -> list[str]:\n        \"\"\"Filters a list of files to only include Python files.\"\"\"\n\n        return [file for file in files if file.endswith(\".py\")]\n\n    @logging_decorator(message=\"Getting Python files\")\n    def _get_python_files(self) -> list[str]:\n        \"\"\"Gets all Python files in the specified directory.\"\"\"\n\n        all_files: list[str] = self._walk_directories()\n        return self._filter_python_files(all_files)\n\n    def _process_file(self, file_path: str) -> ModuleModelBuilder | None:\n        \"\"\"Processes a single Python file.\"\"\"\n\n        file_path_obj = Path(file_path)\n        root = str(file_path_obj.parent)\n        self.directory_modules.setdefault(root, []).append(file_path_obj.name)\n        return self._parse_file(file_path)\n\n    @logging_decorator(message=\"Processing file\")\n    def _parse_file(self, file_path: str) -> ModuleModelBuilder | None:\n        \"\"\"Parses a Python file and saves the parsed data as JSON.\"\"\"\n\n        parser = PythonParser(file_path)\n        code: str = parser.open_file()\n        module_model_builder: ModuleModelBuilder | None = parser.parse(code)\n\n        return module_model_builder\n\n    def _build_module_model(\n        self, visitor_stack: ModuleModelBuilder | None\n    ) -> ModuleModel:\n        \"\"\"\n        Builds a module model from the provided module builder.\n\n        Args:\n            visitor_stack (ModuleModelBuilder): The module builder to build the model from.\n\n        Returns:\n            ModuleModel: A structured module model.\n\n        Example:\n            >>> module_model = python_parser.build_module_model(visitor_stack)\n            # Builds a module model from the provided module builder.\n        \"\"\"\n\n        if not isinstance(visitor_stack, ModuleModelBuilder):\n            raise TypeError(\"Expected the first builder to be a ModuleModelBuilder\")\n\n        return visitor_stack.build()\n\n, \nfrom logging import Logger\nfrom openai import OpenAI\n        "}   n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the class model to a metadata dictionary.\\\"\\\"\\\"\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_class_attributes_to_metadata_dict(),\\n        }\\n\\n\\nclass FunctionSpecificAttributes(BaseModel):\\n    \\\"\\\"\\\"Function specific attributes.\\\"\\\"\\\"\\n\\n    function_name: str = Field(min_length=1)\\n    docstring: str | None = None\\n    decorators: list[DecoratorModel] | None = None\\n    parameters: ParameterListModel | None = None\\n    returns: str | None = None\\n    is_method: bool = False\\n    is_async: bool = False\\n\\n    def _convert_docstring_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the docstring to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.docstring}\\\" if self.docstring else \\\"\\\"\\n\\n    def _convert_decorators_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the decorators to a metadata string.\\\"\\\"\\\"\\n        decorators_str: str = self.model_dump_json() if self.decorators else \\\"\\\"\\n        return f\\\"{decorators_str}\\\"\\n\\n    def _convert_parameters_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the parameters to a metadata string.\\\"\\\"\\\"\\n        return (\\n            self.parameters.convert_parameters_to_metadata() if self.parameters else \\\"\\\"\\n        )\\n\\n    def _convert_returns_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the returns to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.returns}\\\" if self.returns else \\\"\\\"\\n\\n    def _convert_function_attributes_to_metadata_dict(self) -> dict[str, str | bool]:\\n        \\\"\\\"\\\"Converts the function attributes to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            \\\"function_name\\\": self.function_name,\\n            \\\"docstring\\\": self._convert_docstring_to_metadata(),\\n            \\\"decorators\\\": self._convert_decorators_to_metadata(),\\n            \\\"parameters\\\": self._convert_parameters_to_metadata(),\\n            \\\"returns\\\": self._convert_returns_to_metadata(),\\n            \\\"is_method\\\": self.is_method,\\n            \\\"is_async\\\": self.is_async,\\n        }\\n\\n\\nclass FunctionModel(BaseCodeBlockModel, FunctionSpecificAttributes):\\n    \\\"\\\"\\\"Model for a function.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the function model to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_function_attributes_to_metadata_dict(),\\n        }\\n\\n\\nclass StandaloneCodeBlockSpecificAttributes(BaseModel):\\n    \\\"\\\"\\\"Standalone code block specific attributes.\\\"\\\"\\\"\\n\\n    variable_assignments: list[str] | None = None\\n\\n    def _convert_variable_assignments_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the variable assignments to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json() if self.variable_assignments else \\\"\\\"\\n\\n    def _convert_standalone_block_attributes_to_metadata_dict(\\n        self,\\n    ) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the standalone code block attributes to a metadata dictionary.\\\"\\\"\\\"\\n        return {\\n            \\\"variable_assignments\\\": self._convert_variable_assignments_to_metadata(),\\n        }\\n\\n\\nclass StandaloneCodeBlockModel(\\n    BaseCodeBlockModel, StandaloneCodeBlockSpecificAttributes\\n):\\n    \\\"\\\"\\\"Model for a standalone code block.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the standalone code block model to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_standalone_block_attributes_to_metadata_dict(),\\n        }\\n\\n\\nImported code block (postcode:utilities:logger:decorators.py__*__MODULE) code content:\\nfrom functools import wraps\\nimport inspect\\nfrom inspect import FrameInfo\\nimport logging\\nfrom logging import LogRecord, Logger\\nfrom typing import Callable\\nimport libcst\\n\\n\\nimport postcode.python_parser.visitors.node_processing.common_functions as common_functions\\nfrom postcode.utilities.processing_context import LoggingCallerInfo, NodeAndPositionData\\n\\n\\ndef logging_decorator(\\n    level=logging.DEBUG,\\n    *,\\n    message: str | None = None,\\n    syntax_highlighting: bool = False,\\n) -> Callable:\\n    \\\"\\\"\\\"\\n    A decorator for adding enhanced logging to functions, with optional syntax highlighting.\\n\\n    This decorator logs the call to the decorated function at the specified logging level. If syntax_highlighting is enabled and the first argument of the function is a libcst.CSTNode, the decorator logs the node's content with syntax highlighting.\\n\\n    Args:\\n        level (int): The logging level. Defaults to logging.DEBUG.\\n        message (str | None): Custom log message. If None, a default message is generated.\\n        syntax_highlighting (bool): If True, enables syntax highlighting for libcst.CSTNode arguments.\\n\\n    Returns:\\n        Callable: The decorated function with enhanced logging capability.\\n\\n    Example:\\n        >>> @logging_decorator(level=logging.INFO, message=\\\"Function start\\\", syntax_highlighting=True)\\n        >>> def sample_function(arg1):\\n        >>>     pass\\n        # This decorates 'sample_function' with enhanced logging at INFO level.\\n    \\\"\\\"\\\"\\n\\n    def decorator(func):\\n        @wraps(func)\\n        def wrapper(*args, **kwargs):\\n            log_message: str = (\\n                message if message else (f\\\"Calling function: {func.__name__}\\\")\\n            )\\n            frame_info: inspect.FrameInfo = inspect.stack()[1]\\n            caller_info: LoggingCallerInfo = _get_caller_info(frame_info)\\n            code_content: str = _gather_code_content(syntax_highlighting, args)\\n            logger: Logger = _get_logger(caller_info.caller_module_name)\\n\\n            _handle_logging(\\n                logger,\\n                caller_info,\\n                level,\\n                log_message,\\n                syntax_highlighting,\\n                code_content,\\n            )\\n\\n            return func(*args, **kwargs)\\n\\n        return wrapper\\n\\n    return decorator\\n\\n\\ndef _gather_log_record_context(\\n    caller_info: LoggingCallerInfo, level: int, msg: str\\n) -> logging.LogRecord:\\n    \\\"\\\"\\\"Creates and returns a LogRecord with specified context information.\\\"\\\"\\\"\\n\\n    return logging.LogRecord(\\n        name=caller_info.caller_module_name,\\n        level=level,\\n        pathname=caller_info.caller_file_path,\\n        lineno=caller_info.caller_line_no,\\n        msg=msg,\\n        args=None,\\n        exc_info=None,\\n    )\\n\\n\\ndef _get_caller_info(frame_info: FrameInfo) -> LoggingCallerInfo:\\n    \\\"\\\"\\\"Extracts and returns caller information from a frame object.\\\"\\\"\\\"\\n\\n    caller_module_name: str = frame_info.filename.split(\\\"/\\\")[-1].split(\\\".\\\")[0]\\n    caller_file_path: str = frame_info.filename\\n    caller_line_no: int = frame_info.lineno\\n    return LoggingCallerInfo(caller_module_name, caller_file_path, caller_line_no)\\n\\n\\ndef _get_logger(caller_module_name: str) -> Logger:\\n    \\\"\\\"\\\"Retrieves and returns a Logger instance for the specified module name.\\\"\\\"\\\"\\n\\n    return logging.getLogger(caller_module_name)\\n\\n\\ndef _gather_code_content(syntax_highlighting: bool, args: tuple) -> str:\\n    \\\"\\\"\\\"Gathers and returns code content for logging, if `syntax_highlighting` else returns empty string.\\\"\\\"\\\"\\n\\n    if not syntax_highlighting or not args:\\n        return \\\"\\\"\\n\\n    arg_0 = args[0]\\n    content: str = \\\"\\\"\\n\\n    if isinstance(arg_0, libcst.CSTNode):\\n        content = common_functions.extract_code_content(arg_0)\\n    elif isinstance(arg_0, list) and all(\\n        isinstance(node, libcst.CSTNode) for node in arg_0\\n    ):\\n        content = \\\"\\\\n\\\".join(\\n            common_functions.extract_stripped_code_content(node) for node in arg_0\\n        )\\n    elif isinstance(arg_0, NodeAndPositionData):\\n        content = \\\"\\\\n\\\".join(\\n            common_functions.extract_stripped_code_content(node) for node in arg_0.nodes\\n        )\\n\\n    return content\\n\\n\\ndef _handle_syntax_highlighting(\\n    syntax_highlighting: bool,\\n    log_record: logging.LogRecord,\\n    logger: Logger,\\n    content: str,\\n) -> None:\\n    \\\"\\\"\\\"Handles syntax highlighting for the log record if enabled.\\\"\\\"\\\"\\n\\n    if syntax_highlighting:\\n        log_record.syntax_highlight = syntax_highlighting\\n        log_record.content = content\\n        logger.handle(log_record)\\n\\n\\ndef _handle_logging(\\n    logger: Logger,\\n    caller_info: LoggingCallerInfo,\\n    level: int,\\n    log_message: str,\\n    syntax_highlighting: bool,\\n    code_content: str,\\n) -> None:\\n    \\\"\\\"\\\"Handles the logging process, including the creation and handling of log records.\\\"\\\"\\\"\\n\\n    if logger.isEnabledFor(level):\\n        log_record: LogRecord = _gather_log_record_context(\\n            caller_info, level, log_message\\n        )\\n        logger.handle(log_record)  # Print log message\\n        _handle_syntax_highlighting(\\n            syntax_highlighting, log_record, logger, code_content\\n        )\\n\\n, \\nimport json\\nfrom pathlib import Path\\n        \",\"children\":[{\"class_name\":\"JSONHandler\",\"decorators\":null,\"bases\":null,\"docstring\":null,\"keywords\":null,\"id\":\"postcode:json_management:json_handler.py__*__MODULE__*__CLASS-JSONHandler\",\"parent_id\":\"postcode:json_management:json_handler.py__*__MODULE\",\"block_type\":\"CLASS\",\"start_line_num\":6,\"end_line_num\":85,\"code_content\":\"\\n\\nclass JSONHandler:\\n    def __init__(\\n        self,\\n        directory: str,\\n        directory_modules: dict[str, list[str]],\\n        output_directory: str = \\\"../output\\\",\\n    ) -> None:\\n        self.directory: str = directory\\n        self.output_directory: str = output_directory\\n        self.directory_modules: dict[str, list[str]] = directory_modules\\n\\n        self._create_output_directory()\\n\\n    @logging_decorator(message=\\\"Saving model as JSON\\\")\\n    def save_model_as_json(self, module_model: ModuleModel, file_path: str) -> None:\\n        \\\"\\\"\\\"Saves a parsed ModuleModel as JSON.\\\"\\\"\\\"\\n\\n        json_output_directory: str = self._create_json_output_directory()\\n        output_path: str = self._get_json_output_path(file_path, json_output_directory)\\n        self._write_json_file(module_model, output_path)\\n\\n    @logging_decorator(message=\\\"Saving visited directories\\\")\\n    def save_visited_directories(\\n        self, directory_mape_name: str = \\\"directory_map.json\\\"\\n    ) -> None:\\n        \\\"\\\"\\\"\\n        Saves a JSON file mapping each visited directory to its Python files.\\n\\n        The output is saved in a file named '00_directory_module_map.json' within the specified output directory.\\n\\n        Args:\\n            directory_mape_name (str): The name of the output file for the directory map.\\n\\n        Example:\\n            >>> visitor_manager.save_visited_directories(\\\"directory_map.json\\\")\\n            # Saves a mapping of directories to Python files as JSON.\\n        \\\"\\\"\\\"\\n\\n        output_path: str = self._get_directory_map_output_path(directory_mape_name)\\n        self._write_json_directory_map(output_path)\\n\\n    def _create_output_directory(self) -> None:\\n        \\\"\\\"\\\"Creates the output directory if it does not already exist.\\\"\\\"\\\"\\n\\n        Path(self.output_directory).mkdir(exist_ok=True)\\n\\n    def _create_json_output_directory(self) -> str:\\n        \\\"\\\"\\\"Creates the JSON output directory if it does not already exist.\\\"\\\"\\\"\\n\\n        json_output_directory: Path = Path(self.output_directory) / \\\"json\\\"\\n        json_output_directory.mkdir(exist_ok=True)\\n        return str(json_output_directory)\\n\\n    def _get_json_output_path(self, file_path: str, json_output_directory: str) -> str:\\n        \\\"\\\"\\\"Gets the output path for a JSON file.\\\"\\\"\\\"\\n\\n        relative_path: Path = Path(file_path).relative_to(Path(self.directory))\\n        safe_relative_path: str = str(relative_path).replace(\\\"/\\\", \\\":\\\").rstrip(\\\".py\\\")\\n        return str(Path(json_output_directory) / f\\\"{safe_relative_path}.json\\\")\\n\\n    def _write_json_file(self, module_model: ModuleModel, output_path: str) -> None:\\n        \\\"\\\"\\\"Writes a JSON file containing the parsed data from a ModuleModel.\\\"\\\"\\\"\\n\\n        parsed_data_json: str = module_model.model_dump_json(indent=4)\\n        with open(output_path, \\\"w\\\") as json_file:\\n            json_file.write(parsed_data_json)\\n\\n    def _get_directory_map_output_path(self, directory_output_name: str) -> str:\\n        \\\"\\\"\\\"Gets the output path for the directory map JSON file.\\\"\\\"\\\"\\n\\n        return str(Path(self.output_directory) / directory_output_name)\\n\\n    def _write_json_directory_map(self, output_path: str) -> None:\\n        \\\"\\\"\\\"Writes the directory map JSON file.\\\"\\\"\\\"\\n\\n        with open(output_path, \\\"w\\\") as json_file:\\n            json.dump(self.directory_modules, json_file, indent=4)\\n\",\"important_comments\":null,\"dependencies\":[{\"import_names\":[{\"name\":\"json\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":null,\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"Path\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"pathlib\",\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"},{\"import_names\":[{\"name\":\"logging_decorator\",\"as_name\":null,\"local_block_id\":\"postcode:utilities:logger:decorators.py__*__MODULE__*__FUNCTION-logging_decorator\"}],\"imported_from\":\"postcode.utilities.logger.decorators\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:utilities:logger:decorators.py__*__MODULE\"}],\"summary\":null,\"children\":[{\"function_name\":\"__init__\",\"docstring\":null,\"decorators\":null,\"parameters\":null,\"returns\":\"None\",\"is_method\":true,\"is_async\":false,\"id\":\"postcode:json_management:json_handler.py__*__MODULE__*__CLASS-JSONHandler__*__FUNCTION-__init__\",\"parent_id\":\"postcode:json_management:json_handler.py__*__MODULE__*__CLASS-JSONHandler\",\"block_type\":\"FUNCTION\",\"start_line_num\":9,\"end_line_num\":20,\"code_content\":\"def __init__(\\n    self,\\n    directory: str,\\n    directory_modules: dict[str, list[str]],\\n    output_directory: str = \\\"../output\\\",\\n) -> None:\\n    self.directory: str = directory\\n    self.output_directory: str = output_directory\\n    self.directory_modules: dict[str, list[str]] = directory_modules\\n\\n    self._create_output_directory()\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":null,\"children\":null},{\"function_name\":\"save_model_as_json\",\"docstring\":\"Saves a parsed ModuleModel as JSON.\",\"decorators\":[{\"content\":\"@logging_decorator(message=\\\"Saving model as JSON\\\")\",\"decorator_name\":\"logging_decorator\",\"decorator_args\":[\"message=\\\"Saving model as JSON\\\"\"]}],\"parameters\":null,\"returns\":\"None\",\"is_method\":true,\"is_async\":false,\"id\":\"postcode:json_management:json_handler.py__*__MODULE__*__CLASS-JSONHandler__*__FUNCTION-save_model_as_json\",\"parent_id\":\"postcode:json_management:json_handler.py__*__MODULE__*__CLASS-JSONHandler\",\"block_type\":\"FUNCTION\",\"start_line_num\":20,\"end_line_num\":28,\"code_content\":\"\\n@logging_decorator(message=\\\"Saving model as JSON\\\")\\ndef save_model_as_json(self, module_model: ModuleModel, file_path: str) -> None:\\n    \\\"\\\"\\\"Saves a parsed ModuleModel as JSON.\\\"\\\"\\\"\\n\\n    json_output_directory: str = self._create_json_output_directory()\\n    output_path: str = self._get_json_output_path(file_path, json_output_directory)\\n    self._write_json_file(module_model, output_path)\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":null,\"children\":null},{\"function_name\":\"save_visited_directories\",\"docstring\":\"Saves a JSON file mapping each visited directory to its Python files.\\n\\nThe output is saved in a file named '00_directory_module_map.json' within the specified output directory.\\n\\nArgs:\\n    directory_mape_name (str): The name of the output file for the directory map.\\n\\nExample:\\n    >>> visitor_manager.save_visited_directories(\\\"directory_map.json\\\")\\n    # Saves a mapping of directories to Python files as JSON.\",\"decorators\":[{\"content\":\"@logging_decorator(message=\\\"Saving visited directories\\\")\",\"decorator_name\":\"logging_decorator\",\"decorator_args\":[\"message=\\\"Saving visited directories\\\"\"]}],\"parameters\":null,\"returns\":\"None\",\"is_method\":true,\"is_async\":false,\"id\":\"postcode:json_management:json_handler.py__*__MODULE__*__CLASS-JSONHandler__*__FUNCTION-save_visited_directories\",\"parent_id\":\"postcode:json_management:json_handler.py__*__MODULE__*__CLASS-JSONHandler\",\"block_type\":\"FUNCTION\",\"start_line_num\":28,\"end_line_num\":48,\"code_content\":\"\\n@logging_decorator(message=\\\"Saving visited directories\\\")\\ndef save_visited_directories(\\n    self, directory_mape_name: str = \\\"directory_map.json\\\"\\n) -> None:\\n    \\\"\\\"\\\"\\n        Saves a JSON file mapping each visited directory to its Python files.\\n\\n        The output is saved in a file named '00_directo       {"id": "postcode:app.py__*__MODULE", "parent_id": "", "block_type": "MODULE", "start_line_num": 1, "end_line_num": 87, "code_content": "import logging\nfrom logging import Logger\nfrom typing import Union\n\nfrom postcode.models.models import (\n    ModuleModel,\n    ClassModel,\n    FunctionModel,\n    StandaloneCodeBlockModel,\n)\n\nfrom postcode.databases.chroma.setup_chroma import (\n    ChromaSetupReturnContext,\n)\nfrom postcode.updaters.graph_db_updater import GraphDBUpdater\n\nModelType = Union[\n    ModuleModel,\n    ClassModel,\n    FunctionModel,\n    StandaloneCodeBlockModel,\n]\n\nfrom postcode.utilities.logger.logging_config import setup_logging\n\nfrom postcode.databases.chroma.chromadb_collection_manager import (\n    ChromaDBCollectionManager,\n)\n\nfrom chromadb.api.types import (\n    QueryResult,\n)\nfrom chromadb import Collection\n\nfrom postcode.updaters.standard_updater import StandardUpdater\n\n\ndef query_chroma(\n    query: str,\n    chroma_collection_manager: ChromaDBCollectionManager,\n    chroma_collection: Collection,\n    logger: Logger,\n) -> None:\n    logger.info(f\"Querying ChromaDB collection {chroma_collection.name}\")\n    results: QueryResult | None = chroma_collection_manager.query_collection(\n        [query],\n        n_results=10,\n        # where_filter={\"block_type\": \"MODULE\"},\n        include_in_result=[\"metadatas\", \"documents\", \"embeddings\"],\n    )\n    logger.info(\"Query results:\")\n    if results:\n        if results[\"ids\"]:\n            for document in results[\"ids\"][0]:\n                print(document)\n\n            print(f\"Total results: {len(results['ids'][0])}\")\n\n\ndef main(\n    directory: str = \".\",\n    output_directory: str = \"output_json\",\n) -> None:\n    setup_logging()\n    logger: Logger = logging.getLogger(__name__)\n\n    #   ==================== GraphDB ====================\n    graph_db_updater = GraphDBUpdater(directory, output_directory, logger)\n    chroma_context: ChromaSetupReturnContext = graph_db_updater.update_all(\n        directory, output_directory, logger\n    )\n    # ==================== End GraphDB ====================\n\n    #   ==================== Standard ====================\n    # chroma_context: ChromaSetupReturnContext = StandardUpdater.update_all(\n    #     directory, output_directory, logger\n    # )\n    # ==================== End Standard ====================\n\n    query: str = \"summarizes code block\"\n    query_chroma(\n        query,\n        chroma_context.chroma_collection_manager,\n        chroma_context.chroma_collection,\n        logger,\n    )\n", "important_comments": "", "dependencies": "", "summary": "\nSummary:\n\n        postcode:app.py__*__MODULE\n\n        \nChild (postcode:app.py__*__MODULE__*__STANDALONE_BLOCK-1) code content:\nModelType = Union[\n    ModuleModel,\n    ClassModel,\n    FunctionModel,\n    StandaloneCodeBlockModel,\n]\n\n\nChild (postcode:app.py__*__MODULE__*__FUNCTION-query_chroma) code content:\n\n\ndef query_chroma(\n    query: str,\n    chroma_collection_manager: ChromaDBCollectionManager,\n    chroma_collection: Collection,\n    logger: Logger,\n) -> None:\n    logger.info(f\"Querying ChromaDB collection {chroma_collection.name}\")\n    results: QueryResult | None = chroma_collection_manager.query_collection(\n        [query],\n        n_results=10,\n        # where_filter={\"block_type\": \"MODULE\"},\n        include_in_result=[\"metadatas\", \"documents\", \"embeddings\"],\n    )\n    logger.info(\"Query results:\")\n    if results:\n        if results[\"ids\"]:\n            for document in results[\"ids\"][0]:\n                print(document)\n\n            print(f\"Total results: {len(results['ids'][0])}\")\n\n\nChild (postcode:app.py__*__MODULE__*__FUNCTION-main) code content:\n\n\ndef main(\n    directory: str = \".\",\n    output_directory: str = \"output_json\",\n) -> None:\n    setup_logging()\n    logger: Logger = logging.getLogger(__name__)\n\n    #   ==================== GraphDB ====================\n    graph_db_updater = GraphDBUpdater(directory, output_directory, logger)\n    chroma_context: ChromaSetupReturnContext = graph_db_updater.update_all(\n        directory, output_directory, logger\n    )\n    # ==================== End GraphDB ====================\n\n    #   ==================== Standard ====================\n    # chroma_context: ChromaSetupReturnContext = StandardUpdater.update_all(\n    #     directory, output_directory, logger\n    # )\n    # ==================== End Standard ====================\n\n    query: str = \"summarizes code block\"\n    query_chroma(\n        query,\n        chroma_context.chroma_collection_manager,\n        chroma_context.chroma_collection,\n        logger,\n    )\n\n, \nImported code block (postcode:models:models.py__*__MODULE) code content:\nfrom typing import Union\nfrom pydantic import BaseModel, Field, validator\n\nfrom postcode.models.enums import (\n    BlockType,\n    ImportModuleType,\n    CommentType,\n)\n\n\nclass ImportNameModel(BaseModel):\n    \"\"\"Class representing the name of an import.\"\"\"\n\n    name: str\n    as_name: str | None = None\n    local_block_id: str | None = None\n\n    # def convert_import_names_to_metadata(self) -> str:\n    #     \"\"\"Converts the import name to a metadata string.\"\"\"\n\n    #     return self.model_dump_json()\n\n\nclass ImportModel(BaseModel):\n    \"\"\"Class representing an import statement.\"\"\"\n\n    import_names: list[ImportNameModel]\n    imported_from: str | None = None\n    import_module_type: ImportModuleType = ImportModuleType.STANDARD_LIBRARY\n    local_module_id: str | None = None\n\n    def convert_import_to_metadata(self) -> str:\n        \"\"\"Converts the import to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass DependencyModel(BaseModel):\n    \"\"\"Class representing a module dependency.\"\"\"\n\n    code_block_id: str\n\n    def convert_dependency_to_metadata(self) -> str:\n        \"\"\"Converts the dependency to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass CommentModel(BaseModel):\n    \"\"\"Class representing a comment.\"\"\"\n\n    content: str\n    comment_types: list[CommentType]\n\n    def convert_comment_to_metadata(self) -> str:\n        \"\"\"Converts the comment to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass DecoratorModel(BaseModel):\n    \"\"\"Class representing a decorator.\"\"\"\n\n    content: str\n    decorator_name: str\n    decorator_args: list[str] | None = None\n\n    def convert_decorator_to_metadata(self) -> str:\n        \"\"\"Converts the decorator to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass ClassKeywordModel(BaseModel):\n    \"\"\"Class representing a class keyword.\"\"\"\n\n    content: str\n    keyword_name: str\n    args: str | None = None\n\n    def convert_class_keyword_to_metadata(self) -> str:\n        \"\"\"Converts the class keyword to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass ParameterModel(BaseModel):\n    \"\"\"Class representing a function parameter.\"\"\"\n\n    content: str\n\n\nclass ParameterListModel(BaseModel):\n    \"\"\"Class representing a list of parameters.\"\"\"\n\n    params: list[ParameterModel] | None = None\n    star_arg: ParameterModel | None = None\n    kwonly_params: list[ParameterModel] | None = None\n    star_kwarg: ParameterModel | None = None\n    posonly_params: list[ParameterModel] | None = None\n\n    def convert_parameters_to_metadata(self) -> str:\n        \"\"\"Converts the parameter list to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass BaseCodeBlockModel(BaseModel):\n    \"\"\"Attributes common to all code block models.\"\"\"\n\n    id: str\n    parent_id: str | None = None\n    block_type: BlockType\n    start_line_num: int\n    end_line_num: int\n    code_content: str = \"\"\n    important_comments: list[CommentModel] | None = None\n    dependencies: list[ImportModel | DependencyModel] | None = None\n    summary: str | None = None\n    children: list[\n        Union[\n            \"ClassModel\",\n            \"FunctionModel\",\n            \"StandaloneCodeBlockModel\",\n        ]\n    ] | None = []\n\n    @validator(\"parent_id\", always=True)\n    def check_parent_id(cls, v, values, **kwargs) -> str | None:\n        \"\"\"Validates that parent_id is a non-empty string unless block_type is MODULE.\"\"\"\n\n        if \"block_type\" in values and values[\"block_type\"] != BlockType.MODULE:\n            if len(v) < 1:\n                raise ValueError(\"parent_id is required!\")\n        return v\n\n    def _convert_parent_id_to_metadata(self) -> str:\n        \"\"\"Converts the parent_id to a metadata string.\"\"\"\n        return f\"{self.parent_id}\" if self.parent_id else \"\"\n\n    def _convert_block_type_to_metadata(self) -> str:\n        \"\"\"Converts the block_type to a metadata string.\"\"\"\n        return f\"{self.block_type.name}\"\n\n    def _convert_important_comments_to_metadata(self) -> str:\n        \"\"\"Converts the important comments to a metadata string.\"\"\"\n\n        important_comments: str = (\n            self.model_dump_json() if self.important_comments else \"\"\n        )\n\n        return f\"{important_comments}\"\n\n    def _convert_dependencies_to_metadata(self) -> str:\n        \"\"\"Converts the dependencies to a metadata string.\"\"\"\n\n        dependencies_str: str = \"\"\n\n        if self.dependencies:\n            for dependency in self.dependencies:\n                if isinstance(dependency, ImportModel):\n                    dependencies_str += f\"{dependency.convert_import_to_metadata()}\\n\"\n                elif isinstance(dependency, DependencyModel):\n                    dependencies_str += (\n                        f\"{dependency.convert_dependency_to_metadata()}\\n\"\n                    )\n\n        return dependencies_str\n\n    def _convert_summary_to_metadata(self) -> str:\n        \"\"\"Converts the summary to a metadata string.\"\"\"\n        return f\"{self.summary}\" if self.summary else \"\"\n\n    def _convert_children_to_metadata(self) -> str:\n        \"\"\"Converts the children to a metadata string.\"\"\"\n\n        children_str: str = \"\"\n\n        if self.children:\n            for child in self.children:\n                children_str += f\"{child.id}\\n\"\n\n        return children_str\n\n    def _convert_base_attributes_to_metadata_dict(self) -> dict[str, str | int]:\n        \"\"\"Converts the base attributes to a metadata dictionary.\"\"\"\n\n        return {\n            \"id\": self.id,\n            \"parent_id\": self._convert_parent_id_to_metadata(),\n            \"block_type\": self._convert_block_type_to_metadata(),\n            \"start_line_num\": self.start_line_num,\n            \"end_line_num\": self.end_line_num,\n            \"code_content\": self.code_content,\n            \"important_comments\": self._convert_important_comments_to_metadata(),\n            \"dependencies\": self._convert_dependencies_to_metadata(),\n            \"summary\": self._convert_summary_to_metadata(),\n            \"children\": self._convert_children_to_metadata(),\n        }\n\n\nclass ModuleSpecificAttributes(BaseModel):\n    \"\"\"Module specific attributes.\"\"\"\n\n    file_path: str = Field(min_length=1)\n    docstring: str | None = None\n    header: list[str] | None = None\n    footer: list[str] | None = None\n    imports: list[ImportModel] | None = None\n\n    def _convert_docstring_to_metadata(self) -> str:\n        \"\"\"Converts the docstring to a metadata string.\"\"\"\n        return f\"{self.docstring}\"\n\n    def _convert_header_to_metadata(self) -> str:\n        \"\"\"Converts the header and footer to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n    def _convert_footer_to_metadata(self) -> str:\n        \"\"\"Converts the header and footer to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n    def _convert_imports_to_metadata(self) -> str:\n        \"\"\"Converts the imports to a metadata string.\"\"\"\n        imports_str: str = self.model_dump_json() if self.imports else \"\"\n        return f\"{imports_str}\"\n\n    def _convert_module_attributes_to_metadata_dict(self) -> dict[str, str | int]:\n        \"\"\"Converts the module attributes to a metadata dictionary.\"\"\"\n\n        return {\n            \"file_path\": self.file_path,\n            \"docstring\": self._convert_docstring_to_metadata(),\n            \"header\": self._convert_header_to_metadata(),\n            \"footer\": self._convert_footer_to_metadata(),\n            \"imports\": self._convert_imports_to_metadata(),\n        }\n\n\nclass ModuleModel(BaseCodeBlockModel, ModuleSpecificAttributes):\n    \"\"\"Model for a module.\"\"\"\n\n    def convert_to_metadata(self) -> dict[str, str | int]:\n        \"\"\"Converts the module model to a metadata dictionary.\"\"\"\n\n        return {\n            **self._convert_base_attributes_to_metadata_dict(),\n            **self._convert_module_attributes_to_metadata_dict(),\n        }\n\n\nclass ClassSpecificAttributes(BaseModel):\n    \"\"\"Class specific attributes.\"\"\"\n\n    class_name: str = Field(min_length=1)\n    decorators: list[DecoratorModel] | None = None\n    bases: list[str] | None = None\n    docstring: str | None = None\n    keywords: list[ClassKeywordModel] | None = None\n    # attributes: list[dict] | None = None\n\n    def _convert_decorators_to_metadata(self) -> str:\n        \"\"\"Converts the decorators to a metadata string.\"\"\"\n        decorators_str: str = self.model_dump_json() if self.decorators else \"\"\n        return f\"{decorators_str}\"\n\n    def _convert_bases_to_metadata(self) -> str:\n        \"\"\"Converts the bases to a metadata string.\"\"\"\n        return self.model_dump_json() if self.bases else \"\"\n\n    def _convert_docstring_to_metadata(self) -> str:\n        \"\"\"Converts the docstring to a metadata string.\"\"\"\n        return f\"{self.docstring}\" if self.docstring else \"\"\n\n    def _convert_keywords_to_metadata(self) -> str:\n        \"\"\"Converts the keywords to a metadata string.\"\"\"\n        keywords_str: str = self.model_dump_json() if self.keywords else \"\"\n        return f\"{keywords_str}\"\n\n    def _convert_class_attributes_to_metadata_dict(self) -> dict[str, str | int]:\n        \"\"\"Converts the class attributes to a metadata dictionary.\"\"\"\n\n        return {\n            \"class_name\": self.class_name,\n            \"decorators\": self._convert_decorators_to_metadata(),\n            \"bases\": self._convert_bases_to_metadata(),\n            \"docstring\": self._convert_docstring_to_metadata(),\n            \"keywords\": self._convert_keywords_to_metadata(),\n        }\n\n\nclass ClassModel(BaseCodeBlockModel, ClassSpecificAttributes):\n    \"\"\"Model for a class.\"\"\"\n\n    def convert_to_metadata(self) -> dict[str, str | int]:\n        \"\"\"Converts the class model to a metadata dictionary.\"\"\"\n        return {\n            **self._convert_base_attributes_to_metadata_dict(),\n            **self._convert_class_attributes_to_metadata_dict(),\n        }\n\n\nclass FunctionSpecificAttributes(BaseModel):\n    \"\"\"Function specific attributes.\"\"\"\n\n    function_name: str = Field(min_length=1)\n    docstring: str | None = None\n    decorators: list[DecoratorModel] | None = None\n    parameters: ParameterListModel | None = None\n    returns: str | None = None\n    is_method: bool = False\n    is_async: bool = False\n\n    def _convert_docstring_to_metadata(self) -> str:\n        \"\"\"Converts the docstring to a metadata string.\"\"\"\n        return f\"{self.docstring}\" if self.docstring else \"\"\n\n    def _convert_decorators_to_metadata(self) -> str:\n        \"\"\"Converts the decorators to a metadata string.\"\"\"\n        decorators_str: str = self.model_dump_json() if self.decorators else \"\"\n        return f\"{decorators_str}\"\n\n    def _convert_parameters_to_metadata(self) -> str:\n        \"\"\"Converts the parameters to a metadata string.\"\"\"\n        return (\n            self.parameters.convert_parameters_to_metadata() if self.parameters else \"\"\n        )\n\n    def _convert_returns_to_metadata(self) -> str:\n        \"\"\"Converts the returns to a metadata string.\"\"\"\n        return f\"{self.returns}\" if self.returns else \"\"\n\n    def _convert_function_attributes_to_metadata_dict(self) -> dict[str, str | bool]:\n        \"\"\"Converts the function attributes to a metadata dictionary.\"\"\"\n\n        return {\n            \"function_name\": self.function_name,\n            \"docstring\": self._convert_docstring_to_metadata(),\n            \"decorators\": self._convert_decorators_to_metadata(),\n            \"parameters\": self._convert_parameters_to_metadata(),\n            \"returns\": self._convert_returns_to_metadata(),\n            \"is_method\": self.is_method,\n            \"is_async\": self.is_async,\n        }\n\n\nclass FunctionModel(BaseCodeBlockModel, FunctionSpecificAttributes):\n    \"\"\"Model for a function.\"\"\"\n\n    def convert_to_metadata(self) -> dict[str, str | int]:\n        \"\"\"Converts the function model to a metadata dictionary.\"\"\"\n\n        return {\n            **self._convert_base_attributes_to_metadata_dict(),\n            **self._convert_function_attributes_to_metadata_dict(),\n        }\n\n\nclass StandaloneCodeBlockSpecificAttributes(BaseModel):\n    \"\"\"Standalone code block specific attributes.\"\"\"\n\n    variable_assignments: list[str] | None = None\n\n    def _convert_variable_assignments_to_metadata(self) -> str:\n        \"\"\"Converts the variable assignments to a metadata string.\"\"\"\n        return self.model_dump_json() if self.variable_assignments else \"\"\n\n    def _convert_standalone_block_attributes_to_metadata_dict(\n        self,\n    ) -> dict[str, str | int]:\n        \"\"\"Converts the standalone code block attributes to a metadata dictionary.\"\"\"\n        return {\n            \"variable_assignments\": self._convert_variable_assignments_to_metadata(),\n        }\n\n\nclass StandaloneCodeBlockModel(\n    BaseCodeBlockModel, StandaloneCodeBlockSpecificAttributes\n):\n    \"\"\"Model for a standalone code block.\"\"\"\n\n    def convert_to_metadata(self) -> dict[str, str | int]:\n        \"\"\"Converts the standalone code block model to a metadata dictionary.\"\"\"\n\n        return {\n            **self._convert_base_attributes_to_metadata_dict(),\n            **self._convert_standalone_block_attributes_to_metadata_dict(),\n        }\n\n\nImported code block (postcode:databases:chroma:setup_chroma.py__*__MODULE) code content:\nfrom dataclasses import dataclass\nfrom logging import Logger\n\nimport chromadb\nfrom postcode.databases.chroma.chromadb_client_manager import ChromaDBClientManager\n\nfrom postcode.databases.chroma.chromadb_collection_manager import (\n    ChromaDBCollectionManager,\n)\n\nfrom chromadb.config import DEFAULT_DATABASE, DEFAULT_TENANT, Settings\nfrom chromadb.api import ClientAPI\nfrom chromadb.api.types import (\n    DataLoader,\n    CollectionMetadata,\n    GetResult,\n    QueryResult,\n    Where,\n    WhereDocument,\n    Include,\n    URIs,\n    Loadable,\n    Metadata,\n    Embedding,\n)\nfrom chromadb import Collection\nfrom chromadb import EmbeddingFunction\n\nfrom postcode.models.models import ModuleModel\n\n\n@dataclass\nclass ChromaSetupReturnContext:\n    \"\"\"\n    Represents the return value of the ChromaDB setup method.\n\n    Attributes:\n        - chroma_collection_manager (ChromaDBCollectionManager): The ChromaDB collection manager.\n        - chroma_collection (Collection): The ChromaDB collection.\n    \"\"\"\n\n    chroma_collection_manager: ChromaDBCollectionManager\n    chroma_collection: Collection\n\n\ndef setup_chroma(\n    module_models: list[ModuleModel], logger: Logger\n) -> ChromaSetupReturnContext:\n    chroma_settings = Settings(allow_reset=True)\n    chroma_client: ClientAPI = chromadb.PersistentClient(settings=chroma_settings)\n    chroma_client_manager = ChromaDBClientManager(chroma_client)\n\n    logger.debug(f\"Resetting Chroma client\")\n    if chroma_client_manager.reset_client():\n        logger.debug(\"Client reset\")\n\n    chroma_collection: Collection = chroma_client_manager.get_or_create_collection(\n        \"postcode\"\n    )\n\n    chroma_collection_manager = ChromaDBCollectionManager(chroma_collection)\n    chroma_collection_manager.upsert_models(tuple(module_models))\n\n    return ChromaSetupReturnContext(chroma_collection_manager, chroma_collection)\n\n\nImported code block (postcode:updaters:graph_db_updater.py__*__MODULE) code content:\nfrom logging import Logger\n\nfrom openai import OpenAI\nfrom postcode.ai_services.summarizer.graph_db_summarization_manager import (\n    GraphDBSummarizationManager,\n)\nfrom postcode.ai_services.summarizer.openai_summarizer import OpenAISummarizer\nfrom postcode.ai_services.summarizer.summarization_mapper import SummarizationMapper\nfrom postcode.databases.arangodb.arangodb_connector import ArangoDBConnector\n\nfrom postcode.databases.arangodb.arangodb_manager import ArangoDBManager\nfrom postcode.databases.chroma.setup_chroma import (\n    ChromaSetupReturnContext,\n    setup_chroma,\n)\nfrom postcode.json_management.json_handler import JSONHandler\nfrom postcode.models.models import ModuleModel\nfrom postcode.python_parser.visitor_manager.visitor_manager import (\n    VisitorManager,\n    VisitorManagerProcessFilesReturn,\n)\n\n\nclass GraphDBUpdater:\n    def __init__(\n        self,\n        directory: str,\n        output_directory: str,\n        logger: Logger,\n        arango_connector: ArangoDBConnector = ArangoDBConnector(),\n    ) -> None:\n        self.directory: str = directory\n        self.output_directory: str = output_directory\n        self.logger: Logger = logger\n        self.arango_connector: ArangoDBConnector = arango_connector\n\n        self.arango_connector.delete_all_collections()\n        self.arango_connector.ensure_collections()\n        self.graph_manager = ArangoDBManager(arango_connector)\n\n    def update_all(\n        self,\n        directory: str,\n        output_directory: str,\n        logger: Logger,\n    ) -> ChromaSetupReturnContext:\n        logger.info(\"Starting the directory parsing.\")\n\n        visitor_manager = VisitorManager(directory, output_directory)\n        process_files_return: VisitorManagerProcessFilesReturn = (\n            visitor_manager.process_files()\n        )\n\n        module_models_tuple: tuple[ModuleModel, ...] = process_files_return.models_tuple\n        module_ids: list[str] = [model.id for model in module_models_tuple]\n        directory_modules: dict[str, list[str]] = process_files_return.directory_modules\n        self.graph_manager.upsert_models(\n            list(module_models_tuple)\n        ).process_imports_and_dependencies().get_or_create_graph()\n        summarization_mapper = SummarizationMapper(\n            module_ids, module_models_tuple, self.graph_manager\n        )\n        client = OpenAI(max_retries=4)\n        summarizer = OpenAISummarizer(client=client)\n        summarization_manager = GraphDBSummarizationManager(\n            module_models_tuple, summarization_mapper, summarizer, self.graph_manager\n        )\n        finalized_module_models: list[\n            ModuleModel\n        ] | None = summarization_manager.create_summaries_and_return_updated_models()\n        logger.info(\"Summarization complete\")\n\n        logger.info(\"Saving models as JSON\")\n        json_manager = JSONHandler(directory, directory_modules, output_directory)\n\n        for module_model in module_models_tuple:\n            json_manager.save_model_as_json(module_model, module_model.file_path)\n\n        json_manager.save_visited_directories()\n        logger.info(\"JSON save complete\")\n\n        logger.info(\"Directory parsing completed.\")\n\n        # self.graph_manager.upsert_models(\n        #     list(finalized_module_models)\n        # ).process_imports_and_dependencies().get_or_create_graph()\n\n        if finalized_module_models:\n            chroma_context: ChromaSetupReturnContext = setup_chroma(\n                finalized_module_models, logger\n            )\n        else:\n            raise Exception(\"No finalized models returned from summarization.\")\n\n        return chroma_context\n\n\nImported code block (postcode:utilities:logger:logging_config.py__*__MODULE) code content:\nimport logging\n\nfrom rich.logging import RichHandler\nfrom rich.syntax import Syntax\n\n\ndef setup_logging(level=logging.INFO) -> None:\n    \"\"\"\n    Configures the logging system to use RichSyntaxHandler for output.\n\n    This function sets up logging with a specific log level and format. It utilizes the RichSyntaxHandler to support rich text and syntax highlighting in log outputs.\n\n    Args:\n        level (int, optional): The logging level to set for the root logger. Defaults to logging.INFO.\n\n    Example:\n        >>> setup_logging(logging.DEBUG)\n        # Configures logging at DEBUG level with RichSyntaxHandler.\n    \"\"\"\n\n    format_str = \"%(message)s\"\n    logging.basicConfig(level=level, format=format_str, handlers=[RichSyntaxHandler()])\n\n\nclass RichSyntaxHandler(RichHandler):\n    \"\"\"\n    A custom logging handler that extends RichHandler to add syntax highlighting.\n\n    This handler checks if the log record contains a 'syntax_highlight' attribute and, if so, uses 'rich.syntax.Syntax' to render the message with Python syntax highlighting.\n\n    Inherits:\n        RichHandler: The base handler provided by the rich library for rich text formatting.\n    \"\"\"\n\n    def emit(self, record) -> None:\n        \"\"\"\n        Emits a logging record.\n\n        If the record has the 'syntax_highlight' attribute set to True, it renders the 'content' attribute of the record with syntax highlighting. Otherwise, it falls back to the standard behavior of RichHandler.\n\n        Args:\n            record: The logging record to emit.\n\n        Example:\n            # Assuming `logger` is a logger instance\n            >>> logger.info(\"Regular log message\")\n            # Outputs a regular log message.\n\n            >>> logger.info(\"Highlighted log message\", extra={\"syntax_highlight\": True, \"content\": \"print('Hello, world!')\"})\n            # Outputs the message with syntax highlighting.\n        \"\"\"\n\n        try:\n            if hasattr(record, \"syntax_highlight\") and getattr(\n                record, \"syntax_highlight\"\n            ):\n                content: str = getattr(record, \"content\", \"\")\n                if isinstance(content, str):\n                    syntax = Syntax(\n                        content, \"python\", theme=\"material\", line_numbers=True\n                    )\n                    self.console.print(syntax)\n                return\n\n        except Exception as e:\n            self.handleError(record)\n\n        super().emit(record)\n\n\nImported code block (postcode:databases:chroma:chromadb_collection_manager.py__*__MODULE) code content:\nimport logging\nfrom typing import Any, Mapping, Union\n\nfrom postcode.models.models import ModuleModel\nimport postcode.types.chroma as chroma_types\nfrom chromadb.config import DEFAULT_DATABASE, DEFAULT_TENANT, Settings\nfrom chromadb.api import ClientAPI\nfrom chromadb.api.types import (\n    DataLoader,\n    CollectionMetadata,\n    GetResult,\n    QueryResult,\n    Where,\n    WhereDocument,\n    Include,\n    URIs,\n    Loadable,\n    Metadata,\n    Embedding,\n)\nfrom chromadb import Collection\nfrom chromadb import EmbeddingFunction\n# from postcode.types.postcode import ModelType\nfrom postcode.models.models import ModuleModel, ClassModel, FunctionModel, StandaloneCodeBlockModel\nModelType = Union[\n    ModuleModel,\n    ClassModel,\n    FunctionModel,\n    StandaloneCodeBlockModel,\n]\n\n\nclass ChromaDBCollectionManager:\n    \"\"\"\n    Manages a collection within ChromaDB instance, providing functionalities for adding, retrieving,\n    and querying embeddings, and their associated metadata.\n\n    This class serves as an interface to interact with a specific collection in ChromaDB.\n\n    Attributes:\n        - collection (chroma_types.Collection): An instance of the Collection class from ChromaDB\n            which this manager is responsible for.\n\n    Methods:\n        - `collection_embedding_count`: Gets the total number of embeddings in the collection.\n        - `add_embeddings`: Adds embeddings to the collection.\n        - `get_embeddings`: Gets embeddings and their metadata from the collection in the form of a TypedDict.\n        - `query_collection`: Queries and returns the `n` nearest neighbors from the collection.\n        - `upsert_models`: Loads or updates the embeddings of the provided module models into the collection.\n\n    Examples:\n        ```Python\n        from postcode.databases.chroma import ChromaDBClientBuilder\n        import postcode.types.chromadb.types as chroma_types\n\n        # Create a persistent ChromaDB client\n        client: chroma_types.ClientAPI = ChromaDBClientBuilder.create_persistent_client()\n\n        # Instantiate the ChromaDBCollectionManager with a specific collection\n        collection_manager: ChromaDBCollectionManager = (\n            ChromaDBCollectionManager(client.get_collection(\"my_collection\"))\n        )\n\n        # Example usage of the collection manager\n        embedding_count: int = collection_manager.collection_embedding_count()\n        print(f\"Total embeddings: {embedding_count}\")\n        ```\n    \"\"\"\n\n    def __init__(self, collection: Collection) -> None:\n        self.collection: Collection = collection\n\n    def collection_embedding_count(self) -> int | None:\n        \"\"\"\n        Gets the total number of embeddings in the collection.\n\n        Returns:\n            - embedding_count (int): The total number of embeddings in the collection.\n\n        Examples:\n            ```Python\n            embedding_count: int = collection_manager.get_collection_embedding_count()\n            ```\n        \"\"\"\n        try:\n            embedding_count: int = self.collection.count()\n            logging.info(\n                f\"Collection {self.collection.name} has {embedding_count} embeddings.\"\n            )\n            return embedding_count\n        except Exception as exception:\n            logging.error(exception)\n\n    def add_embeddings(\n        self,\n        ids: list[str],\n        documents: list[str],\n        metadatas: list[Mapping[str, str | int | float | bool]],\n    ) -> None:\n        \"\"\"\n        Adds embeddings to the collection.\n\n        Args:\n            - ids (list[str]): A list of ids to add to the collection.\n            - documents (list[str]): A list of documents to add to the collection.\n            - metadatas (list[dict[str, Any]]): A list of metadatas to add to the collection.\n\n        Raises:\n            - ValueError - If you don't provide either embeddings or documents.\n            - ValueError: If the length of ids, embeddings, metadatas, or documents don't match.\n            - ValueError - If you provide an id that already exists.\n\n        Examples:\n            ```Python\n            # define the ids, metadatas, and documents to add to the collection\n            id: list[str] = [\"my_id\", \"my_id2\"]\n            metadatas: list[dict[str, Any]] = [\n                {\"my_metadata\": \"my_metadata_value\"},\n                {\"my_metadata2\": \"my_metadata_value2\"},\n            ]\n            documents: list[str] = [\"my_document\", \"my_document2\"]\n\n            # add the embeddings to the collection\n            collection_manager.add_embeddings(id, metadatas, documents)\n            ```\n        \"\"\"\n\n        if not len(ids) == len(documents) == len(metadatas):\n            raise ValueError(\"The length of ids, documents, and metadatas must match.\")\n\n        try:\n            logging.info(f\"Adding embeddings to collection {self.collection.name}\")\n            self.collection.add(ids, documents=documents, metadatas=metadatas)\n        except Exception as exception:\n            raise exception\n\n    def get_embeddings(\n        self,\n        ids: list[str] | None,\n        *,\n        where_filter: Where | None = None,\n        limit: int | None = None,\n        where_document_filter: WhereDocument | None = None,\n        include_in_result: Include = [\"metadatas\", \"documents\"],\n    ) -> GetResult | None:\n        \"\"\"\n        Gets embeddings and their metadata from the collection in the form of a TypedDict.\n\n        Args:\n            - ids (list[str]): A list of ids to get from the collection.\n            - where_filter (chroma_types.Where | None): A TypedDict used to filter the results.\n            - limit (int | None): The maximum number of results to return.\n            - where_document_filter (chroma_types.WhereDocument | None): A TypedDict used to filter the results by the document,\n                e.g. `{$contains: {\"text\": \"hello\"}}`\n            - include_in_result (chroma_types.Include | None): A list used of what to return from the results, e.g. `[\"metadatas\", \"embeddings\", \"documents\"]`\n\n        Returns:\n            - embeddings (TypedDict): A typed dict of embedding data from the collection with the following keys:\n                - ids: list[str]\n                - embeddings: list[Embedding] | None\n                - documents: list[str] | None\n                - uris: chroma_types.URIs | None\n                - data: chroma_types.Loadable | None\n                - metadatas: list[chroma_types.Metadata]]\n\n        Raises:\n            - ValueError: If the length of ids, embeddings, metadatas, or documents don't match.\n            - ValueError: If you provide an id that doesn't exist.\n\n        Examples:\n            ```Python\n            import postcode.types.chromadb.types as chroma_types\n\n            # define the ids, filters to use to get embeddings from the collection\n            ids: list[str] = [\"my_id\", \"my_id2\"]\n            where_filter: chroma_types.Where = {\"my_metadata\": \"my_metadata_value\"}\n            where_document_filter: chroma_types.WhereDocument = {\"$contains\": {\"text\": \"hello\"}}\n\n            # define the data to return from the collection\n            include_in_result: chroma_types.Include = [\"metadatas\"]\n\n            # get the embeddings from the collection\n            embeddings: chroma_types.GetResult = collection_manager.get_embeddings(\n                ids,\n                where_filter=where_filter,\n                where_document_filter=where_document_filter,\n                include_in_result=include_in_result\n                )\n            ```\n        \"\"\"\n\n        try:\n            logging.info(f\"Getting embeddings from collection {self.collection.name}\")\n            return self.collection.get(\n                ids,\n                where=where_filter,\n                limit=limit,\n                where_document=where_document_filter,\n                include=include_in_result,\n            )\n        except Exception as exception:\n            raise exception\n\n    def query_collection(\n        self,\n        queries: list[str],\n        n_results: int = 10,\n        where_filter: Where | None = None,\n        where_document_filter: WhereDocument | None = None,\n        include_in_result: Include = [\"metadatas\", \"documents\"],\n    ) -> QueryResult | None:\n        \"\"\"\n        Queries and returns the `n` nearest neighbors from the collection.\n\n        Args:\n            - queries (list[str]): A list of queries to search the collection for.\n            - n_results (int): The number of results to return.\n            - where_filter (chroma_types.Where | None): A TypedDict used to filter the results.\n                - e.g. `{\"block_type\": \"FUNCTION\", \"children\": None}`\n            - where_document_filter (chroma_types.WhereDocument | None): A TypedDict used to filter the results by the document,\n                - e.g. `{$contains: \"binary search\"}`\n            - include_in_result (chroma_types.Include | None): A list used of what to return from the results, e.g. `[\"metadatas\", \"embeddings\", \"documents\"]`\n\n        Returns:\n            - results (chroma_types.QueryResult | None): A typed dict of query results from the collection, can have the following keys based on the\n                `include_in_result` parameter:\n                - ids: list[str] # The ids are always returned.\n                - embeddings: List[list[Embedding]] | None\n                - documents: list[list[str]]] | None\n                - uris: list[list[URI]]] | None\n                - data: list[Loadable] | None\n                - metadatas: list[list[Metadata]] | None\n                - distances: list[list[float]] | None\n\n        Raises:\n            - ValueError: If you don't provide query_texts.\n\n        Examples:\n            ```Python\n            import postcode.types.chromadb.types as chroma\n\n            # define the queries and filters used to search the collection\n            queries: list[str] = [\"binary search\", \"linear search\"]\n            where_filter: chroma_types.Where = {\"block_type\": \"FUNCTION\"}\n\n            # define the data to return from the collection\n            include_in_result: chroma_types.Include = [\"metadatas\", \"documents\", \"distances\"]\n\n            # query the collection and return the results from the collection\n            results: chroma_types.QueryResult = collection_manager.query_collection(\n                queries,\n                where_filter=where_filter,\n                include_in_result=include_in_result\n                )\n            ```\n        \"\"\"\n\n        try:\n            logging.info(f\"Querying collection {self.collection.name}\")\n\n            if results := self.collection.query(\n                query_texts=queries,\n                n_results=n_results,\n                where=where_filter,\n                where_document=where_document_filter,\n                include=include_in_result,\n            ):\n                return results\n            else:\n                logging.warning(\n                    f\"No results found from collection {self.collection.name}.\"\n                )\n\n        except Exception as exception:\n            raise exception\n\n    def modify_collection_name(self, name: str) -> None:\n        \"\"\"\n        Modifies the name of the collection managed by this class.\n\n        Args:\n            - name (str): The new name to assign to the collection.\n\n        Examples:\n            ```Python\n            # Rename the collection to 'new_collection_name'\n            collection_manager.modify_collection_name('new_collection_name')\n            ```\n        \"\"\"\n\n        self.collection.modify(name=name)\n\n    def modify_collection_metadata(\n        self, metadata: dict[str, Any] | None = None\n    ) -> None:\n        \"\"\"\n        Modifies the metadata of the collection managed by this class.\n\n        Args:\n            - metadata (dict[str, Any] | None): The new metadata to assign to the collection. If None, no change is made.\n\n        Examples:\n            ```Python\n            # Update metadata of the collection\n            new_metadata = {\"description\": \"Updated collection metadata\"}\n            collection_manager.modify_collection_metadata(new_metadata)\n            ```\n        \"\"\"\n\n        self.collection.modify(metadata=metadata)\n\n    def _update_metadata_or_documents_by_ids(\n        self,\n        ids: list[str],\n        metadatas: list[Mapping[str, str | int | float | bool]] | None = None,\n        documents: list[str] | None = None,\n    ) -> None:\n        \"\"\"\n        Updates the metadata or documents of specific entries in the collection by their ids.\n\n        Args:\n            - ids (list[str]): List of ids of the entries to be updated.\n            - metadatas (list[Mapping[str, Any]] | None): List of metadata updates corresponding to the ids.\n            - documents (list[str] | None): List of document updates corresponding to the ids.\n\n        Raises:\n            - ValueError: If neither metadatas nor documents are provided.\n            - ValueError: If the length of ids and documents don't match.\n            - ValueError: If the length of ids and metadatas don't match.\n            - ValueError: If the length of ids, metadatas, and documents don't match.\n\n        Notes:\n            - As of now, ChromaDB doesn't raise an exception if you provide an id that doesn't exist.\n\n        Examples:\n            ```Python\n            # Update metadata and documents for specific ids\n            ids_to_update = ['id1', 'id2']\n            metadata_updates = [{\"key1\": \"value1\"}, {\"key2\": \"value2\"}]\n            document_updates = [\"new document 1\", \"new document 2\"]\n            collection_manager.update_metadata_or_documents_by_ids(ids_to_update, metadata_updates, document_updates)\n            ```\n        \"\"\"\n\n        if not metadatas and not documents:\n            raise ValueError(\"You must provide either metadatas or documents.\")\n        if not metadatas and documents:\n            if len(ids) != len(documents):\n                raise ValueError(\"The length of ids and documents must match.\")\n        if metadatas and not documents:\n            if len(ids) != len(metadatas):\n                raise ValueError(\"The length of ids and metadatas must match.\")\n        if metadatas and documents:\n            if len(ids) != len(metadatas) != len(documents):\n                raise ValueError(\n                    \"The length of ids, metadatas, and documents must match.\"\n                )\n        for index, id in enumerate(ids):\n            if not self.collection.get(id):\n                logging.error(\n                    f\"Id {id} does not exist in collection {self.collection.name}.\"\n                )\n                ids.pop(index)\n                if metadatas:\n                    popped_metadata = metadatas.pop(index)\n                    if popped_metadata:\n                        logging.warning(\n                            f\"Removing metadata at index {index} from update.\"\n                        )\n                if documents:\n                    popped_document = documents.pop(index)\n                    if popped_document:\n                        logging.warning(\n                            f\"Removing document at index {index} from update.\"\n                        )\n\n        if not ids:\n            logging.warning(\"All updates failed.\")\n            return None\n        else:\n            logging.info(f\"Updating collection {self.collection.name} with ids {ids}.\")\n            self.collection.update(ids=ids, metadatas=metadatas, documents=documents)\n\n    def _upsert_documents(\n        self,\n        ids: list[str],\n        documents: list[str],\n        metadatas: list[Mapping[str, str | int | float | bool]],\n        # embeddings: list[chroma_types.Embedding],\n    ) -> None:\n        \"\"\"\n        Inserts or updates documents in the collection, based on the provided ids.\n\n        Args:\n            - ids (list[str]): List of ids for the documents to be inserted or updated.\n            - documents (list[str]): List of documents corresponding to the ids.\n            - metadatas (list[Mapping[str, Any]]): List of metadata corresponding to the ids.\n\n        Raises:\n            - ValueError: If the lengths of ids, documents, and metadatas don't match.\n\n        Examples:\n            ```Python\n            # Upsert documents in the collection\n            ids = ['id1', 'id2']\n            documents = ['doc1', 'doc2']\n            metadatas = [{\"meta1\": \"value1\"}, {\"meta2\": \"value2\"}]\n\n            # Upsert documents in the collection\n            collection_manager.upsert_documents(ids, documents, metadatas)\n            ```\n        \"\"\"\n\n        if len(ids) != len(documents) != len(metadatas):\n            raise ValueError(\"The length of ids, documents, and metadatas must match.\")\n\n        logging.info(f\"Upserting collection {self.collection.name} with ids {ids}.\")\n        self.collection.upsert(\n            ids=ids,\n            # embeddings=embeddings,\n            metadatas=metadatas,\n            documents=documents,\n        )\n\n    def delete_embeddings(self, ids: list[str]) -> None:\n        \"\"\"\n        Deletes embeddings from the collection based on the provided ids.\n\n        Args:\n            - ids (list[str]): List of ids corresponding to the embeddings to be deleted.\n\n        Examples:\n            ```Python\n            # Delete specific embeddings by ids\n            ids_to_delete = ['id1', 'id2']\n            collection_manager.delete_embeddings(ids_to_delete)\n            ```\n        \"\"\"\n\n        ids_to_delete: list[str] = ids.copy()\n        for index, id in enumerate(ids_to_delete):\n            if not self.collection.get(id):\n                logging.error(\n                    f\"Id {id} does not exist in collection {self.collection.name}.\"\n                )\n                ids_to_delete.pop(index)\n\n        if not ids_to_delete:\n            logging.warning(\"No IDs given were in the database.\")\n            return None\n\n        logging.info(\n            f\"Deleting embeddings from collection {self.collection.name} with ids {ids_to_delete}.\"\n        )\n        self.collection.delete(ids_to_delete)\n\n    def upsert_models(self, module_models: tuple[ModuleModel, ...]) -> None:\n        \"\"\"\n        Loads or updates the embeddings of the provided module models into the collection.\n\n        The Pydantic models are converted to a dictionary with a format that ChromaDB can use, then the ids, documents, and metadatas\n        are added to their respective lists. The lists are then either added to or updated in the collection depending on whether or\n        not the code blocks were in the the collection to begin with.\n\n        Args:\n            - module_models (tuple[ModuleModel, ...]): The module models to load or update into the collection.\n\n        Examples:\n            ```Python\n            # Upsert module models into the collection\n            module_models = (module_model1, module_model2)\n            collection_manager.upsert_models(module_models)\n            ```\n        \"\"\"\n\n        ids: list[str] = []\n        documents: list[str] = []\n        metadatas: list[Mapping[str, str | int | float | bool]] = []\n\n        for module_model in module_models:\n            if module_model.summary:\n                ids.append(module_model.id)\n                documents.append(module_model.summary)\n                metadatas.append(module_model.convert_to_metadata())\n\n            if module_model.children:\n                for child in module_model.children:\n                    child_data: dict[str, Any] = self._recursively_gather_child_data(\n                        child\n                    )\n                    ids.extend(child_data[\"ids\"])\n                    documents.extend(child_data[\"documents\"])\n                    metadatas.extend(child_data[\"metadatas\"])\n\n        logging.info(\n            f\"{self.collection.name} has {self.collection_embedding_count()} embeddings.\"\n        )\n        self._upsert_documents(ids=ids, documents=documents, metadatas=metadatas)\n        logging.info(\n            f\"After upsert {self.collection.name} has {self.collection_embedding_count()} embeddings.\"\n        )\n\n    def _recursively_gather_child_data(self, model: ModelType) -> dict[str, Any]:\n        ids: list[str] = []\n        documents: list[str] = []\n        metadatas: list[Mapping[str, str | int | float | bool]] = []\n        if model.summary:\n            ids.append(model.id)\n            documents.append(model.summary)\n            metadatas.append(model.convert_to_metadata())\n        else:\n            logging.warning(f\"Child {model.id} has no summary.\")\n        if model.children:\n            for child in model.children:\n                child_data: dict[str, Any] = self._recursively_gather_child_data(child)\n                ids.extend(child_data[\"ids\"])\n                documents.extend(child_data[\"documents\"])\n                metadatas.extend(child_data[\"metadatas\"])\n\n        return {\n            \"ids\": ids,\n            \"documents\": documents,\n            \"metadatas\": metadatas,\n        }\n\n\nImported code block (postcode:updaters:standard_updater.py__*__MODULE) code content:\n# Create method, `update_all`, that updates the whole project, it parses all code, wipes all databases, and summarizes all code blocks,\n# then updates all the databases with the new information.\n\n\nfrom logging import Logger\n\nfrom openai import OpenAI\nfrom postcode.ai_services.summarizer.openai_summarizer import OpenAISummarizer\nfrom postcode.ai_services.summarizer.standard_summarization_manager import (\n    StandardSummarizationManager,\n)\n\nfrom postcode.databases.chroma.setup_chroma import (\n    ChromaSetupReturnContext,\n    setup_chroma,\n)\nfrom postcode.json_management.json_handler import JSONHandler\n\nfrom postcode.models.models import ModuleModel\nfrom postcode.python_parser.visitor_manager.visitor_manager import (\n    VisitorManager,\n    VisitorManagerProcessFilesReturn,\n)\n\n\nclass StandardUpdater:\n    @staticmethod\n    def update_all(\n        directory: str, output_directory: str, logger: Logger\n    ) -> ChromaSetupReturnContext:\n        visitor_manager = VisitorManager(directory, output_directory)\n        process_files_return: VisitorManagerProcessFilesReturn = (\n            visitor_manager.process_files()\n        )\n\n        module_models_tuple: tuple[ModuleModel, ...] = process_files_return.models_tuple\n        client = OpenAI(max_retries=4)\n        summarizer = OpenAISummarizer(client=client)\n        summarization_manager = StandardSummarizationManager(\n            module_models_tuple, summarizer\n        )\n        finalized_module_models: tuple[\n            ModuleModel, ...\n        ] = summarization_manager.create_summarizes_and_return_updated_models()\n\n        logger.info(\"Summarization complete\")\n\n        logger.info(\"Saving models as JSON\")\n        directory_modules: dict[str, list[str]] = process_files_return.directory_modules\n        json_manager = JSONHandler(directory, directory_modules, output_directory)\n\n        for module_model in module_models_tuple:\n            json_manager.save_model_as_json(module_model, module_model.file_path)\n\n        json_manager.save_visited_directories()\n        logger.info(\"JSON save complete\")\n\n        logger.info(\"Directory parsing completed.\")\n\n        chroma_context: ChromaSetupReturnContext = setup_chroma(\n            finalized_module_models, logger\n        )\n\n        return chroma_context\n\n, \nimport logging\nfrom logging import Logger\nfrom typing import Union\nfrom chromadb.api.types import QueryResult\nfrom chromadb import Collection\n        ", "children": "postcode:app.py__*__MODULE__*__STANDALONE_BLOCK-1\npostcode:app.py__*__MODULE__*__FUNCTION-query_chroma\npostcode:app.py__*__MODULE__*__FUNCTION-main\n", "file_path": "postcode/app.py", "docstring": "None", "header": "{\"file_path\":\"postcode/app.py\",\"docstring\":null,\"header\":[],\"footer\":[],\"imports\":[{\"import_names\":[{\"name\":\"logging\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":null,\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"Logger\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"logging\",\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"Union\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"typing\",\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"QueryResult\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"chromadb.api.types\",\"import_module_type\":\"THIRD_PARTY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"Collection\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"chromadb\",\"import_module_type\":\"THIRD_PARTY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"},{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ClassModel\"},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-FunctionModel\"},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-StandaloneCodeBlockModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ChromaSetupReturnContext\",\"as_name\":null,\"local_block_id\":\"postcode:databases:chroma:setup_chroma.py__*__MODULE__*__CLASS-ChromaSetupReturnContext\"}],\"imported_from\":\"postcode.databases.chroma.setup_chroma\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:databases:chroma:setup_chroma.py__*__MODULE\"},{\"import_names\":[{\"name\":\"GraphDBUpdater\",\"as_name\":null,\"local_block_id\":\"postcode:updaters:graph_db_updater.py__*__MODULE__*__CLASS-GraphDBUpdater\"}],\"imported_from\":\"postcode.updaters.graph_db_updater\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:updaters:graph_db_updater.py__*__MODULE\"},{\"import_names\":[{\"name\":\"setup_logging\",\"as_name\":null,\"local_block_id\":\"postcode:utilities:logger:logging_config.py__*__MODULE__*__FUNCTION-setup_logging\"}],\"imported_from\":\"postcode.utilities.logger.logging_config\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:utilities:logger:logging_config.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ChromaDBCollectionManager\",\"as_name\":null,\"local_block_id\":\"postcode:databases:chroma:chromadb_collection_manager.py__*__MODULE__*__CLASS-ChromaDBCollectionManager\"}],\"imported_from\":\"postcode.databases.chroma.chromadb_collection_manager\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:databases:chroma:chromadb_collection_manager.py__*__MODULE\"},{\"import_names\":[{\"name\":\"StandardUpdater\",\"as_name\":null,\"local_block_id\":\"postcode:updaters:standard_updater.py__*__MODULE__*__CLASS-StandardUpdater\"}],\"imported_from\":\"postcode.updaters.standard_updater\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:updaters:standard_updater.py__*__MODULE\"}],\"id\":\"postcode:app.py__*__MODULE\",\"parent_id\":null,\"block_type\":\"MODULE\",\"start_line_num\":1,\"end_line_num\":87,\"code_content\":\"import logging\\nfrom logging import Logger\\nfrom typing import Union\\n\\nfrom postcode.models.models import (\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n)\\n\\nfrom postcode.databases.chroma.setup_chroma import (\\n    ChromaSetupReturnContext,\\n)\\nfrom postcode.updaters.graph_db_updater import GraphDBUpdater\\n\\nModelType = Union[\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n]\\n\\nfrom postcode.utilities.logger.logging_config import setup_logging\\n\\nfrom postcode.databases.chroma.chromadb_collection_manager import (\\n    ChromaDBCollectionManager,\\n)\\n\\nfrom chromadb.api.types import (\\n    QueryResult,\\n)\\nfrom chromadb import Collection\\n\\nfrom postcode.updaters.standard_updater import StandardUpdater\\n\\n\\ndef query_chroma(\\n    query: str,\\n    chroma_collection_manager: ChromaDBCollectionManager,\\n    chroma_collection: Collection,\\n    logger: Logger,\\n) -> None:\\n    logger.info(f\\\"Querying ChromaDB collection {chroma_collection.name}\\\")\\n    results: QueryResult | None = chroma_collection_manager.query_collection(\\n        [query],\\n        n_results=10,\\n        # where_filter={\\\"block_type\\\": \\\"MODULE\\\"},\\n        include_in_result=[\\\"metadatas\\\", \\\"documents\\\", \\\"embeddings\\\"],\\n    )\\n    logger.info(\\\"Query results:\\\")\\n    if results:\\n        if results[\\\"ids\\\"]:\\n            for document in results[\\\"ids\\\"][0]:\\n                print(document)\\n\\n            print(f\\\"Total results: {len(results['ids'][0])}\\\")\\n\\n\\ndef main(\\n    directory: str = \\\".\\\",\\n    output_directory: str = \\\"output_json\\\",\\n) -> None:\\n    setup_logging()\\n    logger: Logger = logging.getLogger(__name__)\\n\\n    #   ==================== GraphDB ====================\\n    graph_db_updater = GraphDBUpdater(directory, output_directory, logger)\\n    chroma_context: ChromaSetupReturnContext = graph_db_updater.update_all(\\n        directory, output_directory, logger\\n    )\\n    # ==================== End GraphDB ====================\\n\\n    #   ==================== Standard ====================\\n    # chroma_context: ChromaSetupReturnContext = StandardUpdater.update_all(\\n    #     directory, output_directory, logger\\n    # )\\n    # ==================== End Standard ====================\\n\\n    query: str = \\\"summarizes code block\\\"\\n    query_chroma(\\n        query,\\n        chroma_context.chroma_collection_manager,\\n        chroma_context.chroma_collection,\\n        logger,\\n    )\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":\"\\nSummary:\\n\\n        postcode:app.py__*__MODULE\\n\\n        \\nChild (postcode:app.py__*__MODULE__*__STANDALONE_BLOCK-1) code content:\\nModelType = Union[\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n]\\n\\n\\nChild (postcode:app.py__*__MODULE__*__FUNCTION-query_chroma) code content:\\n\\n\\ndef query_chroma(\\n    query: str,\\n    chroma_collection_manager: ChromaDBCollectionManager,\\n    chroma_collection: Collection,\\n    logger: Logger,\\n) -> None:\\n    logger.info(f\\\"Querying ChromaDB collection {chroma_collection.name}\\\")\\n    results: QueryResult | None = chroma_collection_manager.query_collection(\\n        [query],\\n        n_results=10,\\n        # where_filter={\\\"block_type\\\": \\\"MODULE\\\"},\\n        include_in_result=[\\\"metadatas\\\", \\\"documents\\\", \\\"embeddings\\\"],\\n    )\\n    logger.info(\\\"Query results:\\\")\\n    if results:\\n        if results[\\\"ids\\\"]:\\n            for document in results[\\\"ids\\\"][0]:\\n                print(document)\\n\\n            print(f\\\"Total results: {len(results['ids'][0])}\\\")\\n\\n\\nChild (postcode:app.py__*__MODULE__*__FUNCTION-main) code content:\\n\\n\\ndef main(\\n    directory: str = \\\".\\\",\\n    output_directory: str = \\\"output_json\\\",\\n) -> None:\\n    setup_logging()\\n    logger: Logger = logging.getLogger(__name__)\\n\\n    #   ==================== GraphDB ====================\\n    graph_db_updater = GraphDBUpdater(directory, output_directory, logger)\\n    chroma_context: ChromaSetupReturnContext = graph_db_updater.update_all(\\n        directory, output_directory, logger\\n    )\\n    # ==================== End GraphDB ====================\\n\\n    #   ==================== Standard ====================\\n    # chroma_context: ChromaSetupReturnContext = StandardUpdater.update_all(\\n    #     directory, output_directory, logger\\n    # )\\n    # ==================== End Standard ====================\\n\\n    query: str = \\\"summarizes code block\\\"\\n    query_chroma(\\n        query,\\n        chroma_context.chroma_collection_manager,\\n        chroma_context.chroma_collection,\\n        logger,\\n    )\\n\\n, \\nImported code block (postcode:models:models.py__*__MODULE) code content:\\nfrom typing import Union\\nfrom pydantic import BaseModel, Field, validator\\n\\nfrom postcode.models.enums import (\\n    BlockType,\\n    ImportModuleType,\\n    CommentType,\\n)\\n\\n\\nclass ImportNameModel(BaseModel):\\n    \\\"\\\"\\\"Class representing the name of an import.\\\"\\\"\\\"\\n\\n    name: str\\n    as_name: str | None = None\\n    local_block_id: str | None = None\\n\\n    # def convert_import_names_to_metadata(self) -> str:\\n    #     \\\"\\\"\\\"Converts the import name to a metadata string.\\\"\\\"\\\"\\n\\n    #     return self.model_dump_json()\\n\\n\\nclass ImportModel(BaseModel):\\n    \\\"\\\"\\\"Class representing an import statement.\\\"\\\"\\\"\\n\\n    import_names: list[ImportNameModel]\\n    imported_from: str | None = None\\n    import_module_type: ImportModuleType = ImportModuleType.STANDARD_LIBRARY\\n    local_module_id: str | None = None\\n\\n    def convert_import_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the import to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass DependencyModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a module dependency.\\\"\\\"\\\"\\n\\n    code_block_id: str\\n\\n    def convert_dependency_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the dependency to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass CommentModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a comment.\\\"\\\"\\\"\\n\\n    content: str\\n    comment_types: list[CommentType]\\n\\n    def convert_comment_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the comment to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass DecoratorModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a decorator.\\\"\\\"\\\"\\n\\n    content: str\\n    decorator_name: str\\n    decorator_args: list[str] | None = None\\n\\n    def convert_decorator_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the decorator to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass ClassKeywordModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a class keyword.\\\"\\\"\\\"\\n\\n    content: str\\n    keyword_name: str\\n    args: str | None = None\\n\\n    def convert_class_keyword_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the class keyword to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass ParameterModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a function parameter.\\\"\\\"\\\"\\n\\n    content: str\\n\\n\\nclass ParameterListModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a list of parameters.\\\"\\\"\\\"\\n\\n    params: list[ParameterModel] | None = None\\n    star_arg: ParameterModel | None = None\\n    kwonly_params: list[ParameterModel] | None = None\\n    star_kwarg: ParameterModel | None = None\\n    posonly_params: list[ParameterModel] | None = None\\n\\n    def convert_parameters_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the parameter list to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass BaseCodeBlockModel(BaseModel):\\n    \\\"\\\"\\\"Attributes common to all code block models.\\\"\\\"\\\"\\n\\n    id: str\\n    parent_id: str | None = None\\n    block_type: BlockType\\n    start_line_num: int\\n    end_line_num: int\\n    code_content: str = \\\"\\\"\\n    important_comments: list[CommentModel] | None = None\\n    dependencies: list[ImportModel | DependencyModel] | None = None\\n    summary: str | None = None\\n    children: list[\\n        Union[\\n            \\\"ClassModel\\\",\\n            \\\"FunctionModel\\\",\\n            \\\"StandaloneCodeBlockModel\\\",\\n        ]\\n    ] | None = []\\n\\n    @validator(\\\"parent_id\\\", always=True)\\n    def check_parent_id(cls, v, values, **kwargs) -> str | None:\\n        \\\"\\\"\\\"Validates that parent_id is a non-empty string unless block_type is MODULE.\\\"\\\"\\\"\\n\\n        if \\\"block_type\\\" in values and values[\\\"block_type\\\"] != BlockType.MODULE:\\n            if len(v) < 1:\\n                raise ValueError(\\\"parent_id is required!\\\")\\n        return v\\n\\n    def _convert_parent_id_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the parent_id to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.parent_id}\\\" if self.parent_id else \\\"\\\"\\n\\n    def _convert_block_type_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the block_type to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.block_type.name}\\\"\\n\\n    def _convert_important_comments_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the important comments to a metadata string.\\\"\\\"\\\"\\n\\n        important_comments: str = (\\n            self.model_dump_json() if self.important_comments else \\\"\\\"\\n        )\\n\\n        return f\\\"{important_comments}\\\"\\n\\n    def _convert_dependencies_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the dependencies to a metadata string.\\\"\\\"\\\"\\n\\n        dependencies_str: str = \\\"\\\"\\n\\n        if self.dependencies:\\n            for dependency in self.dependencies:\\n                if isinstance(dependency, ImportModel):\\n                    dependencies_str += f\\\"{dependency.convert_import_to_metadata()}\\\\n\\\"\\n                elif isinstance(dependency, DependencyModel):\\n                    dependencies_str += (\\n                        f\\\"{dependency.convert_dependency_to_metadata()}\\\\n\\\"\\n                    )\\n\\n        return dependencies_str\\n\\n    def _convert_summary_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the summary to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.summary}\\\" if self.summary else \\\"\\\"\\n\\n    def _convert_children_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the children to a metadata string.\\\"\\\"\\\"\\n\\n        children_str: str = \\\"\\\"\\n\\n        if self.children:\\n            for child in self.children:\\n                children_str += f\\\"{child.id}\\\\n\\\"\\n\\n        return children_str\\n\\n    def _convert_base_attributes_to_metadata_dict(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the base attributes to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            \\\"id\\\": self.id,\\n            \\\"parent_id\\\": self._convert_parent_id_to_metadata(),\\n            \\\"block_type\\\": self._convert_block_type_to_metadata(),\\n            \\\"start_line_num\\\": self.start_line_num,\\n            \\\"end_line_num\\\": self.end_line_num,\\n            \\\"code_content\\\": self.code_content,\\n            \\\"important_comments\\\": self._convert_important_comments_to_metadata(),\\n            \\\"dependencies\\\": self._convert_dependencies_to_metadata(),\\n            \\\"summary\\\": self._convert_summary_to_metadata(),\\n            \\\"children\\\": self._convert_children_to_metadata(),\\n        }\\n\\n\\nclass ModuleSpecificAttributes(BaseModel):\\n    \\\"\\\"\\\"Module specific attributes.\\\"\\\"\\\"\\n\\n    file_path: str = Field(min_length=1)\\n    docstring: str | None = None\\n    header: list[str] | None = None\\n    footer: list[str] | None = None\\n    imports: list[ImportModel] | None = None\\n\\n    def _convert_docstring_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the docstring to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.docstring}\\\"\\n\\n    def _convert_header_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the header and footer to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n    def _convert_footer_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the header and footer to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n    def _convert_imports_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the imports to a metadata string.\\\"\\\"\\\"\\n        imports_str: str = self.model_dump_json() if self.imports else \\\"\\\"\\n        return f\\\"{imports_str}\\\"\\n\\n    def _convert_module_attributes_to_metadata_dict(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the module attributes to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            \\\"file_path\\\": self.file_path,\\n            \\\"docstring\\\": self._convert_docstring_to_metadata(),\\n            \\\"header\\\": self._convert_header_to_metadata(),\\n            \\\"footer\\\": self._convert_footer_to_metadata(),\\n            \\\"imports\\\": self._convert_imports_to_metadata(),\\n        }\\n\\n\\nclass ModuleModel(BaseCodeBlockModel, ModuleSpecificAttributes):\\n    \\\"\\\"\\\"Model for a module.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the module model to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_module_attributes_to_metadata_dict(),\\n        }\\n\\n\\nclass ClassSpecificAttributes(BaseModel):\\n    \\\"\\\"\\\"Class specific attributes.\\\"\\\"\\\"\\n\\n    class_name: str = Field(min_length=1)\\n    decorators: list[DecoratorModel] | None = None\\n    bases: list[str] | None = None\\n    docstring: str | None = None\\n    keywords: list[ClassKeywordModel] | None = None\\n    # attributes: list[dict] | None = None\\n\\n    def _convert_decorators_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the decorators to a metadata string.\\\"\\\"\\\"\\n        decorators_str: str = self.model_dump_json() if self.decorators else \\\"\\\"\\n        return f\\\"{decorators_str}\\\"\\n\\n    def _convert_bases_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the bases to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json() if self.bases else \\\"\\\"\\n\\n    def _convert_docstring_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the docstring to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.docstring}\\\" if self.docstring else \\\"\\\"\\n\\n    def _convert_keywords_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the keywords to a metadata string.\\\"\\\"\\\"\\n        keywords_str: str = self.model_dump_json() if self.keywords else \\\"\\\"\\n        return f\\\"{keywords_str}\\\"\\n\\n    def _convert_class_attributes_to_metadata_dict(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the class attributes to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            \\\"class_name\\\": self.class_name,\\n            \\\"decorators\\\": self._convert_decorators_to_metadata(),\\n            \\\"bases\\\": self._convert_bases_to_metadata(),\\n            \\\"docstring\\\": self._convert_docstring_to_metadata(),\\n            \\\"keywords\\\": self._convert_keywords_to_metadata(),\\n        }\\n\\n\\nclass ClassModel(BaseCodeBlockModel, ClassSpecificAttributes):\\n    \\\"\\\"\\\"Model for a class.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the class model to a metadata dictionary.\\\"\\\"\\\"\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_class_attributes_to_metadata_dict(),\\n        }\\n\\n\\nclass FunctionSpecificAttributes(BaseModel):\\n    \\\"\\\"\\\"Function specific attributes.\\\"\\\"\\\"\\n\\n    function_name: str = Field(min_length=1)\\n    docstring: str | None = None\\n    decorators: list[DecoratorModel] | None = None\\n    parameters: ParameterListModel | None = None\\n    returns: str | None = None\\n    is_method: bool = False\\n    is_async: bool = False\\n\\n    def _convert_docstring_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the docstring to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.docstring}\\\" if self.docstring else \\\"\\\"\\n\\n    def _convert_decorators_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the decorators to a metadata string.\\\"\\\"\\\"\\n        decorators_str: str = self.model_dump_json() if self.decorators else \\\"\\\"\\n        return f\\\"{decorators_str}\\\"\\n\\n    def _convert_parameters_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the parameters to a metadata string.\\\"\\\"\\\"\\n        return (\\n            self.parameters.convert_parameters_to_metadata() if self.parameters else \\\"\\\"\\n        )\\n\\n    def _convert_returns_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the returns to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.returns}\\\" if self.returns else \\\"\\\"\\n\\n    def _convert_function_attributes_to_metadata_dict(self) -> dict[str, str | bool]:\\n        \\\"\\\"\\\"Converts the function attributes to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            \\\"function_name\\\": self.function_name,\\n            \\\"docstring\\\": self._convert_docstring_to_metadata(),\\n            \\\"decorators\\\": self._convert_decorators_to_metadata(),\\n            \\\"parameters\\\": self._convert_parameters_to_metadata(),\\n            \\\"returns\\\": self._convert_returns_to_metadata(),\\n            \\\"is_method\\\": self.is_method,\\n            \\\"is_async\\\": self.is_async,\\n        }\\n\\n\\nclass FunctionModel(BaseCodeBlockModel, FunctionSpecificAttributes):\\n    \\\"\\\"\\\"Model for a function.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the function model to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_function_attributes_to_metadata_dict(),\\n        }\\n\\n\\nclass StandaloneCodeBlockSpecificAttributes(BaseModel):\\n    \\\"\\\"\\\"Standalone code block specific attributes.\\\"\\\"\\\"\\n\\n    variable_assignments: list[str] | None = None\\n\\n    def _convert_variable_assignments_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the variable assignments to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json() if self.variable_assignments else \\\"\\\"\\n\\n    def _convert_standalone_block_attributes_to_metadata_dict(\\n        self,\\n    ) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the standalone code block attributes to a metadata dictionary.\\\"\\\"\\\"\\n        return {\\n            \\\"variable_assignments\\\": self._convert_variable_assignments_to_metadata(),\\n        }\\n\\n\\nclass StandaloneCodeBlockModel(\\n    BaseCodeBlockModel, StandaloneCodeBlockSpecificAttributes\\n):\\n    \\\"\\\"\\\"Model for a standalone code block.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the standalone code block model to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_standalone_block_attributes_to_metadata_dict(),\\n        }\\n\\n\\nImported code block (postcode:databases:chroma:setup_chroma.py__*__MODULE) code content:\\nfrom dataclasses import dataclass\\nfrom logging import Logger\\n\\nimport chromadb\\nfrom postcode.databases.chroma.chromadb_client_manager import ChromaDBClientManager\\n\\nfrom postcode.databases.chroma.chromadb_collection_manager import (\\n    ChromaDBCollectionManager,\\n)\\n\\nfrom chromadb.config import DEFAULT_DATABASE, DEFAULT_TENANT, Settings\\nfrom chromadb.api import ClientAPI\\nfrom chromadb.api.types import (\\n    DataLoader,\\n    CollectionMetadata,\\n    GetResult,\\n    QueryResult,\\n    Where,\\n    WhereDocument,\\n    Include,\\n    URIs,\\n    Loadable,\\n    Metadata,\\n    Embedding,\\n)\\nfrom chromadb import Collection\\nfrom chromadb import EmbeddingFunction\\n\\nfrom postcode.models.models import ModuleModel\\n\\n\\n@dataclass\\nclass ChromaSetupReturnContext:\\n    \\\"\\\"\\\"\\n    Represents the return value of the ChromaDB setup method.\\n\\n    Attributes:\\n        - chroma_collection_manager (ChromaDBCollectionManager): The ChromaDB collection manager.\\n        - chroma_collection (Collection): The ChromaDB collection.\\n    \\\"\\\"\\\"\\n\\n    chroma_collection_manager: ChromaDBCollectionManager\\n    chroma_collection: Collection\\n\\n\\ndef setup_chroma(\\n    module_models: list[ModuleModel], logger: Logger\\n) -> ChromaSetupReturnContext:\\n    chroma_settings = Settings(allow_reset=True)\\n    chroma_client: ClientAPI = chromadb.PersistentClient(settings=chroma_settings)\\n    chroma_client_manager = ChromaDBClientManager(chroma_client)\\n\\n    logger.debug(f\\\"Resetting Chroma client\\\")\\n    if chroma_client_manager.reset_client():\\n        logger.debug(\\\"Client reset\\\")\\n\\n    chroma_collection: Collection = chroma_client_manager.get_or_create_collection(\\n        \\\"postcode\\\"\\n    )\\n\\n    chroma_collection_manager = ChromaDBCollectionManager(chroma_collection)\\n    chroma_collection_manager.upsert_models(tuple(module_models))\\n\\n    return ChromaSetupReturnContext(chroma_collection_manager, chroma_collection)\\n\\n\\nImported code block (postcode:updaters:graph_db_updater.py__*__MODULE) code content:\\nfrom logging import Logger\\n\\nfrom openai import OpenAI\\nfrom postcode.ai_services.summarizer.graph_db_summarization_manager import (\\n    GraphDBSummarizationManager,\\n)\\nfrom postcode.ai_services.summarizer.openai_summarizer import OpenAISummarizer\\nfrom postcode.ai_services.summarizer.summarization_mapper import SummarizationMapper\\nfrom postcode.databases.arangodb.arangodb_connector import ArangoDBConnector\\n\\nfrom postcode.databases.arangodb.arangodb_manager import ArangoDBManager\\nfrom postcode.databases.chroma.setup_chroma import (\\n    ChromaSetupReturnContext,\\n    setup_chroma,\\n)\\nfrom postcode.json_management.json_handler import JSONHandler\\nfrom postcode.models.models import ModuleModel\\nfrom postcode.python_parser.visitor_manager.visitor_manager import (\\n    VisitorManager,\\n    VisitorManagerProcessFilesReturn,\\n)\\n\\n\\nclass GraphDBUpdater:\\n    def __init__(\\n        self,\\n        directory: str,\\n        output_directory: str,\\n        logger: Logger,\\n        arango_connector: ArangoDBConnector = ArangoDBConnector(),\\n    ) -> None:\\n        self.directory: str = directory\\n        self.output_directory: str = output_directory\\n        self.logger: Logger = logger\\n        self.arango_connector: ArangoDBConnector = arango_connector\\n\\n        self.arango_connector.delete_all_collections()\\n        self.arango_connector.ensure_collections()\\n        self.graph_manager = ArangoDBManager(arango_connector)\\n\\n    def update_all(\\n        self,\\n        directory: str,\\n        output_directory: str,\\n        logger: Logger,\\n    ) -> ChromaSetupReturnContext:\\n        logger.info(\\\"Starting the directory parsing.\\\")\\n\\n        visitor_manager = VisitorManager(directory, output_directory)\\n        process_files_return: VisitorManagerProcessFilesReturn = (\\n            visitor_manager.process_files()\\n        )\\n\\n        module_models_tuple: tuple[ModuleModel, ...] = process_files_return.models_tuple\\n        module_ids: list[str] = [model.id for model in module_models_tuple]\\n        directory_modules: dict[str, list[str]] = process_files_return.directory_modules\\n        self.graph_manager.upsert_models(\\n            list(module_models_tuple)\\n        ).process_imports_and_dependencies().get_or_create_graph()\\n        summarization_mapper = SummarizationMapper(\\n            module_ids, module_models_tuple, self.graph_manager\\n        )\\n        client = OpenAI(max_retries=4)\\n        summarizer = OpenAISummarizer(client=client)\\n        summarization_manager = GraphDBSummarizationManager(\\n            module_models_tuple, summarization_mapper, summarizer, self.graph_manager\\n        )\\n        finalized_module_models: list[\\n            ModuleModel\\n        ] | None = summarization_manager.create_summaries_and_return_updated_models()\\n        logger.info(\\\"Summarization complete\\\")\\n\\n        logger.info(\\\"Saving models as JSON\\\")\\n        json_manager = JSONHandler(directory, directory_modules, output_directory)\\n\\n        for module_model in module_models_tuple:\\n            json_manager.save_model_as_json(module_model, module_model.file_path)\\n\\n        json_manager.save_visited_directories()\\n        logger.info(\\\"JSON save complete\\\")\\n\\n        logger.info(\\\"Directory parsing completed.\\\")\\n\\n        # self.graph_manager.upsert_models(\\n        #     list(finalized_module_models)\\n        # ).process_imports_and_dependencies().get_or_create_graph()\\n\\n        if finalized_module_models:\\n            chroma_context: ChromaSetupReturnContext = setup_chroma(\\n                finalized_module_models, logger\\n            )\\n        else:\\n            raise Exception(\\\"No finalized models returned from summarization.\\\")\\n\\n        return chroma_context\\n\\n\\nImported code block (postcode:utilities:logger:logging_config.py__*__MODULE) code content:\\nimport logging\\n\\nfrom rich.logging import RichHandler\\nfrom rich.syntax import Syntax\\n\\n\\ndef setup_logging(level=logging.INFO) -> None:\\n    \\\"\\\"\\\"\\n    Configures the logging system to use RichSyntaxHandler for output.\\n\\n    This function sets up logging with a specific log level and format. It utilizes the RichSyntaxHandler to support rich text and syntax highlighting in log outputs.\\n\\n    Args:\\n        level (int, optional): The logging level to set for the root logger. Defaults to logging.INFO.\\n\\n    Example:\\n        >>> setup_logging(logging.DEBUG)\\n        # Configures logging at DEBUG level with RichSyntaxHandler.\\n    \\\"\\\"\\\"\\n\\n    format_str = \\\"%(message)s\\\"\\n    logging.basicConfig(level=level, format=format_str, handlers=[RichSyntaxHandler()])\\n\\n\\nclass RichSyntaxHandler(RichHandler):\\n    \\\"\\\"\\\"\\n    A custom logging handler that extends RichHandler to add syntax highlighting.\\n\\n    This handler checks if the log record contains a 'syntax_highlight' attribute and, if so, uses 'rich.syntax.Syntax' to render the message with Python syntax highlighting.\\n\\n    Inherits:\\n        RichHandler: The base handler provided by the rich library for rich text formatting.\\n    \\\"\\\"\\\"\\n\\n    def emit(self, record) -> None:\\n        \\\"\\\"\\\"\\n        Emits a logging record.\\n\\n        If the record has the 'syntax_highlight' attribute set to True, it renders the 'content' attribute of the record with syntax highlighting. Otherwise, it falls back to the standard behavior of RichHandler.\\n\\n        Args:\\n            record: The logging record to emit.\\n\\n        Example:\\n            # Assuming `logger` is a logger instance\\n            >>> logger.info(\\\"Regular log message\\\")\\n            # Outputs a regular log message.\\n\\n            >>> logger.info(\\\"Highlighted log message\\\", extra={\\\"syntax_highlight\\\": True, \\\"content\\\": \\\"print('Hello, world!')\\\"})\\n            # Outputs the message with syntax highlighting.\\n        \\\"\\\"\\\"\\n\\n        try:\\n            if hasattr(record, \\\"syntax_highlight\\\") and getattr(\\n                record, \\\"syntax_highlight\\\"\\n            ):\\n                content: str = getattr(record, \\\"content\\\", \\\"\\\")\\n                if isinstance(content, str):\\n                    syntax = Syntax(\\n                        content, \\\"python\\\", theme=\\\"material\\\", line_numbers=True\\n                    )\\n                    self.console.print(syntax)\\n                return\\n\\n        except Exception as e:\\n            self.handleError(record)\\n\\n        super().emit(record)\\n\\n\\nImported code block (postcode:databases:chroma:chromadb_collection_manager.py__*__MODULE) code content:\\nimport logging\\nfrom typing import Any, Mapping, Union\\n\\nfrom postcode.models.models import ModuleModel\\nimport postcode.types.chroma as chroma_types\\nfrom chromadb.config import DEFAULT_DATABASE, DEFAULT_TENANT, Settings\\nfrom chromadb.api import ClientAPI\\nfrom chromadb.api.types import (\\n    DataLoader,\\n    CollectionMetadata,\\n    GetResult,\\n    QueryResult,\\n    Where,\\n    WhereDocument,\\n    Include,\\n    URIs,\\n    Loadable,\\n    Metadata,\\n    Embedding,\\n)\\nfrom chromadb import Collection\\nfrom chromadb import EmbeddingFunction\\n# from postcode.types.postcode import ModelType\\nfrom postcode.models.models import ModuleModel, ClassModel, FunctionModel, StandaloneCodeBlockModel\\nModelType = Union[\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n]\\n\\n\\nclass ChromaDBCollectionManager:\\n    \\\"\\\"\\\"\\n    Manages a collection within ChromaDB instance, providing functionalities for adding, retrieving,\\n    and querying embeddings, and their associated metadata.\\n\\n    This class serves as an interface to interact with a specific collection in ChromaDB.\\n\\n    Attributes:\\n        - collection (chroma_types.Collection): An instance of the Collection class from ChromaDB\\n            which this manager is responsible for.\\n\\n    Methods:\\n        - `collection_embedding_count`: Gets the total number of embeddings in the collection.\\n        - `add_embeddings`: Adds embeddings to the collection.\\n        - `get_embeddings`: Gets embeddings and their metadata from the collection in the form of a TypedDict.\\n        - `query_collection`: Queries and returns the `n` nearest neighbors from the collection.\\n        - `upsert_models`: Loads or updates the embeddings of the provided module models into the collection.\\n\\n    Examples:\\n        ```Python\\n        from postcode.databases.chroma import ChromaDBClientBuilder\\n        import postcode.types.chromadb.types as chroma_types\\n\\n        # Create a persistent ChromaDB client\\n        client: chroma_types.ClientAPI = ChromaDBClientBuilder.create_persistent_client()\\n\\n        # Instantiate the ChromaDBCollectionManager with a specific collection\\n        collection_manager: ChromaDBCollectionManager = (\\n            ChromaDBCollectionManager(client.get_collection(\\\"my_collection\\\"))\\n        )\\n\\n        # Example usage of the collection manager\\n        embedding_count: int = collection_manager.collection_embedding_count()\\n        print(f\\\"Total embeddings: {embedding_count}\\\")\\n        ```\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, collection: Collection) -> None:\\n        self.collection: Collection = collection\\n\\n    def collection_embedding_count(self) -> int | None:\\n        \\\"\\\"\\\"\\n        Gets the total number of embeddings in the collection.\\n\\n        Returns:\\n            - embedding_count (int): The total number of embeddings in the collection.\\n\\n        Examples:\\n            ```Python\\n            embedding_count: int = collection_manager.get_collection_embedding_count()\\n            ```\\n        \\\"\\\"\\\"\\n        try:\\n            embedding_count: int = self.collection.count()\\n            logging.info(\\n                f\\\"Collection {self.collection.name} has {embedding_count} embeddings.\\\"\\n            )\\n            return embedding_count\\n        except Exception as exception:\\n            logging.error(exception)\\n\\n    def add_embeddings(\\n        self,\\n        ids: list[str],\\n        documents: list[str],\\n        metadatas: list[Mapping[str, str | int | float | bool]],\\n    ) -> None:\\n        \\\"\\\"\\\"\\n        Adds embeddings to the collection.\\n\\n        Args:\\n            - ids (list[str]): A list of ids to add to the collection.\\n            - documents (list[str]): A list of documents to add to the collection.\\n            - metadatas (list[dict[str, Any]]): A list of metadatas to add to the collection.\\n\\n        Raises:\\n            - ValueError - If you don't provide either embeddings or documents.\\n            - ValueError: If the length of ids, embeddings, metadatas, or documents don't match.\\n            - ValueError - If you provide an id that already exists.\\n\\n        Examples:\\n            ```Python\\n            # define the ids, metadatas, and documents to add to the collection\\n            id: list[str] = [\\\"my_id\\\", \\\"my_id2\\\"]\\n            metadatas: list[dict[str, Any]] = [\\n                {\\\"my_metadata\\\": \\\"my_metadata_value\\\"},\\n                {\\\"my_metadata2\\\": \\\"my_metadata_value2\\\"},\\n            ]\\n            documents: list[str] = [\\\"my_document\\\", \\\"my_document2\\\"]\\n\\n            # add the embeddings to the collection\\n            collection_manager.add_embeddings(id, metadatas, documents)\\n            ```\\n        \\\"\\\"\\\"\\n\\n        if not len(ids) == len(documents) == len(metadatas):\\n            raise ValueError(\\\"The length of ids, documents, and metadatas must match.\\\")\\n\\n        try:\\n            logging.info(f\\\"Adding embeddings to collection {self.collection.name}\\\")\\n            self.collection.add(ids, documents=documents, metadatas=metadatas)\\n        except Exception as exception:\\n            raise exception\\n\\n    def get_embeddings(\\n        self,\\n        ids: list[str] | None,\\n        *,\\n        where_filter: Where | None = None,\\n        limit: int | None = None,\\n        where_document_filter: WhereDocument | None = None,\\n        include_in_result: Include = [\\\"metadatas\\\", \\\"documents\\\"],\\n    ) -> GetResult | None:\\n        \\\"\\\"\\\"\\n        Gets embeddings and their metadata from the collection in the form of a TypedDict.\\n\\n        Args:\\n            - ids (list[str]): A list of ids to get from the collection.\\n            - where_filter (chroma_types.Where | None): A TypedDict used to filter the results.\\n            - limit (int | None): The maximum number of results to return.\\n            - where_document_filter (chroma_types.WhereDocument | None): A TypedDict used to filter the results by the document,\\n                e.g. `{$contains: {\\\"text\\\": \\\"hello\\\"}}`\\n            - include_in_result (chroma_types.Include | None): A list used of what to return from the results, e.g. `[\\\"metadatas\\\", \\\"embeddings\\\", \\\"documents\\\"]`\\n\\n        Returns:\\n            - embeddings (TypedDict): A typed dict of embedding data from the collection with the following keys:\\n                - ids: list[str]\\n                - embeddings: list[Embedding] | None\\n                - documents: list[str] | None\\n                - uris: chroma_types.URIs | None\\n                - data: chroma_types.Loadable | None\\n                - metadatas: list[chroma_types.Metadata]]\\n\\n        Raises:\\n            - ValueError: If the length of ids, embeddings, metadatas, or documents don't match.\\n            - ValueError: If you provide an id that doesn't exist.\\n\\n        Examples:\\n            ```Python\\n            import postcode.types.chromadb.types as chroma_types\\n\\n            # define the ids, filters to use to get embeddings from the collection\\n            ids: list[str] = [\\\"my_id\\\", \\\"my_id2\\\"]\\n            where_filter: chroma_types.Where = {\\\"my_metadata\\\": \\\"my_metadata_value\\\"}\\n            where_document_filter: chroma_types.WhereDocument = {\\\"$contains\\\": {\\\"text\\\": \\\"hello\\\"}}\\n\\n            # define the data to return from the collection\\n            include_in_result: chroma_types.Include = [\\\"metadatas\\\"]\\n\\n            # get the embeddings from the collection\\n            embeddings: chroma_types.GetResult = collection_manager.get_embeddings(\\n                ids,\\n                where_filter=where_filter,\\n                where_document_filter=where_document_filter,\\n                include_in_result=include_in_result\\n                )\\n            ```\\n        \\\"\\\"\\\"\\n\\n        try:\\n            logging.info(f\\\"Getting embeddings from collection {self.collection.name}\\\")\\n            return self.collection.get(\\n                ids,\\n                where=where_filter,\\n                limit=limit,\\n                where_document=where_document_filter,\\n                include=include_in_result,\\n            )\\n        except Exception as exception:\\n            raise exception\\n\\n    def query_collection(\\n        self,\\n        queries: list[str],\\n        n_results: int = 10,\\n        where_filter: Where | None = None,\\n        where_document_filter: WhereDocument | None = None,\\n        include_in_result: Include = [\\\"metadatas\\\", \\\"documents\\\"],\\n    ) -> QueryResult | None:\\n        \\\"\\\"\\\"\\n        Queries and returns the `n` nearest neighbors from the collection.\\n\\n        Args:\\n            - queries (list[str]): A list of queries to search the collection for.\\n            - n_results (int): The number of results to return.\\n            - where_filter (chroma_types.Where | None): A TypedDict used to filter the results.\\n                - e.g. `{\\\"block_type\\\": \\\"FUNCTION\\\", \\\"children\\\": None}`\\n            - where_document_filter (chroma_types.WhereDocument | None): A TypedDict used to filter the results by the document,\\n                - e.g. `{$contains: \\\"binary search\\\"}`\\n            - include_in_result (chroma_types.Include | None): A list used of what to return from the results, e.g. `[\\\"metadatas\\\", \\\"embeddings\\\", \\\"documents\\\"]`\\n\\n        Returns:\\n            - results (chroma_types.QueryResult | None): A typed dict of query results from the collection, can have the following keys based on the\\n                `include_in_result` parameter:\\n                - ids: list[str] # The ids are always returned.\\n                - embeddings: List[list[Embedding]] | None\\n                - documents: list[list[str]]] | None\\n                - uris: list[list[URI]]] | None\\n                - data: list[Loadable] | None\\n                - metadatas: list[list[Metadata]] | None\\n                - distances: list[list[float]] | None\\n\\n        Raises:\\n            - ValueError: If you don't provide query_texts.\\n\\n        Examples:\\n            ```Python\\n            import postcode.types.chromadb.types as chroma\\n\\n            # define the queries and filters used to search the collection\\n            queries: list[str] = [\\\"binary search\\\", \\\"linear search\\\"]\\n            where_filter: chroma_types.Where = {\\\"block_type\\\": \\\"FUNCTION\\\"}\\n\\n            # define the data to return from the collection\\n            include_in_result: chroma_types.Include = [\\\"metadatas\\\", \\\"documents\\\", \\\"distances\\\"]\\n\\n            # query the collection and return the results from the collection\\n            results: chroma_types.QueryResult = collection_manager.query_collection(\\n                queries,\\n                where_filter=where_filter,\\n                include_in_result=include_in_result\\n                )\\n            ```\\n        \\\"\\\"\\\"\\n\\n        try:\\n            logging.info(f\\\"Querying collection {self.collection.name}\\\")\\n\\n            if results := self.collection.query(\\n                query_texts=queries,\\n                n_results=n_results,\\n                where=where_filter,\\n                where_document=where_document_filter,\\n                include=include_in_result,\\n            ):\\n                return results\\n            else:\\n                logging.warning(\\n                    f\\\"No results found from collection {self.collection.name}.\\\"\\n                )\\n\\n        except Exception as exception:\\n            raise exception\\n\\n    def modify_collection_name(self, name: str) -> None:\\n        \\\"\\\"\\\"\\n        Modifies the name of the collection managed by this class.\\n\\n        Args:\\n            - name (str): The new name to assign to the collection.\\n\\n        Examples:\\n            ```Python\\n            # Rename the collection to 'new_collection_name'\\n            collection_manager.modify_collection_name('new_collection_name')\\n            ```\\n        \\\"\\\"\\\"\\n\\n        self.collection.modify(name=name)\\n\\n    def modify_collection_metadata(\\n        self, metadata: dict[str, Any] | None = None\\n    ) -> None:\\n        \\\"\\\"\\\"\\n        Modifies the metadata of the collection managed by this class.\\n\\n        Args:\\n            - metadata (dict[str, Any] | None): The new metadata to assign to the collection. If None, no change is made.\\n\\n        Examples:\\n            ```Python\\n            # Update metadata of the collection\\n            new_metadata = {\\\"description\\\": \\\"Updated collection metadata\\\"}\\n            collection_manager.modify_collection_metadata(new_metadata)\\n            ```\\n        \\\"\\\"\\\"\\n\\n        self.collection.modify(metadata=metadata)\\n\\n    def _update_metadata_or_documents_by_ids(\\n        self,\\n        ids: list[str],\\n        metadatas: list[Mapping[str, str | int | float | bool]] | None = None,\\n        documents: list[str] | None = None,\\n    ) -> None:\\n        \\\"\\\"\\\"\\n        Updates the metadata or documents of specific entries in the collection by their ids.\\n\\n        Args:\\n            - ids (list[str]): List of ids of the entries to be updated.\\n            - metadatas (list[Mapping[str, Any]] | None): List of metadata updates corresponding to the ids.\\n            - documents (list[str] | None): List of document updates corresponding to the ids.\\n\\n        Raises:\\n            - ValueError: If neither metadatas nor documents are provided.\\n            - ValueError: If the length of ids and documents don't match.\\n            - ValueError: If the length of ids and metadatas don't match.\\n            - ValueError: If the length of ids, metadatas, and documents don't match.\\n\\n        Notes:\\n            - As of now, ChromaDB doesn't raise an exception if you provide an id that doesn't exist.\\n\\n        Examples:\\n            ```Python\\n            # Update metadata and documents for specific ids\\n            ids_to_update = ['id1', 'id2']\\n            metadata_updates = [{\\\"key1\\\": \\\"value1\\\"}, {\\\"key2\\\": \\\"value2\\\"}]\\n            document_updates = [\\\"new document 1\\\", \\\"new document 2\\\"]\\n            collection_manager.update_metadata_or_documents_by_ids(ids_to_update, metadata_updates, document_updates)\\n            ```\\n        \\\"\\\"\\\"\\n\\n        if not metadatas and not documents:\\n            raise ValueError(\\\"You must provide either metadatas or documents.\\\")\\n        if not metadatas and documents:\\n            if len(ids) != len(documents):\\n                raise ValueError(\\\"The length of ids and documents must match.\\\")\\n        if metadatas and not documents:\\n            if len(ids) != len(metadatas):\\n                raise ValueError(\\\"The length of ids and metadatas must match.\\\")\\n        if metadatas and documents:\\n            if len(ids) != len(metadatas) != len(documents):\\n                raise ValueError(\\n                    \\\"The length of ids, metadatas, and documents must match.\\\"\\n                )\\n        for index, id in enumerate(ids):\\n            if not self.collection.get(id):\\n                logging.error(\\n                    f\\\"Id {id} does not exist in collection {self.collection.name}.\\\"\\n                )\\n                ids.pop(index)\\n                if metadatas:\\n                    popped_metadata = metadatas.pop(index)\\n                    if popped_metadata:\\n                        logging.warning(\\n                            f\\\"Removing metadata at index {index} from update.\\\"\\n                        )\\n                if documents:\\n                    popped_document = documents.pop(index)\\n                    if popped_document:\\n                        logging.warning(\\n                            f\\\"Removing document at index {index} from update.\\\"\\n                        )\\n\\n        if not ids:\\n            logging.warning(\\\"All updates failed.\\\")\\n            return None\\n        else:\\n            logging.info(f\\\"Updating collection {self.collection.name} with ids {ids}.\\\")\\n            self.collection.update(ids=ids, metadatas=metadatas, documents=documents)\\n\\n    def _upsert_documents(\\n        self,\\n        ids: list[str],\\n        documents: list[str],\\n        metadatas: list[Mapping[str, str | int | float | bool]],\\n        # embeddings: list[chroma_types.Embedding],\\n    ) -> None:\\n        \\\"\\\"\\\"\\n        Inserts or updates documents in the collection, based on the provided ids.\\n\\n        Args:\\n            - ids (list[str]): List of ids for the documents to be inserted or updated.\\n            - documents (list[str]): List of documents corresponding to the ids.\\n            - metadatas (list[Mapping[str, Any]]): List of metadata corresponding to the ids.\\n\\n        Raises:\\n            - ValueError: If the lengths of ids, documents, and metadatas don't match.\\n\\n        Examples:\\n            ```Python\\n            # Upsert documents in the collection\\n            ids = ['id1', 'id2']\\n            documents = ['doc1', 'doc2']\\n            metadatas = [{\\\"meta1\\\": \\\"value1\\\"}, {\\\"meta2\\\": \\\"value2\\\"}]\\n\\n            # Upsert documents in the collection\\n            collection_manager.upsert_documents(ids, documents, metadatas)\\n            ```\\n        \\\"\\\"\\\"\\n\\n        if len(ids) != len(documents) != len(metadatas):\\n            raise ValueError(\\\"The length of ids, documents, and metadatas must match.\\\")\\n\\n        logging.info(f\\\"Upserting collection {self.collection.name} with ids {ids}.\\\")\\n        self.collection.upsert(\\n            ids=ids,\\n            # embeddings=embeddings,\\n            metadatas=metadatas,\\n            documents=documents,\\n        )\\n\\n    def delete_embeddings(self, ids: list[str]) -> None:\\n        \\\"\\\"\\\"\\n        Deletes embeddings from the collection based on the provided ids.\\n\\n        Args:\\n            - ids (list[str]): List of ids corresponding to the embeddings to be deleted.\\n\\n        Examples:\\n            ```Python\\n            # Delete specific embeddings by ids\\n            ids_to_delete = ['id1', 'id2']\\n            collection_manager.delete_embeddings(ids_to_delete)\\n            ```\\n        \\\"\\\"\\\"\\n\\n        ids_to_delete: list[str] = ids.copy()\\n        for index, id in enumerate(ids_to_delete):\\n            if not self.collection.get(id):\\n                logging.error(\\n                    f\\\"Id {id} does not exist in collection {self.collection.name}.\\\"\\n                )\\n                ids_to_delete.pop(index)\\n\\n        if not ids_to_delete:\\n            logging.warning(\\\"No IDs given were in the database.\\\")\\n            return None\\n\\n        logging.info(\\n            f\\\"Deleting embeddings from collection {self.collection.name} with ids {ids_to_delete}.\\\"\\n        )\\n        self.collection.delete(ids_to_delete)\\n\\n    def upsert_models(self, module_models: tuple[ModuleModel, ...]) -> None:\\n        \\\"\\\"\\\"\\n        Loads or updates the embeddings of the provided module models into the collection.\\n\\n        The Pydantic models are converted to a dictionary with a format that ChromaDB can use, then the ids, documents, and metadatas\\n        are added to their respective lists. The lists are then either added to or updated in the collection depending on whether or\\n        not the code blocks were in the the collection to begin with.\\n\\n        Args:\\n            - module_models (tuple[ModuleModel, ...]): The module models to load or update into the collection.\\n\\n        Examples:\\n            ```Python\\n            # Upsert module models into the collection\\n            module_models = (module_model1, module_model2)\\n            collection_manager.upsert_models(module_models)\\n            ```\\n        \\\"\\\"\\\"\\n\\n        ids: list[str] = []\\n        documents: list[str] = []\\n        metadatas: list[Mapping[str, str | int | float | bool]] = []\\n\\n        for module_model in module_models:\\n            if module_model.summary:\\n                ids.append(module_model.id)\\n                documents.append(module_model.summary)\\n                metadatas.append(module_model.convert_to_metadata())\\n\\n            if module_model.children:\\n                for child in module_model.children:\\n                    child_data: dict[str, Any] = self._recursively_gather_child_data(\\n                        child\\n                    )\\n                    ids.extend(child_data[\\\"ids\\\"])\\n                    documents.extend(child_data[\\\"documents\\\"])\\n                    metadatas.extend(child_data[\\\"metadatas\\\"])\\n\\n        logging.info(\\n            f\\\"{self.collection.name} has {self.collection_embedding_count()} embeddings.\\\"\\n        )\\n        self._upsert_documents(ids=ids, documents=documents, metadatas=metadatas)\\n        logging.info(\\n            f\\\"After upsert {self.collection.name} has {self.collection_embedding_count()} embeddings.\\\"\\n        )\\n\\n    def _recursively_gather_child_data(self, model: ModelType) -> dict[str, Any]:\\n        ids: list[str] = []\\n        documents: list[str] = []\\n        metadatas: list[Mapping[str, str | int | float | bool]] = []\\n        if model.summary:\\n            ids.append(model.id)\\n            documents.append(model.summary)\\n            metadatas.append(model.convert_to_metadata())\\n        else:\\n            logging.warning(f\\\"Child {model.id} has no summary.\\\")\\n        if model.children:\\n            for child in model.children:\\n                child_data: dict[str, Any] = self._recursively_gather_child_data(child)\\n                ids.extend(child_data[\\\"ids\\\"])\\n                documents.extend(child_data[\\\"documents\\\"])\\n                metadatas.extend(child_data[\\\"metadatas\\\"])\\n\\n        return {\\n            \\\"ids\\\": ids,\\n            \\\"documents\\\": documents,\\n            \\\"metadatas\\\": metadatas,\\n        }\\n\\n\\nImported code block (postcode:updaters:standard_updater.py__*__MODULE) code content:\\n# Create method, `update_all`, that updates the whole project, it parses all code, wipes all databases, and summarizes all code blocks,\\n# then updates all the databases with the new information.\\n\\n\\nfrom logging import Logger\\n\\nfrom openai import OpenAI\\nfrom postcode.ai_services.summarizer.openai_summarizer import OpenAISummarizer\\nfrom postcode.ai_services.summarizer.standard_summarization_manager import (\\n    StandardSummarizationManager,\\n)\\n\\nfrom postcode.databases.chroma.setup_chroma import (\\n    ChromaSetupReturnContext,\\n    setup_chroma,\\n)\\nfrom postcode.json_management.json_handler import JSONHandler\\n\\nfrom postcode.models.models import ModuleModel\\nfrom postcode.python_parser.visitor_manager.visitor_manager import (\\n    VisitorManager,\\n    VisitorManagerProcessFilesReturn,\\n)\\n\\n\\nclass StandardUpdater:\\n    @staticmethod\\n    def update_all(\\n        directory: str, output_directory: str, logger: Logger\\n    ) -> ChromaSetupReturnContext:\\n        visitor_manager = VisitorManager(directory, output_directory)\\n        process_files_return: VisitorManagerProcessFilesReturn = (\\n            visitor_manager.process_files()\\n        )\\n\\n        module_models_tuple: tuple[ModuleModel, ...] = process_files_return.models_tuple\\n        client = OpenAI(max_retries=4)\\n        summarizer = OpenAISummarizer(client=client)\\n        summarization_manager = StandardSummarizationManager(\\n            module_models_tuple, summarizer\\n        )\\n        finalized_module_models: tuple[\\n            ModuleModel, ...\\n        ] = summarization_manager.create_summarizes_and_return_updated_models()\\n\\n        logger.info(\\\"Summarization complete\\\")\\n\\n        logger.info(\\\"Saving models as JSON\\\")\\n        directory_modules: dict[str, list[str]] = process_files_return.directory_modules\\n        json_manager = JSONHandler(directory, directory_modules, output_directory)\\n\\n        for module_model in module_models_tuple:\\n            json_manager.save_model_as_json(module_model, module_model.file_path)\\n\\n        json_manager.save_visited_directories()\\n        logger.info(\\\"JSON save complete\\\")\\n\\n        logger.info(\\\"Directory parsing completed.\\\")\\n\\n        chroma_context: ChromaSetupReturnContext = setup_chroma(\\n            finalized_module_models, logger\\n        )\\n\\n        return chroma_context\\n\\n, \\nimport logging\\nfrom logging import Logger\\nfrom typing import Union\\nfrom chromadb.api.types import QueryResult\\nfrom chromadb import Collection\\n        \",\"children\":[{\"variable_assignments\":[\"ModelType = Union[\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n]\"],\"id\":\"postcode:app.py__*__MODULE__*__STANDALONE_BLOCK-1\",\"parent_id\":\"postcode:app.py__*__MODULE\",\"block_type\":\"STANDALONE_BLOCK\",\"start_line_num\":16,\"end_line_num\":23,\"code_content\":\"ModelType = Union[\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n]\\n\",\"important_comments\":null,\"dependencies\":[{\"import_names\":[{\"name\":\"Union\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"typing\",\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"},{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ClassModel\"},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-FunctionModel\"},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-StandaloneCodeBlockModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"},{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ClassModel\"},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-FunctionModel\"},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-StandaloneCodeBlockModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"},{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ClassModel\"},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-FunctionModel\"},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-StandaloneCodeBlockModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"},{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ClassModel\"},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-FunctionModel\"},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-StandaloneCodeBlockModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"}],\"summary\":null,\"children\":null},{\"function_name\":\"query_chroma\",\"docstring\":null,\"decorators\":null,\"parameters\":null,\"returns\":\"None\",\"is_method\":false,\"is_async\":false,\"id\":\"postcode:app.py__*__MODULE__*__FUNCTION-query_chroma\",\"parent_id\":\"postcode:app.py__*__MODULE\",\"block_type\":\"FUNCTION\",\"start_line_num\":36,\"end_line_num\":58,\"code_content\":\"\\n\\ndef query_chroma(\\n    query: str,\\n    chroma_collection_manager: ChromaDBCollectionManager,\\n    chroma_collection: Collection,\\n    logger: Logger,\\n) -> None:\\n    logger.info(f\\\"Querying ChromaDB collection {chroma_collection.name}\\\")\\n    results: QueryResult | None = chroma_collection_manager.query_collection(\\n        [query],\\n        n_results=10,\\n        # where_filter={\\\"block_type\\\": \\\"MODULE\\\"},\\n        include_in_result=[\\\"metadatas\\\", \\\"documents\\\", \\\"embeddings\\\"],\\n    )\\n    logger.info(\\\"Query results:\\\")\\n    if results:\\n        if results[\\\"ids\\\"]:\\n            for document in results[\\\"ids\\\"][0]:\\n                print(document)\\n\\n            print(f\\\"Total results: {len(results['ids'][0])}\\\")\\n\",\"important_comments\":null,\"dependencies\":[{\"import_names\":[{\"name\":\"Logger\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"logging\",\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"ChromaDBCollectionManager\",\"as_name\":null,\"local_block_id\":\"postcode:databases:chroma:chromadb_collection_manager.py__*__MODULE__*__CLASS-ChromaDBCollectionManager\"}],\"imported_from\":\"postcode.databases.chroma.chromadb_collection_manager\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:databases:chroma:chromadb_collection_manager.py__*__MODULE\"},{\"import_names\":[{\"name\":\"QueryResult\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"chromadb.api.types\",\"import_module_type\":\"THIRD_PARTY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"Collection\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"chromadb\",\"import_module_type\":\"THIRD_PARTY\",\"local_module_id\":null}],\"summary\":null,\"children\":null},{\"function_name\":\"main\",\"docstring\":null,\"decorators\":null,\"parameters\":null,\"returns\":\"None\",\"is_method\":false,\"is_async\":false,\"id\":\"postcode:app.py__*__MODULE__*__FUNCTION-main\",\"parent_id\":\"postcode:app.py__*__MODULE\",\"block_type\":\"FUNCTION\",\"start_line_num\":58,\"end_line_num\":87,\"code_content\":\"\\n\\ndef main(\\n    directory: str = \\\".\\\",\\n    output_directory: str = \\\"output_json\\\",\\n) -> None:\\n    setup_logging()\\n    logger: Logger = logging.getLogger(__name__)\\n\\n    #   ==================== GraphDB ====================\\n    graph_db_updater = GraphDBUpdater(directory, output_directory, logger)\\n    chroma_context: ChromaSetupReturnContext = graph_db_updater.update_all(\\n        directory, output_directory, logger\\n    )\\n    # ==================== End GraphDB ====================\\n\\n    #   ==================== Standard ====================\\n    # chroma_context: ChromaSetupReturnContext = StandardUpdater.update_all(\\n    #     directory, output_directory, logger\\n    # )\\n    # ==================== End Standard ====================\\n\\n    query: str = \\\"summarizes code block\\\"\\n    query_chroma(\\n        query,\\n        chroma_context.chroma_collection_manager,\\n        chroma_context.chroma_collection,\\n        logger,\\n    )\\n\",\"important_comments\":null,\"dependencies\":[{\"code_block_id\":\"postcode:app.py__*__MODULE__*__FUNCTION-query_chroma\"},{\"import_names\":[{\"name\":\"logging\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":null,\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"Logger\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"logging\",\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"ChromaSetupReturnContext\",\"as_name\":null,\"local_block_id\":\"postcode:databases:chroma:setup_chroma.py__*__MODULE__*__CLASS-ChromaSetupReturnContext\"}],\"imported_from\":\"postcode.databases.chroma.setup_chroma\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:databases:chroma:setup_chroma.py__*__MODULE\"},{\"import_names\":[{\"name\":\"GraphDBUpdater\",\"as_name\":null,\"local_block_id\":\"postcode:updaters:graph_db_updater.py__*__MODULE__*__CLASS-GraphDBUpdater\"}],\"imported_from\":\"postcode.updaters.graph_db_updater\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:updaters:graph_db_updater.py__*__MODULE\"},{\"import_names\":[{\"name\":\"setup_logging\",\"as_name\":null,\"local_block_id\":\"postcode:utilities:logger:logging_config.py__*__MODULE__*__FUNCTION-setup_logging\"}],\"imported_from\":\"postcode.utilities.logger.logging_config\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:utilities:logger:logging_config.py__*__MODULE\"},{\"import_names\":[{\"name\":\"StandardUpdater\",\"as_name\":null,\"local_block_id\":\"postcode:updaters:standard_updater.py__*__MODULE__*__CLASS-StandardUpdater\"}],\"imported_from\":\"postcode.updaters.standard_updater\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:updaters:standard_updater.py__*__MODULE\"}],\"summary\":null,\"children\":null}]}", "footer": "{\"file_path\":\"postcode/app.py\",\"docstring\":null,\"header\":[],\"footer\":[],\"imports\":[{\"import_names\":[{\"name\":\"logging\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":null,\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"Logger\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"logging\",\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"Union\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"typing\",\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"QueryResult\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"chromadb.api.types\",\"import_module_type\":\"THIRD_PARTY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"Collection\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"chromadb\",\"import_module_type\":\"THIRD_PARTY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"},{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ClassModel\"},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-FunctionModel\"},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-StandaloneCodeBlockModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ChromaSetupReturnContext\",\"as_name\":null,\"local_block_id\":\"postcode:databases:chroma:setup_chroma.py__*__MODULE__*__CLASS-ChromaSetupReturnContext\"}],\"imported_from\":\"postcode.databases.chroma.setup_chroma\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:databases:chroma:setup_chroma.py__*__MODULE\"},{\"import_names\":[{\"name\":\"GraphDBUpdater\",\"as_name\":null,\"local_block_id\":\"postcode:updaters:graph_db_updater.py__*__MODULE__*__CLASS-GraphDBUpdater\"}],\"imported_from\":\"postcode.updaters.graph_db_updater\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:updaters:graph_db_updater.py__*__MODULE\"},{\"import_names\":[{\"name\":\"setup_logging\",\"as_name\":null,\"local_block_id\":\"postcode:utilities:logger:logging_config.py__*__MODULE__*__FUNCTION-setup_logging\"}],\"imported_from\":\"postcode.utilities.logger.logging_config\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:utilities:logger:logging_config.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ChromaDBCollectionManager\",\"as_name\":null,\"local_block_id\":\"postcode:databases:chroma:chromadb_collection_manager.py__*__MODULE__*__CLASS-ChromaDBCollectionManager\"}],\"imported_from\":\"postcode.databases.chroma.chromadb_collection_manager\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:databases:chroma:chromadb_collection_manager.py__*__MODULE\"},{\"import_names\":[{\"name\":\"StandardUpdater\",\"as_name\":null,\"local_block_id\":\"postcode:updaters:standard_updater.py__*__MODULE__*__CLASS-StandardUpdater\"}],\"imported_from\":\"postcode.updaters.standard_updater\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:updaters:standard_updater.py__*__MODULE\"}],\"id\":\"postcode:app.py__*__MODULE\",\"parent_id\":null,\"block_type\":\"MODULE\",\"start_line_num\":1,\"end_line_num\":87,\"code_content\":\"import logging\\nfrom logging import Logger\\nfrom typing import Union\\n\\nfrom postcode.models.models import (\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n)\\n\\nfrom postcode.databases.chroma.setup_chroma import (\\n    ChromaSetupReturnContext,\\n)\\nfrom postcode.updaters.graph_db_updater import GraphDBUpdater\\n\\nModelType = Union[\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n]\\n\\nfrom postcode.utilities.logger.logging_config import setup_logging\\n\\nfrom postcode.databases.chroma.chromadb_collection_manager import (\\n    ChromaDBCollectionManager,\\n)\\n\\nfrom chromadb.api.types import (\\n    QueryResult,\\n)\\nfrom chromadb import Collection\\n\\nfrom postcode.updaters.standard_updater import StandardUpdater\\n\\n\\ndef query_chroma(\\n    query: str,\\n    chroma_collection_manager: ChromaDBCollectionManager,\\n    chroma_collection: Collection,\\n    logger: Logger,\\n) -> None:\\n    logger.info(f\\\"Querying ChromaDB collection {chroma_collection.name}\\\")\\n    results: QueryResult | None = chroma_collection_manager.query_collection(\\n        [query],\\n        n_results=10,\\n        # where_filter={\\\"block_type\\\": \\\"MODULE\\\"},\\n        include_in_result=[\\\"metadatas\\\", \\\"documents\\\", \\\"embeddings\\\"],\\n    )\\n    logger.info(\\\"Query results:\\\")\\n    if results:\\n        if results[\\\"ids\\\"]:\\n            for document in results[\\\"ids\\\"][0]:\\n                print(document)\\n\\n            print(f\\\"Total results: {len(results['ids'][0])}\\\")\\n\\n\\ndef main(\\n    directory: str = \\\".\\\",\\n    output_directory: str = \\\"output_json\\\",\\n) -> None:\\n    setup_logging()\\n    logger: Logger = logging.getLogger(__name__)\\n\\n    #   ==================== GraphDB ====================\\n    graph_db_updater = GraphDBUpdater(directory, output_directory, logger)\\n    chroma_context: ChromaSetupReturnContext = graph_db_updater.update_all(\\n        directory, output_directory, logger\\n    )\\n    # ==================== End GraphDB ====================\\n\\n    #   ==================== Standard ====================\\n    # chroma_context: ChromaSetupReturnContext = StandardUpdater.update_all(\\n    #     directory, output_directory, logger\\n    # )\\n    # ==================== End Standard ====================\\n\\n    query: str = \\\"summarizes code block\\\"\\n    query_chroma(\\n        query,\\n        chroma_context.chroma_collection_manager,\\n        chroma_context.chroma_collection,\\n        logger,\\n    )\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":\"\\nSummary:\\n\\n        postcode:app.py__*__MODULE\\n\\n        \\nChild (postcode:app.py__*__MODULE__*__STANDALONE_BLOCK-1) code content:\\nModelType = Union[\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n]\\n\\n\\nChild (postcode:app.py__*__MODULE__*__FUNCTION-query_chroma) code content:\\n\\n\\ndef query_chroma(\\n    query: str,\\n    chroma_collection_manager: ChromaDBCollectionManager,\\n    chroma_collection: Collection,\\n    logger: Logger,\\n) -> None:\\n    logger.info(f\\\"Querying ChromaDB collection {chroma_collection.name}\\\")\\n    results: QueryResult | None = chroma_collection_manager.query_collection(\\n        [query],\\n        n_results=10,\\n        # where_filter={\\\"block_type\\\": \\\"MODULE\\\"},\\n        include_in_result=[\\\"metadatas\\\", \\\"documents\\\", \\\"embeddings\\\"],\\n    )\\n    logger.info(\\\"Query results:\\\")\\n    if results:\\n        if results[\\\"ids\\\"]:\\n            for document in results[\\\"ids\\\"][0]:\\n                print(document)\\n\\n            print(f\\\"Total results: {len(results['ids'][0])}\\\")\\n\\n\\nChild (postcode:app.py__*__MODULE__*__FUNCTION-main) code content:\\n\\n\\ndef main(\\n    directory: str = \\\".\\\",\\n    output_directory: str = \\\"output_json\\\",\\n) -> None:\\n    setup_logging()\\n    logger: Logger = logging.getLogger(__name__)\\n\\n    #   ==================== GraphDB ====================\\n    graph_db_updater = GraphDBUpdater(directory, output_directory, logger)\\n    chroma_context: ChromaSetupReturnContext = graph_db_updater.update_all(\\n        directory, output_directory, logger\\n    )\\n    # ==================== End GraphDB ====================\\n\\n    #   ==================== Standard ====================\\n    # chroma_context: ChromaSetupReturnContext = StandardUpdater.update_all(\\n    #     directory, output_directory, logger\\n    # )\\n    # ==================== End Standard ====================\\n\\n    query: str = \\\"summarizes code block\\\"\\n    query_chroma(\\n        query,\\n        chroma_context.chroma_collection_manager,\\n        chroma_context.chroma_collection,\\n        logger,\\n    )\\n\\n, \\nImported code block (postcode:models:models.py__*__MODULE) code content:\\nfrom typing import Union\\nfrom pydantic import BaseModel, Field, validator\\n\\nfrom postcode.models.enums import (\\n    BlockType,\\n    ImportModuleType,\\n    CommentType,\\n)\\n\\n\\nclass ImportNameModel(BaseModel):\\n    \\\"\\\"\\\"Class representing the name of an import.\\\"\\\"\\\"\\n\\n    name: str\\n    as_name: str | None = None\\n    local_block_id: str | None = None\\n\\n    # def convert_import_names_to_metadata(self) -> str:\\n    #     \\\"\\\"\\\"Converts the import name to a metadata string.\\\"\\\"\\\"\\n\\n    #     return self.model_dump_json()\\n\\n\\nclass ImportModel(BaseModel):\\n    \\\"\\\"\\\"Class representing an import statement.\\\"\\\"\\\"\\n\\n    import_names: list[ImportNameModel]\\n    imported_from: str | None = None\\n    import_module_type: ImportModuleType = ImportModuleType.STANDARD_LIBRARY\\n    local_module_id: str | None = None\\n\\n    def convert_import_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the import to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass DependencyModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a module dependency.\\\"\\\"\\\"\\n\\n    code_block_id: str\\n\\n    def convert_dependency_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the dependency to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass CommentModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a comment.\\\"\\\"\\\"\\n\\n    content: str\\n    comment_types: list[CommentType]\\n\\n    def convert_comment_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the comment to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass DecoratorModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a decorator.\\\"\\\"\\\"\\n\\n    content: str\\n    decorator_name: str\\n    decorator_args: list[str] | None = None\\n\\n    def convert_decorator_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the decorator to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass ClassKeywordModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a class keyword.\\\"\\\"\\\"\\n\\n    content: str\\n    keyword_name: str\\n    args: str | None = None\\n\\n    def convert_class_keyword_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the class keyword to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass ParameterModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a function parameter.\\\"\\\"\\\"\\n\\n    content: str\\n\\n\\nclass ParameterListModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a list of parameters.\\\"\\\"\\\"\\n\\n    params: list[ParameterModel] | None = None\\n    star_arg: ParameterModel | None = None\\n    kwonly_params: list[ParameterModel] | None = None\\n    star_kwarg: ParameterModel | None = None\\n    posonly_params: list[ParameterModel] | None = None\\n\\n    def convert_parameters_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the parameter list to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass BaseCodeBlockModel(BaseModel):\\n    \\\"\\\"\\\"Attributes common to all code block models.\\\"\\\"\\\"\\n\\n    id: str\\n    parent_id: str | None = None\\n    block_type: BlockType\\n    start_line_num: int\\n    end_line_num: int\\n    code_content: str = \\\"\\\"\\n    important_comments: list[CommentModel] | None = None\\n    dependencies: list[ImportModel | DependencyModel] | None = None\\n    summary: str | None = None\\n    children: list[\\n        Union[\\n            \\\"ClassModel\\\",\\n            \\\"FunctionModel\\\",\\n            \\\"StandaloneCodeBlockModel\\\",\\n        ]\\n    ] | None = []\\n\\n    @validator(\\\"parent_id\\\", always=True)\\n    def check_parent_id(cls, v, values, **kwargs) -> str | None:\\n        \\\"\\\"\\\"Validates that parent_id is a non-empty string unless block_type is MODULE.\\\"\\\"\\\"\\n\\n        if \\\"block_type\\\" in values and values[\\\"block_type\\\"] != BlockType.MODULE:\\n            if len(v) < 1:\\n                raise ValueError(\\\"parent_id is required!\\\")\\n        return v\\n\\n    def _convert_parent_id_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the parent_id to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.parent_id}\\\" if self.parent_id else \\\"\\\"\\n\\n    def _convert_block_type_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the block_type to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.block_type.name}\\\"\\n\\n    def _convert_important_comments_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the important comments to a metadata string.\\\"\\\"\\\"\\n\\n        important_comments: str = (\\n            self.model_dump_json() if self.important_comments else \\\"\\\"\\n        )\\n\\n        return f\\\"{important_comments}\\\"\\n\\n    def _convert_dependencies_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the dependencies to a metadata string.\\\"\\\"\\\"\\n\\n        dependencies_str: str = \\\"\\\"\\n\\n        if self.dependencies:\\n            for dependency in self.dependencies:\\n                if isinstance(dependency, ImportModel):\\n                    dependencies_str += f\\\"{dependency.convert_import_to_metadata()}\\\\n\\\"\\n                elif isinstance(dependency, DependencyModel):\\n                    dependencies_str += (\\n                        f\\\"{dependency.convert_dependency_to_metadata()}\\\\n\\\"\\n                    )\\n\\n        return dependencies_str\\n\\n    def _convert_summary_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the summary to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.summary}\\\" if self.summary else \\\"\\\"\\n\\n    def _convert_children_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the children to a metadata string.\\\"\\\"\\\"\\n\\n        children_str: str = \\\"\\\"\\n\\n        if self.children:\\n            for child in self.children:\\n                children_str += f\\\"{child.id}\\\\n\\\"\\n\\n        return children_str\\n\\n    def _convert_base_attributes_to_metadata_dict(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the base attributes to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            \\\"id\\\": self.id,\\n            \\\"parent_id\\\": self._convert_parent_id_to_metadata(),\\n            \\\"block_type\\\": self._convert_block_type_to_metadata(),\\n            \\\"start_line_num\\\": self.start_line_num,\\n            \\\"end_line_num\\\": self.end_line_num,\\n            \\\"code_content\\\": self.code_content,\\n            \\\"important_comments\\\": self._convert_important_comments_to_metadata(),\\n            \\\"dependencies\\\": self._convert_dependencies_to_metadata(),\\n            \\\"summary\\\": self._convert_summary_to_metadata(),\\n            \\\"children\\\": self._convert_children_to_metadata(),\\n        }\\n\\n\\nclass ModuleSpecificAttributes(BaseModel):\\n    \\\"\\\"\\\"Module specific attributes.\\\"\\\"\\\"\\n\\n    file_path: str = Field(min_length=1)\\n    docstring: str | None = None\\n    header: list[str] | None = None\\n    footer: list[str] | None = None\\n    imports: list[ImportModel] | None = None\\n\\n    def _convert_docstring_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the docstring to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.docstring}\\\"\\n\\n    def _convert_header_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the header and footer to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n    def _convert_footer_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the header and footer to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n    def _convert_imports_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the imports to a metadata string.\\\"\\\"\\\"\\n        imports_str: str = self.model_dump_json() if self.imports else \\\"\\\"\\n        return f\\\"{imports_str}\\\"\\n\\n    def _convert_module_attributes_to_metadata_dict(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the module attributes to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            \\\"file_path\\\": self.file_path,\\n            \\\"docstring\\\": self._convert_docstring_to_metadata(),\\n            \\\"header\\\": self._convert_header_to_metadata(),\\n            \\\"footer\\\": self._convert_footer_to_metadata(),\\n            \\\"imports\\\": self._convert_imports_to_metadata(),\\n        }\\n\\n\\nclass ModuleModel(BaseCodeBlockModel, ModuleSpecificAttributes):\\n    \\\"\\\"\\\"Model for a module.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the module model to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_module_attributes_to_metadata_dict(),\\n        }\\n\\n\\nclass ClassSpecificAttributes(BaseModel):\\n    \\\"\\\"\\\"Class specific attributes.\\\"\\\"\\\"\\n\\n    class_name: str = Field(min_length=1)\\n    decorators: list[DecoratorModel] | None = None\\n    bases: list[str] | None = None\\n    docstring: str | None = None\\n    keywords: list[ClassKeywordModel] | None = None\\n    # attributes: list[dict] | None = None\\n\\n    def _convert_decorators_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the decorators to a metadata string.\\\"\\\"\\\"\\n        decorators_str: str = self.model_dump_json() if self.decorators else \\\"\\\"\\n        return f\\\"{decorators_str}\\\"\\n\\n    def _convert_bases_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the bases to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json() if self.bases else \\\"\\\"\\n\\n    def _convert_docstring_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the docstring to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.docstring}\\\" if self.docstring else \\\"\\\"\\n\\n    def _convert_keywords_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the keywords to a metadata string.\\\"\\\"\\\"\\n        keywords_str: str = self.model_dump_json() if self.keywords else \\\"\\\"\\n        return f\\\"{keywords_str}\\\"\\n\\n    def _convert_class_attributes_to_metadata_dict(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the class attributes to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            \\\"class_name\\\": self.class_name,\\n            \\\"decorators\\\": self._convert_decorators_to_metadata(),\\n            \\\"bases\\\": self._convert_bases_to_metadata(),\\n            \\\"docstring\\\": self._convert_docstring_to_metadata(),\\n            \\\"keywords\\\": self._convert_keywords_to_metadata(),\\n        }\\n\\n\\nclass ClassModel(BaseCodeBlockModel, ClassSpecificAttributes):\\n    \\\"\\\"\\\"Model for a class.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the class model to a metadata dictionary.\\\"\\\"\\\"\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_class_attributes_to_metadata_dict(),\\n        }\\n\\n\\nclass FunctionSpecificAttributes(BaseModel):\\n    \\\"\\\"\\\"Function specific attributes.\\\"\\\"\\\"\\n\\n    function_name: str = Field(min_length=1)\\n    docstring: str | None = None\\n    decorators: list[DecoratorModel] | None = None\\n    parameters: ParameterListModel | None = None\\n    returns: str | None = None\\n    is_method: bool = False\\n    is_async: bool = False\\n\\n    def _convert_docstring_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the docstring to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.docstring}\\\" if self.docstring else \\\"\\\"\\n\\n    def _convert_decorators_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the decorators to a metadata string.\\\"\\\"\\\"\\n        decorators_str: str = self.model_dump_json() if self.decorators else \\\"\\\"\\n        return f\\\"{decorators_str}\\\"\\n\\n    def _convert_parameters_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the parameters to a metadata string.\\\"\\\"\\\"\\n        return (\\n            self.parameters.convert_parameters_to_metadata() if self.parameters else \\\"\\\"\\n        )\\n\\n    def _convert_returns_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the returns to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.returns}\\\" if self.returns else \\\"\\\"\\n\\n    def _convert_function_attributes_to_metadata_dict(self) -> dict[str, str | bool]:\\n        \\\"\\\"\\\"Converts the function attributes to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            \\\"function_name\\\": self.function_name,\\n            \\\"docstring\\\": self._convert_docstring_to_metadata(),\\n            \\\"decorators\\\": self._convert_decorators_to_metadata(),\\n            \\\"parameters\\\": self._convert_parameters_to_metadata(),\\n            \\\"returns\\\": self._convert_returns_to_metadata(),\\n            \\\"is_method\\\": self.is_method,\\n            \\\"is_async\\\": self.is_async,\\n        }\\n\\n\\nclass FunctionModel(BaseCodeBlockModel, FunctionSpecificAttributes):\\n    \\\"\\\"\\\"Model for a function.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the function model to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_function_attributes_to_metadata_dict(),\\n        }\\n\\n\\nclass StandaloneCodeBlockSpecificAttributes(BaseModel):\\n    \\\"\\\"\\\"Standalone code block specific attributes.\\\"\\\"\\\"\\n\\n    variable_assignments: list[str] | None = None\\n\\n    def _convert_variable_assignments_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the variable assignments to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json() if self.variable_assignments else \\\"\\\"\\n\\n    def _convert_standalone_block_attributes_to_metadata_dict(\\n        self,\\n    ) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the standalone code block attributes to a metadata dictionary.\\\"\\\"\\\"\\n        return {\\n            \\\"variable_assignments\\\": self._convert_variable_assignments_to_metadata(),\\n        }\\n\\n\\nclass StandaloneCodeBlockModel(\\n    BaseCodeBlockModel, StandaloneCodeBlockSpecificAttributes\\n):\\n    \\\"\\\"\\\"Model for a standalone code block.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the standalone code block model to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_standalone_block_attributes_to_metadata_dict(),\\n        }\\n\\n\\nImported code block (postcode:databases:chroma:setup_chroma.py__*__MODULE) code content:\\nfrom dataclasses import dataclass\\nfrom logging import Logger\\n\\nimport chromadb\\nfrom postcode.databases.chroma.chromadb_client_manager import ChromaDBClientManager\\n\\nfrom postcode.databases.chroma.chromadb_collection_manager import (\\n    ChromaDBCollectionManager,\\n)\\n\\nfrom chromadb.config import DEFAULT_DATABASE, DEFAULT_TENANT, Settings\\nfrom chromadb.api import ClientAPI\\nfrom chromadb.api.types import (\\n    DataLoader,\\n    CollectionMetadata,\\n    GetResult,\\n    QueryResult,\\n    Where,\\n    WhereDocument,\\n    Include,\\n    URIs,\\n    Loadable,\\n    Metadata,\\n    Embedding,\\n)\\nfrom chromadb import Collection\\nfrom chromadb import EmbeddingFunction\\n\\nfrom postcode.models.models import ModuleModel\\n\\n\\n@dataclass\\nclass ChromaSetupReturnContext:\\n    \\\"\\\"\\\"\\n    Represents the return value of the ChromaDB setup method.\\n\\n    Attributes:\\n        - chroma_collection_manager (ChromaDBCollectionManager): The ChromaDB collection manager.\\n        - chroma_collection (Collection): The ChromaDB collection.\\n    \\\"\\\"\\\"\\n\\n    chroma_collection_manager: ChromaDBCollectionManager\\n    chroma_collection: Collection\\n\\n\\ndef setup_chroma(\\n    module_models: list[ModuleModel], logger: Logger\\n) -> ChromaSetupReturnContext:\\n    chroma_settings = Settings(allow_reset=True)\\n    chroma_client: ClientAPI = chromadb.PersistentClient(settings=chroma_settings)\\n    chroma_client_manager = ChromaDBClientManager(chroma_client)\\n\\n    logger.debug(f\\\"Resetting Chroma client\\\")\\n    if chroma_client_manager.reset_client():\\n        logger.debug(\\\"Client reset\\\")\\n\\n    chroma_collection: Collection = chroma_client_manager.get_or_create_collection(\\n        \\\"postcode\\\"\\n    )\\n\\n    chroma_collection_manager = ChromaDBCollectionManager(chroma_collection)\\n    chroma_collection_manager.upsert_models(tuple(module_models))\\n\\n    return ChromaSetupReturnContext(chroma_collection_manager, chroma_collection)\\n\\n\\nImported code block (postcode:updaters:graph_db_updater.py__*__MODULE) code content:\\nfrom logging import Logger\\n\\nfrom openai import OpenAI\\nfrom postcode.ai_services.summarizer.graph_db_summarization_manager import (\\n    GraphDBSummarizationManager,\\n)\\nfrom postcode.ai_services.summarizer.openai_summarizer import OpenAISummarizer\\nfrom postcode.ai_services.summarizer.summarization_mapper import SummarizationMapper\\nfrom postcode.databases.arangodb.arangodb_connector import ArangoDBConnector\\n\\nfrom postcode.databases.arangodb.arangodb_manager import ArangoDBManager\\nfrom postcode.databases.chroma.setup_chroma import (\\n    ChromaSetupReturnContext,\\n    setup_chroma,\\n)\\nfrom postcode.json_management.json_handler import JSONHandler\\nfrom postcode.models.models import ModuleModel\\nfrom postcode.python_parser.visitor_manager.visitor_manager import (\\n    VisitorManager,\\n    VisitorManagerProcessFilesReturn,\\n)\\n\\n\\nclass GraphDBUpdater:\\n    def __init__(\\n        self,\\n        directory: str,\\n        output_directory: str,\\n        logger: Logger,\\n        arango_connector: ArangoDBConnector = ArangoDBConnector(),\\n    ) -> None:\\n        self.directory: str = directory\\n        self.output_directory: str = output_directory\\n        self.logger: Logger = logger\\n        self.arango_connector: ArangoDBConnector = arango_connector\\n\\n        self.arango_connector.delete_all_collections()\\n        self.arango_connector.ensure_collections()\\n        self.graph_manager = ArangoDBManager(arango_connector)\\n\\n    def update_all(\\n        self,\\n        directory: str,\\n        output_directory: str,\\n        logger: Logger,\\n    ) -> ChromaSetupReturnContext:\\n        logger.info(\\\"Starting the directory parsing.\\\")\\n\\n        visitor_manager = VisitorManager(directory, output_directory)\\n        process_files_return: VisitorManagerProcessFilesReturn = (\\n            visitor_manager.process_files()\\n        )\\n\\n        module_models_tuple: tuple[ModuleModel, ...] = process_files_return.models_tuple\\n        module_ids: list[str] = [model.id for model in module_models_tuple]\\n        directory_modules: dict[str, list[str]] = process_files_return.directory_modules\\n        self.graph_manager.upsert_models(\\n            list(module_models_tuple)\\n        ).process_imports_and_dependencies().get_or_create_graph()\\n        summarization_mapper = SummarizationMapper(\\n            module_ids, module_models_tuple, self.graph_manager\\n        )\\n        client = OpenAI(max_retries=4)\\n        summarizer = OpenAISummarizer(client=client)\\n        summarization_manager = GraphDBSummarizationManager(\\n            module_models_tuple, summarization_mapper, summarizer, self.graph_manager\\n        )\\n        finalized_module_models: list[\\n            ModuleModel\\n        ] | None = summarization_manager.create_summaries_and_return_updated_models()\\n        logger.info(\\\"Summarization complete\\\")\\n\\n        logger.info(\\\"Saving models as JSON\\\")\\n        json_manager = JSONHandler(directory, directory_modules, output_directory)\\n\\n        for module_model in module_models_tuple:\\n            json_manager.save_model_as_json(module_model, module_model.file_path)\\n\\n        json_manager.save_visited_directories()\\n        logger.info(\\\"JSON save complete\\\")\\n\\n        logger.info(\\\"Directory parsing completed.\\\")\\n\\n        # self.graph_manager.upsert_models(\\n        #     list(finalized_module_models)\\n        # ).process_imports_and_dependencies().get_or_create_graph()\\n\\n        if finalized_module_models:\\n            chroma_context: ChromaSetupReturnContext = setup_chroma(\\n                finalized_module_models, logger\\n            )\\n        else:\\n            raise Exception(\\\"No finalized models returned from summarization.\\\")\\n\\n        return chroma_context\\n\\n\\nImported code block (postcode:utilities:logger:logging_config.py__*__MODULE) code content:\\nimport logging\\n\\nfrom rich.logging import RichHandler\\nfrom rich.syntax import Syntax\\n\\n\\ndef setup_logging(level=logging.INFO) -> None:\\n    \\\"\\\"\\\"\\n    Configures the logging system to use RichSyntaxHandler for output.\\n\\n    This function sets up logging with a specific log level and format. It utilizes the RichSyntaxHandler to support rich text and syntax highlighting in log outputs.\\n\\n    Args:\\n        level (int, optional): The logging level to set for the root logger. Defaults to logging.INFO.\\n\\n    Example:\\n        >>> setup_logging(logging.DEBUG)\\n        # Configures logging at DEBUG level with RichSyntaxHandler.\\n    \\\"\\\"\\\"\\n\\n    format_str = \\\"%(message)s\\\"\\n    logging.basicConfig(level=level, format=format_str, handlers=[RichSyntaxHandler()])\\n\\n\\nclass RichSyntaxHandler(RichHandler):\\n    \\\"\\\"\\\"\\n    A custom logging handler that extends RichHandler to add syntax highlighting.\\n\\n    This handler checks if the log record contains a 'syntax_highlight' attribute and, if so, uses 'rich.syntax.Syntax' to render the message with Python syntax highlighting.\\n\\n    Inherits:\\n        RichHandler: The base handler provided by the rich library for rich text formatting.\\n    \\\"\\\"\\\"\\n\\n    def emit(self, record) -> None:\\n        \\\"\\\"\\\"\\n        Emits a logging record.\\n\\n        If the record has the 'syntax_highlight' attribute set to True, it renders the 'content' attribute of the record with syntax highlighting. Otherwise, it falls back to the standard behavior of RichHandler.\\n\\n        Args:\\n            record: The logging record to emit.\\n\\n        Example:\\n            # Assuming `logger` is a logger instance\\n            >>> logger.info(\\\"Regular log message\\\")\\n            # Outputs a regular log message.\\n\\n            >>> logger.info(\\\"Highlighted log message\\\", extra={\\\"syntax_highlight\\\": True, \\\"content\\\": \\\"print('Hello, world!')\\\"})\\n            # Outputs the message with syntax highlighting.\\n        \\\"\\\"\\\"\\n\\n        try:\\n            if hasattr(record, \\\"syntax_highlight\\\") and getattr(\\n                record, \\\"syntax_highlight\\\"\\n            ):\\n                content: str = getattr(record, \\\"content\\\", \\\"\\\")\\n                if isinstance(content, str):\\n                    syntax = Syntax(\\n                        content, \\\"python\\\", theme=\\\"material\\\", line_numbers=True\\n                    )\\n                    self.console.print(syntax)\\n                return\\n\\n        except Exception as e:\\n            self.handleError(record)\\n\\n        super().emit(record)\\n\\n\\nImported code block (postcode:databases:chroma:chromadb_collection_manager.py__*__MODULE) code content:\\nimport logging\\nfrom typing import Any, Mapping, Union\\n\\nfrom postcode.models.models import ModuleModel\\nimport postcode.types.chroma as chroma_types\\nfrom chromadb.config import DEFAULT_DATABASE, DEFAULT_TENANT, Settings\\nfrom chromadb.api import ClientAPI\\nfrom chromadb.api.types import (\\n    DataLoader,\\n    CollectionMetadata,\\n    GetResult,\\n    QueryResult,\\n    Where,\\n    WhereDocument,\\n    Include,\\n    URIs,\\n    Loadable,\\n    Metadata,\\n    Embedding,\\n)\\nfrom chromadb import Collection\\nfrom chromadb import EmbeddingFunction\\n# from postcode.types.postcode import ModelType\\nfrom postcode.models.models import ModuleModel, ClassModel, FunctionModel, StandaloneCodeBlockModel\\nModelType = Union[\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n]\\n\\n\\nclass ChromaDBCollectionManager:\\n    \\\"\\\"\\\"\\n    Manages a collection within ChromaDB instance, providing functionalities for adding, retrieving,\\n    and querying embeddings, and their associated metadata.\\n\\n    This class serves as an interface to interact with a specific collection in ChromaDB.\\n\\n    Attributes:\\n        - collection (chroma_types.Collection): An instance of the Collection class from ChromaDB\\n            which this manager is responsible for.\\n\\n    Methods:\\n        - `collection_embedding_count`: Gets the total number of embeddings in the collection.\\n        - `add_embeddings`: Adds embeddings to the collection.\\n        - `get_embeddings`: Gets embeddings and their metadata from the collection in the form of a TypedDict.\\n        - `query_collection`: Queries and returns the `n` nearest neighbors from the collection.\\n        - `upsert_models`: Loads or updates the embeddings of the provided module models into the collection.\\n\\n    Examples:\\n        ```Python\\n        from postcode.databases.chroma import ChromaDBClientBuilder\\n        import postcode.types.chromadb.types as chroma_types\\n\\n        # Create a persistent ChromaDB client\\n        client: chroma_types.ClientAPI = ChromaDBClientBuilder.create_persistent_client()\\n\\n        # Instantiate the ChromaDBCollectionManager with a specific collection\\n        collection_manager: ChromaDBCollectionManager = (\\n            ChromaDBCollectionManager(client.get_collection(\\\"my_collection\\\"))\\n        )\\n\\n        # Example usage of the collection manager\\n        embedding_count: int = collection_manager.collection_embedding_count()\\n        print(f\\\"Total embeddings: {embedding_count}\\\")\\n        ```\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, collection: Collection) -> None:\\n        self.collection: Collection = collection\\n\\n    def collection_embedding_count(self) -> int | None:\\n        \\\"\\\"\\\"\\n        Gets the total number of embeddings in the collection.\\n\\n        Returns:\\n            - embedding_count (int): The total number of embeddings in the collection.\\n\\n        Examples:\\n            ```Python\\n            embedding_count: int = collection_manager.get_collection_embedding_count()\\n            ```\\n        \\\"\\\"\\\"\\n        try:\\n            embedding_count: int = self.collection.count()\\n            logging.info(\\n                f\\\"Collection {self.collection.name} has {embedding_count} embeddings.\\\"\\n            )\\n            return embedding_count\\n        except Exception as exception:\\n            logging.error(exception)\\n\\n    def add_embeddings(\\n        self,\\n        ids: list[str],\\n        documents: list[str],\\n        metadatas: list[Mapping[str, str | int | float | bool]],\\n    ) -> None:\\n        \\\"\\\"\\\"\\n        Adds embeddings to the collection.\\n\\n        Args:\\n            - ids (list[str]): A list of ids to add to the collection.\\n            - documents (list[str]): A list of documents to add to the collection.\\n            - metadatas (list[dict[str, Any]]): A list of metadatas to add to the collection.\\n\\n        Raises:\\n            - ValueError - If you don't provide either embeddings or documents.\\n            - ValueError: If the length of ids, embeddings, metadatas, or documents don't match.\\n            - ValueError - If you provide an id that already exists.\\n\\n        Examples:\\n            ```Python\\n            # define the ids, metadatas, and documents to add to the collection\\n            id: list[str] = [\\\"my_id\\\", \\\"my_id2\\\"]\\n            metadatas: list[dict[str, Any]] = [\\n                {\\\"my_metadata\\\": \\\"my_metadata_value\\\"},\\n                {\\\"my_metadata2\\\": \\\"my_metadata_value2\\\"},\\n            ]\\n            documents: list[str] = [\\\"my_document\\\", \\\"my_document2\\\"]\\n\\n            # add the embeddings to the collection\\n            collection_manager.add_embeddings(id, metadatas, documents)\\n            ```\\n        \\\"\\\"\\\"\\n\\n        if not len(ids) == len(documents) == len(metadatas):\\n            raise ValueError(\\\"The length of ids, documents, and metadatas must match.\\\")\\n\\n        try:\\n            logging.info(f\\\"Adding embeddings to collection {self.collection.name}\\\")\\n            self.collection.add(ids, documents=documents, metadatas=metadatas)\\n        except Exception as exception:\\n            raise exception\\n\\n    def get_embeddings(\\n        self,\\n        ids: list[str] | None,\\n        *,\\n        where_filter: Where | None = None,\\n        limit: int | None = None,\\n        where_document_filter: WhereDocument | None = None,\\n        include_in_result: Include = [\\\"metadatas\\\", \\\"documents\\\"],\\n    ) -> GetResult | None:\\n        \\\"\\\"\\\"\\n        Gets embeddings and their metadata from the collection in the form of a TypedDict.\\n\\n        Args:\\n            - ids (list[str]): A list of ids to get from the collection.\\n            - where_filter (chroma_types.Where | None): A TypedDict used to filter the results.\\n            - limit (int | None): The maximum number of results to return.\\n            - where_document_filter (chroma_types.WhereDocument | None): A TypedDict used to filter the results by the document,\\n                e.g. `{$contains: {\\\"text\\\": \\\"hello\\\"}}`\\n            - include_in_result (chroma_types.Include | None): A list used of what to return from the results, e.g. `[\\\"metadatas\\\", \\\"embeddings\\\", \\\"documents\\\"]`\\n\\n        Returns:\\n            - embeddings (TypedDict): A typed dict of embedding data from the collection with the following keys:\\n                - ids: list[str]\\n                - embeddings: list[Embedding] | None\\n                - documents: list[str] | None\\n                - uris: chroma_types.URIs | None\\n                - data: chroma_types.Loadable | None\\n                - metadatas: list[chroma_types.Metadata]]\\n\\n        Raises:\\n            - ValueError: If the length of ids, embeddings, metadatas, or documents don't match.\\n            - ValueError: If you provide an id that doesn't exist.\\n\\n        Examples:\\n            ```Python\\n            import postcode.types.chromadb.types as chroma_types\\n\\n            # define the ids, filters to use to get embeddings from the collection\\n            ids: list[str] = [\\\"my_id\\\", \\\"my_id2\\\"]\\n            where_filter: chroma_types.Where = {\\\"my_metadata\\\": \\\"my_metadata_value\\\"}\\n            where_document_filter: chroma_types.WhereDocument = {\\\"$contains\\\": {\\\"text\\\": \\\"hello\\\"}}\\n\\n            # define the data to return from the collection\\n            include_in_result: chroma_types.Include = [\\\"metadatas\\\"]\\n\\n            # get the embeddings from the collection\\n            embeddings: chroma_types.GetResult = collection_manager.get_embeddings(\\n                ids,\\n                where_filter=where_filter,\\n                where_document_filter=where_document_filter,\\n                include_in_result=include_in_result\\n                )\\n            ```\\n        \\\"\\\"\\\"\\n\\n        try:\\n            logging.info(f\\\"Getting embeddings from collection {self.collection.name}\\\")\\n            return self.collection.get(\\n                ids,\\n                where=where_filter,\\n                limit=limit,\\n                where_document=where_document_filter,\\n                include=include_in_result,\\n            )\\n        except Exception as exception:\\n            raise exception\\n\\n    def query_collection(\\n        self,\\n        queries: list[str],\\n        n_results: int = 10,\\n        where_filter: Where | None = None,\\n        where_document_filter: WhereDocument | None = None,\\n        include_in_result: Include = [\\\"metadatas\\\", \\\"documents\\\"],\\n    ) -> QueryResult | None:\\n        \\\"\\\"\\\"\\n        Queries and returns the `n` nearest neighbors from the collection.\\n\\n        Args:\\n            - queries (list[str]): A list of queries to search the collection for.\\n            - n_results (int): The number of results to return.\\n            - where_filter (chroma_types.Where | None): A TypedDict used to filter the results.\\n                - e.g. `{\\\"block_type\\\": \\\"FUNCTION\\\", \\\"children\\\": None}`\\n            - where_document_filter (chroma_types.WhereDocument | None): A TypedDict used to filter the results by the document,\\n                - e.g. `{$contains: \\\"binary search\\\"}`\\n            - include_in_result (chroma_types.Include | None): A list used of what to return from the results, e.g. `[\\\"metadatas\\\", \\\"embeddings\\\", \\\"documents\\\"]`\\n\\n        Returns:\\n            - results (chroma_types.QueryResult | None): A typed dict of query results from the collection, can have the following keys based on the\\n                `include_in_result` parameter:\\n                - ids: list[str] # The ids are always returned.\\n                - embeddings: List[list[Embedding]] | None\\n                - documents: list[list[str]]] | None\\n                - uris: list[list[URI]]] | None\\n                - data: list[Loadable] | None\\n                - metadatas: list[list[Metadata]] | None\\n                - distances: list[list[float]] | None\\n\\n        Raises:\\n            - ValueError: If you don't provide query_texts.\\n\\n        Examples:\\n            ```Python\\n            import postcode.types.chromadb.types as chroma\\n\\n            # define the queries and filters used to search the collection\\n            queries: list[str] = [\\\"binary search\\\", \\\"linear search\\\"]\\n            where_filter: chroma_types.Where = {\\\"block_type\\\": \\\"FUNCTION\\\"}\\n\\n            # define the data to return from the collection\\n            include_in_result: chroma_types.Include = [\\\"metadatas\\\", \\\"documents\\\", \\\"distances\\\"]\\n\\n            # query the collection and return the results from the collection\\n            results: chroma_types.QueryResult = collection_manager.query_collection(\\n                queries,\\n                where_filter=where_filter,\\n                include_in_result=include_in_result\\n                )\\n            ```\\n        \\\"\\\"\\\"\\n\\n        try:\\n            logging.info(f\\\"Querying collection {self.collection.name}\\\")\\n\\n            if results := self.collection.query(\\n                query_texts=queries,\\n                n_results=n_results,\\n                where=where_filter,\\n                where_document=where_document_filter,\\n                include=include_in_result,\\n            ):\\n                return results\\n            else:\\n                logging.warning(\\n                    f\\\"No results found from collection {self.collection.name}.\\\"\\n                )\\n\\n        except Exception as exception:\\n            raise exception\\n\\n    def modify_collection_name(self, name: str) -> None:\\n        \\\"\\\"\\\"\\n        Modifies the name of the collection managed by this class.\\n\\n        Args:\\n            - name (str): The new name to assign to the collection.\\n\\n        Examples:\\n            ```Python\\n            # Rename the collection to 'new_collection_name'\\n            collection_manager.modify_collection_name('new_collection_name')\\n            ```\\n        \\\"\\\"\\\"\\n\\n        self.collection.modify(name=name)\\n\\n    def modify_collection_metadata(\\n        self, metadata: dict[str, Any] | None = None\\n    ) -> None:\\n        \\\"\\\"\\\"\\n        Modifies the metadata of the collection managed by this class.\\n\\n        Args:\\n            - metadata (dict[str, Any] | None): The new metadata to assign to the collection. If None, no change is made.\\n\\n        Examples:\\n            ```Python\\n            # Update metadata of the collection\\n            new_metadata = {\\\"description\\\": \\\"Updated collection metadata\\\"}\\n            collection_manager.modify_collection_metadata(new_metadata)\\n            ```\\n        \\\"\\\"\\\"\\n\\n        self.collection.modify(metadata=metadata)\\n\\n    def _update_metadata_or_documents_by_ids(\\n        self,\\n        ids: list[str],\\n        metadatas: list[Mapping[str, str | int | float | bool]] | None = None,\\n        documents: list[str] | None = None,\\n    ) -> None:\\n        \\\"\\\"\\\"\\n        Updates the metadata or documents of specific entries in the collection by their ids.\\n\\n        Args:\\n            - ids (list[str]): List of ids of the entries to be updated.\\n            - metadatas (list[Mapping[str, Any]] | None): List of metadata updates corresponding to the ids.\\n            - documents (list[str] | None): List of document updates corresponding to the ids.\\n\\n        Raises:\\n            - ValueError: If neither metadatas nor documents are provided.\\n            - ValueError: If the length of ids and documents don't match.\\n            - ValueError: If the length of ids and metadatas don't match.\\n            - ValueError: If the length of ids, metadatas, and documents don't match.\\n\\n        Notes:\\n            - As of now, ChromaDB doesn't raise an exception if you provide an id that doesn't exist.\\n\\n        Examples:\\n            ```Python\\n            # Update metadata and documents for specific ids\\n            ids_to_update = ['id1', 'id2']\\n            metadata_updates = [{\\\"key1\\\": \\\"value1\\\"}, {\\\"key2\\\": \\\"value2\\\"}]\\n            document_updates = [\\\"new document 1\\\", \\\"new document 2\\\"]\\n            collection_manager.update_metadata_or_documents_by_ids(ids_to_update, metadata_updates, document_updates)\\n            ```\\n        \\\"\\\"\\\"\\n\\n        if not metadatas and not documents:\\n            raise ValueError(\\\"You must provide either metadatas or documents.\\\")\\n        if not metadatas and documents:\\n            if len(ids) != len(documents):\\n                raise ValueError(\\\"The length of ids and documents must match.\\\")\\n        if metadatas and not documents:\\n            if len(ids) != len(metadatas):\\n                raise ValueError(\\\"The length of ids and metadatas must match.\\\")\\n        if metadatas and documents:\\n            if len(ids) != len(metadatas) != len(documents):\\n                raise ValueError(\\n                    \\\"The length of ids, metadatas, and documents must match.\\\"\\n                )\\n        for index, id in enumerate(ids):\\n            if not self.collection.get(id):\\n                logging.error(\\n                    f\\\"Id {id} does not exist in collection {self.collection.name}.\\\"\\n                )\\n                ids.pop(index)\\n                if metadatas:\\n                    popped_metadata = metadatas.pop(index)\\n                    if popped_metadata:\\n                        logging.warning(\\n                            f\\\"Removing metadata at index {index} from update.\\\"\\n                        )\\n                if documents:\\n                    popped_document = documents.pop(index)\\n                    if popped_document:\\n                        logging.warning(\\n                            f\\\"Removing document at index {index} from update.\\\"\\n                        )\\n\\n        if not ids:\\n            logging.warning(\\\"All updates failed.\\\")\\n            return None\\n        else:\\n            logging.info(f\\\"Updating collection {self.collection.name} with ids {ids}.\\\")\\n            self.collection.update(ids=ids, metadatas=metadatas, documents=documents)\\n\\n    def _upsert_documents(\\n        self,\\n        ids: list[str],\\n        documents: list[str],\\n        metadatas: list[Mapping[str, str | int | float | bool]],\\n        # embeddings: list[chroma_types.Embedding],\\n    ) -> None:\\n        \\\"\\\"\\\"\\n        Inserts or updates documents in the collection, based on the provided ids.\\n\\n        Args:\\n            - ids (list[str]): List of ids for the documents to be inserted or updated.\\n            - documents (list[str]): List of documents corresponding to the ids.\\n            - metadatas (list[Mapping[str, Any]]): List of metadata corresponding to the ids.\\n\\n        Raises:\\n            - ValueError: If the lengths of ids, documents, and metadatas don't match.\\n\\n        Examples:\\n            ```Python\\n            # Upsert documents in the collection\\n            ids = ['id1', 'id2']\\n            documents = ['doc1', 'doc2']\\n            metadatas = [{\\\"meta1\\\": \\\"value1\\\"}, {\\\"meta2\\\": \\\"value2\\\"}]\\n\\n            # Upsert documents in the collection\\n            collection_manager.upsert_documents(ids, documents, metadatas)\\n            ```\\n        \\\"\\\"\\\"\\n\\n        if len(ids) != len(documents) != len(metadatas):\\n            raise ValueError(\\\"The length of ids, documents, and metadatas must match.\\\")\\n\\n        logging.info(f\\\"Upserting collection {self.collection.name} with ids {ids}.\\\")\\n        self.collection.upsert(\\n            ids=ids,\\n            # embeddings=embeddings,\\n            metadatas=metadatas,\\n            documents=documents,\\n        )\\n\\n    def delete_embeddings(self, ids: list[str]) -> None:\\n        \\\"\\\"\\\"\\n        Deletes embeddings from the collection based on the provided ids.\\n\\n        Args:\\n            - ids (list[str]): List of ids corresponding to the embeddings to be deleted.\\n\\n        Examples:\\n            ```Python\\n            # Delete specific embeddings by ids\\n            ids_to_delete = ['id1', 'id2']\\n            collection_manager.delete_embeddings(ids_to_delete)\\n            ```\\n        \\\"\\\"\\\"\\n\\n        ids_to_delete: list[str] = ids.copy()\\n        for index, id in enumerate(ids_to_delete):\\n            if not self.collection.get(id):\\n                logging.error(\\n                    f\\\"Id {id} does not exist in collection {self.collection.name}.\\\"\\n                )\\n                ids_to_delete.pop(index)\\n\\n        if not ids_to_delete:\\n            logging.warning(\\\"No IDs given were in the database.\\\")\\n            return None\\n\\n        logging.info(\\n            f\\\"Deleting embeddings from collection {self.collection.name} with ids {ids_to_delete}.\\\"\\n        )\\n        self.collection.delete(ids_to_delete)\\n\\n    def upsert_models(self, module_models: tuple[ModuleModel, ...]) -> None:\\n        \\\"\\\"\\\"\\n        Loads or updates the embeddings of the provided module models into the collection.\\n\\n        The Pydantic models are converted to a dictionary with a format that ChromaDB can use, then the ids, documents, and metadatas\\n        are added to their respective lists. The lists are then either added to or updated in the collection depending on whether or\\n        not the code blocks were in the the collection to begin with.\\n\\n        Args:\\n            - module_models (tuple[ModuleModel, ...]): The module models to load or update into the collection.\\n\\n        Examples:\\n            ```Python\\n            # Upsert module models into the collection\\n            module_models = (module_model1, module_model2)\\n            collection_manager.upsert_models(module_models)\\n            ```\\n        \\\"\\\"\\\"\\n\\n        ids: list[str] = []\\n        documents: list[str] = []\\n        metadatas: list[Mapping[str, str | int | float | bool]] = []\\n\\n        for module_model in module_models:\\n            if module_model.summary:\\n                ids.append(module_model.id)\\n                documents.append(module_model.summary)\\n                metadatas.append(module_model.convert_to_metadata())\\n\\n            if module_model.children:\\n                for child in module_model.children:\\n                    child_data: dict[str, Any] = self._recursively_gather_child_data(\\n                        child\\n                    )\\n                    ids.extend(child_data[\\\"ids\\\"])\\n                    documents.extend(child_data[\\\"documents\\\"])\\n                    metadatas.extend(child_data[\\\"metadatas\\\"])\\n\\n        logging.info(\\n            f\\\"{self.collection.name} has {self.collection_embedding_count()} embeddings.\\\"\\n        )\\n        self._upsert_documents(ids=ids, documents=documents, metadatas=metadatas)\\n        logging.info(\\n            f\\\"After upsert {self.collection.name} has {self.collection_embedding_count()} embeddings.\\\"\\n        )\\n\\n    def _recursively_gather_child_data(self, model: ModelType) -> dict[str, Any]:\\n        ids: list[str] = []\\n        documents: list[str] = []\\n        metadatas: list[Mapping[str, str | int | float | bool]] = []\\n        if model.summary:\\n            ids.append(model.id)\\n            documents.append(model.summary)\\n            metadatas.append(model.convert_to_metadata())\\n        else:\\n            logging.warning(f\\\"Child {model.id} has no summary.\\\")\\n        if model.children:\\n            for child in model.children:\\n                child_data: dict[str, Any] = self._recursively_gather_child_data(child)\\n                ids.extend(child_data[\\\"ids\\\"])\\n                documents.extend(child_data[\\\"documents\\\"])\\n                metadatas.extend(child_data[\\\"metadatas\\\"])\\n\\n        return {\\n            \\\"ids\\\": ids,\\n            \\\"documents\\\": documents,\\n            \\\"metadatas\\\": metadatas,\\n        }\\n\\n\\nImported code block (postcode:updaters:standard_updater.py__*__MODULE) code content:\\n# Create method, `update_all`, that updates the whole project, it parses all code, wipes all databases, and summarizes all code blocks,\\n# then updates all the databases with the new information.\\n\\n\\nfrom logging import Logger\\n\\nfrom openai import OpenAI\\nfrom postcode.ai_services.summarizer.openai_summarizer import OpenAISummarizer\\nfrom postcode.ai_services.summarizer.standard_summarization_manager import (\\n    StandardSummarizationManager,\\n)\\n\\nfrom postcode.databases.chroma.setup_chroma import (\\n    ChromaSetupReturnContext,\\n    setup_chroma,\\n)\\nfrom postcode.json_management.json_handler import JSONHandler\\n\\nfrom postcode.models.models import ModuleModel\\nfrom postcode.python_parser.visitor_manager.visitor_manager import (\\n    VisitorManager,\\n    VisitorManagerProcessFilesReturn,\\n)\\n\\n\\nclass StandardUpdater:\\n    @staticmethod\\n    def update_all(\\n        directory: str, output_directory: str, logger: Logger\\n    ) -> ChromaSetupReturnContext:\\n        visitor_manager = VisitorManager(directory, output_directory)\\n        process_files_return: VisitorManagerProcessFilesReturn = (\\n            visitor_manager.process_files()\\n        )\\n\\n        module_models_tuple: tuple[ModuleModel, ...] = process_files_return.models_tuple\\n        client = OpenAI(max_retries=4)\\n        summarizer = OpenAISummarizer(client=client)\\n        summarization_manager = StandardSummarizationManager(\\n            module_models_tuple, summarizer\\n        )\\n        finalized_module_models: tuple[\\n            ModuleModel, ...\\n        ] = summarization_manager.create_summarizes_and_return_updated_models()\\n\\n        logger.info(\\\"Summarization complete\\\")\\n\\n        logger.info(\\\"Saving models as JSON\\\")\\n        directory_modules: dict[str, list[str]] = process_files_return.directory_modules\\n        json_manager = JSONHandler(directory, directory_modules, output_directory)\\n\\n        for module_model in module_models_tuple:\\n            json_manager.save_model_as_json(module_model, module_model.file_path)\\n\\n        json_manager.save_visited_directories()\\n        logger.info(\\\"JSON save complete\\\")\\n\\n        logger.info(\\\"Directory parsing completed.\\\")\\n\\n        chroma_context: ChromaSetupReturnContext = setup_chroma(\\n            finalized_module_models, logger\\n        )\\n\\n        return chroma_context\\n\\n, \\nimport logging\\nfrom logging import Logger\\nfrom typing import Union\\nfrom chromadb.api.types import QueryResult\\nfrom chromadb import Collection\\n        \",\"children\":[{\"variable_assignments\":[\"ModelType = Union[\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n]\"],\"id\":\"postcode:app.py__*__MODULE__*__STANDALONE_BLOCK-1\",\"parent_id\":\"postcode:app.py__*__MODULE\",\"block_type\":\"STANDALONE_BLOCK\",\"start_line_num\":16,\"end_line_num\":23,\"code_content\":\"ModelType = Union[\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n]\\n\",\"important_comments\":null,\"dependencies\":[{\"import_names\":[{\"name\":\"Union\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"typing\",\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"},{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ClassModel\"},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-FunctionModel\"},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-StandaloneCodeBlockModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"},{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ClassModel\"},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-FunctionModel\"},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-StandaloneCodeBlockModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"},{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ClassModel\"},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-FunctionModel\"},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-StandaloneCodeBlockModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"},{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ClassModel\"},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-FunctionModel\"},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-StandaloneCodeBlockModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"}],\"summary\":null,\"children\":null},{\"function_name\":\"query_chroma\",\"docstring\":null,\"decorators\":null,\"parameters\":null,\"returns\":\"None\",\"is_method\":false,\"is_async\":false,\"id\":\"postcode:app.py__*__MODULE__*__FUNCTION-query_chroma\",\"parent_id\":\"postcode:app.py__*__MODULE\",\"block_type\":\"FUNCTION\",\"start_line_num\":36,\"end_line_num\":58,\"code_content\":\"\\n\\ndef query_chroma(\\n    query: str,\\n    chroma_collection_manager: ChromaDBCollectionManager,\\n    chroma_collection: Collection,\\n    logger: Logger,\\n) -> None:\\n    logger.info(f\\\"Querying ChromaDB collection {chroma_collection.name}\\\")\\n    results: QueryResult | None = chroma_collection_manager.query_collection(\\n        [query],\\n        n_results=10,\\n        # where_filter={\\\"block_type\\\": \\\"MODULE\\\"},\\n        include_in_result=[\\\"metadatas\\\", \\\"documents\\\", \\\"embeddings\\\"],\\n    )\\n    logger.info(\\\"Query results:\\\")\\n    if results:\\n        if results[\\\"ids\\\"]:\\n            for document in results[\\\"ids\\\"][0]:\\n                print(document)\\n\\n            print(f\\\"Total results: {len(results['ids'][0])}\\\")\\n\",\"important_comments\":null,\"dependencies\":[{\"import_names\":[{\"name\":\"Logger\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"logging\",\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"ChromaDBCollectionManager\",\"as_name\":null,\"local_block_id\":\"postcode:databases:chroma:chromadb_collection_manager.py__*__MODULE__*__CLASS-ChromaDBCollectionManager\"}],\"imported_from\":\"postcode.databases.chroma.chromadb_collection_manager\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:databases:chroma:chromadb_collection_manager.py__*__MODULE\"},{\"import_names\":[{\"name\":\"QueryResult\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"chromadb.api.types\",\"import_module_type\":\"THIRD_PARTY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"Collection\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"chromadb\",\"import_module_type\":\"THIRD_PARTY\",\"local_module_id\":null}],\"summary\":null,\"children\":null},{\"function_name\":\"main\",\"docstring\":null,\"decorators\":null,\"parameters\":null,\"returns\":\"None\",\"is_method\":false,\"is_async\":false,\"id\":\"postcode:app.py__*__MODULE__*__FUNCTION-main\",\"parent_id\":\"postcode:app.py__*__MODULE\",\"block_type\":\"FUNCTION\",\"start_line_num\":58,\"end_line_num\":87,\"code_content\":\"\\n\\ndef main(\\n    directory: str = \\\".\\\",\\n    output_directory: str = \\\"output_json\\\",\\n) -> None:\\n    setup_logging()\\n    logger: Logger = logging.getLogger(__name__)\\n\\n    #   ==================== GraphDB ====================\\n    graph_db_updater = GraphDBUpdater(directory, output_directory, logger)\\n    chroma_context: ChromaSetupReturnContext = graph_db_updater.update_all(\\n        directory, output_directory, logger\\n    )\\n    # ==================== End GraphDB ====================\\n\\n    #   ==================== Standard ====================\\n    # chroma_context: ChromaSetupReturnContext = StandardUpdater.update_all(\\n    #     directory, output_directory, logger\\n    # )\\n    # ==================== End Standard ====================\\n\\n    query: str = \\\"summarizes code block\\\"\\n    query_chroma(\\n        query,\\n        chroma_context.chroma_collection_manager,\\n        chroma_context.chroma_collection,\\n        logger,\\n    )\\n\",\"important_comments\":null,\"dependencies\":[{\"code_block_id\":\"postcode:app.py__*__MODULE__*__FUNCTION-query_chroma\"},{\"import_names\":[{\"name\":\"logging\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":null,\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"Logger\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"logging\",\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"ChromaSetupReturnContext\",\"as_name\":null,\"local_block_id\":\"postcode:databases:chroma:setup_chroma.py__*__MODULE__*__CLASS-ChromaSetupReturnContext\"}],\"imported_from\":\"postcode.databases.chroma.setup_chroma\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:databases:chroma:setup_chroma.py__*__MODULE\"},{\"import_names\":[{\"name\":\"GraphDBUpdater\",\"as_name\":null,\"local_block_id\":\"postcode:updaters:graph_db_updater.py__*__MODULE__*__CLASS-GraphDBUpdater\"}],\"imported_from\":\"postcode.updaters.graph_db_updater\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:updaters:graph_db_updater.py__*__MODULE\"},{\"import_names\":[{\"name\":\"setup_logging\",\"as_name\":null,\"local_block_id\":\"postcode:utilities:logger:logging_config.py__*__MODULE__*__FUNCTION-setup_logging\"}],\"imported_from\":\"postcode.utilities.logger.logging_config\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:utilities:logger:logging_config.py__*__MODULE\"},{\"import_names\":[{\"name\":\"StandardUpdater\",\"as_name\":null,\"local_block_id\":\"postcode:updaters:standard_updater.py__*__MODULE__*__CLASS-StandardUpdater\"}],\"imported_from\":\"postcode.updaters.standard_updater\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:updaters:standard_updater.py__*__MODULE\"}],\"summary\":null,\"children\":null}]}", "imports": "{\"file_path\":\"postcode/app.py\",\"docstring\":null,\"header\":[],\"footer\":[],\"imports\":[{\"import_names\":[{\"name\":\"logging\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":null,\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"Logger\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"logging\",\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"Union\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"typing\",\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"QueryResult\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"chromadb.api.types\",\"import_module_type\":\"THIRD_PARTY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"Collection\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"chromadb\",\"import_module_type\":\"THIRD_PARTY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"},{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ClassModel\"},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-FunctionModel\"},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-StandaloneCodeBlockModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ChromaSetupReturnContext\",\"as_name\":null,\"local_block_id\":\"postcode:databases:chroma:setup_chroma.py__*__MODULE__*__CLASS-ChromaSetupReturnContext\"}],\"imported_from\":\"postcode.databases.chroma.setup_chroma\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:databases:chroma:setup_chroma.py__*__MODULE\"},{\"import_names\":[{\"name\":\"GraphDBUpdater\",\"as_name\":null,\"local_block_id\":\"postcode:updaters:graph_db_updater.py__*__MODULE__*__CLASS-GraphDBUpdater\"}],\"imported_from\":\"postcode.updaters.graph_db_updater\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:updaters:graph_db_updater.py__*__MODULE\"},{\"import_names\":[{\"name\":\"setup_logging\",\"as_name\":null,\"local_block_id\":\"postcode:utilities:logger:logging_config.py__*__MODULE__*__FUNCTION-setup_logging\"}],\"imported_from\":\"postcode.utilities.logger.logging_config\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:utilities:logger:logging_config.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ChromaDBCollectionManager\",\"as_name\":null,\"local_block_id\":\"postcode:databases:chroma:chromadb_collection_manager.py__*__MODULE__*__CLASS-ChromaDBCollectionManager\"}],\"imported_from\":\"postcode.databases.chroma.chromadb_collection_manager\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:databases:chroma:chromadb_collection_manager.py__*__MODULE\"},{\"import_names\":[{\"name\":\"StandardUpdater\",\"as_name\":null,\"local_block_id\":\"postcode:updaters:standard_updater.py__*__MODULE__*__CLASS-StandardUpdater\"}],\"imported_from\":\"postcode.updaters.standard_updater\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:updaters:standard_updater.py__*__MODULE\"}],\"id\":\"postcode:app.py__*__MODULE\",\"parent_id\":null,\"block_type\":\"MODULE\",\"start_line_num\":1,\"end_line_num\":87,\"code_content\":\"import logging\\nfrom logging import Logger\\nfrom typing import Union\\n\\nfrom postcode.models.models import (\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n)\\n\\nfrom postcode.databases.chroma.setup_chroma import (\\n    ChromaSetupReturnContext,\\n)\\nfrom postcode.updaters.graph_db_updater import GraphDBUpdater\\n\\nModelType = Union[\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n]\\n\\nfrom postcode.utilities.logger.logging_config import setup_logging\\n\\nfrom postcode.databases.chroma.chromadb_collection_manager import (\\n    ChromaDBCollectionManager,\\n)\\n\\nfrom chromadb.api.types import (\\n    QueryResult,\\n)\\nfrom chromadb import Collection\\n\\nfrom postcode.updaters.standard_updater import StandardUpdater\\n\\n\\ndef query_chroma(\\n    query: str,\\n    chroma_collection_manager: ChromaDBCollectionManager,\\n    chroma_collection: Collection,\\n    logger: Logger,\\n) -> None:\\n    logger.info(f\\\"Querying ChromaDB collection {chroma_collection.name}\\\")\\n    results: QueryResult | None = chroma_collection_manager.query_collection(\\n        [query],\\n        n_results=10,\\n        # where_filter={\\\"block_type\\\": \\\"MODULE\\\"},\\n        include_in_result=[\\\"metadatas\\\", \\\"documents\\\", \\\"embeddings\\\"],\\n    )\\n    logger.info(\\\"Query results:\\\")\\n    if results:\\n        if results[\\\"ids\\\"]:\\n            for document in results[\\\"ids\\\"][0]:\\n                print(document)\\n\\n            print(f\\\"Total results: {len(results['ids'][0])}\\\")\\n\\n\\ndef main(\\n    directory: str = \\\".\\\",\\n    output_directory: str = \\\"output_json\\\",\\n) -> None:\\n    setup_logging()\\n    logger: Logger = logging.getLogger(__name__)\\n\\n    #   ==================== GraphDB ====================\\n    graph_db_updater = GraphDBUpdater(directory, output_directory, logger)\\n    chroma_context: ChromaSetupReturnContext = graph_db_updater.update_all(\\n        directory, output_directory, logger\\n    )\\n    # ==================== End GraphDB ====================\\n\\n    #   ==================== Standard ====================\\n    # chroma_context: ChromaSetupReturnContext = StandardUpdater.update_all(\\n    #     directory, output_directory, logger\\n    # )\\n    # ==================== End Standard ====================\\n\\n    query: str = \\\"summarizes code block\\\"\\n    query_chroma(\\n        query,\\n        chroma_context.chroma_collection_manager,\\n        chroma_context.chroma_collection,\\n        logger,\\n    )\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":\"\\nSummary:\\n\\n        postcode:app.py__*__MODULE\\n\\n        \\nChild (postcode:app.py__*__MODULE__*__STANDALONE_BLOCK-1) code content:\\nModelType = Union[\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n]\\n\\n\\nChild (postcode:app.py__*__MODULE__*__FUNCTION-query_chroma) code content:\\n\\n\\ndef query_chroma(\\n    query: str,\\n    chroma_collection_manager: ChromaDBCollectionManager,\\n    chroma_collection: Collection,\\n    logger: Logger,\\n) -> None:\\n    logger.info(f\\\"Querying ChromaDB collection {chroma_collection.name}\\\")\\n    results: QueryResult | None = chroma_collection_manager.query_collection(\\n        [query],\\n        n_results=10,\\n        # where_filter={\\\"block_type\\\": \\\"MODULE\\\"},\\n        include_in_result=[\\\"metadatas\\\", \\\"documents\\\", \\\"embeddings\\\"],\\n    )\\n    logger.info(\\\"Query results:\\\")\\n    if results:\\n        if results[\\\"ids\\\"]:\\n            for document in results[\\\"ids\\\"][0]:\\n                print(document)\\n\\n            print(f\\\"Total results: {len(results['ids'][0])}\\\")\\n\\n\\nChild (postcode:app.py__*__MODULE__*__FUNCTION-main) code content:\\n\\n\\ndef main(\\n    directory: str = \\\".\\\",\\n    output_directory: str = \\\"output_json\\\",\\n) -> None:\\n    setup_logging()\\n    logger: Logger = logging.getLogger(__name__)\\n\\n    #   ==================== GraphDB ====================\\n    graph_db_updater = GraphDBUpdater(directory, output_directory, logger)\\n    chroma_context: ChromaSetupReturnContext = graph_db_updater.update_all(\\n        directory, output_directory, logger\\n    )\\n    # ==================== End GraphDB ====================\\n\\n    #   ==================== Standard ====================\\n    # chroma_context: ChromaSetupReturnContext = StandardUpdater.update_all(\\n    #     directory, output_directory, logger\\n    # )\\n    # ==================== End Standard ====================\\n\\n    query: str = \\\"summarizes code block\\\"\\n    query_chroma(\\n        query,\\n        chroma_context.chroma_collection_manager,\\n        chroma_context.chroma_collection,\\n        logger,\\n    )\\n\\n, \\nImported code block (postcode:models:models.py__*__MODULE) code content:\\nfrom typing import Union\\nfrom pydantic import BaseModel, Field, validator\\n\\nfrom postcode.models.enums import (\\n    BlockType,\\n    ImportModuleType,\\n    CommentType,\\n)\\n\\n\\nclass ImportNameModel(BaseModel):\\n    \\\"\\\"\\\"Class representing the name of an import.\\\"\\\"\\\"\\n\\n    name: str\\n    as_name: str | None = None\\n    local_block_id: str | None = None\\n\\n    # def convert_import_names_to_metadata(self) -> str:\\n    #     \\\"\\\"\\\"Converts the import name to a metadata string.\\\"\\\"\\\"\\n\\n    #     return self.model_dump_json()\\n\\n\\nclass ImportModel(BaseModel):\\n    \\\"\\\"\\\"Class representing an import statement.\\\"\\\"\\\"\\n\\n    import_names: list[ImportNameModel]\\n    imported_from: str | None = None\\n    import_module_type: ImportModuleType = ImportModuleType.STANDARD_LIBRARY\\n    local_module_id: str | None = None\\n\\n    def convert_import_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the import to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass DependencyModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a module dependency.\\\"\\\"\\\"\\n\\n    code_block_id: str\\n\\n    def convert_dependency_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the dependency to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass CommentModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a comment.\\\"\\\"\\\"\\n\\n    content: str\\n    comment_types: list[CommentType]\\n\\n    def convert_comment_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the comment to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass DecoratorModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a decorator.\\\"\\\"\\\"\\n\\n    content: str\\n    decorator_name: str\\n    decorator_args: list[str] | None = None\\n\\n    def convert_decorator_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the decorator to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass ClassKeywordModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a class keyword.\\\"\\\"\\\"\\n\\n    content: str\\n    keyword_name: str\\n    args: str | None = None\\n\\n    def convert_class_keyword_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the class keyword to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass ParameterModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a function parameter.\\\"\\\"\\\"\\n\\n    content: str\\n\\n\\nclass ParameterListModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a list of parameters.\\\"\\\"\\\"\\n\\n    params: list[ParameterModel] | None = None\\n    star_arg: ParameterModel | None = None\\n    kwonly_params: list[ParameterModel] | None = None\\n    star_kwarg: ParameterModel | None = None\\n    posonly_params: list[ParameterModel] | None = None\\n\\n    def convert_parameters_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the parameter list to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass BaseCodeBlockModel(BaseModel):\\n    \\\"\\\"\\\"Attributes common to all code block models.\\\"\\\"\\\"\\n\\n    id: str\\n    parent_id: str | None = None\\n    block_type: BlockType\\n    start_line_num: int\\n    end_line_num: int\\n    code_content: str = \\\"\\\"\\n    important_comments: list[CommentModel] | None = None\\n    dependencies: list[ImportModel | DependencyModel] | None = None\\n    summary: str | None = None\\n    children: list[\\n        Union[\\n            \\\"ClassModel\\\",\\n            \\\"FunctionModel\\\",\\n            \\\"StandaloneCodeBlockModel\\\",\\n        ]\\n    ] | None = []\\n\\n    @validator(\\\"parent_id\\\", always=True)\\n    def check_parent_id(cls, v, values, **kwargs) -> str | None:\\n        \\\"\\\"\\\"Validates that parent_id is a non-empty string unless block_type is MODULE.\\\"\\\"\\\"\\n\\n        if \\\"block_type\\\" in values and values[\\\"block_type\\\"] != BlockType.MODULE:\\n            if len(v) < 1:\\n                raise ValueError(\\\"parent_id is required!\\\")\\n        return v\\n\\n    def _convert_parent_id_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the parent_id to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.parent_id}\\\" if self.parent_id else \\\"\\\"\\n\\n    def _convert_block_type_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the block_type to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.block_type.name}\\\"\\n\\n    def _convert_important_comments_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the important comments to a metadata string.\\\"\\\"\\\"\\n\\n        important_comments: str = (\\n            self.model_dump_json() if self.important_comments else \\\"\\\"\\n        )\\n\\n        return f\\\"{important_comments}\\\"\\n\\n    def _convert_dependencies_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the dependencies to a metadata string.\\\"\\\"\\\"\\n\\n        dependencies_str: str = \\\"\\\"\\n\\n        if self.dependencies:\\n            for dependency in self.dependencies:\\n                if isinstance(dependency, ImportModel):\\n                    dependencies_str += f\\\"{dependency.convert_import_to_metadata()}\\\\n\\\"\\n                elif isinstance(dependency, DependencyModel):\\n                    dependencies_str += (\\n                        f\\\"{dependency.convert_dependency_to_metadata()}\\\\n\\\"\\n                    )\\n\\n        return dependencies_str\\n\\n    def _convert_summary_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the summary to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.summary}\\\" if self.summary else \\\"\\\"\\n\\n    def _convert_children_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the children to a metadata string.\\\"\\\"\\\"\\n\\n        children_str: str = \\\"\\\"\\n\\n        if self.children:\\n            for child in self.children:\\n                children_str += f\\\"{child.id}\\\\n\\\"\\n\\n        return children_str\\n\\n    def _convert_base_attributes_to_metadata_dict(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the base attributes to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            \\\"id\\\": self.id,\\n            \\\"parent_id\\\": self._convert_parent_id_to_metadata(),\\n            \\\"block_type\\\": self._convert_block_type_to_metadata(),\\n            \\\"start_line_num\\\": self.start_line_num,\\n            \\\"end_line_num\\\": self.end_line_num,\\n            \\\"code_content\\\": self.code_content,\\n            \\\"important_comments\\\": self._convert_important_comments_to_metadata(),\\n            \\\"dependencies\\\": self._convert_dependencies_to_metadata(),\\n            \\\"summary\\\": self._convert_summary_to_metadata(),\\n            \\\"children\\\": self._convert_children_to_metadata(),\\n        }\\n\\n\\nclass ModuleSpecificAttributes(BaseModel):\\n    \\\"\\\"\\\"Module specific attributes.\\\"\\\"\\\"\\n\\n    file_path: str = Field(min_length=1)\\n    docstring: str | None = None\\n    header: list[str] | None = None\\n    footer: list[str] | None = None\\n    imports: list[ImportModel] | None = None\\n\\n    def _convert_docstring_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the docstring to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.docstring}\\\"\\n\\n    def _convert_header_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the header and footer to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n    def _convert_footer_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the header and footer to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n    def _convert_imports_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the imports to a metadata string.\\\"\\\"\\\"\\n        imports_str: str = self.model_dump_json() if self.imports else \\\"\\\"\\n        return f\\\"{imports_str}\\\"\\n\\n    def _convert_module_attributes_to_metadata_dict(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the module attributes to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            \\\"file_path\\\": self.file_path,\\n            \\\"docstring\\\": self._convert_docstring_to_metadata(),\\n            \\\"header\\\": self._convert_header_to_metadata(),\\n            \\\"footer\\\": self._convert_footer_to_metadata(),\\n            \\\"imports\\\": self._convert_imports_to_metadata(),\\n        }\\n\\n\\nclass ModuleModel(BaseCodeBlockModel, ModuleSpecificAttributes):\\n    \\\"\\\"\\\"Model for a module.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the module model to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_module_attributes_to_metadata_dict(),\\n        }\\n\\n\\nclass ClassSpecificAttributes(BaseModel):\\n    \\\"\\\"\\\"Class specific attributes.\\\"\\\"\\\"\\n\\n    class_name: str = Field(min_length=1)\\n    decorators: list[DecoratorModel] | None = None\\n    bases: list[str] | None = None\\n    docstring: str | None = None\\n    keywords: list[ClassKeywordModel] | None = None\\n    # attributes: list[dict] | None = None\\n\\n    def _convert_decorators_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the decorators to a metadata string.\\\"\\\"\\\"\\n        decorators_str: str = self.model_dump_json() if self.decorators else \\\"\\\"\\n        return f\\\"{decorators_str}\\\"\\n\\n    def _convert_bases_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the bases to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json() if self.bases else \\\"\\\"\\n\\n    def _convert_docstring_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the docstring to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.docstring}\\\" if self.docstring else \\\"\\\"\\n\\n    def _convert_keywords_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the keywords to a metadata string.\\\"\\\"\\\"\\n        keywords_str: str = self.model_dump_json() if self.keywords else \\\"\\\"\\n        return f\\\"{keywords_str}\\\"\\n\\n    def _convert_class_attributes_to_metadata_dict(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the class attributes to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            \\\"class_name\\\": self.class_name,\\n            \\\"decorators\\\": self._convert_decorators_to_metadata(),\\n            \\\"bases\\\": self._convert_bases_to_metadata(),\\n            \\\"docstring\\\": self._convert_docstring_to_metadata(),\\n            \\\"keywords\\\": self._convert_keywords_to_metadata(),\\n        }\\n\\n\\nclass ClassModel(BaseCodeBlockModel, ClassSpecificAttributes):\\n    \\\"\\\"\\\"Model for a class.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the class model to a metadata dictionary.\\\"\\\"\\\"\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_class_attributes_to_metadata_dict(),\\n        }\\n\\n\\nclass FunctionSpecificAttributes(BaseModel):\\n    \\\"\\\"\\\"Function specific attributes.\\\"\\\"\\\"\\n\\n    function_name: str = Field(min_length=1)\\n    docstring: str | None = None\\n    decorators: list[DecoratorModel] | None = None\\n    parameters: ParameterListModel | None = None\\n    returns: str | None = None\\n    is_method: bool = False\\n    is_async: bool = False\\n\\n    def _convert_docstring_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the docstring to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.docstring}\\\" if self.docstring else \\\"\\\"\\n\\n    def _convert_decorators_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the decorators to a metadata string.\\\"\\\"\\\"\\n        decorators_str: str = self.model_dump_json() if self.decorators else \\\"\\\"\\n        return f\\\"{decorators_str}\\\"\\n\\n    def _convert_parameters_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the parameters to a metadata string.\\\"\\\"\\\"\\n        return (\\n            self.parameters.convert_parameters_to_metadata() if self.parameters else \\\"\\\"\\n        )\\n\\n    def _convert_returns_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the returns to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.returns}\\\" if self.returns else \\\"\\\"\\n\\n    def _convert_function_attributes_to_metadata_dict(self) -> dict[str, str | bool]:\\n        \\\"\\\"\\\"Converts the function attributes to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            \\\"function_name\\\": self.function_name,\\n            \\\"docstring\\\": self._convert_docstring_to_metadata(),\\n            \\\"decorators\\\": self._convert_decorators_to_metadata(),\\n            \\\"parameters\\\": self._convert_parameters_to_metadata(),\\n            \\\"returns\\\": self._convert_returns_to_metadata(),\\n            \\\"is_method\\\": self.is_method,\\n            \\\"is_async\\\": self.is_async,\\n        }\\n\\n\\nclass FunctionModel(BaseCodeBlockModel, FunctionSpecificAttributes):\\n    \\\"\\\"\\\"Model for a function.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the function model to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_function_attributes_to_metadata_dict(),\\n        }\\n\\n\\nclass StandaloneCodeBlockSpecificAttributes(BaseModel):\\n    \\\"\\\"\\\"Standalone code block specific attributes.\\\"\\\"\\\"\\n\\n    variable_assignments: list[str] | None = None\\n\\n    def _convert_variable_assignments_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the variable assignments to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json() if self.variable_assignments else \\\"\\\"\\n\\n    def _convert_standalone_block_attributes_to_metadata_dict(\\n        self,\\n    ) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the standalone code block attributes to a metadata dictionary.\\\"\\\"\\\"\\n        return {\\n            \\\"variable_assignments\\\": self._convert_variable_assignments_to_metadata(),\\n        }\\n\\n\\nclass StandaloneCodeBlockModel(\\n    BaseCodeBlockModel, StandaloneCodeBlockSpecificAttributes\\n):\\n    \\\"\\\"\\\"Model for a standalone code block.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the standalone code block model to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_standalone_block_attributes_to_metadata_dict(),\\n        }\\n\\n\\nImported code block (postcode:databases:chroma:setup_chroma.py__*__MODULE) code content:\\nfrom dataclasses import dataclass\\nfrom logging import Logger\\n\\nimport chromadb\\nfrom postcode.databases.chroma.chromadb_client_manager import ChromaDBClientManager\\n\\nfrom postcode.databases.chroma.chromadb_collection_manager import (\\n    ChromaDBCollectionManager,\\n)\\n\\nfrom chromadb.config import DEFAULT_DATABASE, DEFAULT_TENANT, Settings\\nfrom chromadb.api import ClientAPI\\nfrom chromadb.api.types import (\\n    DataLoader,\\n    CollectionMetadata,\\n    GetResult,\\n    QueryResult,\\n    Where,\\n    WhereDocument,\\n    Include,\\n    URIs,\\n    Loadable,\\n    Metadata,\\n    Embedding,\\n)\\nfrom chromadb import Collection\\nfrom chromadb import EmbeddingFunction\\n\\nfrom postcode.models.models import ModuleModel\\n\\n\\n@dataclass\\nclass ChromaSetupReturnContext:\\n    \\\"\\\"\\\"\\n    Represents the return value of the ChromaDB setup method.\\n\\n    Attributes:\\n        - chroma_collection_manager (ChromaDBCollectionManager): The ChromaDB collection manager.\\n        - chroma_collection (Collection): The ChromaDB collection.\\n    \\\"\\\"\\\"\\n\\n    chroma_collection_manager: ChromaDBCollectionManager\\n    chroma_collection: Collection\\n\\n\\ndef setup_chroma(\\n    module_models: list[ModuleModel], logger: Logger\\n) -> ChromaSetupReturnContext:\\n    chroma_settings = Settings(allow_reset=True)\\n    chroma_client: ClientAPI = chromadb.PersistentClient(settings=chroma_settings)\\n    chroma_client_manager = ChromaDBClientManager(chroma_client)\\n\\n    logger.debug(f\\\"Resetting Chroma client\\\")\\n    if chroma_client_manager.reset_client():\\n        logger.debug(\\\"Client reset\\\")\\n\\n    chroma_collection: Collection = chroma_client_manager.get_or_create_collection(\\n        \\\"postcode\\\"\\n    )\\n\\n    chroma_collection_manager = ChromaDBCollectionManager(chroma_collection)\\n    chroma_collection_manager.upsert_models(tuple(module_models))\\n\\n    return ChromaSetupReturnContext(chroma_collection_manager, chroma_collection)\\n\\n\\nImported code block (postcode:updaters:graph_db_updater.py__*__MODULE) code content:\\nfrom logging import Logger\\n\\nfrom openai import OpenAI\\nfrom postcode.ai_services.summarizer.graph_db_summarization_manager import (\\n    GraphDBSummarizationManager,\\n)\\nfrom postcode.ai_services.summarizer.openai_summarizer import OpenAISummarizer\\nfrom postcode.ai_services.summarizer.summarization_mapper import SummarizationMapper\\nfrom postcode.databases.arangodb.arangodb_connector import ArangoDBConnector\\n\\nfrom postcode.databases.arangodb.arangodb_manager import ArangoDBManager\\nfrom postcode.databases.chroma.setup_chroma import (\\n    ChromaSetupReturnContext,\\n    setup_chroma,\\n)\\nfrom postcode.json_management.json_handler import JSONHandler\\nfrom postcode.models.models import ModuleModel\\nfrom postcode.python_parser.visitor_manager.visitor_manager import (\\n    VisitorManager,\\n    VisitorManagerProcessFilesReturn,\\n)\\n\\n\\nclass GraphDBUpdater:\\n    def __init__(\\n        self,\\n        directory: str,\\n        output_directory: str,\\n        logger: Logger,\\n        arango_connector: ArangoDBConnector = ArangoDBConnector(),\\n    ) -> None:\\n        self.directory: str = directory\\n        self.output_directory: str = output_directory\\n        self.logger: Logger = logger\\n        self.arango_connector: ArangoDBConnector = arango_connector\\n\\n        self.arango_connector.delete_all_collections()\\n        self.arango_connector.ensure_collections()\\n        self.graph_manager = ArangoDBManager(arango_connector)\\n\\n    def update_all(\\n        self,\\n        directory: str,\\n        output_directory: str,\\n        logger: Logger,\\n    ) -> ChromaSetupReturnContext:\\n        logger.info(\\\"Starting the directory parsing.\\\")\\n\\n        visitor_manager = VisitorManager(directory, output_directory)\\n        process_files_return: VisitorManagerProcessFilesReturn = (\\n            visitor_manager.process_files()\\n        )\\n\\n        module_models_tuple: tuple[ModuleModel, ...] = process_files_return.models_tuple\\n        module_ids: list[str] = [model.id for model in module_models_tuple]\\n        directory_modules: dict[str, list[str]] = process_files_return.directory_modules\\n        self.graph_manager.upsert_models(\\n            list(module_models_tuple)\\n        ).process_imports_and_dependencies().get_or_create_graph()\\n        summarization_mapper = SummarizationMapper(\\n            module_ids, module_models_tuple, self.graph_manager\\n        )\\n        client = OpenAI(max_retries=4)\\n        summarizer = OpenAISummarizer(client=client)\\n        summarization_manager = GraphDBSummarizationManager(\\n            module_models_tuple, summarization_mapper, summarizer, self.graph_manager\\n        )\\n        finalized_module_models: list[\\n            ModuleModel\\n        ] | None = summarization_manager.create_summaries_and_return_updated_models()\\n        logger.info(\\\"Summarization complete\\\")\\n\\n        logger.info(\\\"Saving models as JSON\\\")\\n        json_manager = JSONHandler(directory, directory_modules, output_directory)\\n\\n        for module_model in module_models_tuple:\\n            json_manager.save_model_as_json(module_model, module_model.file_path)\\n\\n        json_manager.save_visited_directories()\\n        logger.info(\\\"JSON save complete\\\")\\n\\n        logger.info(\\\"Directory parsing completed.\\\")\\n\\n        # self.graph_manager.upsert_models(\\n        #     list(finalized_module_models)\\n        # ).process_imports_and_dependencies().get_or_create_graph()\\n\\n        if finalized_module_models:\\n            chroma_context: ChromaSetupReturnContext = setup_chroma(\\n                finalized_module_models, logger\\n            )\\n        else:\\n            raise Exception(\\\"No finalized models returned from summarization.\\\")\\n\\n        return chroma_context\\n\\n\\nImported code block (postcode:utilities:logger:logging_config.py__*__MODULE) code content:\\nimport logging\\n\\nfrom rich.logging import RichHandler\\nfrom rich.syntax import Syntax\\n\\n\\ndef setup_logging(level=logging.INFO) -> None:\\n    \\\"\\\"\\\"\\n    Configures the logging system to use RichSyntaxHandler for output.\\n\\n    This function sets up logging with a specific log level and format. It utilizes the RichSyntaxHandler to support rich text and syntax highlighting in log outputs.\\n\\n    Args:\\n        level (int, optional): The logging level to set for the root logger. Defaults to logging.INFO.\\n\\n    Example:\\n        >>> setup_logging(logging.DEBUG)\\n        # Configures logging at DEBUG level with RichSyntaxHandler.\\n    \\\"\\\"\\\"\\n\\n    format_str = \\\"%(message)s\\\"\\n    logging.basicConfig(level=level, format=format_str, handlers=[RichSyntaxHandler()])\\n\\n\\nclass RichSyntaxHandler(RichHandler):\\n    \\\"\\\"\\\"\\n    A custom logging handler that extends RichHandler to add syntax highlighting.\\n\\n    This handler checks if the log record contains a 'syntax_highlight' attribute and, if so, uses 'rich.syntax.Syntax' to render the message with Python syntax highlighting.\\n\\n    Inherits:\\n        RichHandler: The base handler provided by the rich library for rich text formatting.\\n    \\\"\\\"\\\"\\n\\n    def emit(self, record) -> None:\\n        \\\"\\\"\\\"\\n        Emits a logging record.\\n\\n        If the record has the 'syntax_highlight' attribute set to True, it renders the 'content' attribute of the record with syntax highlighting. Otherwise, it falls back to the standard behavior of RichHandler.\\n\\n        Args:\\n            record: The logging record to emit.\\n\\n        Example:\\n            # Assuming `logger` is a logger instance\\n            >>> logger.info(\\\"Regular log message\\\")\\n            # Outputs a regular log message.\\n\\n            >>> logger.info(\\\"Highlighted log message\\\", extra={\\\"syntax_highlight\\\": True, \\\"content\\\": \\\"print('Hello, world!')\\\"})\\n            # Outputs the message with syntax highlighting.\\n        \\\"\\\"\\\"\\n\\n        try:\\n            if hasattr(record, \\\"syntax_highlight\\\") and getattr(\\n                record, \\\"syntax_highlight\\\"\\n            ):\\n                content: str = getattr(record, \\\"content\\\", \\\"\\\")\\n                if isinstance(content, str):\\n                    syntax = Syntax(\\n                        content, \\\"python\\\", theme=\\\"material\\\", line_numbers=True\\n                    )\\n                    self.console.print(syntax)\\n                return\\n\\n        except Exception as e:\\n            self.handleError(record)\\n\\n        super().emit(record)\\n\\n\\nImported code block (postcode:databases:chroma:chromadb_collection_manager.py__*__MODULE) code content:\\nimport logging\\nfrom typing import Any, Mapping, Union\\n\\nfrom postcode.models.models import ModuleModel\\nimport postcode.types.chroma as chroma_types\\nfrom chromadb.config import DEFAULT_DATABASE, DEFAULT_TENANT, Settings\\nfrom chromadb.api import ClientAPI\\nfrom chromadb.api.types import (\\n    DataLoader,\\n    CollectionMetadata,\\n    GetResult,\\n    QueryResult,\\n    Where,\\n    WhereDocument,\\n    Include,\\n    URIs,\\n    Loadable,\\n    Metadata,\\n    Embedding,\\n)\\nfrom chromadb import Collection\\nfrom chromadb import EmbeddingFunction\\n# from postcode.types.postcode import ModelType\\nfrom postcode.models.models import ModuleModel, ClassModel, FunctionModel, StandaloneCodeBlockModel\\nModelType = Union[\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n]\\n\\n\\nclass ChromaDBCollectionManager:\\n    \\\"\\\"\\\"\\n    Manages a collection within ChromaDB instance, providing functionalities for adding, retrieving,\\n    and querying embeddings, and their associated metadata.\\n\\n    This class serves as an interface to interact with a specific collection in ChromaDB.\\n\\n    Attributes:\\n        - collection (chroma_types.Collection): An instance of the Collection class from ChromaDB\\n            which this manager is responsible for.\\n\\n    Methods:\\n        - `collection_embedding_count`: Gets the total number of embeddings in the collection.\\n        - `add_embeddings`: Adds embeddings to the collection.\\n        - `get_embeddings`: Gets embeddings and their metadata from the collection in the form of a TypedDict.\\n        - `query_collection`: Queries and returns the `n` nearest neighbors from the collection.\\n        - `upsert_models`: Loads or updates the embeddings of the provided module models into the collection.\\n\\n    Examples:\\n        ```Python\\n        from postcode.databases.chroma import ChromaDBClientBuilder\\n        import postcode.types.chromadb.types as chroma_types\\n\\n        # Create a persistent ChromaDB client\\n        client: chroma_types.ClientAPI = ChromaDBClientBuilder.create_persistent_client()\\n\\n        # Instantiate the ChromaDBCollectionManager with a specific collection\\n        collection_manager: ChromaDBCollectionManager = (\\n            ChromaDBCollectionManager(client.get_collection(\\\"my_collection\\\"))\\n        )\\n\\n        # Example usage of the collection manager\\n        embedding_count: int = collection_manager.collection_embedding_count()\\n        print(f\\\"Total embeddings: {embedding_count}\\\")\\n        ```\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, collection: Collection) -> None:\\n        self.collection: Collection = collection\\n\\n    def collection_embedding_count(self) -> int | None:\\n        \\\"\\\"\\\"\\n        Gets the total number of embeddings in the collection.\\n\\n        Returns:\\n            - embedding_count (int): The total number of embeddings in the collection.\\n\\n        Examples:\\n            ```Python\\n            embedding_count: int = collection_manager.get_collection_embedding_count()\\n            ```\\n        \\\"\\\"\\\"\\n        try:\\n            embedding_count: int = self.collection.count()\\n            logging.info(\\n                f\\\"Collection {self.collection.name} has {embedding_count} embeddings.\\\"\\n            )\\n            return embedding_count\\n        except Exception as exception:\\n            logging.error(exception)\\n\\n    def add_embeddings(\\n        self,\\n        ids: list[str],\\n        documents: list[str],\\n        metadatas: list[Mapping[str, str | int | float | bool]],\\n    ) -> None:\\n        \\\"\\\"\\\"\\n        Adds embeddings to the collection.\\n\\n        Args:\\n            - ids (list[str]): A list of ids to add to the collection.\\n            - documents (list[str]): A list of documents to add to the collection.\\n            - metadatas (list[dict[str, Any]]): A list of metadatas to add to the collection.\\n\\n        Raises:\\n            - ValueError - If you don't provide either embeddings or documents.\\n            - ValueError: If the length of ids, embeddings, metadatas, or documents don't match.\\n            - ValueError - If you provide an id that already exists.\\n\\n        Examples:\\n            ```Python\\n            # define the ids, metadatas, and documents to add to the collection\\n            id: list[str] = [\\\"my_id\\\", \\\"my_id2\\\"]\\n            metadatas: list[dict[str, Any]] = [\\n                {\\\"my_metadata\\\": \\\"my_metadata_value\\\"},\\n                {\\\"my_metadata2\\\": \\\"my_metadata_value2\\\"},\\n            ]\\n            documents: list[str] = [\\\"my_document\\\", \\\"my_document2\\\"]\\n\\n            # add the embeddings to the collection\\n            collection_manager.add_embeddings(id, metadatas, documents)\\n            ```\\n        \\\"\\\"\\\"\\n\\n        if not len(ids) == len(documents) == len(metadatas):\\n            raise ValueError(\\\"The length of ids, documents, and metadatas must match.\\\")\\n\\n        try:\\n            logging.info(f\\\"Adding embeddings to collection {self.collection.name}\\\")\\n            self.collection.add(ids, documents=documents, metadatas=metadatas)\\n        except Exception as exception:\\n            raise exception\\n\\n    def get_embeddings(\\n        self,\\n        ids: list[str] | None,\\n        *,\\n        where_filter: Where | None = None,\\n        limit: int | None = None,\\n        where_document_filter: WhereDocument | None = None,\\n        include_in_result: Include = [\\\"metadatas\\\", \\\"documents\\\"],\\n    ) -> GetResult | None:\\n        \\\"\\\"\\\"\\n        Gets embeddings and their metadata from the collection in the form of a TypedDict.\\n\\n        Args:\\n            - ids (list[str]): A list of ids to get from the collection.\\n            - where_filter (chroma_types.Where | None): A TypedDict used to filter the results.\\n            - limit (int | None): The maximum number of results to return.\\n            - where_document_filter (chroma_types.WhereDocument | None): A TypedDict used to filter the results by the document,\\n                e.g. `{$contains: {\\\"text\\\": \\\"hello\\\"}}`\\n            - include_in_result (chroma_types.Include | None): A list used of what to return from the results, e.g. `[\\\"metadatas\\\", \\\"embeddings\\\", \\\"documents\\\"]`\\n\\n        Returns:\\n            - embeddings (TypedDict): A typed dict of embedding data from the collection with the following keys:\\n                - ids: list[str]\\n                - embeddings: list[Embedding] | None\\n                - documents: list[str] | None\\n                - uris: chroma_types.URIs | None\\n                - data: chroma_types.Loadable | None\\n                - metadatas: list[chroma_types.Metadata]]\\n\\n        Raises:\\n            - ValueError: If the length of ids, embeddings, metadatas, or documents don't match.\\n            - ValueError: If you provide an id that doesn't exist.\\n\\n        Examples:\\n            ```Python\\n            import postcode.types.chromadb.types as chroma_types\\n\\n            # define the ids, filters to use to get embeddings from the collection\\n            ids: list[str] = [\\\"my_id\\\", \\\"my_id2\\\"]\\n            where_filter: chroma_types.Where = {\\\"my_metadata\\\": \\\"my_metadata_value\\\"}\\n            where_document_filter: chroma_types.WhereDocument = {\\\"$contains\\\": {\\\"text\\\": \\\"hello\\\"}}\\n\\n            # define the data to return from the collection\\n            include_in_result: chroma_types.Include = [\\\"metadatas\\\"]\\n\\n            # get the embeddings from the collection\\n            embeddings: chroma_types.GetResult = collection_manager.get_embeddings(\\n                ids,\\n                where_filter=where_filter,\\n                where_document_filter=where_document_filter,\\n                include_in_result=include_in_result\\n                )\\n            ```\\n        \\\"\\\"\\\"\\n\\n        try:\\n            logging.info(f\\\"Getting embeddings from collection {self.collection.name}\\\")\\n            return self.collection.get(\\n                ids,\\n                where=where_filter,\\n                limit=limit,\\n                where_document=where_document_filter,\\n                include=include_in_result,\\n            )\\n        except Exception as exception:\\n            raise exception\\n\\n    def query_collection(\\n        self,\\n        queries: list[str],\\n        n_results: int = 10,\\n        where_filter: Where | None = None,\\n        where_document_filter: WhereDocument | None = None,\\n        include_in_result: Include = [\\\"metadatas\\\", \\\"documents\\\"],\\n    ) -> QueryResult | None:\\n        \\\"\\\"\\\"\\n        Queries and returns the `n` nearest neighbors from the collection.\\n\\n        Args:\\n            - queries (list[str]): A list of queries to search the collection for.\\n            - n_results (int): The number of results to return.\\n            - where_filter (chroma_types.Where | None): A TypedDict used to filter the results.\\n                - e.g. `{\\\"block_type\\\": \\\"FUNCTION\\\", \\\"children\\\": None}`\\n            - where_document_filter (chroma_types.WhereDocument | None): A TypedDict used to filter the results by the document,\\n                - e.g. `{$contains: \\\"binary search\\\"}`\\n            - include_in_result (chroma_types.Include | None): A list used of what to return from the results, e.g. `[\\\"metadatas\\\", \\\"embeddings\\\", \\\"documents\\\"]`\\n\\n        Returns:\\n            - results (chroma_types.QueryResult | None): A typed dict of query results from the collection, can have the following keys based on the\\n                `include_in_result` parameter:\\n                - ids: list[str] # The ids are always returned.\\n                - embeddings: List[list[Embedding]] | None\\n                - documents: list[list[str]]] | None\\n                - uris: list[list[URI]]] | None\\n                - data: list[Loadable] | None\\n                - metadatas: list[list[Metadata]] | None\\n                - distances: list[list[float]] | None\\n\\n        Raises:\\n            - ValueError: If you don't provide query_texts.\\n\\n        Examples:\\n            ```Python\\n            import postcode.types.chromadb.types as chroma\\n\\n            # define the queries and filters used to search the collection\\n            queries: list[str] = [\\\"binary search\\\", \\\"linear search\\\"]\\n            where_filter: chroma_types.Where = {\\\"block_type\\\": \\\"FUNCTION\\\"}\\n\\n            # define the data to return from the collection\\n            include_in_result: chroma_types.Include = [\\\"metadatas\\\", \\\"documents\\\", \\\"distances\\\"]\\n\\n            # query the collection and return the results from the collection\\n            results: chroma_types.QueryResult = collection_manager.query_collection(\\n                queries,\\n                where_filter=where_filter,\\n                include_in_result=include_in_result\\n                )\\n            ```\\n        \\\"\\\"\\\"\\n\\n        try:\\n            logging.info(f\\\"Querying collection {self.collection.name}\\\")\\n\\n            if results := self.collection.query(\\n                query_texts=queries,\\n                n_results=n_results,\\n                where=where_filter,\\n                where_document=where_document_filter,\\n                include=include_in_result,\\n            ):\\n                return results\\n            else:\\n                logging.warning(\\n                    f\\\"No results found from collection {self.collection.name}.\\\"\\n                )\\n\\n        except Exception as exception:\\n            raise exception\\n\\n    def modify_collection_name(self, name: str) -> None:\\n        \\\"\\\"\\\"\\n        Modifies the name of the collection managed by this class.\\n\\n        Args:\\n            - name (str): The new name to assign to the collection.\\n\\n        Examples:\\n            ```Python\\n            # Rename the collection to 'new_collection_name'\\n            collection_manager.modify_collection_name('new_collection_name')\\n            ```\\n        \\\"\\\"\\\"\\n\\n        self.collection.modify(name=name)\\n\\n    def modify_collection_metadata(\\n        self, metadata: dict[str, Any] | None = None\\n    ) -> None:\\n        \\\"\\\"\\\"\\n        Modifies the metadata of the collection managed by this class.\\n\\n        Args:\\n            - metadata (dict[str, Any] | None): The new metadata to assign to the collection. If None, no change is made.\\n\\n        Examples:\\n            ```Python\\n            # Update metadata of the collection\\n            new_metadata = {\\\"description\\\": \\\"Updated collection metadata\\\"}\\n            collection_manager.modify_collection_metadata(new_metadata)\\n            ```\\n        \\\"\\\"\\\"\\n\\n        self.collection.modify(metadata=metadata)\\n\\n    def _update_metadata_or_documents_by_ids(\\n        self,\\n        ids: list[str],\\n        metadatas: list[Mapping[str, str | int | float | bool]] | None = None,\\n        documents: list[str] | None = None,\\n    ) -> None:\\n        \\\"\\\"\\\"\\n        Updates the metadata or documents of specific entries in the collection by their ids.\\n\\n        Args:\\n            - ids (list[str]): List of ids of the entries to be updated.\\n            - metadatas (list[Mapping[str, Any]] | None): List of metadata updates corresponding to the ids.\\n            - documents (list[str] | None): List of document updates corresponding to the ids.\\n\\n        Raises:\\n            - ValueError: If neither metadatas nor documents are provided.\\n            - ValueError: If the length of ids and documents don't match.\\n            - ValueError: If the length of ids and metadatas don't match.\\n            - ValueError: If the length of ids, metadatas, and documents don't match.\\n\\n        Notes:\\n            - As of now, ChromaDB doesn't raise an exception if you provide an id that doesn't exist.\\n\\n        Examples:\\n            ```Python\\n            # Update metadata and documents for specific ids\\n            ids_to_update = ['id1', 'id2']\\n            metadata_updates = [{\\\"key1\\\": \\\"value1\\\"}, {\\\"key2\\\": \\\"value2\\\"}]\\n            document_updates = [\\\"new document 1\\\", \\\"new document 2\\\"]\\n            collection_manager.update_metadata_or_documents_by_ids(ids_to_update, metadata_updates, document_updates)\\n            ```\\n        \\\"\\\"\\\"\\n\\n        if not metadatas and not documents:\\n            raise ValueError(\\\"You must provide either metadatas or documents.\\\")\\n        if not metadatas and documents:\\n            if len(ids) != len(documents):\\n                raise ValueError(\\\"The length of ids and documents must match.\\\")\\n        if metadatas and not documents:\\n            if len(ids) != len(metadatas):\\n                raise ValueError(\\\"The length of ids and metadatas must match.\\\")\\n        if metadatas and documents:\\n            if len(ids) != len(metadatas) != len(documents):\\n                raise ValueError(\\n                    \\\"The length of ids, metadatas, and documents must match.\\\"\\n                )\\n        for index, id in enumerate(ids):\\n            if not self.collection.get(id):\\n                logging.error(\\n                    f\\\"Id {id} does not exist in collection {self.collection.name}.\\\"\\n                )\\n                ids.pop(index)\\n                if metadatas:\\n                    popped_metadata = metadatas.pop(index)\\n                    if popped_metadata:\\n                        logging.warning(\\n                            f\\\"Removing metadata at index {index} from update.\\\"\\n                        )\\n                if documents:\\n                    popped_document = documents.pop(index)\\n                    if popped_document:\\n                        logging.warning(\\n                            f\\\"Removing document at index {index} from update.\\\"\\n                        )\\n\\n        if not ids:\\n            logging.warning(\\\"All updates failed.\\\")\\n            return None\\n        else:\\n            logging.info(f\\\"Updating collection {self.collection.name} with ids {ids}.\\\")\\n            self.collection.update(ids=ids, metadatas=metadatas, documents=documents)\\n\\n    def _upsert_documents(\\n        self,\\n        ids: list[str],\\n        documents: list[str],\\n        metadatas: list[Mapping[str, str | int | float | bool]],\\n        # embeddings: list[chroma_types.Embedding],\\n    ) -> None:\\n        \\\"\\\"\\\"\\n        Inserts or updates documents in the collection, based on the provided ids.\\n\\n        Args:\\n            - ids (list[str]): List of ids for the documents to be inserted or updated.\\n            - documents (list[str]): List of documents corresponding to the ids.\\n            - metadatas (list[Mapping[str, Any]]): List of metadata corresponding to the ids.\\n\\n        Raises:\\n            - ValueError: If the lengths of ids, documents, and metadatas don't match.\\n\\n        Examples:\\n            ```Python\\n            # Upsert documents in the collection\\n            ids = ['id1', 'id2']\\n            documents = ['doc1', 'doc2']\\n            metadatas = [{\\\"meta1\\\": \\\"value1\\\"}, {\\\"meta2\\\": \\\"value2\\\"}]\\n\\n            # Upsert documents in the collection\\n            collection_manager.upsert_documents(ids, documents, metadatas)\\n            ```\\n        \\\"\\\"\\\"\\n\\n        if len(ids) != len(documents) != len(metadatas):\\n            raise ValueError(\\\"The length of ids, documents, and metadatas must match.\\\")\\n\\n        logging.info(f\\\"Upserting collection {self.collection.name} with ids {ids}.\\\")\\n        self.collection.upsert(\\n            ids=ids,\\n            # embeddings=embeddings,\\n            metadatas=metadatas,\\n            documents=documents,\\n        )\\n\\n    def delete_embeddings(self, ids: list[str]) -> None:\\n        \\\"\\\"\\\"\\n        Deletes embeddings from the collection based on the provided ids.\\n\\n        Args:\\n            - ids (list[str]): List of ids corresponding to the embeddings to be deleted.\\n\\n        Examples:\\n            ```Python\\n            # Delete specific embeddings by ids\\n            ids_to_delete = ['id1', 'id2']\\n            collection_manager.delete_embeddings(ids_to_delete)\\n            ```\\n        \\\"\\\"\\\"\\n\\n        ids_to_delete: list[str] = ids.copy()\\n        for index, id in enumerate(ids_to_delete):\\n            if not self.collection.get(id):\\n                logging.error(\\n                    f\\\"Id {id} does not exist in collection {self.collection.name}.\\\"\\n                )\\n                ids_to_delete.pop(index)\\n\\n        if not ids_to_delete:\\n            logging.warning(\\\"No IDs given were in the database.\\\")\\n            return None\\n\\n        logging.info(\\n            f\\\"Deleting embeddings from collection {self.collection.name} with ids {ids_to_delete}.\\\"\\n        )\\n        self.collection.delete(ids_to_delete)\\n\\n    def upsert_models(self, module_models: tuple[ModuleModel, ...]) -> None:\\n        \\\"\\\"\\\"\\n        Loads or updates the embeddings of the provided module models into the collection.\\n\\n        The Pydantic models are converted to a dictionary with a format that ChromaDB can use, then the ids, documents, and metadatas\\n        are added to their respective lists. The lists are then either added to or updated in the collection depending on whether or\\n        not the code blocks were in the the collection to begin with.\\n\\n        Args:\\n            - module_models (tuple[ModuleModel, ...]): The module models to load or update into the collection.\\n\\n        Examples:\\n            ```Python\\n            # Upsert module models into the collection\\n            module_models = (module_model1, module_model2)\\n            collection_manager.upsert_models(module_models)\\n            ```\\n        \\\"\\\"\\\"\\n\\n        ids: list[str] = []\\n        documents: list[str] = []\\n        metadatas: list[Mapping[str, str | int | float | bool]] = []\\n\\n        for module_model in module_models:\\n            if module_model.summary:\\n                ids.append(module_model.id)\\n                documents.append(module_model.summary)\\n                metadatas.append(module_model.convert_to_metadata())\\n\\n            if module_model.children:\\n                for child in module_model.children:\\n                    child_data: dict[str, Any] = self._recursively_gather_child_data(\\n                        child\\n                    )\\n                    ids.extend(child_data[\\\"ids\\\"])\\n                    documents.extend(child_data[\\\"documents\\\"])\\n                    metadatas.extend(child_data[\\\"metadatas\\\"])\\n\\n        logging.info(\\n            f\\\"{self.collection.name} has {self.collection_embedding_count()} embeddings.\\\"\\n        )\\n        self._upsert_documents(ids=ids, documents=documents, metadatas=metadatas)\\n        logging.info(\\n            f\\\"After upsert {self.collection.name} has {self.collection_embedding_count()} embeddings.\\\"\\n        )\\n\\n    def _recursively_gather_child_data(self, model: ModelType) -> dict[str, Any]:\\n        ids: list[str] = []\\n        documents: list[str] = []\\n        metadatas: list[Mapping[str, str | int | float | bool]] = []\\n        if model.summary:\\n            ids.append(model.id)\\n            documents.append(model.summary)\\n            metadatas.append(model.convert_to_metadata())\\n        else:\\n            logging.warning(f\\\"Child {model.id} has no summary.\\\")\\n        if model.children:\\n            for child in model.children:\\n                child_data: dict[str, Any] = self._recursively_gather_child_data(child)\\n                ids.extend(child_data[\\\"ids\\\"])\\n                documents.extend(child_data[\\\"documents\\\"])\\n                metadatas.extend(child_data[\\\"metadatas\\\"])\\n\\n        return {\\n            \\\"ids\\\": ids,\\n            \\\"documents\\\": documents,\\n            \\\"metadatas\\\": metadatas,\\n        }\\n\\n\\nImported code block (postcode:updaters:standard_updater.py__*__MODULE) code content:\\n# Create method, `update_all`, that updates the whole project, it parses all code, wipes all databases, and summarizes all code blocks,\\n# then updates all the databases with the new information.\\n\\n\\nfrom logging import Logger\\n\\nfrom openai import OpenAI\\nfrom postcode.ai_services.summarizer.openai_summarizer import OpenAISummarizer\\nfrom postcode.ai_services.summarizer.standard_summarization_manager import (\\n    StandardSummarizationManager,\\n)\\n\\nfrom postcode.databases.chroma.setup_chroma import (\\n    ChromaSetupReturnContext,\\n    setup_chroma,\\n)\\nfrom postcode.json_management.json_handler import JSONHandler\\n\\nfrom postcode.models.models import ModuleModel\\nfrom postcode.python_parser.visitor_manager.visitor_manager import (\\n    VisitorManager,\\n    VisitorManagerProcessFilesReturn,\\n)\\n\\n\\nclass StandardUpdater:\\n    @staticmethod\\n    def update_all(\\n        directory: str, output_directory: str, logger: Logger\\n    ) -> ChromaSetupReturnContext:\\n        visitor_manager = VisitorManager(directory, output_directory)\\n        process_files_return: VisitorManagerProcessFilesReturn = (\\n            visitor_manager.process_files()\\n        )\\n\\n        module_models_tuple: tuple[ModuleModel, ...] = process_files_return.models_tuple\\n        client = OpenAI(max_retries=4)\\n        summarizer = OpenAISummarizer(client=client)\\n        summarization_manager = StandardSummarizationManager(\\n            module_models_tuple, summarizer\\n        )\\n        finalized_module_models: tuple[\\n            ModuleModel, ...\\n        ] = summarization_manager.create_summarizes_and_return_updated_models()\\n\\n        logger.info(\\\"Summarization complete\\\")\\n\\n        logger.info(\\\"Saving models as JSON\\\")\\n        directory_modules: dict[str, list[str]] = process_files_return.directory_modules\\n        json_manager = JSONHandler(directory, directory_modules, output_directory)\\n\\n        for module_model in module_models_tuple:\\n            json_manager.save_model_as_json(module_model, module_model.file_path)\\n\\n        json_manager.save_visited_directories()\\n        logger.info(\\\"JSON save complete\\\")\\n\\n        logger.info(\\\"Directory parsing completed.\\\")\\n\\n        chroma_context: ChromaSetupReturnContext = setup_chroma(\\n            finalized_module_models, logger\\n        )\\n\\n        return chroma_context\\n\\n, \\nimport logging\\nfrom logging import Logger\\nfrom typing import Union\\nfrom chromadb.api.types import QueryResult\\nfrom chromadb import Collection\\n        \",\"children\":[{\"variable_assignments\":[\"ModelType = Union[\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n]\"],\"id\":\"postcode:app.py__*__MODULE__*__STANDALONE_BLOCK-1\",\"parent_id\":\"postcode:app.py__*__MODULE\",\"block_type\":\"STANDALONE_BLOCK\",\"start_line_num\":16,\"end_line_num\":23,\"code_content\":\"ModelType = Union[\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n]\\n\",\"important_comments\":null,\"dependencies\":[{\"import_names\":[{\"name\":\"Union\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"typing\",\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"},{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ClassModel\"},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-FunctionModel\"},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-StandaloneCodeBlockModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"},{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ClassModel\"},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-FunctionModel\"},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-StandaloneCodeBlockModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"},{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ClassModel\"},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-FunctionModel\"},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-StandaloneCodeBlockModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"},{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ClassModel\"},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-FunctionModel\"},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-StandaloneCodeBlockModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"}],\"summary\":null,\"children\":null},{\"function_name\":\"query_chroma\",\"docstring\":null,\"decorators\":null,\"parameters\":null,\"returns\":\"None\",\"is_method\":false,\"is_async\":false,\"id\":\"postcode:app.py__*__MODULE__*__FUNCTION-query_chroma\",\"parent_id\":\"postcode:app.py__*__MODULE\",\"block_type\":\"FUNCTION\",\"start_line_num\":36,\"end_line_num\":58,\"code_content\":\"\\n\\ndef query_chroma(\\n    query: str,\\n    chroma_collection_manager: ChromaDBCollectionManager,\\n    chroma_collection: Collection,\\n    logger: Logger,\\n) -> None:\\n    logger.info(f\\\"Querying ChromaDB collection {chroma_collection.name}\\\")\\n    results: QueryResult | None = chroma_collection_manager.query_collection(\\n        [query],\\n        n_results=10,\\n        # where_filter={\\\"block_type\\\": \\\"MODULE\\\"},\\n        include_in_result=[\\\"metadatas\\\", \\\"documents\\\", \\\"embeddings\\\"],\\n    )\\n    logger.info(\\\"Query results:\\\")\\n    if results:\\n        if results[\\\"ids\\\"]:\\n            for document in results[\\\"ids\\\"][0]:\\n                print(document)\\n\\n            print(f\\\"Total results: {len(results['ids'][0])}\\\")\\n\",\"important_comments\":null,\"dependencies\":[{\"import_names\":[{\"name\":\"Logger\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"logging\",\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"ChromaDBCollectionManager\",\"as_name\":null,\"local_block_id\":\"postcode:databases:chroma:chromadb_collection_manager.py__*__MODULE__*__CLASS-ChromaDBCollectionManager\"}],\"imported_from\":\"postcode.databases.chroma.chromadb_collection_manager\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:databases:chroma:chromadb_collection_manager.py__*__MODULE\"},{\"import_names\":[{\"name\":\"QueryResult\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"chromadb.api.types\",\"import_module_type\":\"THIRD_PARTY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"Collection\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"chromadb\",\"import_module_type\":\"THIRD_PARTY\",\"local_module_id\":null}],\"summary\":null,\"children\":null},{\"function_name\":\"main\",\"docstring\":null,\"decorators\":null,\"parameters\":null,\"returns\":\"None\",\"is_method\":false,\"is_async\":false,\"id\":\"postcode:app.py__*__MODULE__*__FUNCTION-main\",\"parent_id\":\"postcode:app.py__*__MODULE\",\"block_type\":\"FUNCTION\",\"start_line_num\":58,\"end_line_num\":87,\"code_content\":\"\\n\\ndef main(\\n    directory: str = \\\".\\\",\\n    output_directory: str = \\\"output_json\\\",\\n) -> None:\\n    setup_logging()\\n    logger: Logger = logging.getLogger(__name__)\\n\\n    #   ==================== GraphDB ====================\\n    graph_db_updater = GraphDBUpdater(directory, output_directory, logger)\\n    chroma_context: ChromaSetupReturnContext = graph_db_updater.update_all(\\n        directory, output_directory, logger\\n    )\\n    # ==================== End GraphDB ====================\\n\\n    #   ==================== Standard ====================\\n    # chroma_context: ChromaSetupReturnContext = StandardUpdater.update_all(\\n    #     directory, output_directory, logger\\n    # )\\n    # ==================== End Standard ====================\\n\\n    query: str = \\\"summarizes code block\\\"\\n    query_chroma(\\n        query,\\n        chroma_context.chroma_collection_manager,\\n        chroma_context.chroma_collection,\\n        logger,\\n    )\\n\",\"important_comments\":null,\"dependencies\":[{\"code_block_id\":\"postcode:app.py__*__MODULE__*__FUNCTION-query_chroma\"},{\"import_names\":[{\"name\":\"logging\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":null,\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"Logger\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"logging\",\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"ChromaSetupReturnContext\",\"as_name\":null,\"local_block_id\":\"postcode:databases:chroma:setup_chroma.py__*__MODULE__*__CLASS-ChromaSetupReturnContext\"}],\"imported_from\":\"postcode.databases.chroma.setup_chroma\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:databases:chroma:setup_chroma.py__*__MODULE\"},{\"import_names\":[{\"name\":\"GraphDBUpdater\",\"as_name\":null,\"local_block_id\":\"postcode:updaters:graph_db_updater.py__*__MODULE__*__CLASS-GraphDBUpdater\"}],\"imported_from\":\"postcode.updaters.graph_db_updater\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:updaters:graph_db_updater.py__*__MODULE\"},{\"import_names\":[{\"name\":\"setup_logging\",\"as_name\":null,\"local_block_id\":\"postcode:utilities:logger:logging_config.py__*__MODULE__*__FUNCTION-setup_logging\"}],\"imported_from\":\"postcode.utilities.logger.logging_config\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:utilities:logger:logging_config.py__*__MODULE\"},{\"import_names\":[{\"name\":\"StandardUpdater\",\"as_name\":null,\"local_block_id\":\"postcode:updaters:standard_updater.py__*__MODULE__*__CLASS-StandardUpdater\"}],\"imported_from\":\"postcode.updaters.standard_updater\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:updaters:standard_updater.py__*__MODULE\"}],\"summary\":null,\"children\":null}]}", "chroma:document": "\nSummary:\n\n        postcode:app.py__*__MODULE\n\n        \nChild (postcode:app.py__*__MODULE__*__STANDALONE_BLOCK-1) code content:\nModelType = Union[\n    ModuleModel,\n    ClassModel,\n    FunctionModel,\n    StandaloneCodeBlockModel,\n]\n\n\nChild (postcode:app.py__*__MODULE__*__FUNCTION-query_chroma) code content:\n\n\ndef query_chroma(\n    query: str,\n    chroma_collection_manager: ChromaDBCollectionManager,\n    chroma_collection: Collection,\n    logger: Logger,\n) -> None:\n    logger.info(f\"Querying ChromaDB collection {chroma_collection.name}\")\n    results: QueryResult | None = chroma_collection_manager.query_collection(\n        [query],\n        n_results=10,\n        # where_filter={\"block_type\": \"MODULE\"},\n        include_in_result=[\"metadatas\", \"documents\", \"embeddings\"],\n    )\n    logger.info(\"Query results:\")\n    if results:\n        if results[\"ids\"]:\n            for document in results[\"ids\"][0]:\n                print(document)\n\n            print(f\"Total results: {len(results['ids'][0])}\")\n\n\nChild (postcode:app.py__*__MODULE__*__FUNCTION-main) code content:\n\n\ndef main(\n    directory: str = \".\",\n    output_directory: str = \"output_json\",\n) -> None:\n    setup_logging()\n    logger: Logger = logging.getLogger(__name__)\n\n    #   ==================== GraphDB ====================\n    graph_db_updater = GraphDBUpdater(directory, output_directory, logger)\n    chroma_context: ChromaSetupReturnContext = graph_db_updater.update_all(\n        directory, output_directory, logger\n    )\n    # ==================== End GraphDB ====================\n\n    #   ==================== Standard ====================\n    # chroma_context: ChromaSetupReturnContext = StandardUpdater.update_all(\n    #     directory, output_directory, logger\n    # )\n    # ==================== End Standard ====================\n\n    query: str = \"summarizes code block\"\n    query_chroma(\n        query,\n        chroma_context.chroma_collection_manager,\n        chroma_context.chroma_collection,\n        logger,\n    )\n\n, \nImported code block (postcode:models:models.py__*__MODULE) code content:\nfrom typing import Union\nfrom pydantic import BaseModel, Field, validator\n\nfrom postcode.models.enums import (\n    BlockType,\n    ImportModuleType,\n    CommentType,\n)\n\n\nclass ImportNameModel(BaseModel):\n    \"\"\"Class representing the name of an import.\"\"\"\n\n    name: str\n    as_name: str | None = None\n    local_block_id: str | None = None\n\n    # def convert_import_names_to_metadata(self) -> str:\n    #     \"\"\"Converts the import name to a metadata string.\"\"\"\n\n    #     return self.model_dump_json()\n\n\nclass ImportModel(BaseModel):\n    \"\"\"Class representing an import statement.\"\"\"\n\n    import_names: list[ImportNameModel]\n    imported_from: str | None = None\n    import_module_type: ImportModuleType = ImportModuleType.STANDARD_LIBRARY\n    local_module_id: str | None = None\n\n    def convert_import_to_metadata(self) -> str:\n        \"\"\"Converts the import to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass DependencyModel(BaseModel):\n    \"\"\"Class representing a module dependency.\"\"\"\n\n    code_block_id: str\n\n    def convert_dependency_to_metadata(self) -> str:\n        \"\"\"Converts the dependency to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass CommentModel(BaseModel):\n    \"\"\"Class representing a comment.\"\"\"\n\n    content: str\n    comment_types: list[CommentType]\n\n    def convert_comment_to_metadata(self) -> str:\n        \"\"\"Converts the comment to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass DecoratorModel(BaseModel):\n    \"\"\"Class representing a decorator.\"\"\"\n\n    content: str\n    decorator_name: str\n    decorator_args: list[str] | None = None\n\n    def convert_decorator_to_metadata(self) -> str:\n        \"\"\"Converts the decorator to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass ClassKeywordModel(BaseModel):\n    \"\"\"Class representing a class keyword.\"\"\"\n\n    content: str\n    keyword_name: str\n    args: str | None = None\n\n    def convert_class_keyword_to_metadata(self) -> str:\n        \"\"\"Converts the class keyword to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass ParameterModel(BaseModel):\n    \"\"\"Class representing a function parameter.\"\"\"\n\n    content: str\n\n\nclass ParameterListModel(BaseModel):\n    \"\"\"Class representing a list of parameters.\"\"\"\n\n    params: list[ParameterModel] | None = None\n    star_arg: ParameterModel | None = None\n    kwonly_params: list[ParameterModel] | None = None\n    star_kwarg: ParameterModel | None = None\n    posonly_params: list[ParameterModel] | None = None\n\n    def convert_parameters_to_metadata(self) -> str:\n        \"\"\"Converts the parameter list to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass BaseCodeBlockModel(BaseModel):\n    \"\"\"Attributes common to all code block models.\"\"\"\n\n    id: str\n    parent_id: str | None = None\n    block_type: BlockType\n    start_line_num: int\n    end_line_num: int\n    code_content: str = \"\"\n    important_comments: list[CommentModel] | None = None\n    dependencies: list[ImportModel | DependencyModel] | None = None\n    summary: str | None = None\n    children: list[\n        Union[\n            \"ClassModel\",\n            \"FunctionModel\",\n            \"StandaloneCodeBlockModel\",\n        ]\n    ] | None = []\n\n    @validator(\"parent_id\", always=True)\n    def check_parent_id(cls, v, values, **kwargs) -> str | None:\n        \"\"\"Validates that parent_id is a non-empty string unless block_type is MODULE.\"\"\"\n\n        if \"block_type\" in values and values[\"block_type\"] != BlockType.MODULE:\n            if len(v) < 1:\n                raise ValueError(\"parent_id is required!\")\n        return v\n\n    def _convert_parent_id_to_metadata(self) -> str:\n        \"\"\"Converts the parent_id to a metadata string.\"\"\"\n        return f\"{self.parent_id}\" if self.parent_id else \"\"\n\n    def _convert_block_type_to_metadata(self) -> str:\n        \"\"\"Converts the block_type to a metadata string.\"\"\"\n        return f\"{self.block_type.name}\"\n\n    def _convert_important_comments_to_metadata(self) -> str:\n        \"\"\"Converts the important comments to a metadata string.\"\"\"\n\n        important_comments: str = (\n            self.model_dump_json() if self.important_comments else \"\"\n        )\n\n        return f\"{important_comments}\"\n\n    def _convert_dependencies_to_metadata(self) -> str:\n        \"\"\"Converts the dependencies to a metadata string.\"\"\"\n\n        dependencies_str: str = \"\"\n\n        if self.dependencies:\n            for dependency in self.dependencies:\n                if isinstance(dependency, ImportModel):\n                    dependencies_str += f\"{dependency.convert_import_to_metadata()}\\n\"\n                elif isinstance(dependency, DependencyModel):\n                    dependencies_str += (\n                        f\"{dependency.convert_dependency_to_metadata()}\\n\"\n                    )\n\n        return dependencies_str\n\n    def _convert_summary_to_metadata(self) -> str:\n        \"\"\"Converts the summary to a metadata string.\"\"\"\n        return f\"{self.summary}\" if self.summary else \"\"\n\n    def _convert_children_to_metadata(self) -> str:\n        \"\"\"Converts the children to a metadata string.\"\"\"\n\n        children_str: str = \"\"\n\n        if self.children:\n            for child in self.children:\n                children_str += f\"{child.id}\\n\"\n\n        return children_str\n\n    def _convert_base_attributes_to_metadata_dict(self) -> dict[str, str | int]:\n        \"\"\"Converts the base attributes to a metadata dictionary.\"\"\"\n\n        return {\n            \"id\": self.id,\n            \"parent_id\": self._convert_parent_id_to_metadata(),\n            \"block_type\": self._convert_block_type_to_metadata(),\n            \"start_line_num\": self.start_line_num,\n            \"end_line_num\": self.end_line_num,\n            \"code_content\": self.code_content,\n            \"important_comments\": self._convert_important_comments_to_metadata(),\n            \"dependencies\": self._convert_dependencies_to_metadata(),\n            \"summary\": self._convert_summary_to_metadata(),\n            \"children\": self._convert_children_to_metadata(),\n        }\n\n\nclass ModuleSpecificAttributes(BaseModel):\n    \"\"\"Module specific attributes.\"\"\"\n\n    file_path: str = Field(min_length=1)\n    docstring: str | None = None\n    header: list[str] | None = None\n    footer: list[str] | None = None\n    imports: list[ImportModel] | None = None\n\n    def _convert_docstring_to_metadata(self) -> str:\n        \"\"\"Converts the docstring to a metadata string.\"\"\"\n        return f\"{self.docstring}\"\n\n    def _convert_header_to_metadata(self) -> str:\n        \"\"\"Converts the header and footer to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n    def _convert_footer_to_metadata(self) -> str:\n        \"\"\"Converts the header and footer to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n    def _convert_imports_to_metadata(self) -> str:\n        \"\"\"Converts the imports to a metadata string.\"\"\"\n        imports_str: str = self.model_dump_json() if self.imports else \"\"\n        return f\"{imports_str}\"\n\n    def _convert_module_attributes_to_metadata_dict(self) -> dict[str, str | int]:\n        \"\"\"Converts the module attributes to a metadata dictionary.\"\"\"\n\n        return {\n            \"file_path\": self.file_path,\n            \"docstring\": self._convert_docstring_to_metadata(),\n            \"header\": self._convert_header_to_metadata(),\n            \"footer\": self._convert_footer_to_metadata(),\n            \"imports\": self._convert_imports_to_metadata(),\n        }\n\n\nclass ModuleModel(BaseCodeBlockModel, ModuleSpecificAttributes):\n    \"\"\"Model for a module.\"\"\"\n\n    def convert_to_metadata(self) -> dict[str, str | int]:\n        \"\"\"Converts the module model to a metadata dictionary.\"\"\"\n\n        return {\n            **self._convert_base_attributes_to_metadata_dict(),\n            **self._convert_module_attributes_to_metadata_dict(),\n        }\n\n\nclass ClassSpecificAttributes(BaseModel):\n    \"\"\"Class specific attributes.\"\"\"\n\n    class_name: str = Field(min_length=1)\n    decorators: list[DecoratorModel] | None = None\n    bases: list[str] | None = None\n    docstring: str | None = None\n    keywords: list[ClassKeywordModel] | None = None\n    # attributes: list[dict] | None = None\n\n    def _convert_decorators_to_metadata(self) -> str:\n        \"\"\"Converts the decorators to a metadata string.\"\"\"\n        decorators_str: str = self.model_dump_json() if self.decorators else \"\"\n        return f\"{decorators_str}\"\n\n    def _convert_bases_to_metadata(self) -> str:\n        \"\"\"Converts the bases to a metadata string.\"\"\"\n        return self.model_dump_json() if self.bases else \"\"\n\n    def _convert_docstring_to_metadata(self) -> str:\n        \"\"\"Converts the docstring to a metadata string.\"\"\"\n        return f\"{self.docstring}\" if self.docstring else \"\"\n\n    def _convert_keywords_to_metadata(self) -> str:\n        \"\"\"Converts the keywords to a metadata string.\"\"\"\n        keywords_str: str = self.model_dump_json() if self.keywords else \"\"\n        return f\"{keywords_str}\"\n\n    def _convert_class_attributes_to_metadata_dict(self) -> dict[str, str | int]:\n        \"\"\"Converts the class attributes to a metadata dictionary.\"\"\"\n\n        return {\n            \"class_name\": self.class_name,\n            \"decorators\": self._convert_decorators_to_metadata(),\n            \"bases\": self._convert_bases_to_metadata(),\n            \"docstring\": self._convert_docstring_to_metadata(),\n            \"keywords\": self._convert_keywords_to_metadata(),\n        }\n\n\nclass ClassModel(BaseCodeBlockModel, ClassSpecificAttributes):\n    \"\"\"Model for a class.\"\"\"\n\n    def convert_to_metadata(self) -> dict[str, str | int]:\n        \"\"\"Converts the class model to a metadata dictionary.\"\"\"\n        return {\n            **self._convert_base_attributes_to_metadata_dict(),\n            **self._convert_class_attributes_to_metadata_dict(),\n        }\n\n\nclass FunctionSpecificAttributes(BaseModel):\n    \"\"\"Function specific attributes.\"\"\"\n\n    function_name: str = Field(min_length=1)\n    docstring: str | None = None\n    decorators: list[DecoratorModel] | None = None\n    parameters: ParameterListModel | None = None\n    returns: str | None = None\n    is_method: bool = False\n    is_async: bool = False\n\n    def _convert_docstring_to_metadata(self) -> str:\n        \"\"\"Converts the docstring to a metadata string.\"\"\"\n        return f\"{self.docstring}\" if self.docstring else \"\"\n\n    def _convert_decorators_to_metadata(self) -> str:\n        \"\"\"Converts the decorators to a metadata string.\"\"\"\n        decorators_str: str = self.model_dump_json() if self.decorators else \"\"\n        return f\"{decorators_str}\"\n\n    def _convert_parameters_to_metadata(self) -> str:\n        \"\"\"Converts the parameters to a metadata string.\"\"\"\n        return (\n            self.parameters.convert_parameters_to_metadata() if self.parameters else \"\"\n        )\n\n    def _convert_returns_to_metadata(self) -> str:\n        \"\"\"Converts the returns to a metadata string.\"\"\"\n        return f\"{self.returns}\" if self.returns else \"\"\n\n    def _convert_function_attributes_to_metadata_dict(self) -> dict[str, str | bool]:\n        \"\"\"Converts the function attributes to a metadata dictionary.\"\"\"\n\n        return {\n            \"function_name\": self.function_name,\n            \"docstring\": self._convert_docstring_to_metadata(),\n            \"decorators\": self._convert_decorators_to_metadata(),\n            \"parameters\": self._convert_parameters_to_metadata(),\n            \"returns\": self._convert_returns_to_metadata(),\n            \"is_method\": self.is_method,\n            \"is_async\": self.is_async,\n        }\n\n\nclass FunctionModel(BaseCodeBlockModel, FunctionSpecificAttributes):\n    \"\"\"Model for a function.\"\"\"\n\n    def convert_to_metadata(self) -> dict[str, str | int]:\n        \"\"\"Converts the function model to a metadata dictionary.\"\"\"\n\n        return {\n            **self._convert_base_attributes_to_metadata_dict(),\n            **self._convert_function_attributes_to_metadata_dict(),\n        }\n\n\nclass StandaloneCodeBlockSpecificAttributes(BaseModel):\n    \"\"\"Standalone code block specific attributes.\"\"\"\n\n    variable_assignments: list[str] | None = None\n\n    def _convert_variable_assignments_to_metadata(self) -> str:\n        \"\"\"Converts the variable assignments to a metadata string.\"\"\"\n        return self.model_dump_json() if self.variable_assignments else \"\"\n\n    def _convert_standalone_block_attributes_to_metadata_dict(\n        self,\n    ) -> dict[str, str | int]:\n        \"\"\"Converts the standalone code block attributes to a metadata dictionary.\"\"\"\n        return {\n            \"variable_assignments\": self._convert_variable_assignments_to_metadata(),\n        }\n\n\nclass StandaloneCodeBlockModel(\n    BaseCodeBlockModel, StandaloneCodeBlockSpecificAttributes\n):\n    \"\"\"Model for a standalone code block.\"\"\"\n\n    def convert_to_metadata(self) -> dict[str, str | int]:\n        \"\"\"Converts the standalone code block model to a metadata dictionary.\"\"\"\n\n        return {\n            **self._convert_base_attributes_to_metadata_dict(),\n            **self._convert_standalone_block_attributes_to_metadata_dict(),\n        }\n\n\nImported code block (postcode:databases:chroma:setup_chroma.py__*__MODULE) code content:\nfrom dataclasses import dataclass\nfrom logging import Logger\n\nimport chromadb\nfrom postcode.databases.chroma.chromadb_client_manager import ChromaDBClientManager\n\nfrom postcode.databases.chroma.chromadb_collection_manager import (\n    ChromaDBCollectionManager,\n)\n\nfrom chromadb.config import DEFAULT_DATABASE, DEFAULT_TENANT, Settings\nfrom chromadb.api import ClientAPI\nfrom chromadb.api.types import (\n    DataLoader,\n    CollectionMetadata,\n    GetResult,\n    QueryResult,\n    Where,\n    WhereDocument,\n    Include,\n    URIs,\n    Loadable,\n    Metadata,\n    Embedding,\n)\nfrom chromadb import Collection\nfrom chromadb import EmbeddingFunction\n\nfrom postcode.models.models import ModuleModel\n\n\n@dataclass\nclass ChromaSetupReturnContext:\n    \"\"\"\n    Represents the return value of the ChromaDB setup method.\n\n    Attributes:\n        - chroma_collection_manager (ChromaDBCollectionManager): The ChromaDB collection manager.\n        - chroma_collection (Collection): The ChromaDB collection.\n    \"\"\"\n\n    chroma_collection_manager: ChromaDBCollectionManager\n    chroma_collection: Collection\n\n\ndef setup_chroma(\n    module_models: list[ModuleModel], logger: Logger\n) -> ChromaSetupReturnContext:\n    chroma_settings = Settings(allow_reset=True)\n    chroma_client: ClientAPI = chromadb.PersistentClient(settings=chroma_settings)\n    chroma_client_manager = ChromaDBClientManager(chroma_client)\n\n    logger.debug(f\"Resetting Chroma client\")\n    if chroma_client_manager.reset_client():\n        logger.debug(\"Client reset\")\n\n    chroma_collection: Collection = chroma_client_manager.get_or_create_collection(\n        \"postcode\"\n    )\n\n    chroma_collection_manager = ChromaDBCollectionManager(chroma_collection)\n    chroma_collection_manager.upsert_models(tuple(module_models))\n\n    return ChromaSetupReturnContext(chroma_collection_manager, chroma_collection)\n\n\nImported code block (postcode:updaters:graph_db_updater.py__*__MODULE) code content:\nfrom logging import Logger\n\nfrom openai import OpenAI\nfrom postcode.ai_services.summarizer.graph_db_summarization_manager import (\n    GraphDBSummarizationManager,\n)\nfrom postcode.ai_services.summarizer.openai_summarizer import OpenAISummarizer\nfrom postcode.ai_services.summarizer.summarization_mapper import SummarizationMapper\nfrom postcode.databases.arangodb.arangodb_connector import ArangoDBConnector\n\nfrom postcode.databases.arangodb.arangodb_manager import ArangoDBManager\nfrom postcode.databases.chroma.setup_chroma import (\n    ChromaSetupReturnContext,\n    setup_chroma,\n)\nfrom postcode.json_management.json_handler import JSONHandler\nfrom postcode.models.models import ModuleModel\nfrom postcode.python_parser.visitor_manager.visitor_manager import (\n    VisitorManager,\n    VisitorManagerProcessFilesReturn,\n)\n\n\nclass GraphDBUpdater:\n    def __init__(\n        self,\n        directory: str,\n        output_directory: str,\n        logger: Logger,\n        arango_connector: ArangoDBConnector = ArangoDBConnector(),\n    ) -> None:\n        self.directory: str = directory\n        self.output_directory: str = output_directory\n        self.logger: Logger = logger\n        self.arango_connector: ArangoDBConnector = arango_connector\n\n        self.arango_connector.delete_all_collections()\n        self.arango_connector.ensure_collections()\n        self.graph_manager = ArangoDBManager(arango_connector)\n\n    def update_all(\n        self,\n        directory: str,\n        output_directory: str,\n        logger: Logger,\n    ) -> ChromaSetupReturnContext:\n        logger.info(\"Starting the directory parsing.\")\n\n        visitor_manager = VisitorManager(directory, output_directory)\n        process_files_return: VisitorManagerProcessFilesReturn = (\n            visitor_manager.process_files()\n        )\n\n        module_models_tuple: tuple[ModuleModel, ...] = process_files_return.models_tuple\n        module_ids: list[str] = [model.id for model in module_models_tuple]\n        directory_modules: dict[str, list[str]] = process_files_return.directory_modules\n        self.graph_manager.upsert_models(\n            list(module_models_tuple)\n        ).process_imports_and_dependencies().get_or_create_graph()\n        summarization_mapper = SummarizationMapper(\n            module_ids, module_models_tuple, self.graph_manager\n        )\n        client = OpenAI(max_retries=4)\n        summarizer = OpenAISummarizer(client=client)\n        summarization_manager = GraphDBSummarizationManager(\n            module_models_tuple, summarization_mapper, summarizer, self.graph_manager\n        )\n        finalized_module_models: list[\n            ModuleModel\n        ] | None = summarization_manager.create_summaries_and_return_updated_models()\n        logger.info(\"Summarization complete\")\n\n        logger.info(\"Saving models as JSON\")\n        json_manager = JSONHandler(directory, directory_modules, output_directory)\n\n        for module_model in module_models_tuple:\n            json_manager.save_model_as_json(module_model, module_model.file_path)\n\n        json_manager.save_visited_directories()\n        logger.info(\"JSON save complete\")\n\n        logger.info(\"Directory parsing completed.\")\n\n        # self.graph_manager.upsert_models(\n        #     list(finalized_module_models)\n        # ).process_imports_and_dependencies().get_or_create_graph()\n\n        if finalized_module_models:\n            chroma_context: ChromaSetupReturnContext = setup_chroma(\n                finalized_module_models, logger\n            )\n        else:\n            raise Exception(\"No finalized models returned from summarization.\")\n\n        return chroma_context\n\n\nImported code block (postcode:utilities:logger:logging_config.py__*__MODULE) code content:\nimport logging\n\nfrom rich.logging import RichHandler\nfrom rich.syntax import Syntax\n\n\ndef setup_logging(level=logging.INFO) -> None:\n    \"\"\"\n    Configures the logging system to use RichSyntaxHandler for output.\n\n    This function sets up logging with a specific log level and format. It utilizes the RichSyntaxHandler to support rich text and syntax highlighting in log outputs.\n\n    Args:\n        level (int, optional): The logging level to set for the root logger. Defaults to logging.INFO.\n\n    Example:\n        >>> setup_logging(logging.DEBUG)\n        # Configures logging at DEBUG level with RichSyntaxHandler.\n    \"\"\"\n\n    format_str = \"%(message)s\"\n    logging.basicConfig(level=level, format=format_str, handlers=[RichSyntaxHandler()])\n\n\nclass RichSyntaxHandler(RichHandler):\n    \"\"\"\n    A custom logging handler that extends RichHandler to add syntax highlighting.\n\n    This handler checks if the log record contains a 'syntax_highlight' attribute and, if so, uses 'rich.syntax.Syntax' to render the message with Python syntax highlighting.\n\n    Inherits:\n        RichHandler: The base handler provided by the rich library for rich text formatting.\n    \"\"\"\n\n    def emit(self, record) -> None:\n        \"\"\"\n        Emits a logging record.\n\n        If the record has the 'syntax_highlight' attribute set to True, it renders the 'content' attribute of the record with syntax highlighting. Otherwise, it falls back to the standard behavior of RichHandler.\n\n        Args:\n            record: The logging record to emit.\n\n        Example:\n            # Assuming `logger` is a logger instance\n            >>> logger.info(\"Regular log message\")\n            # Outputs a regular log message.\n\n            >>> logger.info(\"Highlighted log message\", extra={\"syntax_highlight\": True, \"content\": \"print('Hello, world!')\"})\n            # Outputs the message with syntax highlighting.\n        \"\"\"\n\n        try:\n            if hasattr(record, \"syntax_highlight\") and getattr(\n                record, \"syntax_highlight\"\n            ):\n                content: str = getattr(record, \"content\", \"\")\n                if isinstance(content, str):\n                    syntax = Syntax(\n                        content, \"python\", theme=\"material\", line_numbers=True\n                    )\n                    self.console.print(syntax)\n                return\n\n        except Exception as e:\n            self.handleError(record)\n\n        super().emit(record)\n\n\nImported code block (postcode:databases:chroma:chromadb_collection_manager.py__*__MODULE) code content:\nimport logging\nfrom typing import Any, Mapping, Union\n\nfrom postcode.models.models import ModuleModel\nimport postcode.types.chroma as chroma_types\nfrom chromadb.config import DEFAULT_DATABASE, DEFAULT_TENANT, Settings\nfrom chromadb.api import ClientAPI\nfrom chromadb.api.types import (\n    DataLoader,\n    CollectionMetadata,\n    GetResult,\n    QueryResult,\n    Where,\n    WhereDocument,\n    Include,\n    URIs,\n    Loadable,\n    Metadata,\n    Embedding,\n)\nfrom chromadb import Collection\nfrom chromadb import EmbeddingFunction\n# from postcode.types.postcode import ModelType\nfrom postcode.models.models import ModuleModel, ClassModel, FunctionModel, StandaloneCodeBlockModel\nModelType = Union[\n    ModuleModel,\n    ClassModel,\n    FunctionModel,\n    StandaloneCodeBlockModel,\n]\n\n\nclass ChromaDBCollectionManager:\n    \"\"\"\n    Manages a collection within ChromaDB instance, providing functionalities for adding, retrieving,\n    and querying embeddings, and their associated metadata.\n\n    This class serves as an interface to interact with a specific collection in ChromaDB.\n\n    Attributes:\n        - collection (chroma_types.Collection): An instance of the Collection class from ChromaDB\n            which this manager is responsible for.\n\n    Methods:\n        - `collection_embedding_count`: Gets the total number of embeddings in the collection.\n        - `add_embeddings`: Adds embeddings to the collection.\n        - `get_embeddings`: Gets embeddings and their metadata from the collection in the form of a TypedDict.\n        - `query_collection`: Queries and returns the `n` nearest neighbors from the collection.\n        - `upsert_models`: Loads or updates the embeddings of the provided module models into the collection.\n\n    Examples:\n        ```Python\n        from postcode.databases.chroma import ChromaDBClientBuilder\n        import postcode.types.chromadb.types as chroma_types\n\n        # Create a persistent ChromaDB client\n        client: chroma_types.ClientAPI = ChromaDBClientBuilder.create_persistent_client()\n\n        # Instantiate the ChromaDBCollectionManager with a specific collection\n        collection_manager: ChromaDBCollectionManager = (\n            ChromaDBCollectionManager(client.get_collection(\"my_collection\"))\n        )\n\n        # Example usage of the collection manager\n        embedding_count: int = collection_manager.collection_embedding_count()\n        print(f\"Total embeddings: {embedding_count}\")\n        ```\n    \"\"\"\n\n    def __init__(self, collection: Collection) -> None:\n        self.collection: Collection = collection\n\n    def collection_embedding_count(self) -> int | None:\n        \"\"\"\n        Gets the total number of embeddings in the collection.\n\n        Returns:\n            - embedding_count (int): The total number of embeddings in the collection.\n\n        Examples:\n            ```Python\n            embedding_count: int = collection_manager.get_collection_embedding_count()\n            ```\n        \"\"\"\n        try:\n            embedding_count: int = self.collection.count()\n            logging.info(\n                f\"Collection {self.collection.name} has {embedding_count} embeddings.\"\n            )\n            return embedding_count\n        except Exception as exception:\n            logging.error(exception)\n\n    def add_embeddings(\n        self,\n        ids: list[str],\n        documents: list[str],\n        metadatas: list[Mapping[str, str | int | float | bool]],\n    ) -> None:\n        \"\"\"\n        Adds embeddings to the collection.\n\n        Args:\n            - ids (list[str]): A list of ids to add to the collection.\n            - documents (list[str]): A list of documents to add to the collection.\n            - metadatas (list[dict[str, Any]]): A list of metadatas to add to the collection.\n\n        Raises:\n            - ValueError - If you don't provide either embeddings or documents.\n            - ValueError: If the length of ids, embeddings, metadatas, or documents don't match.\n            - ValueError - If you provide an id that already exists.\n\n        Examples:\n            ```Python\n            # define the ids, metadatas, and documents to add to the collection\n            id: list[str] = [\"my_id\", \"my_id2\"]\n            metadatas: list[dict[str, Any]] = [\n                {\"my_metadata\": \"my_metadata_value\"},\n                {\"my_metadata2\": \"my_metadata_value2\"},\n            ]\n            documents: list[str] = [\"my_document\", \"my_document2\"]\n\n            # add the embeddings to the collection\n            collection_manager.add_embeddings(id, metadatas, documents)\n            ```\n        \"\"\"\n\n        if not len(ids) == len(documents) == len(metadatas):\n            raise ValueError(\"The length of ids, documents, and metadatas must match.\")\n\n        try:\n            logging.info(f\"Adding embeddings to collection {self.collection.name}\")\n            self.collection.add(ids, documents=documents, metadatas=metadatas)\n        except Exception as exception:\n            raise exception\n\n    def get_embeddings(\n        self,\n        ids: list[str] | None,\n        *,\n        where_filter: Where | None = None,\n        limit: int | None = None,\n        where_document_filter: WhereDocument | None = None,\n        include_in_result: Include = [\"metadatas\", \"documents\"],\n    ) -> GetResult | None:\n        \"\"\"\n        Gets embeddings and their metadata from the collection in the form of a TypedDict.\n\n        Args:\n            - ids (list[str]): A list of ids to get from the collection.\n            - where_filter (chroma_types.Where | None): A TypedDict used to filter the results.\n            - limit (int | None): The maximum number of results to return.\n            - where_document_filter (chroma_types.WhereDocument | None): A TypedDict used to filter the results by the document,\n                e.g. `{$contains: {\"text\": \"hello\"}}`\n            - include_in_result (chroma_types.Include | None): A list used of what to return from the results, e.g. `[\"metadatas\", \"embeddings\", \"documents\"]`\n\n        Returns:\n            - embeddings (TypedDict): A typed dict of embedding data from the collection with the following keys:\n                - ids: list[str]\n                - embeddings: list[Embedding] | None\n                - documents: list[str] | None\n                - uris: chroma_types.URIs | None\n                - data: chroma_types.Loadable | None\n                - metadatas: list[chroma_types.Metadata]]\n\n        Raises:\n            - ValueError: If the length of ids, embeddings, metadatas, or documents don't match.\n            - ValueError: If you provide an id that doesn't exist.\n\n        Examples:\n            ```Python\n            import postcode.types.chromadb.types as chroma_types\n\n            # define the ids, filters to use to get embeddings from the collection\n            ids: list[str] = [\"my_id\", \"my_id2\"]\n            where_filter: chroma_types.Where = {\"my_metadata\": \"my_metadata_value\"}\n            where_document_filter: chroma_types.WhereDocument = {\"$contains\": {\"text\": \"hello\"}}\n\n            # define the data to return from the collection\n            include_in_result: chroma_types.Include = [\"metadatas\"]\n\n            # get the embeddings from the collection\n            embeddings: chroma_types.GetResult = collection_manager.get_embeddings(\n                ids,\n                where_filter=where_filter,\n                where_document_filter=where_document_filter,\n                include_in_result=include_in_result\n                )\n            ```\n        \"\"\"\n\n        try:\n            logging.info(f\"Getting embeddings from collection {self.collection.name}\")\n            return self.collection.get(\n                ids,\n                where=where_filter,\n                limit=limit,\n                where_document=where_document_filter,\n                include=include_in_result,\n            )\n        except Exception as exception:\n            raise exception\n\n    def query_collection(\n        self,\n        queries: list[str],\n        n_results: int = 10,\n        where_filter: Where | None = None,\n        where_document_filter: WhereDocument | None = None,\n        include_in_result: Include = [\"metadatas\", \"documents\"],\n    ) -> QueryResult | None:\n        \"\"\"\n        Queries and returns the `n` nearest neighbors from the collection.\n\n        Args:\n            - queries (list[str]): A list of queries to search the collection for.\n            - n_results (int): The number of results to return.\n            - where_filter (chroma_types.Where | None): A TypedDict used to filter the results.\n                - e.g. `{\"block_type\": \"FUNCTION\", \"children\": None}`\n            - where_document_filter (chroma_types.WhereDocument | None): A TypedDict used to filter the results by the document,\n                - e.g. `{$contains: \"binary search\"}`\n            - include_in_result (chroma_types.Include | None): A list used of what to return from the results, e.g. `[\"metadatas\", \"embeddings\", \"documents\"]`\n\n        Returns:\n            - results (chroma_types.QueryResult | None): A typed dict of query results from the collection, can have the following keys based on the\n                `include_in_result` parameter:\n                - ids: list[str] # The ids are always returned.\n                - embeddings: List[list[Embedding]] | None\n                - documents: list[list[str]]] | None\n                - uris: list[list[URI]]] | None\n                - data: list[Loadable] | None\n                - metadatas: list[list[Metadata]] | None\n                - distances: list[list[float]] | None\n\n        Raises:\n            - ValueError: If you don't provide query_texts.\n\n        Examples:\n            ```Python\n            import postcode.types.chromadb.types as chroma\n\n            # define the queries and filters used to search the collection\n            queries: list[str] = [\"binary search\", \"linear search\"]\n            where_filter: chroma_types.Where = {\"block_type\": \"FUNCTION\"}\n\n            # define the data to return from the collection\n            include_in_result: chroma_types.Include = [\"metadatas\", \"documents\", \"distances\"]\n\n            # query the collection and return the results from the collection\n            results: chroma_types.QueryResult = collection_manager.query_collection(\n                queries,\n                where_filter=where_filter,\n                include_in_result=include_in_result\n                )\n            ```\n        \"\"\"\n\n        try:\n            logging.info(f\"Querying collection {self.collection.name}\")\n\n            if results := self.collection.query(\n                query_texts=queries,\n                n_results=n_results,\n                where=where_filter,\n                where_document=where_document_filter,\n                include=include_in_result,\n            ):\n                return results\n            else:\n                logging.warning(\n                    f\"No results found from collection {self.collection.name}.\"\n                )\n\n        except Exception as exception:\n            raise exception\n\n    def modify_collection_name(self, name: str) -> None:\n        \"\"\"\n        Modifies the name of the collection managed by this class.\n\n        Args:\n            - name (str): The new name to assign to the collection.\n\n        Examples:\n            ```Python\n            # Rename the collection to 'new_collection_name'\n            collection_manager.modify_collection_name('new_collection_name')\n            ```\n        \"\"\"\n\n        self.collection.modify(name=name)\n\n    def modify_collection_metadata(\n        self, metadata: dict[str, Any] | None = None\n    ) -> None:\n        \"\"\"\n        Modifies the metadata of the collection managed by this class.\n\n        Args:\n            - metadata (dict[str, Any] | None): The new metadata to assign to the collection. If None, no change is made.\n\n        Examples:\n            ```Python\n            # Update metadata of the collection\n            new_metadata = {\"description\": \"Updated collection metadata\"}\n            collection_manager.modify_collection_metadata(new_metadata)\n            ```\n        \"\"\"\n\n        self.collection.modify(metadata=metadata)\n\n    def _update_metadata_or_documents_by_ids(\n        self,\n        ids: list[str],\n        metadatas: list[Mapping[str, str | int | float | bool]] | None = None,\n        documents: list[str] | None = None,\n    ) -> None:\n        \"\"\"\n        Updates the metadata or documents of specific entries in the collection by their ids.\n\n        Args:\n            - ids (list[str]): List of ids of the entries to be updated.\n            - metadatas (list[Mapping[str, Any]] | None): List of metadata updates corresponding to the ids.\n            - documents (list[str] | None): List of document updates corresponding to the ids.\n\n        Raises:\n            - ValueError: If neither metadatas nor documents are provided.\n            - ValueError: If the length of ids and documents don't match.\n            - ValueError: If the length of ids and metadatas don't match.\n            - ValueError: If the length of ids, metadatas, and documents don't match.\n\n        Notes:\n            - As of now, ChromaDB doesn't raise an exception if you provide an id that doesn't exist.\n\n        Examples:\n            ```Python\n            # Update metadata and documents for specific ids\n            ids_to_update = ['id1', 'id2']\n            metadata_updates = [{\"key1\": \"value1\"}, {\"key2\": \"value2\"}]\n            document_updates = [\"new document 1\", \"new document 2\"]\n            collection_manager.update_metadata_or_documents_by_ids(ids_to_update, metadata_updates, document_updates)\n            ```\n        \"\"\"\n\n        if not metadatas and not documents:\n            raise ValueError(\"You must provide either metadatas or documents.\")\n        if not metadatas and documents:\n            if len(ids) != len(documents):\n                raise ValueError(\"The length of ids and documents must match.\")\n        if metadatas and not documents:\n            if len(ids) != len(metadatas):\n                raise ValueError(\"The length of ids and metadatas must match.\")\n        if metadatas and documents:\n            if len(ids) != len(metadatas) != len(documents):\n                raise ValueError(\n                    \"The length of ids, metadatas, and documents must match.\"\n                )\n        for index, id in enumerate(ids):\n            if not self.collection.get(id):\n                logging.error(\n                    f\"Id {id} does not exist in collection {self.collection.name}.\"\n                )\n                ids.pop(index)\n                if metadatas:\n                    popped_metadata = metadatas.pop(index)\n                    if popped_metadata:\n                        logging.warning(\n                            f\"Removing metadata at index {index} from update.\"\n                        )\n                if documents:\n                    popped_document = documents.pop(index)\n                    if popped_document:\n                        logging.warning(\n                            f\"Removing document at index {index} from update.\"\n                        )\n\n        if not ids:\n            logging.warning(\"All updates failed.\")\n            return None\n        else:\n            logging.info(f\"Updating collection {self.collection.name} with ids {ids}.\")\n            self.collection.update(ids=ids, metadatas=metadatas, documents=documents)\n\n    def _upsert_documents(\n        self,\n        ids: list[str],\n        documents: list[str],\n        metadatas: list[Mapping[str, str | int | float | bool]],\n        # embeddings: list[chroma_types.Embedding],\n    ) -> None:\n        \"\"\"\n        Inserts or updates documents in the collection, based on the provided ids.\n\n        Args:\n            - ids (list[str]): List of ids for the documents to be inserted or updated.\n            - documents (list[str]): List of documents corresponding to the ids.\n            - metadatas (list[Mapping[str, Any]]): List of metadata corresponding to the ids.\n\n        Raises:\n            - ValueError: If the lengths of ids, documents, and metadatas don't match.\n\n        Examples:\n            ```Python\n            # Upsert documents in the collection\n            ids = ['id1', 'id2']\n            documents = ['doc1', 'doc2']\n            metadatas = [{\"meta1\": \"value1\"}, {\"meta2\": \"value2\"}]\n\n            # Upsert documents in the collection\n            collection_manager.upsert_documents(ids, documents, metadatas)\n            ```\n        \"\"\"\n\n        if len(ids) != len(documents) != len(metadatas):\n            raise ValueError(\"The length of ids, documents, and metadatas must match.\")\n\n        logging.info(f\"Upserting collection {self.collection.name} with ids {ids}.\")\n        self.collection.upsert(\n            ids=ids,\n            # embeddings=embeddings,\n            metadatas=metadatas,\n            documents=documents,\n        )\n\n    def delete_embeddings(self, ids: list[str]) -> None:\n        \"\"\"\n        Deletes embeddings from the collection based on the provided ids.\n\n        Args:\n            - ids (list[str]): List of ids corresponding to the embeddings to be deleted.\n\n        Examples:\n            ```Python\n            # Delete specific embeddings by ids\n            ids_to_delete = ['id1', 'id2']\n            collection_manager.delete_embeddings(ids_to_delete)\n            ```\n        \"\"\"\n\n        ids_to_delete: list[str] = ids.copy()\n        for index, id in enumerate(ids_to_delete):\n            if not self.collection.get(id):\n                logging.error(\n                    f\"Id {id} does not exist in collection {self.collection.name}.\"\n                )\n                ids_to_delete.pop(index)\n\n        if not ids_to_delete:\n            logging.warning(\"No IDs given were in the database.\")\n            return None\n\n        logging.info(\n            f\"Deleting embeddings from collection {self.collection.name} with ids {ids_to_delete}.\"\n        )\n        self.collection.delete(ids_to_delete)\n\n    def upsert_models(self, module_models: tuple[ModuleModel, ...]) -> None:\n        \"\"\"\n        Loads or updates the embeddings of the provided module models into the collection.\n\n        The Pydantic models are converted to a dictionary with a format that ChromaDB can use, then the ids, documents, and metadatas\n        are added to their respective lists. The lists are then either added to or updated in the collection depending on whether or\n        not the code blocks were in the the collection to begin with.\n\n        Args:\n            - module_models (tuple[ModuleModel, ...]): The module models to load or update into the collection.\n\n        Examples:\n            ```Python\n            # Upsert module models into the collection\n            module_models = (module_model1, module_model2)\n            collection_manager.upsert_models(module_models)\n            ```\n        \"\"\"\n\n        ids: list[str] = []\n        documents: list[str] = []\n        metadatas: list[Mapping[str, str | int | float | bool]] = []\n\n        for module_model in module_models:\n            if module_model.summary:\n                ids.append(module_model.id)\n                documents.append(module_model.summary)\n                metadatas.append(module_model.convert_to_metadata())\n\n            if module_model.children:\n                for child in module_model.children:\n                    child_data: dict[str, Any] = self._recursively_gather_child_data(\n                        child\n                    )\n                    ids.extend(child_data[\"ids\"])\n                    documents.extend(child_data[\"documents\"])\n                    metadatas.extend(child_data[\"metadatas\"])\n\n        logging.info(\n            f\"{self.collection.name} has {self.collection_embedding_count()} embeddings.\"\n        )\n        self._upsert_documents(ids=ids, documents=documents, metadatas=metadatas)\n        logging.info(\n            f\"After upsert {self.collection.name} has {self.collection_embedding_count()} embeddings.\"\n        )\n\n    def _recursively_gather_child_data(self, model: ModelType) -> dict[str, Any]:\n        ids: list[str] = []\n        documents: list[str] = []\n        metadatas: list[Mapping[str, str | int | float | bool]] = []\n        if model.summary:\n            ids.append(model.id)\n            documents.append(model.summary)\n            metadatas.append(model.convert_to_metadata())\n        else:\n            logging.warning(f\"Child {model.id} has no summary.\")\n        if model.children:\n            for child in model.children:\n                child_data: dict[str, Any] = self._recursively_gather_child_data(child)\n                ids.extend(child_data[\"ids\"])\n                documents.extend(child_data[\"documents\"])\n                metadatas.extend(child_data[\"metadatas\"])\n\n        return {\n            \"ids\": ids,\n            \"documents\": documents,\n            \"metadatas\": metadatas,\n        }\n\n\nImported code block (postcode:updaters:standard_updater.py__*__MODULE) code content:\n# Create method, `update_all`, that updates the whole project, it parses all code, wipes all databases, and summarizes all code blocks,\n# then updates all the databases with the new information.\n\n\nfrom logging import Logger\n\nfrom openai import OpenAI\nfrom postcode.ai_services.summarizer.openai_summarizer import OpenAISummarizer\nfrom postcode.ai_services.summarizer.standard_summarization_manager import (\n    StandardSummarizationManager,\n)\n\nfrom postcode.databases.chroma.setup_chroma import (\n    ChromaSetupReturnContext,\n    setup_chroma,\n)\nfrom postcode.json_management.json_handler import JSONHandler\n\nfrom postcode.models.models import ModuleModel\nfrom postcode.python_parser.visitor_manager.visitor_manager import (\n    VisitorManager,\n    VisitorManagerProcessFilesReturn,\n)\n\n\nclass StandardUpdater:\n    @staticmethod\n    def update_all(\n        directory: str, output_directory: str, logger: Logger\n    ) -> ChromaSetupReturnContext:\n        visitor_manager = VisitorManager(directory, output_directory)\n        process_files_return: VisitorManagerProcessFilesReturn = (\n            visitor_manager.process_files()\n        )\n\n        module_models_tuple: tuple[ModuleModel, ...] = process_files_return.models_tuple\n        client = OpenAI(max_retries=4)\n        summarizer = OpenAISummarizer(client=client)\n        summarization_manager = StandardSummarizationManager(\n            module_models_tuple, summarizer\n        )\n        finalized_module_models: tuple[\n            ModuleModel, ...\n        ] = summarization_manager.create_summarizes_and_return_updated_models()\n\n        logger.info(\"Summarization complete\")\n\n        logger.info(\"Saving models as JSON\")\n        directory_modules: dict[str, list[str]] = process_files_return.directory_modules\n        json_manager = JSONHandler(directory, directory_modules, output_directory)\n\n        for module_model in module_models_tuple:\n            json_manager.save_model_as_json(module_model, module_model.file_path)\n\n        json_manager.save_visited_directories()\n        logger.info(\"JSON save complete\")\n\n        logger.info(\"Directory parsing completed.\")\n\n        chroma_context: ChromaSetupReturnContext = setup_chroma(\n            finalized_module_models, logger\n        )\n\n        return chroma_context\n\n, \nimport logging\nfrom logging import Logger\nfrom typing import Union\nfrom chromadb.api.types import QueryResult\nfrom chromadb import Collection\n        "}    str | None = None\\n    local_block_id: str | None = None\\n\\n    # def convert_import_names_to_metadata(self) -> str:\\n    #     \\\"\\\"\\\"Converts the import name to a metadata string.\\\"\\\"\\\"\\n\\n    #     return self.model_dump_json()\\n\\n\\nclass ImportModel(BaseModel):\\n    \\\"\\\"\\\"Class representing an import statement.\\\"\\\"\\\"\\n\\n    import_names: list[ImportNameModel]\\n    imported_from: str | None = None\\n    import_module_type: ImportModuleType = ImportModuleType.STANDARD_LIBRARY\\n    local_module_id: str | None = None\\n\\n    def convert_import_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the import to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass DependencyModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a module dependency.\\\"\\\"\\\"\\n\\n    code_block_id: str\\n\\n    def convert_dependency_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the dependency to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass CommentModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a comment.\\\"\\\"\\\"\\n\\n    content: str\\n    comment_types: list[CommentType]\\n\\n    def convert_comment_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the comment to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass DecoratorModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a decorator.\\\"\\\"\\\"\\n\\n    content: str\\n    decorator_name: str\\n    decorator_args: list[str] | None = None\\n\\n    def convert_decorator_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the decorator to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass ClassKeywordModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a class keyword.\\\"\\\"\\\"\\n\\n    content: str\\n    keyword_name: str\\n    args: str | None = None\\n\\n    def convert_class_keyword_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the class keyword to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass ParameterModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a function parameter.\\\"\\\"\\\"\\n\\n    content: str\\n\\n\\nclass ParameterListModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a list of parameters.\\\"\\\"\\\"\\n\\n    params: list[ParameterModel] | None = None\\n    star_arg: ParameterModel | None = None\\n    kwonly_params: list[ParameterModel] | None = None\\n    star_kwarg: ParameterModel | None = None\\n    posonly_params: list[ParameterModel] | None = None\\n\\n    def convert_parameters_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the parameter list to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass BaseCodeBlockModel(BaseModel):\\n    \\\"\\\"\\\"Attributes common to all code block models.\\\"\\\"\\\"\\n\\n    id: str\\n    parent_id: str | None = None\\n    block_type: BlockType\\n    start_line_num: int\\n    end_line_num: int\\n    code_content: str = \\\"\\\"\\n    important_comments: list[CommentModel] | None = None\\n    dependencies: list[ImportModel | DependencyModel] | None = None\\n    summary: str | None = None\\n    children: list[\\n        Union[\\n            \\\"ClassModel\\\",\\n            \\\"FunctionModel\\\",\\n            \\\"StandaloneCodeBlockModel\\\",\\n        ]\\n    ] | None = []\\n\\n    @validator(\\\"parent_id\\\", always=True)\\n    def check_parent_id(cls, v, values, **kwargs) -> str | None:\\n        \\\"\\\"\\\"Validates that parent_id is a non-empty string unless block_type is MODULE.\\\"\\\"\\\"\\n\\n        if \\\"block_type\\\" in values and values[\\\"block_type\\\"] != BlockType.MODULE:\\n            if len(v) < 1:\\n                raise ValueError(\\\"parent_id is required!\\\")\\n        return v\\n\\n    def _convert_parent_id_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the parent_id to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.parent_id}\\\" if self.parent_id else \\\"\\\"\\n\\n    def _convert_block_type_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the block_type to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.block_type.name}\\\"\\n\\n    def _convert_important_comments_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the important comments to a metadata string.\\\"\\\"\\\"\\n\\n        important_comments: str = (\\n            self.model_dump_json() if self.important_comments else \\\"\\\"\\n        )\\n\\n        return f\\\"{important_comments}\\\"\\n\\n    def _convert_dependencies_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the dependencies to a metadata string.\\\"\\\"\\\"\\n\\n        dependencies_str: str = \\\"\\\"\\n\\n        if self.dependencies:\\n            for dependency in self.dependencies:\\n                if isinstance(dependency, ImportModel):\\n                    dependencies_str += f\\\"{dependency.convert_import_to_metadata()}\\\\n\\\"\\n                elif isinstance(dependency, DependencyModel):\\n                    dependencies_str += (\\n                        f\\\"{dependency.convert_dependency_to_metadata()}\\\\n\\\"\\n                    )\\n\\n        return dependencies_str\\n\\n    def _convert_summary_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the summary to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.summary}\\\" if self.summary else \\\"\\\"\\n\\n    def _convert_children_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the children to a metadata string.\\\"\\\"\\\"\\n\\n        children_str: str = \\\"\\\"\\n\\n        if self.children:\\n            for child in self.children:\\n                children_str += f\\\"{child.id}\\\\n\\\"\\n\\n        return children_str\\n\\n    def _convert_base_attributes_to_metadata_dict(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the base attributes to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            \\\"id\\\": self.id,\\n            \\\"parent_id\\\": self._convert_parent_id_to_metadata(),\\n            \\\"block_type\\\": self._convert_block_type_to_metadata(),\\n            \\\"start_line_num\\\": self.start_line_num,\\n            \\\"end_line_num\\\": self.end_line_num,\\n            \\\"code_content\\\": self.code_content,\\n            \\\"important_comments\\\": self._convert_important_comments_to_metadata(),\\n            \\\"dependencies\\\": self._convert_dependencies_to_metadata(),\\n            \\\"summary\\\": self._convert_summary_to_metadata(),\\n            \\\"children\\\": self._convert_children_to_metadata(),\\n        }\\n\\n\\nclass ModuleSpecificAttributes(BaseModel):\\n    \\\"\\\"\\\"Module specific attributes.\\\"\\\"\\\"\\n\\n    file_path: str = Field(min_length=1)\\n    docstring: str | None = None\\n    header: list[str] | None = None\\n    footer: list[str] | None = None\\n    imports: list[ImportModel] | None = None\\n\\n    def _convert_docstring_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the docstring to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.docstring}\\\"\\n\\n    def _convert_header_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the header and footer to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n    def _convert_footer_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the header and footer to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n    def _convert_imports_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the imports to a metadata string.\\\"\\\"\\\"\\n        imports_str: str = self.model_dump_json() if self.imports else \\\"\\\"\\n        return f\\\"{imports_str}\\\"\\n\\n    def _convert_module_attributes_to_metadata_dict(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the module attributes to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            \\\"file_path\\\": self.file_path,\\n            \\\"docstring\\\": self._convert_docstring_to_metadata(),\\n            \\\"header\\\": self._convert_header_to_metadata(),\\n            \\\"footer\\\": self._convert_footer_to_metadata(),\\n            \\\"imports\\\": self._convert_imports_to_metadata(),\\n        }\\n\\n\\nclass ModuleModel(BaseCodeBlockModel, ModuleSpecificAttributes):\\n    \\\"\\\"\\\"Model for a module.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the module model to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_module_attributes_to_metadata_dict(),\\n        }\\n\\n\\nclass ClassSpecificAttributes(BaseModel):\\n    \\\"\\\"\\\"Class specific attributes.\\\"\\\"\\\"\\n\\n    class_name: str = Field(min_length=1)\\n    decorators: list[DecoratorModel] | None = None\\n    bases: list[str] | None = None\\n    docstring: str | None = None\\n    keywords: list[ClassKeywordModel] | None = None\\n    # attributes: list[dict] | None = None\\n\\n    def _convert_decorators_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the decorators to a metadata string.\\\"\\\"\\\"\\n        decorators_str: str = self.model_dump_json() if self.decorators else \\\"\\\"\\n        return f\\\"{decorators_str}\\\"\\n\\n    def _convert_bases_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the bases to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json() if self.bases else \\\"\\\"\\n\\n    def _convert_docstring_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the docstring to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.docstring}\\\" if self.docstring else \\\"\\\"\\n\\n    def _convert_keywords_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the keywords to a metadata string.\\\"\\\"\\\"\\n        keywords_str: str = self.model_dump_json() if self.keywords else \\\"\\\"\\n        return f\\\"{keywords_str}\\\"\\n\\n    def _convert_class_attributes_to_metadata_dict(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the class attributes to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            \\\"class_name\\\": self.class_name,\\n            \\\"decorators\\\": self._convert_decorators_to_metadata(),\\n            \\\"bases\\\": self._convert_bases_to_metadata(),\\n            \\\"docstring\\\": self._convert_docstring_to_metadata(),\\n            \\\"keywords\\\": self._convert_keywords_to_metadata(),\\n        }\\n\\n\\nclass ClassModel(BaseCodeBlockModel, ClassSpecificAttributes):\\n    \\\"\\\"\\\"Model for a class.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the class model to a metadata dictionary.\\\"\\\"\\\"\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_class_attributes_to_metadata_dict(),\\n        }\\n\\n\\nclass FunctionSpecificAttributes(BaseModel):\\n    \\\"\\\"\\\"Function specific attributes.\\\"\\\"\\\"\\n\\n    function_name: str = Field(min_length=1)\\n    docstring: str | None = None\\n    decorators: list[DecoratorModel] | None = None\\n    parameters: ParameterListModel | None = None\\n    returns: str | None = None\\n    is_method: bool = False\\n    is_async: bool = False\\n\\n    def _convert_docstring_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the docstring to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.docstring}\\\" if self.docstring else \\\"\\\"\\n\\n    def _convert_decorators_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the decorators to a metadata string.\\\"\\\"\\\"\\n        decorators_str: str = self.model_dump_json() if self.decorators else \\\"\\\"\\n        return f\\\"{decorators_str}\\\"\\n\\n    def _convert_parameters_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the parameters to a metadata string.\\\"\\\"\\\"\\n        return (\\n            self.parameters.convert_parameters_to_metadata() if self.parameters else \\\"\\\"\\n        )\\n\\n    def _convert_returns_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the returns to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.returns}\\\" if self.returns else \\\"\\\"\\n\\n    def _convert_function_attributes_to_metadata_dict(self) -> dict[str, str | bool]:\\n        \\\"\\\"\\\"Converts the function attributes to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            \\\"function_name\\\": self.function_name,\\n            \\\"docstring\\\": self._convert_docstring_to_metadata(),\\n            \\\"decorators\\\": self._convert_decorators_to_metadata(),\\n            \\\"parameters\\\": self._convert_parameters_to_metadata(),\\n            \\\"returns\\\": self._convert_returns_to_metadata(),\\n            \\\"is_method\\\": self.is_method,\\n            \\\"is_async\\\": self.is_async,\\n        }\\n\\n\\nclass FunctionModel(BaseCodeBlockModel, FunctionSpecificAttributes):\\n    \\\"\\\"\\\"Model for a function.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the function model to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_function_attributes_to_metadata_dict(),\\n        }\\n\\n\\nclass StandaloneCodeBlockSpecificAttributes(BaseModel):\\n    \\\"\\\"\\\"Standalone code block specific attributes.\\\"\\\"\\\"\\n\\n    variable_assignments: list[str] | None = None\\n\\n    def _convert_variable_assignments_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the variable assignments to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json() if self.variable_assignments else \\\"\\\"\\n\\n    def _convert_standalone_block_attributes_to_metadata_dict(\\n        self,\\n    ) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the standalone code block attributes to a metadata dictionary.\\\"\\\"\\\"\\n        return {\\n            \\\"variable_assignments\\\": self._convert_variable_assignments_to_metadata(),\\n        }\\n\\n\\nclass StandaloneCodeBlockModel(\\n    BaseCodeBlockModel, StandaloneCodeBlockSpecificAttributes\\n):\\n    \\\"\\\"\\\"Model for a standalone code block.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the standalone code block model to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_standalone_block_attributes_to_metadata_dict(),\\n        }\\n\\n\\nImported code block (postcode:python_parser:visitor_manager:visitor_manager.py__*__MODULE) code content:\\nfrom dataclasses import dataclass\\nimport logging\\nfrom pathlib import Path\\n\\nfrom postcode.python_parser.model_builders.module_model_builder import (\\n    ModuleModelBuilder,\\n)\\nfrom postcode.utilities.logger.decorators import logging_decorator\\n\\nfrom postcode.python_parser.parsers.python_parser import PythonParser\\nfrom postcode.python_parser.visitor_manager.import_and_dependency_updater import (\\n    ImportAndDependencyUpdater,\\n)\\nfrom postcode.models.models import ModuleModel\\n\\nfrom postcode.ai_services.summarizer.summarization_context import Summarizer\\n\\nEXCLUDED_DIRECTORIES: set[str] = {\\\".venv\\\", \\\"node_modules\\\", \\\"__pycache__\\\", \\\".git\\\"}\\n\\n\\n@dataclass\\nclass VisitorManagerProcessFilesReturn:\\n    \\\"\\\"\\\"\\n    Represents the return value of the VisitorManager.process_files() method.\\n\\n    Attributes:\\n        - models_tuple (tuple[ModuleModel, ...]): A tuple of ModuleModel objects representing the parsed modules.\\n        - directory_modules (dict[str, list[str]]): A dictionary mapping directory paths to lists of module names.\\n            This is used to keep track of the modules present in each directory.\\n    \\\"\\\"\\\"\\n\\n    models_tuple: tuple[ModuleModel, ...]\\n    directory_modules: dict[str, list[str]]\\n\\n\\nclass VisitorManager:\\n    \\\"\\\"\\\"\\n    Manages the visiting and processing of Python files in a given directory.\\n\\n    This class scans a specified directory, filters for Python files, parses them, and saves the parsed data in a structured JSON format. It also maintains a mapping of directories to the Python files they contain.\\n\\n    Attributes:\\n        directory (str): The root directory to scan for Python files.\\n        output_directory (str): The directory where output JSON files will be saved.\\n        directory_modules (dict): A mapping of directories to their contained Python files.\\n\\n    Example:\\n        >>> visitor_manager = VisitorManager(\\\"/path/to/python/code\\\", \\\"output\\\")\\n        >>> visitor_manager.process_files()\\n        # This will process all Python files in /path/to/python/code and save their parsed data in the output directory.\\n    \\\"\\\"\\\"\\n\\n    @logging_decorator(message=\\\"Initializing VisitorManager\\\")\\n    def __init__(self, directory: str, output_directory: str = \\\"output_json\\\") -> None:\\n        self.directory: str = directory\\n        self.output_directory: str = output_directory\\n        self.directory_modules: dict[str, list[str]] = {}\\n\\n    def process_files(self) -> VisitorManagerProcessFilesReturn:\\n        \\\"\\\"\\\"\\n        Process the files in the directory and return the module models.\\n\\n        This function iterates through all the Python files in the directory, processes each file,\\n        updates the imports, and builds module models for each file. It returns a tuple of module models\\n        and a dictionary of directory modules.\\n\\n        Returns:\\n            A named tuple (VisitorManagerProcessFilesReturn) containing:\\n            - models_tuple (tuple[ModuleModel, ...]): A tuple of module models.\\n            - directory_modules (dict[str, ModuleModel]): A dictionary of directory modules.\\n\\n        Examples:\\n            >>> visitor_manager = VisitorManager()\\n            >>> result = visitor_manager.process_files()\\n            >>> print(result.models_tuple)\\n            (ModuleModel(file_path='/path/to/file1.py'), ModuleModel(file_path='/path/to/file2.py'))\\n            >>> print(result.directory_modules)\\n            {'/path/to/directory1': ModuleModel(file_path='/path/to/directory1/__init__.py')}\\n        \\\"\\\"\\\"\\n\\n        logging.info(\\\"Processing files\\\")\\n        python_files: list[str] = self._get_python_files()\\n        model_builder_list: list[ModuleModelBuilder] = []\\n        for file_path in python_files:\\n            if model_builder := self._process_file(file_path):\\n                model_builder_list.append((model_builder))\\n\\n        logging.info(\\\"File processing completed\\\")\\n        logging.info(\\\"Updating imports\\\")\\n\\n        # TODO: Test making this a tuple of tuples, see if that solves the double update import issue\\n        model_builder_tuple: tuple[ModuleModelBuilder, ...] = tuple(model_builder_list)\\n\\n        import_and_dependency_updater = ImportAndDependencyUpdater(model_builder_tuple)\\n        import_and_dependency_updater.update_imports()\\n        logging.info(\\\"Updated imports\\\")\\n\\n        module_models_list: list[ModuleModel] = []\\n        for module_model_builder in model_builder_tuple:\\n            module_model: ModuleModel = self._build_module_model(module_model_builder)\\n            module_models_list.append(module_model)\\n\\n        module_models_tuple: tuple[ModuleModel, ...] = tuple(module_models_list)\\n\\n        return VisitorManagerProcessFilesReturn(\\n            models_tuple=module_models_tuple, directory_modules=self.directory_modules\\n        )\\n\\n    def _walk_directories(self) -> list[str]:\\n        \\\"\\\"\\\"Walks the specified directory and returns a list of all files.\\\"\\\"\\\"\\n\\n        all_files: list[str] = []\\n        for file_path in Path(self.directory).rglob(\\\"*\\\"):\\n            if not any(\\n                excluded in file_path.parts for excluded in EXCLUDED_DIRECTORIES\\n            ):\\n                all_files.append(str(file_path))\\n        return all_files\\n\\n    def _filter_python_files(self, files: list[str]) -> list[str]:\\n        \\\"\\\"\\\"Filters a list of files to only include Python files.\\\"\\\"\\\"\\n\\n        return [file for file in files if file.endswith(\\\".py\\\")]\\n\\n    @logging_decorator(message=\\\"Getting Python files\\\")\\n    def _get_python_files(self) -> list[str]:\\n        \\\"\\\"\\\"Gets all Python files in the specified directory.\\\"\\\"\\\"\\n\\n        all_files: list[str] = self._walk_directories()\\n        return self._filter_python_files(all_files)\\n\\n    def _process_file(self, file_path: str) -> ModuleModelBuilder | None:\\n        \\\"\\\"\\\"Processes a single Python file.\\\"\\\"\\\"\\n\\n        file_path_obj = Path(file_path)\\n        root = str(file_path_obj.parent)\\n        self.directory_modules.setdefault(root, []).append(file_path_obj.name)\\n        return self._parse_file(file_path)\\n\\n    @logging_decorator(message=\\\"Processing file\\\")\\n    def _parse_file(self, file_path: str) -> ModuleModelBuilder | None:\\n        \\\"\\\"\\\"Parses a Python file and saves the parsed data as JSON.\\\"\\\"\\\"\\n\\n        parser = PythonParser(file_path)\\n        code: str = parser.open_file()\\n        module_model_builder: ModuleModelBuilder | None = parser.parse(code)\\n\\n        return module_model_builder\\n\\n    def _build_module_model(\\n        self, visitor_stack: ModuleModelBuilder | None\\n    ) -> ModuleModel:\\n        \\\"\\\"\\\"\\n        Builds a module model from the provided module builder.\\n\\n        Args:\\n            visitor_stack (ModuleModelBuilder): The module builder to build the model from.\\n\\n        Returns:\\n            ModuleModel: A structured module model.\\n\\n        Example:\\n            >>> module_model = python_parser.build_module_model(visitor_stack)\\n            # Builds a module model from the provided module builder.\\n        \\\"\\\"\\\"\\n\\n        if not isinstance(visitor_stack, ModuleModelBuilder):\\n            raise TypeError(\\\"Expected the first builder to be a ModuleModelBuilder\\\")\\n\\n        return visitor_stack.build()\\n\\n, \\nfrom logging import Logger\\nfrom openai import OpenAI\\n        \",\"children\":[{\"class_name\":\"StandardUpdater\",\"decorators\":null,\"bases\":null,\"docstring\":null,\"keywords\":null,\"id\":\"postcode:updaters:standard_updater.py__*__MODULE__*__CLASS-StandardUpdater\",\"parent_id\":\"postcode:updaters:standard_updater.py__*__MODULE\",\"block_type\":\"CLASS\",\"start_line_num\":24,\"end_line_num\":65,\"code_content\":\"\\n\\nclass StandardUpdater:\\n    @staticmethod\\n    def update_all(\\n        directory: str, output_directory: str, logger: Logger\\n    ) -> ChromaSetupReturnContext:\\n        visitor_manager = VisitorManager(directory, output_directory)\\n        process_files_return: VisitorManagerProcessFilesReturn = (\\n            visitor_manager.process_files()\\n        )\\n\\n        module_models_tuple: tuple[ModuleModel, ...] = process_files_return.models_tuple\\n        client = OpenAI(max_retries=4)\\n        summarizer = OpenAISummarizer(client=client)\\n        summarization_manager = StandardSummarizationManager(\\n            module_models_tuple, summarizer\\n        )\\n        finalized_module_models: tuple[\\n            ModuleModel, ...\\n        ] = summarization_manager.create_summarizes_and_return_updated_models()\\n\\n        logger.info(\\\"Summarization complete\\\")\\n\\n        logger.info(\\\"Saving models as JSON\\\")\\n        directory_modules: dict[str, list[str]] = process_files_return.directory_modules\\n        json_manager = JSONHandler(directory, directory_modules, output_directory)\\n\\n        for module_model in module_models_tuple:\\n            json_manager.save_model_as_json(module_model, module_model.file_path)\\n\\n        json_manager.save_visited_directories()\\n        logger.info(\\\"JSON save complete\\\")\\n\\n        logger.info(\\\"Directory parsing completed.\\\")\\n\\n        chroma_context: ChromaSetupReturnContext = setup_chroma(\\n            finalized_module_models, logger\\n        )\\n\\n        return chroma_context\\n\",\"important_comments\":null,\"dependencies\":[{\"import_names\":[{\"name\":\"VisitorManager\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"VisitorManagerProcessFilesReturn\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"postcode.python_parser.visitor_manager.visitor_manager\",\"import_module_type\":\"LOCAL\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"VisitorManager\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"VisitorManagerProcessFilesReturn\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"postcode.python_parser.visitor_manager.visitor_manager\",\"import_module_type\":\"LOCAL\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"Logger\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"logging\",\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"OpenAI\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"openai\",\"import_module_type\":\"THIRD_PARTY\",\"local_mod       {"id": "postcode:updaters:git_updater.py__*__MODULE", "parent_id": "", "block_type": "MODULE", "start_line_num": 1, "end_line_num": 114, "code_content": "import subprocess\n\n\nclass UpdateUsingGit:\n    \"\"\"\n    DO NOT USE: The necessary functionality for this class is not yet implemented.\n\n    A class that provides methods to get the names of the Python modules that have been changed using on version control.\n\n    Use this class to get all the file names for the Python modules that have been changes since the last commit or since\n    a specific commit. You can get the `commit_hash` for a specific commit by going to the commit on GitHub and copying\n    the hash from the URL. For example, the commit hash for the following commit is `e8856d2`, or you can use the terminal, for\n    instance: `git log --author=\"username\" --grep=\"commit message\" --format=\"%H\"` if you know all the details of the commit.\n\n    Methods:\n        - `get_module_names_updated_since_last_commit()`: Returns a list of the modules that have been changed since the last commit.\n        - `get_module_names_updated_since_commit(commit_hash: str)`: Returns a list of the modules that have been changed since the specified commit.\n\n    Examples:\n        ```Python\n        from postcode.updaters.git_updater import UpdateUsingGit\n\n        # Get the names of the modules that have been changed since the last commit\n        changed_modules_name_list = UpdateUsingGit.get_module_names_updated_since_last_commit()\n        ```\n    \"\"\"\n\n    @staticmethod\n    def get_module_names_updated_since_last_commit() -> list[str]:\n        \"\"\"\n        Returns a list of the modules that have been changed since the last commit.\n\n        Runs the following command using subprocess:\n            (git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\n\n        Returns:\n            - list[str]: A list of the modules that have been changed since the last commit.\n\n        Raises:\n            - Exception: If the git command fails.\n        \"\"\"\n\n        git_command = \"(git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\"\n\n        result: subprocess.CompletedProcess[str] = subprocess.run(\n            git_command, shell=True, capture_output=True, text=True\n        )\n        if result.returncode != 0:\n            raise Exception(\"Git command failed: \" + result.stderr)\n\n        changed_files: list[str] = result.stdout.strip().split(\"\\n\")\n\n        return [file for file in changed_files if file.endswith(\".py\")]\n\n    @staticmethod\n    def get_module_names_updated_since_commit(commit_hash: str) -> list[str]:\n        \"\"\"\n        Returns a list of the Python modules that have been changed since the specified commit.\n\n        Args:\n            - commit (str): The commit hash or reference to compare the current state against.\n\n        Runs the following command using subprocess:\n            (git ls-files --others --exclude-standard; git diff --name-only COMMIT) | sort | uniq\n\n        Returns:\n            - list[str]: A list of the modules that have been changed since the specified commit.\n\n        Raises:\n            - Exception: If the git command fails.\n        \"\"\"\n\n        git_command = f\"(git ls-files --others --exclude-standard; git diff --name-only {commit_hash}) | sort | uniq\"\n\n        result: subprocess.CompletedProcess[str] = subprocess.run(\n            git_command, shell=True, capture_output=True, text=True\n        )\n        if result.returncode != 0:\n            raise Exception(\"Git command failed: \" + result.stderr)\n\n        changed_files: list[str] = result.stdout.strip().split(\"\\n\")\n\n        return [file for file in changed_files if file.endswith(\".py\")]\n\n    @staticmethod\n    def __get_updated_modules(directory: str | None = None) -> list[str]:\n        \"\"\"\n        DO NOT USE: The necessary functionality for this method is not yet implemented.\n\n        Returns a list of the modules that have been changed since the last commit based on a directory path.\n        \"\"\"\n        git_ls_files_cmd = \"git ls-files --others --exclude-standard\"\n        git_diff_cmd = \"git diff --name-only HEAD\"\n\n        if directory:\n            git_ls_files_cmd += f\" '{directory}'\"\n            git_diff_cmd += f\" '{directory}'\"\n\n        git_command: str = f\"({git_ls_files_cmd}; {git_diff_cmd}) | sort | uniq\"\n\n        result: subprocess.CompletedProcess[str] = subprocess.run(\n            git_command, shell=True, capture_output=True, text=True\n        )\n        if result.returncode != 0:\n            raise Exception(\"Git command failed: \" + result.stderr)\n\n        changed_files: list[str] = result.stdout.strip().split(\"\\n\")\n\n        return [file for file in changed_files if file.endswith(\".py\")]\n\n\nif __name__ == \"__main__\":\n    print(UpdateUsingGit.get_module_names_updated_since_commit(\"e8856d2\"))\n", "important_comments": "", "dependencies": "", "summary": "\nSummary:\n\n        postcode:updaters:git_updater.py__*__MODULE\n\n        \nChild (postcode:updaters:git_updater.py__*__MODULE__*__STANDALONE_BLOCK-1) code content:\nif __name__ == \"__main__\":\n    print(UpdateUsingGit.get_module_names_updated_since_commit(\"e8856d2\"))\n\n\nChild (postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit) code content:\n\n\nclass UpdateUsingGit:\n    \"\"\"\n    DO NOT USE: The necessary functionality for this class is not yet implemented.\n\n    A class that provides methods to get the names of the Python modules that have been changed using on version control.\n\n    Use this class to get all the file names for the Python modules that have been changes since the last commit or since\n    a specific commit. You can get the `commit_hash` for a specific commit by going to the commit on GitHub and copying\n    the hash from the URL. For example, the commit hash for the following commit is `e8856d2`, or you can use the terminal, for\n    instance: `git log --author=\"username\" --grep=\"commit message\" --format=\"%H\"` if you know all the details of the commit.\n\n    Methods:\n        - `get_module_names_updated_since_last_commit()`: Returns a list of the modules that have been changed since the last commit.\n        - `get_module_names_updated_since_commit(commit_hash: str)`: Returns a list of the modules that have been changed since the specified commit.\n\n    Examples:\n        ```Python\n        from postcode.updaters.git_updater import UpdateUsingGit\n\n        # Get the names of the modules that have been changed since the last commit\n        changed_modules_name_list = UpdateUsingGit.get_module_names_updated_since_last_commit()\n        ```\n    \"\"\"\n\n    @staticmethod\n    def get_module_names_updated_since_last_commit() -> list[str]:\n        \"\"\"\n        Returns a list of the modules that have been changed since the last commit.\n\n        Runs the following command using subprocess:\n            (git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\n\n        Returns:\n            - list[str]: A list of the modules that have been changed since the last commit.\n\n        Raises:\n            - Exception: If the git command fails.\n        \"\"\"\n\n        git_command = \"(git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\"\n\n        result: subprocess.CompletedProcess[str] = subprocess.run(\n            git_command, shell=True, capture_output=True, text=True\n        )\n        if result.returncode != 0:\n            raise Exception(\"Git command failed: \" + result.stderr)\n\n        changed_files: list[str] = result.stdout.strip().split(\"\\n\")\n\n        return [file for file in changed_files if file.endswith(\".py\")]\n\n    @staticmethod\n    def get_module_names_updated_since_commit(commit_hash: str) -> list[str]:\n        \"\"\"\n        Returns a list of the Python modules that have been changed since the specified commit.\n\n        Args:\n            - commit (str): The commit hash or reference to compare the current state against.\n\n        Runs the following command using subprocess:\n            (git ls-files --others --exclude-standard; git diff --name-only COMMIT) | sort | uniq\n\n        Returns:\n            - list[str]: A list of the modules that have been changed since the specified commit.\n\n        Raises:\n            - Exception: If the git command fails.\n        \"\"\"\n\n        git_command = f\"(git ls-files --others --exclude-standard; git diff --name-only {commit_hash}) | sort | uniq\"\n\n        result: subprocess.CompletedProcess[str] = subprocess.run(\n            git_command, shell=True, capture_output=True, text=True\n        )\n        if result.returncode != 0:\n            raise Exception(\"Git command failed: \" + result.stderr)\n\n        changed_files: list[str] = result.stdout.strip().split(\"\\n\")\n\n        return [file for file in changed_files if file.endswith(\".py\")]\n\n    @staticmethod\n    def __get_updated_modules(directory: str | None = None) -> list[str]:\n        \"\"\"\n        DO NOT USE: The necessary functionality for this method is not yet implemented.\n\n        Returns a list of the modules that have been changed since the last commit based on a directory path.\n        \"\"\"\n        git_ls_files_cmd = \"git ls-files --others --exclude-standard\"\n        git_diff_cmd = \"git diff --name-only HEAD\"\n\n        if directory:\n            git_ls_files_cmd += f\" '{directory}'\"\n            git_diff_cmd += f\" '{directory}'\"\n\n        git_command: str = f\"({git_ls_files_cmd}; {git_diff_cmd}) | sort | uniq\"\n\n        result: subprocess.CompletedProcess[str] = subprocess.run(\n            git_command, shell=True, capture_output=True, text=True\n        )\n        if result.returncode != 0:\n            raise Exception(\"Git command failed: \" + result.stderr)\n\n        changed_files: list[str] = result.stdout.strip().split(\"\\n\")\n\n        return [file for file in changed_files if file.endswith(\".py\")]\n\n, None, \nimport subprocess\n        ", "children": "postcode:updaters:git_updater.py__*__MODULE__*__STANDALONE_BLOCK-1\npostcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit\n", "file_path": "postcode/updaters/git_updater.py", "docstring": "None", "header": "{\"file_path\":\"postcode/updaters/git_updater.py\",\"docstring\":null,\"header\":[],\"footer\":[],\"imports\":[{\"import_names\":[{\"name\":\"subprocess\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":null,\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null}],\"id\":\"postcode:updaters:git_updater.py__*__MODULE\",\"parent_id\":null,\"block_type\":\"MODULE\",\"start_line_num\":1,\"end_line_num\":114,\"code_content\":\"import subprocess\\n\\n\\nclass UpdateUsingGit:\\n    \\\"\\\"\\\"\\n    DO NOT USE: The necessary functionality for this class is not yet implemented.\\n\\n    A class that provides methods to get the names of the Python modules that have been changed using on version control.\\n\\n    Use this class to get all the file names for the Python modules that have been changes since the last commit or since\\n    a specific commit. You can get the `commit_hash` for a specific commit by going to the commit on GitHub and copying\\n    the hash from the URL. For example, the commit hash for the following commit is `e8856d2`, or you can use the terminal, for\\n    instance: `git log --author=\\\"username\\\" --grep=\\\"commit message\\\" --format=\\\"%H\\\"` if you know all the details of the commit.\\n\\n    Methods:\\n        - `get_module_names_updated_since_last_commit()`: Returns a list of the modules that have been changed since the last commit.\\n        - `get_module_names_updated_since_commit(commit_hash: str)`: Returns a list of the modules that have been changed since the specified commit.\\n\\n    Examples:\\n        ```Python\\n        from postcode.updaters.git_updater import UpdateUsingGit\\n\\n        # Get the names of the modules that have been changed since the last commit\\n        changed_modules_name_list = UpdateUsingGit.get_module_names_updated_since_last_commit()\\n        ```\\n    \\\"\\\"\\\"\\n\\n    @staticmethod\\n    def get_module_names_updated_since_last_commit() -> list[str]:\\n        \\\"\\\"\\\"\\n        Returns a list of the modules that have been changed since the last commit.\\n\\n        Runs the following command using subprocess:\\n            (git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\\n\\n        Returns:\\n            - list[str]: A list of the modules that have been changed since the last commit.\\n\\n        Raises:\\n            - Exception: If the git command fails.\\n        \\\"\\\"\\\"\\n\\n        git_command = \\\"(git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\\\"\\n\\n        result: subprocess.CompletedProcess[str] = subprocess.run(\\n            git_command, shell=True, capture_output=True, text=True\\n        )\\n        if result.returncode != 0:\\n            raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n        changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n        return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\\n    @staticmethod\\n    def get_module_names_updated_since_commit(commit_hash: str) -> list[str]:\\n        \\\"\\\"\\\"\\n        Returns a list of the Python modules that have been changed since the specified commit.\\n\\n        Args:\\n            - commit (str): The commit hash or reference to compare the current state against.\\n\\n        Runs the following command using subprocess:\\n            (git ls-files --others --exclude-standard; git diff --name-only COMMIT) | sort | uniq\\n\\n        Returns:\\n            - list[str]: A list of the modules that have been changed since the specified commit.\\n\\n        Raises:\\n            - Exception: If the git command fails.\\n        \\\"\\\"\\\"\\n\\n        git_command = f\\\"(git ls-files --others --exclude-standard; git diff --name-only {commit_hash}) | sort | uniq\\\"\\n\\n        result: subprocess.CompletedProcess[str] = subprocess.run(\\n            git_command, shell=True, capture_output=True, text=True\\n        )\\n        if result.returncode != 0:\\n            raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n        changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n        return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\\n    @staticmethod\\n    def __get_updated_modules(directory: str | None = None) -> list[str]:\\n        \\\"\\\"\\\"\\n        DO NOT USE: The necessary functionality for this method is not yet implemented.\\n\\n        Returns a list of the modules that have been changed since the last commit based on a directory path.\\n        \\\"\\\"\\\"\\n        git_ls_files_cmd = \\\"git ls-files --others --exclude-standard\\\"\\n        git_diff_cmd = \\\"git diff --name-only HEAD\\\"\\n\\n        if directory:\\n            git_ls_files_cmd += f\\\" '{directory}'\\\"\\n            git_diff_cmd += f\\\" '{directory}'\\\"\\n\\n        git_command: str = f\\\"({git_ls_files_cmd}; {git_diff_cmd}) | sort | uniq\\\"\\n\\n        result: subprocess.CompletedProcess[str] = subprocess.run(\\n            git_command, shell=True, capture_output=True, text=True\\n        )\\n        if result.returncode != 0:\\n            raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n        changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n        return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\\n\\nif __name__ == \\\"__main__\\\":\\n    print(UpdateUsingGit.get_module_names_updated_since_commit(\\\"e8856d2\\\"))\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":\"\\nSummary:\\n\\n        postcode:updaters:git_updater.py__*__MODULE\\n\\n        \\nChild (postcode:updaters:git_updater.py__*__MODULE__*__STANDALONE_BLOCK-1) code content:\\nif __name__ == \\\"__main__\\\":\\n    print(UpdateUsingGit.get_module_names_updated_since_commit(\\\"e8856d2\\\"))\\n\\n\\nChild (postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit) code content:\\n\\n\\nclass UpdateUsingGit:\\n    \\\"\\\"\\\"\\n    DO NOT USE: The necessary functionality for this class is not yet implemented.\\n\\n    A class that provides methods to get the names of the Python modules that have been changed using on version control.\\n\\n    Use this class to get all the file names for the Python modules that have been changes since the last commit or since\\n    a specific commit. You can get the `commit_hash` for a specific commit by going to the commit on GitHub and copying\\n    the hash from the URL. For example, the commit hash for the following commit is `e8856d2`, or you can use the terminal, for\\n    instance: `git log --author=\\\"username\\\" --grep=\\\"commit message\\\" --format=\\\"%H\\\"` if you know all the details of the commit.\\n\\n    Methods:\\n        - `get_module_names_updated_since_last_commit()`: Returns a list of the modules that have been changed since the last commit.\\n        - `get_module_names_updated_since_commit(commit_hash: str)`: Returns a list of the modules that have been changed since the specified commit.\\n\\n    Examples:\\n        ```Python\\n        from postcode.updaters.git_updater import UpdateUsingGit\\n\\n        # Get the names of the modules that have been changed since the last commit\\n        changed_modules_name_list = UpdateUsingGit.get_module_names_updated_since_last_commit()\\n        ```\\n    \\\"\\\"\\\"\\n\\n    @staticmethod\\n    def get_module_names_updated_since_last_commit() -> list[str]:\\n        \\\"\\\"\\\"\\n        Returns a list of the modules that have been changed since the last commit.\\n\\n        Runs the following command using subprocess:\\n            (git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\\n\\n        Returns:\\n            - list[str]: A list of the modules that have been changed since the last commit.\\n\\n        Raises:\\n            - Exception: If the git command fails.\\n        \\\"\\\"\\\"\\n\\n        git_command = \\\"(git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\\\"\\n\\n        result: subprocess.CompletedProcess[str] = subprocess.run(\\n            git_command, shell=True, capture_output=True, text=True\\n        )\\n        if result.returncode != 0:\\n            raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n        changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n        return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\\n    @staticmethod\\n    def get_module_names_updated_since_commit(commit_hash: str) -> list[str]:\\n        \\\"\\\"\\\"\\n        Returns a list of the Python modules that have been changed since the specified commit.\\n\\n        Args:\\n            - commit (str): The commit hash or reference to compare the current state against.\\n\\n        Runs the following command using subprocess:\\n            (git ls-files --others --exclude-standard; git diff --name-only COMMIT) | sort | uniq\\n\\n        Returns:\\n            - list[str]: A list of the modules that have been changed since the specified commit.\\n\\n        Raises:\\n            - Exception: If the git command fails.\\n        \\\"\\\"\\\"\\n\\n        git_command = f\\\"(git ls-files --others --exclude-standard; git diff --name-only {commit_hash}) | sort | uniq\\\"\\n\\n        result: subprocess.CompletedProcess[str] = subprocess.run(\\n            git_command, shell=True, capture_output=True, text=True\\n        )\\n        if result.returncode != 0:\\n            raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n        changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n        return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\\n    @staticmethod\\n    def __get_updated_modules(directory: str | None = None) -> list[str]:\\n        \\\"\\\"\\\"\\n        DO NOT USE: The necessary functionality for this method is not yet implemented.\\n\\n        Returns a list of the modules that have been changed since the last commit based on a directory path.\\n        \\\"\\\"\\\"\\n        git_ls_files_cmd = \\\"git ls-files --others --exclude-standard\\\"\\n        git_diff_cmd = \\\"git diff --name-only HEAD\\\"\\n\\n        if directory:\\n            git_ls_files_cmd += f\\\" '{directory}'\\\"\\n            git_diff_cmd += f\\\" '{directory}'\\\"\\n\\n        git_command: str = f\\\"({git_ls_files_cmd}; {git_diff_cmd}) | sort | uniq\\\"\\n\\n        result: subprocess.CompletedProcess[str] = subprocess.run(\\n            git_command, shell=True, capture_output=True, text=True\\n        )\\n        if result.returncode != 0:\\n            raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n        changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n        return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\\n, None, \\nimport subprocess\\n        \",\"children\":[{\"variable_assignments\":[],\"id\":\"postcode:updaters:git_updater.py__*__MODULE__*__STANDALONE_BLOCK-1\",\"parent_id\":\"postcode:updaters:git_updater.py__*__MODULE\",\"block_type\":\"STANDALONE_BLOCK\",\"start_line_num\":110,\"end_line_num\":114,\"code_content\":\"if __name__ == \\\"__main__\\\":\\n    print(UpdateUsingGit.get_module_names_updated_since_commit(\\\"e8856d2\\\"))\\n\",\"important_comments\":null,\"dependencies\":[{\"code_block_id\":\"postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit\"}],\"summary\":null,\"children\":null},{\"class_name\":\"UpdateUsingGit\",\"decorators\":null,\"bases\":null,\"docstring\":\"DO NOT USE: The necessary functionality for this class is not yet implemented.\\n\\nA class that provides methods to get the names of the Python modules that have been changed using on version control.\\n\\nUse this class to get all the file names for the Python modules that have been changes since the last commit or since\\na specific commit. You can get the `commit_hash` for a specific commit by going to the commit on GitHub and copying\\nthe hash from the URL. For example, the commit hash for the following commit is `e8856d2`, or you can use the terminal, for\\ninstance: `git log --author=\\\"username\\\" --grep=\\\"commit message\\\" --format=\\\"%H\\\"` if you know all the details of the commit.\\n\\nMethods:\\n    - `get_module_names_updated_since_last_commit()`: Returns a list of the modules that have been changed since the last commit.\\n    - `get_module_names_updated_since_commit(commit_hash: str)`: Returns a list of the modules that have been changed since the specified commit.\\n\\nExamples:\\n    ```Python\\n    from postcode.updaters.git_updater import UpdateUsingGit\\n\\n    # Get the names of the modules that have been changed since the last commit\\n    changed_modules_name_list = UpdateUsingGit.get_module_names_updated_since_last_commit()\\n    ```\",\"keywords\":null,\"id\":\"postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit\",\"parent_id\":\"postcode:updaters:git_updater.py__*__MODULE\",\"block_type\":\"CLASS\",\"start_line_num\":2,\"end_line_num\":110,\"code_content\":\"\\n\\nclass UpdateUsingGit:\\n    \\\"\\\"\\\"\\n    DO NOT USE: The necessary functionality for this class is not yet implemented.\\n\\n    A class that provides methods to get the names of the Python modules that have been changed using on version control.\\n\\n    Use this class to get all the file names for the Python modules that have been changes since the last commit or since\\n    a specific commit. You can get the `commit_hash` for a specific commit by going to the commit on GitHub and copying\\n    the hash from the URL. For example, the commit hash for the following commit is `e8856d2`, or you can use the terminal, for\\n    instance: `git log --author=\\\"username\\\" --grep=\\\"commit message\\\" --format=\\\"%H\\\"` if you know all the details of the commit.\\n\\n    Methods:\\n        - `get_module_names_updated_since_last_commit()`: Returns a list of the modules that have been changed since the last commit.\\n        - `get_module_names_updated_since_commit(commit_hash: str)`: Returns a list of the modules that have been changed since the specified commit.\\n\\n    Examples:\\n        ```Python\\n        from postcode.updaters.git_updater import UpdateUsingGit\\n\\n        # Get the names of the modules that have been changed since the last commit\\n        changed_modules_name_list = UpdateUsingGit.get_module_names_updated_since_last_commit()\\n        ```\\n    \\\"\\\"\\\"\\n\\n    @staticmethod\\n    def get_module_names_updated_since_last_commit() -> list[str]:\\n        \\\"\\\"\\\"\\n        Returns a list of the modules that have been changed since the last commit.\\n\\n        Runs the following command using subprocess:\\n            (git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\\n\\n        Returns:\\n            - list[str]: A list of the modules that have been changed since the last commit.\\n\\n        Raises:\\n            - Exception: If the git command fails.\\n        \\\"\\\"\\\"\\n\\n        git_command = \\\"(git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\\\"\\n\\n        result: subprocess.CompletedProcess[str] = subprocess.run(\\n            git_command, shell=True, capture_output=True, text=True\\n        )\\n        if result.returncode != 0:\\n            raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n        changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n        return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\\n    @staticmethod\\n    def get_module_names_updated_since_commit(commit_hash: str) -> list[str]:\\n        \\\"\\\"\\\"\\n        Returns a list of the Python modules that have been changed since the specified commit.\\n\\n        Args:\\n            - commit (str): The commit hash or reference to compare the current state against.\\n\\n        Runs the following command using subprocess:\\n            (git ls-files --others --exclude-standard; git diff --name-only COMMIT) | sort | uniq\\n\\n        Returns:\\n            - list[str]: A list of the modules that have been changed since the specified commit.\\n\\n        Raises:\\n            - Exception: If the git command fails.\\n        \\\"\\\"\\\"\\n\\n        git_command = f\\\"(git ls-files --others --exclude-standard; git diff --name-only {commit_hash}) | sort | uniq\\\"\\n\\n        result: subprocess.CompletedProcess[str] = subprocess.run(\\n            git_command, shell=True, capture_output=True, text=True\\n        )\\n        if result.returncode != 0:\\n            raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n        changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n        return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\\n    @staticmethod\\n    def __get_updated_modules(directory: str | None = None) -> list[str]:\\n        \\\"\\\"\\\"\\n        DO NOT USE: The necessary functionality for this method is not yet implemented.\\n\\n        Returns a list of the modules that have been changed since the last commit based on a directory path.\\n        \\\"\\\"\\\"\\n        git_ls_files_cmd = \\\"git ls-files --others --exclude-standard\\\"\\n        git_diff_cmd = \\\"git diff --name-only HEAD\\\"\\n\\n        if directory:\\n            git_ls_files_cmd += f\\\" '{directory}'\\\"\\n            git_diff_cmd += f\\\" '{directory}'\\\"\\n\\n        git_command: str = f\\\"({git_ls_files_cmd}; {git_diff_cmd}) | sort | uniq\\\"\\n\\n        result: subprocess.CompletedProcess[str] = subprocess.run(\\n            git_command, shell=True, capture_output=True, text=True\\n        )\\n        if result.returncode != 0:\\n            raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n        changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n        return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\",\"important_comments\":null,\"dependencies\":[{\"import_names\":[{\"name\":\"subprocess\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":null,\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null}],\"summary\":null,\"children\":[{\"function_name\":\"get_module_names_updated_since_last_commit\",\"docstring\":\"Returns a list of the modules that have been changed since the last commit.\\n\\nRuns the following command using subprocess:\\n    (git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\\n\\nReturns:\\n    - list[str]: A list of the modules that have been changed since the last commit.\\n\\nRaises:\\n    - Exception: If the git command fails.\",\"decorators\":[{\"content\":\"@staticmethod\",\"decorator_name\":\"staticmethod\",\"decorator_args\":null}],\"parameters\":null,\"returns\":\"list[str]\",\"is_method\":true,\"is_async\":false,\"id\":\"postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit__*__FUNCTION-get_module_names_updated_since_last_commit\",\"parent_id\":\"postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit\",\"block_type\":\"FUNCTION\",\"start_line_num\":27,\"end_line_num\":54,\"code_content\":\"\\n@staticmethod\\ndef get_module_names_updated_since_last_commit() -> list[str]:\\n    \\\"\\\"\\\"\\n        Returns a list of the modules that have been changed since the last commit.\\n\\n        Runs the following command using subprocess:\\n            (git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\\n\\n        Returns:\\n            - list[str]: A list of the modules that have been changed since the last commit.\\n\\n        Raises:\\n            - Exception: If the git command fails.\\n        \\\"\\\"\\\"\\n\\n    git_command = \\\"(git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\\\"\\n\\n    result: subprocess.CompletedProcess[str] = subprocess.run(\\n        git_command, shell=True, capture_output=True, text=True\\n    )\\n    if result.returncode != 0:\\n        raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n    changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n    return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":null,\"children\":null},{\"function_name\":\"get_module_names_updated_since_commit\",\"docstring\":\"Returns a list of the Python modules that have been changed since the specified commit.\\n\\nArgs:\\n    - commit (str): The commit hash or reference to compare the current state against.\\n\\nRuns the following command using subprocess:\\n    (git ls-files --others --exclude-standard; git diff --name-only COMMIT) | sort | uniq\\n\\nReturns:\\n    - list[str]: A list of the modules that have been changed since the specified commit.\\n\\nRaises:\\n    - Exception: If the git command fails.\",\"decorators\":[{\"content\":\"@staticmethod\",\"decorator_name\":\"staticmethod\",\"decorator_args\":null}],\"parameters\":null,\"returns\":\"list[str]\",\"is_method\":true,\"is_async\":false,\"id\":\"postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit__*__FUNCTION-get_module_names_updated_since_commit\",\"parent_id\":\"postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit\",\"block_type\":\"FUNCTION\",\"start_line_num\":54,\"end_line_num\":84,\"code_content\":\"\\n@staticmethod\\ndef get_module_names_updated_since_commit(commit_hash: str) -> list[str]:\\n    \\\"\\\"\\\"\\n        Returns a list of the Python modules that have been changed since the specified commit.\\n\\n        Args:\\n            - commit (str): The commit hash or reference to compare the current state against.\\n\\n        Runs the following command using subprocess:\\n            (git ls-files --others --exclude-standard; git diff --name-only COMMIT) | sort | uniq\\n\\n        Returns:\\n            - list[str]: A list of the modules that have been changed since the specified commit.\\n\\n        Raises:\\n            - Exception: If the git command fails.\\n        \\\"\\\"\\\"\\n\\n    git_command = f\\\"(git ls-files --others --exclude-standard; git diff --name-only {commit_hash}) | sort | uniq\\\"\\n\\n    result: subprocess.CompletedProcess[str] = subprocess.run(\\n        git_command, shell=True, capture_output=True, text=True\\n    )\\n    if result.returncode != 0:\\n        raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n    changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n    return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":null,\"children\":null},{\"function_name\":\"__get_updated_modules\",\"docstring\":\"DO NOT USE: The necessary functionality for this method is not yet implemented.\\n\\nReturns a list of the modules that have been changed since the last commit based on a directory path.\",\"decorators\":[{\"content\":\"@staticmethod\",\"decorator_name\":\"staticmethod\",\"decorator_args\":null}],\"parameters\":null,\"returns\":\"list[str]\",\"is_method\":true,\"is_async\":false,\"id\":\"postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit__*__FUNCTION-__get_updated_modules\",\"parent_id\":\"postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit\",\"block_type\":\"FUNCTION\",\"start_line_num\":84,\"end_line_num\":110,\"code_content\":\"\\n@staticmethod\\ndef __get_updated_modules(directory: str | None = None) -> list[str]:\\n    \\\"\\\"\\\"\\n        DO NOT USE: The necessary functionality for this method is not yet implemented.\\n\\n        Returns a list of the modules that have been changed since the last commit based on a directory path.\\n        \\\"\\\"\\\"\\n    git_ls_files_cmd = \\\"git ls-files --others --exclude-standard\\\"\\n    git_diff_cmd = \\\"git diff --name-only HEAD\\\"\\n\\n    if directory:\\n        git_ls_files_cmd += f\\\" '{directory}'\\\"\\n        git_diff_cmd += f\\\" '{directory}'\\\"\\n\\n    git_command: str = f\\\"({git_ls_files_cmd}; {git_diff_cmd}) | sort | uniq\\\"\\n\\n    result: subprocess.CompletedProcess[str] = subprocess.run(\\n        git_command, shell=True, capture_output=True, text=True\\n    )\\n    if result.returncode != 0:\\n        raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n    changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n    return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":null,\"children\":null}]}]}", "footer": "{\"file_path\":\"postcode/updaters/git_updater.py\",\"docstring\":null,\"header\":[],\"footer\":[],\"imports\":[{\"import_names\":[{\"name\":\"subprocess\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":null,\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null}],\"id\":\"postcode:updaters:git_updater.py__*__MODULE\",\"parent_id\":null,\"block_type\":\"MODULE\",\"start_line_num\":1,\"end_line_num\":114,\"code_content\":\"import subprocess\\n\\n\\nclass UpdateUsingGit:\\n    \\\"\\\"\\\"\\n    DO NOT USE: The necessary functionality for this class is not yet implemented.\\n\\n    A class that provides methods to get the names of the Python modules that have been changed using on version control.\\n\\n    Use this class to get all the file names for the Python modules that have been changes since the last commit or since\\n    a specific commit. You can get the `commit_hash` for a specific commit by going to the commit on GitHub and copying\\n    the hash from the URL. For example, the commit hash for the following commit is `e8856d2`, or you can use the terminal, for\\n    instance: `git log --author=\\\"username\\\" --grep=\\\"commit message\\\" --format=\\\"%H\\\"` if you know all the details of the commit.\\n\\n    Methods:\\n        - `get_module_names_updated_since_last_commit()`: Returns a list of the modules that have been changed since the last commit.\\n        - `get_module_names_updated_since_commit(commit_hash: str)`: Returns a list of the modules that have been changed since the specified commit.\\n\\n    Examples:\\n        ```Python\\n        from postcode.updaters.git_updater import UpdateUsingGit\\n\\n        # Get the names of the modules that have been changed since the last commit\\n        changed_modules_name_list = UpdateUsingGit.get_module_names_updated_since_last_commit()\\n        ```\\n    \\\"\\\"\\\"\\n\\n    @staticmethod\\n    def get_module_names_updated_since_last_commit() -> list[str]:\\n        \\\"\\\"\\\"\\n        Returns a list of the modules that have been changed since the last commit.\\n\\n        Runs the following command using subprocess:\\n            (git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\\n\\n        Returns:\\n            - list[str]: A list of the modules that have been changed since the last commit.\\n\\n        Raises:\\n            - Exception: If the git command fails.\\n        \\\"\\\"\\\"\\n\\n        git_command = \\\"(git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\\\"\\n\\n        result: subprocess.CompletedProcess[str] = subprocess.run(\\n            git_command, shell=True, capture_output=True, text=True\\n        )\\n        if result.returncode != 0:\\n            raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n        changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n        return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\\n    @staticmethod\\n    def get_module_names_updated_since_commit(commit_hash: str) -> list[str]:\\n        \\\"\\\"\\\"\\n        Returns a list of the Python modules that have been changed since the specified commit.\\n\\n        Args:\\n            - commit (str): The commit hash or reference to compare the current state against.\\n\\n        Runs the following command using subprocess:\\n            (git ls-files --others --exclude-standard; git diff --name-only COMMIT) | sort | uniq\\n\\n        Returns:\\n            - list[str]: A list of the modules that have been changed since the specified commit.\\n\\n        Raises:\\n            - Exception: If the git command fails.\\n        \\\"\\\"\\\"\\n\\n        git_command = f\\\"(git ls-files --others --exclude-standard; git diff --name-only {commit_hash}) | sort | uniq\\\"\\n\\n        result: subprocess.CompletedProcess[str] = subprocess.run(\\n            git_command, shell=True, capture_output=True, text=True\\n        )\\n        if result.returncode != 0:\\n            raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n        changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n        return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\\n    @staticmethod\\n    def __get_updated_modules(directory: str | None = None) -> list[str]:\\n        \\\"\\\"\\\"\\n        DO NOT USE: The necessary functionality for this method is not yet implemented.\\n\\n        Returns a list of the modules that have been changed since the last commit based on a directory path.\\n        \\\"\\\"\\\"\\n        git_ls_files_cmd = \\\"git ls-files --others --exclude-standard\\\"\\n        git_diff_cmd = \\\"git diff --name-only HEAD\\\"\\n\\n        if directory:\\n            git_ls_files_cmd += f\\\" '{directory}'\\\"\\n            git_diff_cmd += f\\\" '{directory}'\\\"\\n\\n        git_command: str = f\\\"({git_ls_files_cmd}; {git_diff_cmd}) | sort | uniq\\\"\\n\\n        result: subprocess.CompletedProcess[str] = subprocess.run(\\n            git_command, shell=True, capture_output=True, text=True\\n        )\\n        if result.returncode != 0:\\n            raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n        changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n        return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\\n\\nif __name__ == \\\"__main__\\\":\\n    print(UpdateUsingGit.get_module_names_updated_since_commit(\\\"e8856d2\\\"))\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":\"\\nSummary:\\n\\n        postcode:updaters:git_updater.py__*__MODULE\\n\\n        \\nChild (postcode:updaters:git_updater.py__*__MODULE__*__STANDALONE_BLOCK-1) code content:\\nif __name__ == \\\"__main__\\\":\\n    print(UpdateUsingGit.get_module_names_updated_since_commit(\\\"e8856d2\\\"))\\n\\n\\nChild (postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit) code content:\\n\\n\\nclass UpdateUsingGit:\\n    \\\"\\\"\\\"\\n    DO NOT USE: The necessary functionality for this class is not yet implemented.\\n\\n    A class that provides methods to get the names of the Python modules that have been changed using on version control.\\n\\n    Use this class to get all the file names for the Python modules that have been changes since the last commit or since\\n    a specific commit. You can get the `commit_hash` for a specific commit by going to the commit on GitHub and copying\\n    the hash from the URL. For example, the commit hash for the following commit is `e8856d2`, or you can use the terminal, for\\n    instance: `git log --author=\\\"username\\\" --grep=\\\"commit message\\\" --format=\\\"%H\\\"` if you know all the details of the commit.\\n\\n    Methods:\\n        - `get_module_names_updated_since_last_commit()`: Returns a list of the modules that have been changed since the last commit.\\n        - `get_module_names_updated_since_commit(commit_hash: str)`: Returns a list of the modules that have been changed since the specified commit.\\n\\n    Examples:\\n        ```Python\\n        from postcode.updaters.git_updater import UpdateUsingGit\\n\\n        # Get the names of the modules that have been changed since the last commit\\n        changed_modules_name_list = UpdateUsingGit.get_module_names_updated_since_last_commit()\\n        ```\\n    \\\"\\\"\\\"\\n\\n    @staticmethod\\n    def get_module_names_updated_since_last_commit() -> list[str]:\\n        \\\"\\\"\\\"\\n        Returns a list of the modules that have been changed since the last commit.\\n\\n        Runs the following command using subprocess:\\n            (git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\\n\\n        Returns:\\n            - list[str]: A list of the modules that have been changed since the last commit.\\n\\n        Raises:\\n            - Exception: If the git command fails.\\n        \\\"\\\"\\\"\\n\\n        git_command = \\\"(git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\\\"\\n\\n        result: subprocess.CompletedProcess[str] = subprocess.run(\\n            git_command, shell=True, capture_output=True, text=True\\n        )\\n        if result.returncode != 0:\\n            raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n        changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n        return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\\n    @staticmethod\\n    def get_module_names_updated_since_commit(commit_hash: str) -> list[str]:\\n        \\\"\\\"\\\"\\n        Returns a list of the Python modules that have been changed since the specified commit.\\n\\n        Args:\\n            - commit (str): The commit hash or reference to compare the current state against.\\n\\n        Runs the following command using subprocess:\\n            (git ls-files --others --exclude-standard; git diff --name-only COMMIT) | sort | uniq\\n\\n        Returns:\\n            - list[str]: A list of the modules that have been changed since the specified commit.\\n\\n        Raises:\\n            - Exception: If the git command fails.\\n        \\\"\\\"\\\"\\n\\n        git_command = f\\\"(git ls-files --others --exclude-standard; git diff --name-only {commit_hash}) | sort | uniq\\\"\\n\\n        result: subprocess.CompletedProcess[str] = subprocess.run(\\n            git_command, shell=True, capture_output=True, text=True\\n        )\\n        if result.returncode != 0:\\n            raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n        changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n        return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\\n    @staticmethod\\n    def __get_updated_modules(directory: str | None = None) -> list[str]:\\n        \\\"\\\"\\\"\\n        DO NOT USE: The necessary functionality for this method is not yet implemented.\\n\\n        Returns a list of the modules that have been changed since the last commit based on a directory path.\\n        \\\"\\\"\\\"\\n        git_ls_files_cmd = \\\"git ls-files --others --exclude-standard\\\"\\n        git_diff_cmd = \\\"git diff --name-only HEAD\\\"\\n\\n        if directory:\\n            git_ls_files_cmd += f\\\" '{directory}'\\\"\\n            git_diff_cmd += f\\\" '{directory}'\\\"\\n\\n        git_command: str = f\\\"({git_ls_files_cmd}; {git_diff_cmd}) | sort | uniq\\\"\\n\\n        result: subprocess.CompletedProcess[str] = subprocess.run(\\n            git_command, shell=True, capture_output=True, text=True\\n        )\\n        if result.returncode != 0:\\n            raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n        changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n        return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\\n, None, \\nimport subprocess\\n        \",\"children\":[{\"variable_assignments\":[],\"id\":\"postcode:updaters:git_updater.py__*__MODULE__*__STANDALONE_BLOCK-1\",\"parent_id\":\"postcode:updaters:git_updater.py__*__MODULE\",\"block_type\":\"STANDALONE_BLOCK\",\"start_line_num\":110,\"end_line_num\":114,\"code_content\":\"if __name__ == \\\"__main__\\\":\\n    print(UpdateUsingGit.get_module_names_updated_since_commit(\\\"e8856d2\\\"))\\n\",\"important_comments\":null,\"dependencies\":[{\"code_block_id\":\"postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit\"}],\"summary\":null,\"children\":null},{\"class_name\":\"UpdateUsingGit\",\"decorators\":null,\"bases\":null,\"docstring\":\"DO NOT USE: The necessary functionality for this class is not yet implemented.\\n\\nA class that provides methods to get the names of the Python modules that have been changed using on version control.\\n\\nUse this class to get all the file names for the Python modules that have been changes since the last commit or since\\na specific commit. You can get the `commit_hash` for a specific commit by going to the commit on GitHub and copying\\nthe hash from the URL. For example, the commit hash for the following commit is `e8856d2`, or you can use the terminal, for\\ninstance: `git log --author=\\\"username\\\" --grep=\\\"commit message\\\" --format=\\\"%H\\\"` if you know all the details of the commit.\\n\\nMethods:\\n    - `get_module_names_updated_since_last_commit()`: Returns a list of the modules that have been changed since the last commit.\\n    - `get_module_names_updated_since_commit(commit_hash: str)`: Returns a list of the modules that have been changed since the specified commit.\\n\\nExamples:\\n    ```Python\\n    from postcode.updaters.git_updater import UpdateUsingGit\\n\\n    # Get the names of the modules that have been changed since the last commit\\n    changed_modules_name_list = UpdateUsingGit.get_module_names_updated_since_last_commit()\\n    ```\",\"keywords\":null,\"id\":\"postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit\",\"parent_id\":\"postcode:updaters:git_updater.py__*__MODULE\",\"block_type\":\"CLASS\",\"start_line_num\":2,\"end_line_num\":110,\"code_content\":\"\\n\\nclass UpdateUsingGit:\\n    \\\"\\\"\\\"\\n    DO NOT USE: The necessary functionality for this class is not yet implemented.\\n\\n    A class that provides methods to get the names of the Python modules that have been changed using on version control.\\n\\n    Use this class to get all the file names for the Python modules that have been changes since the last commit or since\\n    a specific commit. You can get the `commit_hash` for a specific commit by going to the commit on GitHub and copying\\n    the hash from the URL. For example, the commit hash for the following commit is `e8856d2`, or you can use the terminal, for\\n    instance: `git log --author=\\\"username\\\" --grep=\\\"commit message\\\" --format=\\\"%H\\\"` if you know all the details of the commit.\\n\\n    Methods:\\n        - `get_module_names_updated_since_last_commit()`: Returns a list of the modules that have been changed since the last commit.\\n        - `get_module_names_updated_since_commit(commit_hash: str)`: Returns a list of the modules that have been changed since the specified commit.\\n\\n    Examples:\\n        ```Python\\n        from postcode.updaters.git_updater import UpdateUsingGit\\n\\n        # Get the names of the modules that have been changed since the last commit\\n        changed_modules_name_list = UpdateUsingGit.get_module_names_updated_since_last_commit()\\n        ```\\n    \\\"\\\"\\\"\\n\\n    @staticmethod\\n    def get_module_names_updated_since_last_commit() -> list[str]:\\n        \\\"\\\"\\\"\\n        Returns a list of the modules that have been changed since the last commit.\\n\\n        Runs the following command using subprocess:\\n            (git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\\n\\n        Returns:\\n            - list[str]: A list of the modules that have been changed since the last commit.\\n\\n        Raises:\\n            - Exception: If the git command fails.\\n        \\\"\\\"\\\"\\n\\n        git_command = \\\"(git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\\\"\\n\\n        result: subprocess.CompletedProcess[str] = subprocess.run(\\n            git_command, shell=True, capture_output=True, text=True\\n        )\\n        if result.returncode != 0:\\n            raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n        changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n        return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\\n    @staticmethod\\n    def get_module_names_updated_since_commit(commit_hash: str) -> list[str]:\\n        \\\"\\\"\\\"\\n        Returns a list of the Python modules that have been changed since the specified commit.\\n\\n        Args:\\n            - commit (str): The commit hash or reference to compare the current state against.\\n\\n        Runs the following command using subprocess:\\n            (git ls-files --others --exclude-standard; git diff --name-only COMMIT) | sort | uniq\\n\\n        Returns:\\n            - list[str]: A list of the modules that have been changed since the specified commit.\\n\\n        Raises:\\n            - Exception: If the git command fails.\\n        \\\"\\\"\\\"\\n\\n        git_command = f\\\"(git ls-files --others --exclude-standard; git diff --name-only {commit_hash}) | sort | uniq\\\"\\n\\n        result: subprocess.CompletedProcess[str] = subprocess.run(\\n            git_command, shell=True, capture_output=True, text=True\\n        )\\n        if result.returncode != 0:\\n            raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n        changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n        return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\\n    @staticmethod\\n    def __get_updated_modules(directory: str | None = None) -> list[str]:\\n        \\\"\\\"\\\"\\n        DO NOT USE: The necessary functionality for this method is not yet implemented.\\n\\n        Returns a list of the modules that have been changed since the last commit based on a directory path.\\n        \\\"\\\"\\\"\\n        git_ls_files_cmd = \\\"git ls-files --others --exclude-standard\\\"\\n        git_diff_cmd = \\\"git diff --name-only HEAD\\\"\\n\\n        if directory:\\n            git_ls_files_cmd += f\\\" '{directory}'\\\"\\n            git_diff_cmd += f\\\" '{directory}'\\\"\\n\\n        git_command: str = f\\\"({git_ls_files_cmd}; {git_diff_cmd}) | sort | uniq\\\"\\n\\n        result: subprocess.CompletedProcess[str] = subprocess.run(\\n            git_command, shell=True, capture_output=True, text=True\\n        )\\n        if result.returncode != 0:\\n            raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n        changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n        return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\",\"important_comments\":null,\"dependencies\":[{\"import_names\":[{\"name\":\"subprocess\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":null,\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null}],\"summary\":null,\"children\":[{\"function_name\":\"get_module_names_updated_since_last_commit\",\"docstring\":\"Returns a list of the modules that have been changed since the last commit.\\n\\nRuns the following command using subprocess:\\n    (git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\\n\\nReturns:\\n    - list[str]: A list of the modules that have been changed since the last commit.\\n\\nRaises:\\n    - Exception: If the git command fails.\",\"decorators\":[{\"content\":\"@staticmethod\",\"decorator_name\":\"staticmethod\",\"decorator_args\":null}],\"parameters\":null,\"returns\":\"list[str]\",\"is_method\":true,\"is_async\":false,\"id\":\"postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit__*__FUNCTION-get_module_names_updated_since_last_commit\",\"parent_id\":\"postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit\",\"block_type\":\"FUNCTION\",\"start_line_num\":27,\"end_line_num\":54,\"code_content\":\"\\n@staticmethod\\ndef get_module_names_updated_since_last_commit() -> list[str]:\\n    \\\"\\\"\\\"\\n        Returns a list of the modules that have been changed since the last commit.\\n\\n        Runs the following command using subprocess:\\n            (git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\\n\\n        Returns:\\n            - list[str]: A list of the modules that have been changed since the last commit.\\n\\n        Raises:\\n            - Exception: If the git command fails.\\n        \\\"\\\"\\\"\\n\\n    git_command = \\\"(git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\\\"\\n\\n    result: subprocess.CompletedProcess[str] = subprocess.run(\\n        git_command, shell=True, capture_output=True, text=True\\n    )\\n    if result.returncode != 0:\\n        raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n    changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n    return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":null,\"children\":null},{\"function_name\":\"get_module_names_updated_since_commit\",\"docstring\":\"Returns a list of the Python modules that have been changed since the specified commit.\\n\\nArgs:\\n    - commit (str): The commit hash or reference to compare the current state against.\\n\\nRuns the following command using subprocess:\\n    (git ls-files --others --exclude-standard; git diff --name-only COMMIT) | sort | uniq\\n\\nReturns:\\n    - list[str]: A list of the modules that have been changed since the specified commit.\\n\\nRaises:\\n    - Exception: If the git command fails.\",\"decorators\":[{\"content\":\"@staticmethod\",\"decorator_name\":\"staticmethod\",\"decorator_args\":null}],\"parameters\":null,\"returns\":\"list[str]\",\"is_method\":true,\"is_async\":false,\"id\":\"postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit__*__FUNCTION-get_module_names_updated_since_commit\",\"parent_id\":\"postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit\",\"block_type\":\"FUNCTION\",\"start_line_num\":54,\"end_line_num\":84,\"code_content\":\"\\n@staticmethod\\ndef get_module_names_updated_since_commit(commit_hash: str) -> list[str]:\\n    \\\"\\\"\\\"\\n        Returns a list of the Python modules that have been changed since the specified commit.\\n\\n        Args:\\n            - commit (str): The commit hash or reference to compare the current state against.\\n\\n        Runs the following command using subprocess:\\n            (git ls-files --others --exclude-standard; git diff --name-only COMMIT) | sort | uniq\\n\\n        Returns:\\n            - list[str]: A list of the modules that have been changed since the specified commit.\\n\\n        Raises:\\n            - Exception: If the git command fails.\\n        \\\"\\\"\\\"\\n\\n    git_command = f\\\"(git ls-files --others --exclude-standard; git diff --name-only {commit_hash}) | sort | uniq\\\"\\n\\n    result: subprocess.CompletedProcess[str] = subprocess.run(\\n        git_command, shell=True, capture_output=True, text=True\\n    )\\n    if result.returncode != 0:\\n        raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n    changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n    return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":null,\"children\":null},{\"function_name\":\"__get_updated_modules\",\"docstring\":\"DO NOT USE: The necessary functionality for this method is not yet implemented.\\n\\nReturns a list of the modules that have been changed since the last commit based on a directory path.\",\"decorators\":[{\"content\":\"@staticmethod\",\"decorator_name\":\"staticmethod\",\"decorator_args\":null}],\"parameters\":null,\"returns\":\"list[str]\",\"is_method\":true,\"is_async\":false,\"id\":\"postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit__*__FUNCTION-__get_updated_modules\",\"parent_id\":\"postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit\",\"block_type\":\"FUNCTION\",\"start_line_num\":84,\"end_line_num\":110,\"code_content\":\"\\n@staticmethod\\ndef __get_updated_modules(directory: str | None = None) -> list[str]:\\n    \\\"\\\"\\\"\\n        DO NOT USE: The necessary functionality for this method is not yet implemented.\\n\\n        Returns a list of the modules that have been changed since the last commit based on a directory path.\\n        \\\"\\\"\\\"\\n    git_ls_files_cmd = \\\"git ls-files --others --exclude-standard\\\"\\n    git_diff_cmd = \\\"git diff --name-only HEAD\\\"\\n\\n    if directory:\\n        git_ls_files_cmd += f\\\" '{directory}'\\\"\\n        git_diff_cmd += f\\\" '{directory}'\\\"\\n\\n    git_command: str = f\\\"({git_ls_files_cmd}; {git_diff_cmd}) | sort | uniq\\\"\\n\\n    result: subprocess.CompletedProcess[str] = subprocess.run(\\n        git_command, shell=True, capture_output=True, text=True\\n    )\\n    if result.returncode != 0:\\n        raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n    changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n    return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":null,\"children\":null}]}]}", "imports": "{\"file_path\":\"postcode/updaters/git_updater.py\",\"docstring\":null,\"header\":[],\"footer\":[],\"imports\":[{\"import_names\":[{\"name\":\"subprocess\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":null,\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null}],\"id\":\"postcode:updaters:git_updater.py__*__MODULE\",\"parent_id\":null,\"block_type\":\"MODULE\",\"start_line_num\":1,\"end_line_num\":114,\"code_content\":\"import subprocess\\n\\n\\nclass UpdateUsingGit:\\n    \\\"\\\"\\\"\\n    DO NOT USE: The necessary functionality for this class is not yet implemented.\\n\\n    A class that provides methods to get the names of the Python modules that have been changed using on version control.\\n\\n    Use this class to get all the file names for the Python modules that have been changes since the last commit or since\\n    a specific commit. You can get the `commit_hash` for a specific commit by going to the commit on GitHub and copying\\n    the hash from the URL. For example, the commit hash for the following commit is `e8856d2`, or you can use the terminal, for\\n    instance: `git log --author=\\\"username\\\" --grep=\\\"commit message\\\" --format=\\\"%H\\\"` if you know all the details of the commit.\\n\\n    Methods:\\n        - `get_module_names_updated_since_last_commit()`: Returns a list of the modules that have been changed since the last commit.\\n        - `get_module_names_updated_since_commit(commit_hash: str)`: Returns a list of the modules that have been changed since the specified commit.\\n\\n    Examples:\\n        ```Python\\n        from postcode.updaters.git_updater import UpdateUsingGit\\n\\n        # Get the names of the modules that have been changed since the last commit\\n        changed_modules_name_list = UpdateUsingGit.get_module_names_updated_since_last_commit()\\n        ```\\n    \\\"\\\"\\\"\\n\\n    @staticmethod\\n    def get_module_names_updated_since_last_commit() -> list[str]:\\n        \\\"\\\"\\\"\\n        Returns a list of the modules that have been changed since the last commit.\\n\\n        Runs the following command using subprocess:\\n            (git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\\n\\n        Returns:\\n            - list[str]: A list of the modules that have been changed since the last commit.\\n\\n        Raises:\\n            - Exception: If the git command fails.\\n        \\\"\\\"\\\"\\n\\n        git_command = \\\"(git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\\\"\\n\\n        result: subprocess.CompletedProcess[str] = subprocess.run(\\n            git_command, shell=True, capture_output=True, text=True\\n        )\\n        if result.returncode != 0:\\n            raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n        changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n        return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\\n    @staticmethod\\n    def get_module_names_updated_since_commit(commit_hash: str) -> list[str]:\\n        \\\"\\\"\\\"\\n        Returns a list of the Python modules that have been changed since the specified commit.\\n\\n        Args:\\n            - commit (str): The commit hash or reference to compare the current state against.\\n\\n        Runs the following command using subprocess:\\n            (git ls-files --others --exclude-standard; git diff --name-only COMMIT) | sort | uniq\\n\\n        Returns:\\n            - list[str]: A list of the modules that have been changed since the specified commit.\\n\\n        Raises:\\n            - Exception: If the git command fails.\\n        \\\"\\\"\\\"\\n\\n        git_command = f\\\"(git ls-files --others --exclude-standard; git diff --name-only {commit_hash}) | sort | uniq\\\"\\n\\n        result: subprocess.CompletedProcess[str] = subprocess.run(\\n            git_command, shell=True, capture_output=True, text=True\\n        )\\n        if result.returncode != 0:\\n            raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n        changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n        return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\\n    @staticmethod\\n    def __get_updated_modules(directory: str | None = None) -> list[str]:\\n        \\\"\\\"\\\"\\n        DO NOT USE: The necessary functionality for this method is not yet implemented.\\n\\n        Returns a list of the modules that have been changed since the last commit based on a directory path.\\n        \\\"\\\"\\\"\\n        git_ls_files_cmd = \\\"git ls-files --others --exclude-standard\\\"\\n        git_diff_cmd = \\\"git diff --name-only HEAD\\\"\\n\\n        if directory:\\n            git_ls_files_cmd += f\\\" '{directory}'\\\"\\n            git_diff_cmd += f\\\" '{directory}'\\\"\\n\\n        git_command: str = f\\\"({git_ls_files_cmd}; {git_diff_cmd}) | sort | uniq\\\"\\n\\n        result: subprocess.CompletedProcess[str] = subprocess.run(\\n            git_command, shell=True, capture_output=True, text=True\\n        )\\n        if result.returncode != 0:\\n            raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n        changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n        return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\\n\\nif __name__ == \\\"__main__\\\":\\n    print(UpdateUsingGit.get_module_names_updated_since_commit(\\\"e8856d2\\\"))\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":\"\\nSummary:\\n\\n        postcode:updaters:git_updater.py__*__MODULE\\n\\n        \\nChild (postcode:updaters:git_updater.py__*__MODULE__*__STANDALONE_BLOCK-1) code content:\\nif __name__ == \\\"__main__\\\":\\n    print(UpdateUsingGit.get_module_names_updated_since_commit(\\\"e8856d2\\\"))\\n\\n\\nChild (postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit) code content:\\n\\n\\nclass UpdateUsingGit:\\n    \\\"\\\"\\\"\\n    DO NOT USE: The necessary functionality for this class is not yet implemented.\\n\\n    A class that provides methods to get the names of the Python modules that have been changed using on version control.\\n\\n    Use this class to get all the file names for the Python modules that have been changes since the last commit or since\\n    a specific commit. You can get the `commit_hash` for a specific commit by going to the commit on GitHub and copying\\n    the hash from the URL. For example, the commit hash for the following commit is `e8856d2`, or you can use the terminal, for\\n    instance: `git log --author=\\\"username\\\" --grep=\\\"commit message\\\" --format=\\\"%H\\\"` if you know all the details of the commit.\\n\\n    Methods:\\n        - `get_module_names_updated_since_last_commit()`: Returns a list of the modules that have been changed since the last commit.\\n        - `get_module_names_updated_since_commit(commit_hash: str)`: Returns a list of the modules that have been changed since the specified commit.\\n\\n    Examples:\\n        ```Python\\n        from postcode.updaters.git_updater import UpdateUsingGit\\n\\n        # Get the names of the modules that have been changed since the last commit\\n        changed_modules_name_list = UpdateUsingGit.get_module_names_updated_since_last_commit()\\n        ```\\n    \\\"\\\"\\\"\\n\\n    @staticmethod\\n    def get_module_names_updated_since_last_commit() -> list[str]:\\n        \\\"\\\"\\\"\\n        Returns a list of the modules that have been changed since the last commit.\\n\\n        Runs the following command using subprocess:\\n            (git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\\n\\n        Returns:\\n            - list[str]: A list of the modules that have been changed since the last commit.\\n\\n        Raises:\\n            - Exception: If the git command fails.\\n        \\\"\\\"\\\"\\n\\n        git_command = \\\"(git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\\\"\\n\\n        result: subprocess.CompletedProcess[str] = subprocess.run(\\n            git_command, shell=True, capture_output=True, text=True\\n        )\\n        if result.returncode != 0:\\n            raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n        changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n        return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\\n    @staticmethod\\n    def get_module_names_updated_since_commit(commit_hash: str) -> list[str]:\\n        \\\"\\\"\\\"\\n        Returns a list of the Python modules that have been changed since the specified commit.\\n\\n        Args:\\n            - commit (str): The commit hash or reference to compare the current state against.\\n\\n        Runs the following command using subprocess:\\n            (git ls-files --others --exclude-standard; git diff --name-only COMMIT) | sort | uniq\\n\\n        Returns:\\n            - list[str]: A list of the modules that have been changed since the specified commit.\\n\\n        Raises:\\n            - Exception: If the git command fails.\\n        \\\"\\\"\\\"\\n\\n        git_command = f\\\"(git ls-files --others --exclude-standard; git diff --name-only {commit_hash}) | sort | uniq\\\"\\n\\n        result: subprocess.CompletedProcess[str] = subprocess.run(\\n            git_command, shell=True, capture_output=True, text=True\\n        )\\n        if result.returncode != 0:\\n            raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n        changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n        return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\\n    @staticmethod\\n    def __get_updated_modules(directory: str | None = None) -> list[str]:\\n        \\\"\\\"\\\"\\n        DO NOT USE: The necessary functionality for this method is not yet implemented.\\n\\n        Returns a list of the modules that have been changed since the last commit based on a directory path.\\n        \\\"\\\"\\\"\\n        git_ls_files_cmd = \\\"git ls-files --others --exclude-standard\\\"\\n        git_diff_cmd = \\\"git diff --name-only HEAD\\\"\\n\\n        if directory:\\n            git_ls_files_cmd += f\\\" '{directory}'\\\"\\n            git_diff_cmd += f\\\" '{directory}'\\\"\\n\\n        git_command: str = f\\\"({git_ls_files_cmd}; {git_diff_cmd}) | sort | uniq\\\"\\n\\n        result: subprocess.CompletedProcess[str] = subprocess.run(\\n            git_command, shell=True, capture_output=True, text=True\\n        )\\n        if result.returncode != 0:\\n            raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n        changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n        return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\\n, None, \\nimport subprocess\\n        \",\"children\":[{\"variable_assignments\":[],\"id\":\"postcode:updaters:git_updater.py__*__MODULE__*__STANDALONE_BLOCK-1\",\"parent_id\":\"postcode:updaters:git_updater.py__*__MODULE\",\"block_type\":\"STANDALONE_BLOCK\",\"start_line_num\":110,\"end_line_num\":114,\"code_content\":\"if __name__ == \\\"__main__\\\":\\n    print(UpdateUsingGit.get_module_names_updated_since_commit(\\\"e8856d2\\\"))\\n\",\"important_comments\":null,\"dependencies\":[{\"code_block_id\":\"postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit\"}],\"summary\":null,\"children\":null},{\"class_name\":\"UpdateUsingGit\",\"decorators\":null,\"bases\":null,\"docstring\":\"DO NOT USE: The necessary functionality for this class is not yet implemented.\\n\\nA class that provides methods to get the names of the Python modules that have been changed using on version control.\\n\\nUse this class to get all the file names for the Python modules that have been changes since the last commit or since\\na specific commit. You can get the `commit_hash` for a specific commit by going to the commit on GitHub and copying\\nthe hash from the URL. For example, the commit hash for the following commit is `e8856d2`, or you can use the terminal, for\\ninstance: `git log --author=\\\"username\\\" --grep=\\\"commit message\\\" --format=\\\"%H\\\"` if you know all the details of the commit.\\n\\nMethods:\\n    - `get_module_names_updated_since_last_commit()`: Returns a list of the modules that have been changed since the last commit.\\n    - `get_module_names_updated_since_commit(commit_hash: str)`: Returns a list of the modules that have been changed since the specified commit.\\n\\nExamples:\\n    ```Python\\n    from postcode.updaters.git_updater import UpdateUsingGit\\n\\n    # Get the names of the modules that have been changed since the last commit\\n    changed_modules_name_list = UpdateUsingGit.get_module_names_updated_since_last_commit()\\n    ```\",\"keywords\":null,\"id\":\"postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit\",\"parent_id\":\"postcode:updaters:git_updater.py__*__MODULE\",\"block_type\":\"CLASS\",\"start_line_num\":2,\"end_line_num\":110,\"code_content\":\"\\n\\nclass UpdateUsingGit:\\n    \\\"\\\"\\\"\\n    DO NOT USE: The necessary functionality for this class is not yet implemented.\\n\\n    A class that provides methods to get the names of the Python modules that have been changed using on version control.\\n\\n    Use this class to get all the file names for the Python modules that have been changes since the last commit or since\\n    a specific commit. You can get the `commit_hash` for a specific commit by going to the commit on GitHub and copying\\n    the hash from the URL. For example, the commit hash for the following commit is `e8856d2`, or you can use the terminal, for\\n    instance: `git log --author=\\\"username\\\" --grep=\\\"commit message\\\" --format=\\\"%H\\\"` if you know all the details of the commit.\\n\\n    Methods:\\n        - `get_module_names_updated_since_last_commit()`: Returns a list of the modules that have been changed since the last commit.\\n        - `get_module_names_updated_since_commit(commit_hash: str)`: Returns a list of the modules that have been changed since the specified commit.\\n\\n    Examples:\\n        ```Python\\n        from postcode.updaters.git_updater import UpdateUsingGit\\n\\n        # Get the names of the modules that have been changed since the last commit\\n        changed_modules_name_list = UpdateUsingGit.get_module_names_updated_since_last_commit()\\n        ```\\n    \\\"\\\"\\\"\\n\\n    @staticmethod\\n    def get_module_names_updated_since_last_commit() -> list[str]:\\n        \\\"\\\"\\\"\\n        Returns a list of the modules that have been changed since the last commit.\\n\\n        Runs the following command using subprocess:\\n            (git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\\n\\n        Returns:\\n            - list[str]: A list of the modules that have been changed since the last commit.\\n\\n        Raises:\\n            - Exception: If the git command fails.\\n        \\\"\\\"\\\"\\n\\n        git_command = \\\"(git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\\\"\\n\\n        result: subprocess.CompletedProcess[str] = subprocess.run(\\n            git_command, shell=True, capture_output=True, text=True\\n        )\\n        if result.returncode != 0:\\n            raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n        changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n        return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\\n    @staticmethod\\n    def get_module_names_updated_since_commit(commit_hash: str) -> list[str]:\\n        \\\"\\\"\\\"\\n        Returns a list of the Python modules that have been changed since the specified commit.\\n\\n        Args:\\n            - commit (str): The commit hash or reference to compare the current state against.\\n\\n        Runs the following command using subprocess:\\n            (git ls-files --others --exclude-standard; git diff --name-only COMMIT) | sort | uniq\\n\\n        Returns:\\n            - list[str]: A list of the modules that have been changed since the specified commit.\\n\\n        Raises:\\n            - Exception: If the git command fails.\\n        \\\"\\\"\\\"\\n\\n        git_command = f\\\"(git ls-files --others --exclude-standard; git diff --name-only {commit_hash}) | sort | uniq\\\"\\n\\n        result: subprocess.CompletedProcess[str] = subprocess.run(\\n            git_command, shell=True, capture_output=True, text=True\\n        )\\n        if result.returncode != 0:\\n            raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n        changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n        return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\\n    @staticmethod\\n    def __get_updated_modules(directory: str | None = None) -> list[str]:\\n        \\\"\\\"\\\"\\n        DO NOT USE: The necessary functionality for this method is not yet implemented.\\n\\n        Returns a list of the modules that have been changed since the last commit based on a directory path.\\n        \\\"\\\"\\\"\\n        git_ls_files_cmd = \\\"git ls-files --others --exclude-standard\\\"\\n        git_diff_cmd = \\\"git diff --name-only HEAD\\\"\\n\\n        if directory:\\n            git_ls_files_cmd += f\\\" '{directory}'\\\"\\n            git_diff_cmd += f\\\" '{directory}'\\\"\\n\\n        git_command: str = f\\\"({git_ls_files_cmd}; {git_diff_cmd}) | sort | uniq\\\"\\n\\n        result: subprocess.CompletedProcess[str] = subprocess.run(\\n            git_command, shell=True, capture_output=True, text=True\\n        )\\n        if result.returncode != 0:\\n            raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n        changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n        return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\",\"important_comments\":null,\"dependencies\":[{\"import_names\":[{\"name\":\"subprocess\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":null,\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null}],\"summary\":null,\"children\":[{\"function_name\":\"get_module_names_updated_since_last_commit\",\"docstring\":\"Returns a list of the modules that have been changed since the last commit.\\n\\nRuns the following command using subprocess:\\n    (git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\\n\\nReturns:\\n    - list[str]: A list of the modules that have been changed since the last commit.\\n\\nRaises:\\n    - Exception: If the git command fails.\",\"decorators\":[{\"content\":\"@staticmethod\",\"decorator_name\":\"staticmethod\",\"decorator_args\":null}],\"parameters\":null,\"returns\":\"list[str]\",\"is_method\":true,\"is_async\":false,\"id\":\"postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit__*__FUNCTION-get_module_names_updated_since_last_commit\",\"parent_id\":\"postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit\",\"block_type\":\"FUNCTION\",\"start_line_num\":27,\"end_line_num\":54,\"code_content\":\"\\n@staticmethod\\ndef get_module_names_updated_since_last_commit() -> list[str]:\\n    \\\"\\\"\\\"\\n        Returns a list of the modules that have been changed since the last commit.\\n\\n        Runs the following command using subprocess:\\n            (git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\\n\\n        Returns:\\n            - list[str]: A list of the modules that have been changed since the last commit.\\n\\n        Raises:\\n            - Exception: If the git command fails.\\n        \\\"\\\"\\\"\\n\\n    git_command = \\\"(git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\\\"\\n\\n    result: subprocess.CompletedProcess[str] = subprocess.run(\\n        git_command, shell=True, capture_output=True, text=True\\n    )\\n    if result.returncode != 0:\\n        raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n    changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n    return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":null,\"children\":null},{\"function_name\":\"get_module_names_updated_since_commit\",\"docstring\":\"Returns a list of the Python modules that have been changed since the specified commit.\\n\\nArgs:\\n    - commit (str): The commit hash or reference to compare the current state against.\\n\\nRuns the following command using subprocess:\\n    (git ls-files --others --exclude-standard; git diff --name-only COMMIT) | sort | uniq\\n\\nReturns:\\n    - list[str]: A list of the modules that have been changed since the specified commit.\\n\\nRaises:\\n    - Exception: If the git command fails.\",\"decorators\":[{\"content\":\"@staticmethod\",\"decorator_name\":\"staticmethod\",\"decorator_args\":null}],\"parameters\":null,\"returns\":\"list[str]\",\"is_method\":true,\"is_async\":false,\"id\":\"postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit__*__FUNCTION-get_module_names_updated_since_commit\",\"parent_id\":\"postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit\",\"block_type\":\"FUNCTION\",\"start_line_num\":54,\"end_line_num\":84,\"code_content\":\"\\n@staticmethod\\ndef get_module_names_updated_since_commit(commit_hash: str) -> list[str]:\\n    \\\"\\\"\\\"\\n        Returns a list of the Python modules that have been changed since the specified commit.\\n\\n        Args:\\n            - commit (str): The commit hash or reference to compare the current state against.\\n\\n        Runs the following command using subprocess:\\n            (git ls-files --others --exclude-standard; git diff --name-only COMMIT) | sort | uniq\\n\\n        Returns:\\n            - list[str]: A list of the modules that have been changed since the specified commit.\\n\\n        Raises:\\n            - Exception: If the git command fails.\\n        \\\"\\\"\\\"\\n\\n    git_command = f\\\"(git ls-files --others --exclude-standard; git diff --name-only {commit_hash}) | sort | uniq\\\"\\n\\n    result: subprocess.CompletedProcess[str] = subprocess.run(\\n        git_command, shell=True, capture_output=True, text=True\\n    )\\n    if result.returncode != 0:\\n        raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n    changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n    return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":null,\"children\":null},{\"function_name\":\"__get_updated_modules\",\"docstring\":\"DO NOT USE: The necessary functionality for this method is not yet implemented.\\n\\nReturns a list of the modules that have been changed since the last commit based on a directory path.\",\"decorators\":[{\"content\":\"@staticmethod\",\"decorator_name\":\"staticmethod\",\"decorator_args\":null}],\"parameters\":null,\"returns\":\"list[str]\",\"is_method\":true,\"is_async\":false,\"id\":\"postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit__*__FUNCTION-__get_updated_modules\",\"parent_id\":\"postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit\",\"block_type\":\"FUNCTION\",\"start_line_num\":84,\"end_line_num\":110,\"code_content\":\"\\n@staticmethod\\ndef __get_updated_modules(directory: str | None = None) -> list[str]:\\n    \\\"\\\"\\\"\\n        DO NOT USE: The necessary functionality for this method is not yet implemented.\\n\\n        Returns a list of the modules that have been changed since the last commit based on a directory path.\\n        \\\"\\\"\\\"\\n    git_ls_files_cmd = \\\"git ls-files --others --exclude-standard\\\"\\n    git_diff_cmd = \\\"git diff --name-only HEAD\\\"\\n\\n    if directory:\\n        git_ls_files_cmd += f\\\" '{directory}'\\\"\\n        git_diff_cmd += f\\\" '{directory}'\\\"\\n\\n    git_command: str = f\\\"({git_ls_files_cmd}; {git_diff_cmd}) | sort | uniq\\\"\\n\\n    result: subprocess.CompletedProcess[str] = subprocess.run(\\n        git_command, shell=True, capture_output=True, text=True\\n    )\\n    if result.returncode != 0:\\n        raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n    changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n    return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":null,\"children\":null}]}]}", "chroma:document": "\nSummary:\n\n        postcode:updaters:git_updater.py__*__MODULE\n\n        \nChild (postcode:updaters:git_updater.py__*__MODULE__*__STANDALONE_BLOCK-1) code content:\nif __name__ == \"__main__\":\n    print(UpdateUsingGit.get_module_names_updated_since_commit(\"e8856d2\"))\n\n\nChild (postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit) code content:\n\n\nclass UpdateUsingGit:\n    \"\"\"\n    DO NOT USE: The necessary functionality for this class is not yet implemented.\n\n    A class that provides methods to get the names of the Python modules that have been changed using on version control.\n\n    Use this class to get all the file names for the Python modules that have been changes since the last commit or since\n    a specific commit. You can get the `commit_hash` for a specific commit by going to the commit on GitHub and copying\n    the hash from the URL. For example, the commit hash for the following commit is `e8856d2`, or you can use the terminal, for\n    instance: `git log --author=\"username\" --grep=\"commit message\" --format=\"%H\"` if you know all the details of the commit.\n\n    Methods:\n        - `get_module_names_updated_since_last_commit()`: Returns a list of the modules that have been changed since the last commit.\n        - `get_module_names_updated_since_commit(commit_hash: str)`: Returns a list of the modules that have been changed since the specified commit.\n\n    Examples:\n        ```Python\n        from postcode.updaters.git_updater import UpdateUsingGit\n\n        # Get the names of the modules that have been changed since the last commit\n        changed_modules_name_list = UpdateUsingGit.get_module_names_updated_since_last_commit()\n        ```\n    \"\"\"\n\n    @staticmethod\n    def get_module_names_updated_since_last_commit() -> list[str]:\n        \"\"\"\n        Returns a list of the modules that have been changed since the last commit.\n\n        Runs the following command using subprocess:\n            (git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\n\n        Returns:\n            - list[str]: A list of the modules that have been changed since the last commit.\n\n        Raises:\n            - Exception: If the git command fails.\n        \"\"\"\n\n        git_command = \"(git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\"\n\n        result: subprocess.CompletedProcess[str] = subprocess.run(\n            git_command, shell=True, capture_output=True, text=True\n        )\n        if result.returncode != 0:\n            raise Exception(\"Git command failed: \" + result.stderr)\n\n        changed_files: list[str] = result.stdout.strip().split(\"\\n\")\n\n        return [file for file in changed_files if file.endswith(\".py\")]\n\n    @staticmethod\n    def get_module_names_updated_since_commit(commit_hash: str) -> list[str]:\n        \"\"\"\n        Returns a list of the Python modules that have been changed since the specified commit.\n\n        Args:\n            - commit (str): The commit hash or reference to compare the current state against.\n\n        Runs the following command using subprocess:\n            (git ls-files --others --exclude-standard; git diff --name-only COMMIT) | sort | uniq\n\n        Returns:\n            - list[str]: A list of the modules that have been changed since the specified commit.\n\n        Raises:\n            - Exception: If the git command fails.\n        \"\"\"\n\n        git_command = f\"(git ls-files --others --exclude-standard; git diff --name-only {commit_hash}) | sort | uniq\"\n\n        result: subprocess.CompletedProcess[str] = subprocess.run(\n            git_command, shell=True, capture_output=True, text=True\n        )\n        if result.returncode != 0:\n            raise Exception(\"Git command failed: \" + result.stderr)\n\n        changed_files: list[str] = result.stdout.strip().split(\"\\n\")\n\n        return [file for file in changed_files if file.endswith(\".py\")]\n\n    @staticmethod\n    def __get_updated_modules(directory: str | None = None) -> list[str]:\n        \"\"\"\n        DO NOT USE: The necessary functionality for this method is not yet implemented.\n\n        Returns a list of the modules that have been changed since the last commit based on a directory path.\n        \"\"\"\n        git_ls_files_cmd = \"git ls-files --others --exclude-standard\"\n        git_diff_cmd = \"git diff --name-only HEAD\"\n\n        if directory:\n            git_ls_files_cmd += f\" '{directory}'\"\n            git_diff_cmd += f\" '{directory}'\"\n\n        git_command: str = f\"({git_ls_files_cmd}; {git_diff_cmd}) | sort | uniq\"\n\n        result: subprocess.CompletedProcess[str] = subprocess.run(\n            git_command, shell=True, capture_output=True, text=True\n        )\n        if result.returncode != 0:\n            raise Exception(\"Git command failed: \" + result.stderr)\n\n        changed_files: list[str] = result.stdout.strip().split(\"\\n\")\n\n        return [file for file in changed_files if file.endswith(\".py\")]\n\n, None, \nimport subprocess\n        "}   .] = module_models_tuple\n        self.summarizer: Summarizer = summarizer\n        self.summarized_code_block_ids: set[str] = set()\n        self.prompt_tokens: int = 0\n        self.completion_tokens: int = 0\n        self.updated_module_models: list[ModuleModel] = []\n\n    @property\n    def total_cost(self) -> float:\n        \"\"\"Provides the total cost of the summarization process.\"\"\"\n        prompt_cost: int = self.prompt_tokens * 1  # Costs 1 cent per 1,000 tokens\n        completion_cost: int = (\n            self.completion_tokens * 3\n        )  # Costs 3 cents per 1,000 tokens\n        return (prompt_cost + completion_cost) / 100_000  # Convert to dollars\n\n    def create_summarizes_and_return_updated_models(self) -> tuple[ModuleModel, ...]:\n        \"\"\"\n        Generates summaries for each module model and updates them.\n\n        This method iterates over the provided module models, generating summaries for each. The summarized modules are then added to the list of updated module models.\n\n        Returns:\n            - tuple[ModuleModel, ...]: A tuple of module models with updated summaries.\n\n        Example:\n            ```Python\n            summarization_manager = SummarizationManager(...)\n            updated_modules = summarization_manager.create_and_add_summaries_to_models()\n            print(updated_modules)\n            ```\n        \"\"\"\n        for module_model in self.module_models_tuple:\n            self._summarize_module(module_model)\n\n        return tuple(self.updated_module_models)\n\n    def _summarize_module(self, module_model: ModuleModel) -> None:\n        \"\"\"\n        Summarizes a single module model by calling `_summarize_code_block` method and adds it to the list of\n        updated module models.\n        \"\"\"\n        if module_model.id not in self.summarized_code_block_ids:\n            self._summarize_code_block(module_model)\n            # logging.info(f\"Summarized module: {module_model.id}\")\n            self.summarized_code_block_ids.add(module_model.id)\n            self.updated_module_models.append(module_model)\n\n    def _summarize_code_block(\n        self,\n        model: ModelType,\n        recursion_path: list[str] = [],\n    ) -> str | None:\n        \"\"\"\n        Recursively summarizes a code block, its children, and its dependencies.\n\n        Travels down the tree of code blocks until it finds ones that have no children or dependencies summarizes that code block\n        and returns the summary. The return summary is then added to the summary of the parent code block to allow for better contextual\n        information in the summary. If a code block has already been summarized, the summary will be gotten from the code block model\n        and added to the prompt for generating the parent summary.\n\n        Args:\n            - model (ModelType): The code block model to summarize.\n            - recursion_path (list[str]): A list of code block IDs that have been visited to avoid infinite recursion.\n\n        Returns:\n            - str | None: The summary of the provided code block, or None if the summarization failed.\n\n        Notes:\n            - This method is too large and needs to be refactored.\n            - We plan to allow it to take a `recursion_path` argument to allow for customization of summary creation direction.\n        \"\"\"\n        if model.id in recursion_path or not model.code_content:\n            return None\n        if model.id in self.summarized_code_block_ids:\n            return model.summary\n\n        recursion_path.append(model.id)\n\n        child_summary_list: list[str] | None = None\n        if model.children:\n            child_summary_list = self._get_child_summaries(model, recursion_path)\n\n        dependency_summary_list: list[str] = []\n        import_details: str | None = None\n        if model.dependencies:\n            for dependency in model.dependencies:\n                if isinstance(dependency, DependencyModel) and dependency.code_block_id:\n                    if module_local_dependency_summary := self._get_local_dependency_summary(\n                        dependency, model, recursion_path\n                    ):\n                        dependency_summary_list.append(module_local_dependency_summary)\n\n                if isinstance(dependency, ImportModel):\n                    if dependency.import_module_type == \"LOCAL\":\n                        if not dependency.import_names:\n                            if module_import_dependency := self._get_local_import_summary(\n                                dependency, recursion_path\n                            ):\n                                dependency_summary_list.append(module_import_dependency)\n                        else:\n                            if import_from_dependency := self._get_local_import_from_summary(\n                                dependency, recursion_path\n                            ):\n                                dependency_summary_list.append(import_from_dependency)\n                    else:\n                        import_detail: str | None = self._get_import_details(dependency)\n                        if not import_detail:\n                            continue\n                        if not import_details:\n                            import_details = \"\"\n                        import_details += f\"\\n{import_detail}\"\n\n        if isinstance(model, ModuleModel) and recursion_path:\n            dependency_summary_list, import_details = self._handle_module_model(\n                model, recursion_path\n            )\n\n        children_summaries: str | None = self._stringify_children_summaries(\n            child_summary_list\n        )\n        dependency_summaries: str | None = self._stringify_dependencies_summaries(\n            dependency_summary_list\n        )\n\n        summary_context: OpenAIReturnContext | None = (\n            self.summarizer.test_summarize_code(\n                model.code_content,\n                model_id=model.id,\n                children_summaries=children_summaries,\n                dependency_summaries=dependency_summaries,\n                import_details=import_details,\n            )\n        )\n\n        if isinstance(summary_context, OpenAIReturnContext):\n            if summary_context.summary:\n                model.summary = summary_context.summary\n                self.summarized_code_block_ids.add(model.id)\n                recursion_path.remove(model.id)\n\n                self.prompt_tokens += summary_context.prompt_tokens\n                self.completion_tokens += summary_context.completion_tokens\n                logging.info(f\"Summarized code block: {model.id}\")\n                logging.info(f\"Total cost: {self.total_cost}\")\n\n        return (\n            summary_context.summary\n            if isinstance(summary_context, OpenAIReturnContext)\n            else summary_context\n        )\n\n    def _handle_module_model(\n        self, model: ModuleModel, recursion_path: list[str]\n    ) -> tuple[list[str], str | None]:\n        \"\"\"Handles the special case of summarizing a module model.\"\"\"\n        dependency_summary_list: list[str] = []\n        all_import_details: str | None = None\n        if model.imports:\n            for import_model in model.imports:\n                if import_model.import_module_type == \"LOCAL\":\n                    if not import_model.import_names:\n                        if module_import := self._get_local_import_summary(\n                            import_model, recursion_path\n                        ):\n                            dependency_summary_list.append(module_import)\n                    else:\n                        if import_from := self._get_local_import_from_summary(\n                            import_model, recursion_path\n                        ):\n                            dependency_summary_list.append(import_from)\n                else:\n                    if import_details := self._get_import_details(import_model):\n                        if not all_import_details:\n                            all_import_details = \"\"\n                        all_import_details += f\"\\n{import_details}\"\n\n        return dependency_summary_list, all_import_details\n\n    def _get_import_details(self, import_model: ImportModel) -> str | None:\n        \"\"\"Retrieves details of import statements to be used in the prompt.\"\"\"\n        if import_model.import_module_type == \"LOCAL\" or not import_model.import_names:\n            return None\n\n        import_names_list: list[str] = []\n        for import_name in import_model.import_names:\n            if import_name.as_name:\n                import_names_list.append(f\"{import_name.name} as {import_name.as_name}\")\n            else:\n                import_names_list.append(f\"{import_name.name}\")\n\n        if import_model.imported_from:\n            import_details: str = f\"from {import_model.imported_from} import {', '.join(import_names_list)}\"\n        else:\n            import_details = f\"import {', '.join(import_names_list)}\"\n\n        return import_details\n\n    def _get_child_summaries(\n        self, model: ModelType, recursion_path: list[str]\n    ) -> list[str]:\n        \"\"\"Gathers summaries of child models.\"\"\"\n        child_summary_list: list[str] = []\n        if model.children:\n            for child in model.children:\n                child_summary: str | None = self._summarize_code_block(\n                    child,\n                    recursion_path,\n                )\n                if child.summary:\n                    child_summary = child.summary\n                else:\n                    child_summary = (\n                        f\"Child ({child.id}) code content:\\n{child.code_content}\\n\"\n                    )\n                child_summary_list.append(child_summary)\n        return child_summary_list\n\n    def _stringify_children_summaries(\n        self, children_summary_list: list[str] | None\n    ) -> str | None:\n        \"\"\"Converts all of the child summaries to a single string to be used in the prompt.\"\"\"\n        if not children_summary_list:\n            return None\n\n        children_summaries: str = \"\"\n        for child_summary in children_summary_list:\n            children_summaries += f\"\\n{child_summary}\"\n        return children_summaries\n\n    def _stringify_dependencies_summaries(\n        self, dependencies_summary_list: list[str] | None\n    ) -> str | None:\n        \"\"\"Converts all of the dependency summaries to a single string to be used in the prompt.\"\"\"\n        if not dependencies_summary_list:\n            return None\n\n        dependency_summaries: str = \"\"\n        for dependency_summary in dependencies_summary_list:\n            dependency_summaries += f\"\\n{dependency_summary}\"\n        return dependency_summaries\n\n    def _get_local_dependency_summary(\n        self,\n        dependency: DependencyModel,\n        model: ModelType,\n        recursion_path: list[str],\n    ) -> str | None:\n        \"\"\"Gets a summary for a dependency local to the module.\"\"\"\n        if not model.children:\n            return None\n\n        for child_model in model.children:\n            if child_model.id == dependency.code_block_id:\n                dependency_summary = self._summarize_code_block(\n                    child_model,\n                    recursion_path,\n                )\n                if dependency_summary:\n                    return dependency_summary\n                else:\n                    return f\"Dependency ({child_model.id}) code content:\\n{child_model.code_content}\\n\"\n\n    def _get_local_import_summary(\n        self, dependency: ImportModel, recursion_path: list[str]\n    ) -> str | None:\n        \"\"\"Gets the summary of a dependency imported from a separate module, but is local to the project.\"\"\"\n        for module_model in self.module_models_tuple:\n            if module_model.id == dependency.local_module_id:\n                import_summary = self._summarize_code_block(\n                    module_model,\n                    recursion_path,\n                )\n                if import_summary:\n                    return import_summary\n                else:\n                    return f\"Module import ({module_model.id}) code content:\\n{module_model.code_content}\\n\"\n\n    def _get_local_import_from_summary(\n        self, dependency: ImportModel, recursion_path: list[str]\n    ) -> str | None:\n        \"\"\"\n        Gets the summary of a dependency imported from a separate module, but is local to the project.\n        Unique handling for 'from' import statements.\n        \"\"\"\n        for import_name in dependency.import_names:\n            for module_model in self.module_models_tuple:\n                if module_model.id == dependency.local_module_id:\n                    if module_model.children:\n                        for child_model in module_model.children:\n                            if (\n                                child_model.id == import_name.local_block_id\n                                and child_model.id\n                            ):\n                                import_summary = self._summarize_code_block(\n                                    child_model,\n                                    recursion_path,\n                                )\n                                if import_summary:\n                                    return import_summary\n                                else:\n                                    return f\"Code block import ({module_model.id}) code content:\\n{module_model.code_content}\\n\"\n\n\nImported code block (postcode:databases:chroma:setup_chroma.py__*__MODULE) code content:\nfrom dataclasses import dataclass\nfrom logging import Logger\n\nimport chromadb\nfrom postcode.databases.chroma.chromadb_client_manager import ChromaDBClientManager\n\nfrom postcode.databases.chroma.chromadb_collection_manager import (\n    ChromaDBCollectionManager,\n)\n\nfrom chromadb.config import DEFAULT_DATABASE, DEFAULT_TENANT, Settings\nfrom chromadb.api import ClientAPI\nfrom chromadb.api.types import (\n    DataLoader,\n    CollectionMetadata,\n    GetResult,\n    QueryResult,\n    Where,\n    WhereDocument,\n    Include,\n    URIs,\n    Loadable,\n    Metadata,\n    Embedding,\n)\nfrom chromadb import Collection\nfrom chromadb import EmbeddingFunction\n\nfrom postcode.models.models import ModuleModel\n\n\n@dataclass\nclass ChromaSetupReturnContext:\n    \"\"\"\n    Represents the return value of the ChromaDB setup method.\n\n    Attributes:\n        - chroma_collection_manager (ChromaDBCollectionManager): The ChromaDB collection manager.\n        - chroma_collection (Collection): The ChromaDB collection.\n    \"\"\"\n\n    chroma_collection_manager: ChromaDBCollectionManager\n    chroma_collection: Collection\n\n\ndef setup_chroma(\n    module_models: list[ModuleModel], logger: Logger\n) -> ChromaSetupReturnContext:\n    chroma_settings = Settings(allow_reset=True)\n    chroma_client: ClientAPI = chromadb.PersistentClient(settings=chroma_settings)\n    chroma_client_manager = ChromaDBClientManager(chroma_client)\n\n    logger.debug(f\"Resetting Chroma client\")\n    if chroma_client_manager.reset_client():\n        logger.debug(\"Client reset\")\n\n    chroma_collection: Collection = chroma_client_manager.get_or_create_collection(\n        \"postcode\"\n    )\n\n    chroma_collection_manager = ChromaDBCollectionManager(chroma_collection)\n    chroma_collection_manager.upsert_models(tuple(module_models))\n\n    return ChromaSetupReturnContext(chroma_collection_manager, chroma_collection)\n\n\nImported code block (postcode:json_management:json_handler.py__*__MODULE) code content:\nimport json\nfrom pathlib import Path\n\nfrom postcode.models.models import ModuleModel\nfrom postcode.utilities.logger.decorators import logging_decorator\n\n\nclass JSONHandler:\n    def __init__(\n        self,\n        directory: str,\n        directory_modules: dict[str, list[str]],\n        output_directory: str = \"../output\",\n    ) -> None:\n        self.directory: str = directory\n        self.output_directory: str = output_directory\n        self.directory_modules: dict[str, list[str]] = directory_modules\n\n        self._create_output_directory()\n\n    @logging_decorator(message=\"Saving model as JSON\")\n    def save_model_as_json(self, module_model: ModuleModel, file_path: str) -> None:\n        \"\"\"Saves a parsed ModuleModel as JSON.\"\"\"\n\n        json_output_directory: str = self._create_json_output_directory()\n        output_path: str = self._get_json_output_path(file_path, json_output_directory)\n        self._write_json_file(module_model, output_path)\n\n    @logging_decorator(message=\"Saving visited directories\")\n    def save_visited_directories(\n        self, directory_mape_name: str = \"directory_map.json\"\n    ) -> None:\n        \"\"\"\n        Saves a JSON file mapping each visited directory to its Python files.\n\n        The output is saved in a file named '00_directory_module_map.json' within the specified output directory.\n\n        Args:\n            directory_mape_name (str): The name of the output file for the directory map.\n\n        Example:\n            >>> visitor_manager.save_visited_directories(\"directory_map.json\")\n            # Saves a mapping of directories to Python files as JSON.\n        \"\"\"\n\n        output_path: str = self._get_directory_map_output_path(directory_mape_name)\n        self._write_json_directory_map(output_path)\n\n    def _create_output_directory(self) -> None:\n        \"\"\"Creates the output directory if it does not already exist.\"\"\"\n\n        Path(self.output_directory).mkdir(exist_ok=True)\n\n    def _create_json_output_directory(self) -> str:\n        \"\"\"Creates the JSON output directory if it does not already exist.\"\"\"\n\n        json_output_directory: Path = Path(self.output_directory) / \"json\"\n        json_output_directory.mkdir(exist_ok=True)\n        return str(json_output_directory)\n\n    def _get_json_output_path(self, file_path: str, json_output_directory: str) -> str:\n        \"\"\"Gets the output path for a JSON file.\"\"\"\n\n        relative_path: Path = Path(file_path).relative_to(Path(self.directory))\n        safe_relative_path: str = str(relative_path).replace(\"/\", \":\").rstrip(\".py\")\n        return str(Path(json_output_directory) / f\"{safe_relative_path}.json\")\n\n    def _write_json_file(self, module_model: ModuleModel, output_path: str) -> None:\n        \"\"\"Writes a JSON file containing the parsed data from a ModuleModel.\"\"\"\n\n        parsed_data_json: str = module_model.model_dump_json(indent=4)\n        with open(output_path, \"w\") as json_file:\n            json_file.write(parsed_data_json)\n\n    def _get_directory_map_output_path(self, directory_output_name: str) -> str:\n        \"\"\"Gets the output path for the directory map JSON file.\"\"\"\n\n        return str(Path(self.output_directory) / directory_output_name)\n\n    def _write_json_directory_map(self, output_path: str) -> None:\n        \"\"\"Writes the directory map JSON file.\"\"\"\n\n        with open(output_path, \"w\") as json_file:\n            json.dump(self.directory_modules, json_file, indent=4)\n\n\nImported code block (postcode:models:models.py__*__MODULE) code content:\nfrom typing import Union\nfrom pydantic import BaseModel, Field, validator\n\nfrom postcode.models.enums import (\n    BlockType,\n    ImportModuleType,\n    CommentType,\n)\n\n\nclass ImportNameModel(BaseModel):\n    \"\"\"Class representing the name of an import.\"\"\"\n\n    name: str\n    as_name: str | None = None\n    local_block_id: str | None = None\n\n    # def convert_import_names_to_metadata(self) -> str:\n    #     \"\"\"Converts the import name to a metadata string.\"\"\"\n\n    #     return self.model_dump_json()\n\n\nclass ImportModel(BaseModel):\n    \"\"\"Class representing an import statement.\"\"\"\n\n    import_names: list[ImportNameModel]\n    imported_from: str | None = None\n    import_module_type: ImportModuleType = ImportModuleType.STANDARD_LIBRARY\n    local_module_id: str | None = None\n\n    def convert_import_to_metadata(self) -> str:\n        \"\"\"Converts the import to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass DependencyModel(BaseModel):\n    \"\"\"Class representing a module dependency.\"\"\"\n\n    code_block_id: str\n\n    def convert_dependency_to_metadata(self) -> str:\n        \"\"\"Converts the dependency to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass CommentModel(BaseModel):\n    \"\"\"Class representing a comment.\"\"\"\n\n    content: str\n    comment_types: list[CommentType]\n\n    def convert_comment_to_metadata(self) -> str:\n        \"\"\"Converts the comment to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass DecoratorModel(BaseModel):\n    \"\"\"Class representing a decorator.\"\"\"\n\n    content: str\n    decorator_name: str\n    decorator_args: list[str] | None = None\n\n    def convert_decorator_to_metadata(self) -> str:\n        \"\"\"Converts the decorator to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass ClassKeywordModel(BaseModel):\n    \"\"\"Class representing a class keyword.\"\"\"\n\n    content: str\n    keyword_name: str\n    args: str | None = None\n\n    def convert_class_keyword_to_metadata(self) -> str:\n        \"\"\"Converts the class keyword to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass ParameterModel(BaseModel):\n    \"\"\"Class representing a function parameter.\"\"\"\n\n    content: str\n\n\nclass ParameterListModel(BaseModel):\n    \"\"\"Class representing a list of parameters.\"\"\"\n\n    params: list[ParameterModel] | None = None\n    star_arg: ParameterModel | None = None\n    kwonly_params: list[ParameterModel] | None = None\n    star_kwarg: ParameterModel | None = None\n    posonly_params: list[ParameterModel] | None = None\n\n    def convert_parameters_to_metadata(self) -> str:\n        \"\"\"Converts the parameter list to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass BaseCodeBlockModel(BaseModel):\n    \"\"\"Attributes common to all code block models.\"\"\"\n\n    id: str\n    parent_id: str | None = None\n    block_type: BlockType\n    start_line_num: int\n    end_line_num: int\n    code_content: str = \"\"\n    important_comments: list[CommentModel] | None = None\n    dependencies: list[ImportModel | DependencyModel] | None = None\n    summary: str | None = None\n    children: list[\n        Union[\n            \"ClassModel\",\n            \"FunctionModel\",\n            \"StandaloneCodeBlockModel\",\n        ]\n    ] | None = []\n\n    @validator(\"parent_id\", always=True)\n    def check_parent_id(cls, v, values, **kwargs) -> str | None:\n        \"\"\"Validates that parent_id is a non-empty string unless block_type is MODULE.\"\"\"\n\n        if \"block_type\" in values and values[\"block_type\"] != BlockType.MODULE:\n            if len(v) < 1:\n                raise ValueError(\"parent_id is required!\")\n        return v\n\n    def _convert_parent_id_to_metadata(self) -> str:\n        \"\"\"Converts the parent_id to a metadata string.\"\"\"\n        return f\"{self.parent_id}\" if self.parent_id else \"\"\n\n    def _convert_block_type_to_metadata(self) -> str:\n        \"\"\"Converts the block_type to a metadata string.\"\"\"\n        return f\"{self.block_type.name}\"\n\n    def _convert_important_comments_to_metadata(self) -> str:\n        \"\"\"Converts the important comments to a metadata string.\"\"\"\n\n        important_comments: str = (\n            self.model_dump_json() if self.important_comments else \"\"\n        )\n\n        return f\"{important_comments}\"\n\n    def _convert_dependencies_to_metadata(self) -> str:\n        \"\"\"Converts the dependencies to a metadata string.\"\"\"\n\n        dependencies_str: str = \"\"\n\n        if self.dependencies:\n            for dependency in self.dependencies:\n                if isinstance(dependency, ImportModel):\n                    dependencies_str += f\"{dependency.convert_import_to_metadata()}\\n\"\n                elif isinstance(dependency, DependencyModel):\n                    dependencies_str += (\n                        f\"{dependency.convert_dependency_to_metadata()}\\n\"\n                    )\n\n        return dependencies_str\n\n    def _convert_summary_to_metadata(self) -> str:\n        \"\"\"Converts the summary to a metadata string.\"\"\"\n        return f\"{self.summary}\" if self.summary else \"\"\n\n    def _convert_children_to_metadata(self) -> str:\n        \"\"\"Converts the children to a metadata string.\"\"\"\n\n        children_str: str = \"\"\n\n        if self.children:\n            for child in self.children:\n                children_str += f\"{child.id}\\n\"\n\n        return children_str\n\n    def _convert_base_attributes_to_metadata_dict(self) -> dict[str, str | int]:\n        \"\"\"Converts the base attributes to a metadata dictionary.\"\"\"\n\n        return {\n            \"id\": self.id,\n            \"parent_id\": self._convert_parent_id_to_metadata(),\n            \"block_type\": self._convert_block_type_to_metadata(),\n            \"start_line_num\": self.start_line_num,\n            \"end_line_num\": self.end_line_num,\n            \"code_content\": self.code_content,\n            \"important_comments\": self._convert_important_comments_to_metadata(),\n            \"dependencies\": self._convert_dependencies_to_metadata(),\n            \"summary\": self._convert_summary_to_metadata(),\n            \"children\": self._convert_children_to_metadata(),\n        }\n\n\nclass ModuleSpecificAttributes(BaseModel):\n    \"\"\"Module specific attributes.\"\"\"\n\n    file_path: str = Field(min_length=1)\n    docstring: str | None = None\n    header: list[str] | None = None\n    footer: list[str] | None = None\n    imports: list[ImportModel] | None = None\n\n    def _convert_docstring_to_metadata(self) -> str:\n        \"\"\"Converts the docstring to a metadata string.\"\"\"\n        return f\"{self.docstring}\"\n\n    def _convert_header_to_metadata(self) -> str:\n        \"\"\"Converts the header and footer to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n    def _convert_footer_to_metadata(self) -> str:\n        \"\"\"Converts the header and footer to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n    def _convert_imports_to_metadata(self) -> str:\n        \"\"\"Converts the imports to a metadata string.\"\"\"\n        imports_str: str = self.model_dump_json() if self.imports else \"\"\n        return f\"{imports_str}\"\n\n    def _convert_module_attributes_to_metadata_dict(self) -> dict[str, str | int]:\n        \"\"\"Converts the module attributes to a metadata dictionary.\"\"\"\n\n        return {\n            \"file_path\": self.file_path,\n            \"docstring\": self._convert_docstring_to_metadata(),\n            \"header\": self._convert_header_to_metadata(),\n            \"footer\": self._convert_footer_to_metadata(),\n            \"imports\": self._convert_imports_to_metadata(),\n        }\n\n\nclass ModuleModel(BaseCodeBlockModel, ModuleSpecificAttributes):\n    \"\"\"Model for a module.\"\"\"\n\n    def convert_to_metadata(self) -> dict[str, str | int]:\n        \"\"\"Converts the module model to a metadata dictionary.\"\"\"\n\n        return {\n            **self._convert_base_attributes_to_metadata_dict(),\n            **self._convert_module_attributes_to_metadata_dict(),\n        }\n\n\nclass ClassSpecificAttributes(BaseModel):\n    \"\"\"Class specific attributes.\"\"\"\n\n    class_name: str = Field(min_length=1)\n    decorators: list[DecoratorModel] | None = None\n    bases: list[str] | None = None\n    docstring: str | None = None\n    keywords: list[ClassKeywordModel] | None = None\n    # attributes: list[dict] | None = None\n\n    def _convert_decorators_to_metadata(self) -> str:\n        \"\"\"Converts the decorators to a metadata string.\"\"\"\n        decorators_str: str = self.model_dump_json() if self.decorators else \"\"\n        return f\"{decorators_str}\"\n\n    def _convert_bases_to_metadata(self) -> str:\n        \"\"\"Converts the bases to a metadata string.\"\"\"\n        return self.model_dump_json() if self.bases else \"\"\n\n    def _convert_docstring_to_metadata(self) -> str:\n        \"\"\"Converts the docstring to a metadata string.\"\"\"\n        return f\"{self.docstring}\" if self.docstring else \"\"\n\n    def _convert_keywords_to_metadata(self) -> str:\n        \"\"\"Converts the keywords to a metadata string.\"\"\"\n        keywords_str: str = self.model_dump_json() if self.keywords else \"\"\n        return f\"{keywords_str}\"\n\n    def _convert_class_attributes_to_metadata_dict(self) -> dict[str, str | int]:\n        \"\"\"Converts the class attributes to a metadata dictionary.\"\"\"\n\n        return {\n            \"class_name\": self.class_name,\n            \"decorators\": self._convert_decorators_to_metadata(),\n            \"bases\": self._convert_bases_to_metadata(),\n            \"docstring\": self._convert_docstring_to_metadata(),\n            \"keywords\": self._convert_keywords_to_metadata(),\n        }\n\n\nclass ClassModel(BaseCodeBlockModel, ClassSpecificAttributes):\n    \"\"\"Model for a class.\"\"\"\n\n    def convert_to_metadata(self) -> dict[str, str | int]:\n        \"\"\"Converts the class model to a metadata dictionary.\"\"\"\n        return {\n            **self._convert_base_attributes_to_metadata_dict(),\n            **self._convert_class_attributes_to_metadata_dict(),\n        }\n\n\nclass FunctionSpecificAttributes(BaseModel):\n    \"\"\"Function specific attributes.\"\"\"\n\n    function_name: str = Field(min_length=1)\n    docstring: str | None = None\n    decorators: list[DecoratorModel] | None = None\n    parameters: ParameterListModel | None = None\n    returns: str | None = None\n    is_method: bool = False\n    is_async: bool = False\n\n    def _convert_docstring_to_metadata(self) -> str:\n        \"\"\"Converts the docstring to a metadata string.\"\"\"\n        return f\"{self.docstring}\" if self.docstring else \"\"\n\n    def _convert_decorators_to_metadata(self) -> str:\n        \"\"\"Converts the decorators to a metadata string.\"\"\"\n        decorators_str: str = self.model_dump_json() if self.decorators else \"\"\n        return f\"{decorators_str}\"\n\n    def _convert_parameters_to_metadata(self) -> str:\n        \"\"\"Converts the parameters to a metadata string.\"\"\"\n        return (\n            self.parameters.convert_parameters_to_metadata() if self.parameters else \"\"\n        )\n\n    def _convert_returns_to_metadata(self) -> str:\n        \"\"\"Converts the returns to a metadata string.\"\"\"\n        return f\"{self.returns}\" if self.returns else \"\"\n\n    def _convert_function_attributes_to_metadata_dict(self) -> dict[str, str | bool]:\n        \"\"\"Converts the function attributes to a metadata dictionary.\"\"\"\n\n        return {\n            \"function_name\": self.function_name,\n            \"docstring\": self._convert_docstring_to_metadata(),\n            \"decorators\": self._convert_decorators_to_metadata(),\n            \"parameters\": self._convert_parameters_to_metadata(),\n            \"returns\": self._convert_returns_to_metadata(),\n            \"is_method\": self.is_method,\n            \"is_async\": self.is_async,\n        }\n\n\nclass FunctionModel(BaseCodeBlockModel, FunctionSpecificAttributes):\n    \"\"\"Model for a function.\"\"\"\n\n    def convert_to_metadata(self) -> dict[str, str | int]:\n        \"\"\"Converts the function model to a metadata dictionary.\"\"\"\n\n        return {\n            **self._convert_base_attributes_to_metadata_dict(),\n            **self._convert_function_attributes_to_metadata_dict(),\n        }\n\n\nclass StandaloneCodeBlockSpecificAttributes(BaseModel):\n    \"\"\"Standalone code block specific attributes.\"\"\"\n\n    variable_assignments: list[str] | None = None\n\n    def _convert_variable_assignments_to_metadata(self) -> str:\n        \"\"\"Converts the variable assignments to a metadata string.\"\"\"\n        return self.model_dump_json() if self.variable_assignments else \"\"\n\n    def _convert_standalone_block_attributes_to_metadata_dict(\n        self,\n    ) -> dict[str, str | int]:\n        \"\"\"Converts the standalone code block attributes to a metadata dictionary.\"\"\"\n        return {\n            \"variable_assignments\": self._convert_variable_assignments_to_metadata(),\n        }\n\n\nclass StandaloneCodeBlockModel(\n    BaseCodeBlockModel, StandaloneCodeBlockSpecificAttributes\n):\n    \"\"\"Model for a standalone code block.\"\"\"\n\n    def convert_to_metadata(self) -> dict[str, str | int]:\n        \"\"\"Converts the standalone code block model to a metadata dictionary.\"\"\"\n\n        return {\n            **self._convert_base_attributes_to_metadata_dict(),\n            **self._convert_standalone_block_attributes_to_metadata_dict(),\n        }\n\n\nImported code block (postcode:python_parser:visitor_manager:visitor_manager.py__*__MODULE) code content:\nfrom dataclasses import dataclass\nimport logging\nfrom pathlib import Path\n\nfrom postcode.python_parser.model_builders.module_model_builder import (\n    ModuleModelBuilder,\n)\nfrom postcode.utilities.logger.decorators import logging_decorator\n\nfrom postcode.python_parser.parsers.python_parser import PythonParser\nfrom postcode.python_parser.visitor_manager.import_and_dependency_updater import (\n    ImportAndDependencyUpdater,\n)\nfrom postcode.models.models import ModuleModel\n\nfrom postcode.ai_services.summarizer.summarization_context import Summarizer\n\nEXCLUDED_DIRECTORIES: set[str] = {\".venv\", \"node_modules\", \"__pycache__\", \".git\"}\n\n\n@dataclass\nclass VisitorManagerProcessFilesReturn:\n    \"\"\"\n    Represents the return value of the VisitorManager.process_files() method.\n\n    Attributes:\n        - models_tuple (tuple[ModuleModel, ...]): A tuple of ModuleModel objects representing the parsed modules.\n        - directory_modules (dict[str, list[str]]): A dictionary mapping directory paths to lists of module names.\n            This is used to keep track of the modules present in each directory.\n    \"\"\"\n\n    models_tuple: tuple[ModuleModel, ...]\n    directory_modules: dict[str, list[str]]\n\n\nclass VisitorManager:\n    \"\"\"\n    Manages the visiting and processing of Python files in a given directory.\n\n    This class scans a specified directory, filters for Python files, parses them, and saves the parsed data in a structured JSON format. It also maintains a mapping of directories to the Python files they contain.\n\n    Attributes:\n        directory (str): The root directory to scan for Python files.\n        output_directory (str): The directory where output JSON files will be saved.\n        directory_modules (dict): A mapping of directories to their contained Python files.\n\n    Example:\n        >>> visitor_manager = VisitorManager(\"/path/to/python/code\", \"output\")\n        >>> visitor_manager.process_files()\n        # This will process all Python files in /path/to/python/code and save their parsed data in the output directory.\n    \"\"\"\n\n    @logging_decorator(message=\"Initializing VisitorManager\")\n    def __init__(self, directory: str, output_directory: str = \"output_json\") -> None:\n        self.directory: str = directory\n        self.output_directory: str = output_directory\n        self.directory_modules: dict[str, list[str]] = {}\n\n    def process_files(self) -> VisitorManagerProcessFilesReturn:\n        \"\"\"\n        Process the files in the directory and return the module models.\n\n        This function iterates through all the Python files in the directory, processes each file,\n        updates the imports, and builds module models for each file. It returns a tuple of module models\n        and a dictionary of directory modules.\n\n        Returns:\n            A named tuple (VisitorManagerProcessFilesReturn) containing:\n            - models_tuple (tuple[ModuleModel, ...]): A tuple of module models.\n            - directory_modules (dict[str, ModuleModel]): A dictionary of directory modules.\n\n        Examples:\n            >>> visitor_manager = VisitorManager()\n            >>> result = visitor_manager.process_files()\n            >>> print(result.models_tuple)\n            (ModuleModel(file_path='/path/to/file1.py'), ModuleModel(file_path='/path/to/file2.py'))\n            >>> print(result.directory_modules)\n            {'/path/to/directory1': ModuleModel(file_path='/path/to/directory1/__init__.py')}\n        \"\"\"\n\n        logging.info(\"Processing files\")\n        python_files: list[str] = self._get_python_files()\n        model_builder_list: list[ModuleModelBuilder] = []\n        for file_path in python_files:\n            if model_builder := self._process_file(file_path):\n                model_builder_list.append((model_builder))\n\n        logging.info(\"File processing completed\")\n        logging.info(\"Updating imports\")\n\n        # TODO: Test making this a tuple of tuples, see if that solves the double update import issue\n        model_builder_tuple: tuple[ModuleModelBuilder, ...] = tuple(model_builder_list)\n\n        import_and_dependency_updater = ImportAndDependencyUpdater(model_builder_tuple)\n        import_and_dependency_updater.update_imports()\n        logging.info(\"Updated imports\")\n\n        module_models_list: list[ModuleModel] = []\n        for module_model_builder in model_builder_tuple:\n            module_model: ModuleModel = self._build_module_model(module_model_builder)\n            module_models_list.append(module_model)\n\n        module_models_tuple: tuple[ModuleModel, ...] = tuple(module_models_list)\n\n        return VisitorManagerProcessFilesReturn(\n            models_tuple=module_models_tuple, directory_modules=self.directory_modules\n        )\n\n    def _walk_directories(self) -> list[str]:\n        \"\"\"Walks the specified directory and returns a list of all files.\"\"\"\n\n        all_files: list[str] = []\n        for file_path in Path(self.directory).rglob(\"*\"):\n            if not any(\n                excluded in file_path.parts for excluded in EXCLUDED_DIRECTORIES\n            ):\n                all_files.append(str(file_path))\n        return all_files\n\n    def _filter_python_files(self, files: list[str]) -> list[str]:\n        \"\"\"Filters a list of files to only include Python files.\"\"\"\n\n        return [file for file in files if file.endswith(\".py\")]\n\n    @logging_decorator(message=\"Getting Python files\")\n    def _get_python_files(self) -> list[str]:\n        \"\"\"Gets all Python files in the specified directory.\"\"\"\n\n        all_files: list[str] = self._walk_directories()\n        return self._filter_python_files(all_files)\n\n    def _process_file(self, file_path: str) -> ModuleModelBuilder | None:\n        \"\"\"Processes a single Python file.\"\"\"\n\n        file_path_obj = Path(file_path)\n        root = str(file_path_obj.parent)\n        self.directory_modules.setdefault(root, []).append(file_path_obj.name)\n        return self._parse_file(file_path)\n\n    @logging_decorator(message=\"Processing file\")\n    def _parse_file(self, file_path: str) -> ModuleModelBuilder | None:\n        \"\"\"Parses a Python file and saves the parsed data as JSON.\"\"\"\n\n        parser = PythonParser(file_path)\n        code: str = parser.open_file()\n        module_model_builder: ModuleModelBuilder | None = parser.parse(code)\n\n        return module_model_builder\n\n    def _build_module_model(\n        self, visitor_stack: ModuleModelBuilder | None\n    ) -> ModuleModel:\n        \"\"\"\n        Builds a module model from the provided module builder.\n\n        Args:\n            visitor_stack (ModuleModelBuilder): The module builder to build the model from.\n\n        Returns:\n            ModuleModel: A structured module model.\n\n        Example:\n            >>> module_model = python_parser.build_module_model(visitor_stack)\n            # Builds a module model from the provided module builder.\n        \"\"\"\n\n        if not isinstance(visitor_stack, ModuleModelBuilder):\n            raise TypeError(\"Expected the first builder to be a ModuleModelBuilder\")\n\n        return visitor_stack.build()\n\n, \nfrom logging import Logger\nfrom openai import OpenAI\n        "}   return self\\n\\n    def set_return_annotation(self, return_type: str) -> \\\"FunctionModelBuilder\\\":\\n        \\\"\\\"\\\"Sets the return type.\\\"\\\"\\\"\\n        self.function_attributes.returns = return_type\\n        return self\\n\\n    def set_is_method(self, is_method: bool) -> \\\"FunctionModelBuilder\\\":\\n        \\\"\\\"\\\"Sets the is_method attribute in the function model.\\\"\\\"\\\"\\n        self.function_attributes.is_method = is_method\\n        return self\\n\\n    def set_is_async(self, is_async: bool) -> \\\"FunctionModelBuilder\\\":\\n        \\\"\\\"\\\"Sets the is_async attribute in the function model.\\\"\\\"\\\"\\n        self.function_attributes.is_async = is_async\\n        return self\\n\\n    def _get_function_specific_attributes(self) -> dict[str, Any]:\\n        \\\"\\\"\\\"\\n        Gets the function specific attributes from the builder.\\n        \\\"\\\"\\\"\\n        return self.function_attributes.model_dump()\\n\\n    @logging_decorator(message=\\\"Building function model\\\")\\n    def build(self) -> FunctionModel:\\n        \\\"\\\"\\\"Builds and returns the function model instance after building and setting the children models.\\\"\\\"\\\"\\n        self.build_and_set_children()\\n        return FunctionModel(\\n            **self._get_common_attributes(),\\n            **self._get_function_specific_attributes(),\\n        )\\n\",\"important_comments\":null,\"dependencies\":[{\"import_names\":[{\"name\":\"DecoratorModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"FunctionSpecificAttributes\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"ParameterListModel\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"DecoratorModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"FunctionSpecificAttributes\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"ParameterListModel\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"DecoratorModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"FunctionSpecificAttributes\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"ParameterListModel\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"DecoratorModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"FunctionSpecificAttributes\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"ParameterListModel\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"Any\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"typing\",\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"BaseModelBuilder\",\"as_name\":null,\"local_block_id\":\"postcode:python_parser:model_builders:base_model_builder.py__*__MODULE__*__CLASS-BaseModelBuilder\"}],\"imported_from\":\"postcode.python_parser.model_builders.base_model_builder\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:python_parser:model_builders:base_model_builder.py__*__MODULE\"},{\"import_names\":[{\"name\":\"logging_decorator\",\"as_name\":null,\"local_block_id\":\"postcode:utilities:logger:decorators.py__*__MODULE__*__FUNCTION-logging_decorator\"}],\"imported_from\":\"postcode.utilities.logger.decorators\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:utilities:logger:decorators.py__*__MODULE\"},{\"import_names\":[{\"name\":\"BlockType\",\"as_name\":null,\"local_block_id\":\"postcode:models:enums.py__*__MODULE__*__CLASS-BlockType\"}],\"imported_from\":\"postcode.models.enums\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:enums.py__*__MODULE\"}],\"summary\":null,\"children\":[{\"function_name\":\"__init__\",\"docstring\":null,\"decorators\":null,\"parameters\":null,\"returns\":\"None\",\"is_method\":true,\"is_async\":false,\"id\":\"postcode:python_parser:model_builders:function_model_builder.py__*__MODULE__*__CLASS-FunctionModelBuilder__*__FUNCTION-__init__\",\"parent_id\":\"postcode:python_parser:model_builders:function_model_builder.py__*__MODULE__*__CLASS-FunctionModelBuilder\",\"block_type\":\"FUNCTION\",\"start_line_num\":29,\"end_line_num\":45,\"code_content\":\"\\ndef __init__(self, id: str, function_name: str, parent_id: str) -> None:\\n    super().__init__(\\n        id=id,\\n        block_type=BlockType.FUNCTION,\\n        parent_id=parent_id,\\n    )\\n    self.function_attributes = FunctionSpecificAttributes(\\n        function_name=function_name,\\n        docstring=None,\\n        decorators=None,\\n        parameters=None,\\n        is_method=False,\\n        is_async=False,\\n        returns=None,\\n    )\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":null,\"children\":null},{\"function_name\":\"set_parameters_list\",\"docstring\":\"Adds a parameter to the function model.\",\"decorators\":null,\"parameters\":null,\"returns\":\"No return annotation\",\"is_method\":true,\"is_async\":false,\"id\":\"postcode:python_parser:model_builders:function_model_builder.py__*__MODULE__*__CLASS-FunctionModelBuilder__*__FUNCTION-set_parameters_list\",\"parent_id\":\"postcode:python_parser:model_builders:function_model_builder.py__*__MODULE__*__CLASS-FunctionModelBuilder\",\"block_type\":\"FUNCTION\",\"start_line_num\":45,\"end_line_num\":52,\"code_content\":\"\\ndef set_parameters_list(\\n    self, parameter_list_model: ParameterListModel | None\\n) -> \\\"FunctionModelBuilder\\\":\\n    \\\"\\\"\\\"Adds a parameter to the function model.\\\"\\\"\\\"\\n    self.function_attributes.parameters = parameter_list_model\\n    return self\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":null,\"children\":null},{\"function_name\":\"set_decorators\",\"docstring\":\"Adds decorator to the decorators list in the class model.\",\"decorators\":null,\"parameters\":null,\"returns\":\"No return annotation\",\"is_method\":true,\"is_async\":false,\"id\":\"postcode:python_parser:model_builders:function_model_builder.py__*__MODULE__*__CLASS-FunctionModelBuilder__*__FUNCTION-set_decorators\",\"parent_id\":\"postcode:python_parser:model_builders:function_model_builder.py__*__MODULE__*__CLASS-FunctionModelBuilder\",\"block_type\":\"FUNCTION\",\"start_line_num\":52,\"end_line_num\":62,\"code_content\":\"\\ndef set_decorators(\\n    self, decorators: list[DecoratorModel] | None\\n) -> \\\"FunctionModelBuilder\\\":\\n    \\\"\\\"\\\"Adds decorator to the decorators list in the class model.\\\"\\\"\\\"\\n    if decorators:\\n        self.function_attributes.decorators = decorators\\n    else:\\n        self.function_attributes.decorators = None\\n    return self\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":null,\"children\":null},{\"function_name\":\"set_docstring\",\"docstring\":\"Sets the docstring.\",\"decorators\":null,\"parameters\":null,\"returns\":\"No return annotation\",\"is_method\":true,\"is_async\":false,\"id\":\"postcode:python_parser:model_builders:function_model_builder.py__*__MODULE__*__CLASS-FunctionModelBuilder__*__FUNCTION-set_docstring\",\"parent_id\":\"postcode:python_parser:model_builders:function_model_builder.py__*__MODULE__*__CLASS-FunctionModelBuilder\",\"block_type\":\"FUNCTION\",\"start_line_num\":62,\"end_line_num\":67,\"code_content\":\"\\ndef set_docstring(self, docstring: str | None) -> \\\"FunctionModelBuilder\\\":\\n    \\\"\\\"\\\"Sets the docstring.\\\"\\\"\\\"\\n    self.function_attributes.docstring = docstring\\n    return self\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":null,\"children\":null},{\"function_name\":\"set_return_annotation\",\"docstring\":\"Sets the return type.\",\"decorators\":null,\"parameters\":null,\"returns\":\"No return annotation\",\"is_method\":true,\"is_async\":false,\"id\":\"postcode:python_parser:model_builders:function_model_builder.py__*__MODULE__*__CLASS-FunctionModelBuilder__*__FUNCTION-set_return_annotation\",\"parent_id\":\"postcode:python_parser:model_builders:function_model_builder.py__*__MODULE__*__CLASS-FunctionModelBuilder\",\"block_type\":\"FUNCTION\",\"start_line_num\":67,\"end_line_num\":72,\"code_content\":\"\\ndef set_return_annotation(self, return_type: str) -> \\\"FunctionModelBuilder\\\":\\n    \\\"\\\"\\\"Sets the return type.\\\"\\\"\\\"\\n    self.function_attributes.returns = return_type\\n    return self\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":null,\"children\":null},{\"function_name\":\"set_is_method\",\"docstring\":\"Sets the is_method attribute in the function model.\",\"decorators\":null,\"parameters\":null,\"returns\":\"No return annotation\",\"is_method\":true,\"is_async\":false,\"id\":\"postcode:python_parser:model_builders:function_model_builder.py__*__MODULE__*__CLASS-FunctionModelBuilder__*__FUNCTION-set_is_method\",\"parent_id\":\"postcode:python_parser:model_builders:function_model_builder.py__*__MODULE__*__CLASS-FunctionModelBuilder\",\"block_type\":\"FUNCTION\",\"start_line_num\":72,\"end_line_num\":77,\"code_content\":\"\\ndef set_is_method(self, is_method: bool) -> \\\"FunctionModelBuilder\\\":\\n    \\\"\\\"\\\"Sets the is_method attribute in the function model.\\\"\\\"\\\"\\n    self.function_attributes.is_method = is_method\\n    return self\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":null,\"children\":null},{\"function_name\":\"set_is_async\",\"docstring\":\"Sets the is_async attribute in the function model.\",\"decorators\":null,\"parameters\":null,\"returns\":\"No return annotation\",\"is_method\":true,\"is_async\":false,\"id\":\"postcode:python_parser:model_builders:function_model_builder.py__*__MODULE__*__CLASS-FunctionModelBuilder__*__FUNCTION-set_is_async\",\"parent_id\":\"postcode:python_parser:model_builders:function_model_builder.py__*__MODULE__*__CLASS-FunctionModelBuilder\",\"block_type\":\"FUNCTION\",\"start_line_num\":77,\"end_line_num\":82,\"code_content\":\"\\ndef set_is_async(self, is_async: bool) -> \\\"FunctionModelBuilder\\\":\\n    \\\"\\\"\\\"Sets the is_async attribute in the function model.\\\"\\\"\\\"\\n    self.function_attributes.is_async = is_async\\n    return self\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":null,\"children\":null},{\"function_name\":\"_get_function_specific_attributes\",\"docstring\":\"Gets the function specific attributes from the builder.\",\"decorators\":null,\"parameters\":null,\"returns\":\"dict[str, Any]\",\"is_method\":true,\"is_async\":false,\"id\":\"postcode:python_parser:model_builders:function_model_builder.py__*__MODULE__*__CLASS-FunctionModelBuilder__*__FUNCTION-_get_function_specific_attributes\",\"parent_id\":\"postcode:python_parser:model_builders:function_model_builder.py__*__MODULE__*__CLASS-FunctionModelBuilder\",\"block_type\":\"FUNCTION\",\"start_line_num\":82,\"end_line_num\":88,\"code_content\":\"\\ndef _get_function_specific_attributes(self) -> dict[str, Any]:\\n    \\\"\\\"\\\"\\n        Gets the function specific attributes from the builder.\\n        \\\"\\\"\\\"\\n    return self.function_attributes.model_dump()\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":null,\"children\":null},{\"function_name\":\"build\",\"docstring\":\"Builds and returns the function model instance after building and setting the children models.\",\"decorators\":[{\"content\":\"@logging_decorator(message=\\\"Building function model\\\")\",\"decorator_name\":\"logging_decorator\",\"decorator_args\":[\"message=\\\"Building function model\\\"\"]}],\"parameters\":null,\"returns\":\"FunctionModel\",\"is_method\":true,\"is_async\":false,\"id\":\"postcode:python_parser:model_builders:function_model_builder.py__*__MODULE__*__CLASS-FunctionModelBuilder__*__FUNCTION-build\",\"parent_id\":\"postcode:python_parser:model_builders:function_model_builder.py__*__MODULE__*__CLASS-FunctionModelBuilder\",\"block_type\":\"FUNCTION\",\"start_line_num\":88,\"end_line_num\":97,\"code_content\":\"\\n@logging_decorator(message=\\\"Building function model\\\")\\ndef build(self) -> FunctionModel:\\n    \\\"\\\"\\\"Builds and returns the function model instance after building and setting the children models.\\\"\\\"\\\"\\n    self.build_and_set_children()\\n    return FunctionModel(\\n        **self._get_common_attributes(),\\n        **self._get_function_specific_attributes(),\\n    )\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":null,\"children\":null}]}]}", "chroma:document": "\nSummary:\n\n        postcode:python_parser:model_builders:function_model_builder.py__*__MODULE\n\n        \nChild (postcode:python_parser:model_builders:function_model_builder.py__*__MODULE__*__CLASS-FunctionModelBuilder) code content:\n\n\nclass FunctionModelBuilder(BaseModelBuilder):\n    \"\"\"\n    A builder class for constructing a model of a Python function.\n\n    This class extends BaseModelBuilder and specializes in building a detailed model of a Python function, capturing various aspects such as function name, docstring, parameters, decorators, return type, and whether the function is a method or asynchronous.\n\n    Attributes:\n        function_attributes (FunctionSpecificAttributes): An instance containing attributes specific to a function.\n\n    Args:\n        id (str): The unique identifier for the function model.\n        function_name (str): The name of the function.\n        parent_id (str): The identifier of the parent model (e.g., module or class containing this function).\n    \"\"\"\n\n    def __init__(self, id: str, function_name: str, parent_id: str) -> None:\n        super().__init__(\n            id=id,\n            block_type=BlockType.FUNCTION,\n            parent_id=parent_id,\n        )\n        self.function_attributes = FunctionSpecificAttributes(\n            function_name=function_name,\n            docstring=None,\n            decorators=None,\n            parameters=None,\n            is_method=False,\n            is_async=False,\n            returns=None,\n        )\n\n    def set_parameters_list(\n        self, parameter_list_model: ParameterListModel | None\n    ) -> \"FunctionModelBuilder\":\n        \"\"\"Adds a parameter to the function model.\"\"\"\n        self.function_attributes.parameters = parameter_list_model\n        return self\n\n    def set_decorators(\n        self, decorators: list[DecoratorModel] | None\n    ) -> \"FunctionModelBuilder\":\n        \"\"\"Adds decorator to the decorators list in the class model.\"\"\"\n        if decorators:\n            self.function_attributes.decorators = decorators\n        else:\n            self.function_attributes.decorators = None\n        return self\n\n    def set_docstring(self, docstring: str | None) -> \"FunctionModelBuilder\":\n        \"\"\"Sets the docstring.\"\"\"\n        self.function_attributes.docstring = docstring\n        return self\n\n    def set_return_annotation(self, return_type: str) -> \"FunctionModelBuilder\":\n        \"\"\"Sets the return type.\"\"\"\n        self.function_attributes.returns = return_type\n        return self\n\n    def set_is_method(self, is_method: bool) -> \"FunctionModelBuilder\":\n        \"\"\"Sets the is_method attribute in the function model.\"\"\"\n        self.function_attributes.is_method = is_method\n        return self\n\n    def set_is_async(self, is_async: bool) -> \"FunctionModelBuilder\":\n        \"\"\"Sets the is_async attribute in the function model.\"\"\"\n        self.function_attributes.is_async = is_async\n        return self\n\n    def _get_function_specific_attributes(self) -> dict[str, Any]:\n        \"\"\"\n        Gets the function specific attributes from the builder.\n        \"\"\"\n        return self.function_attributes.model_dump()\n\n    @logging_decorator(message=\"Building function model\")\n    def build(self) -> FunctionModel:\n        \"\"\"Builds and returns the function model instance after building and setting the children models.\"\"\"\n        self.build_and_set_children()\n        return FunctionModel(\n            **self._get_common_attributes(),\n            **self._get_function_specific_attributes(),\n        )\n\n, \nImported code block (postcode:python_parser:model_builders:base_model_builder.py__*__MODULE) code content:\nfrom __future__ import annotations\n\nfrom typing import TYPE_CHECKING, Any, Union\nfrom abc import ABC, abstractmethod\n\nfrom postcode.models.models import (\n    BaseCodeBlockModel,\n    CommentModel,\n    ImportModel,\n    DependencyModel,\n    BlockType,\n)\n\n\nif TYPE_CHECKING:\n    from postcode.python_parser.model_builders.class_model_builder import (\n        ClassModelBuilder,\n    )\n    from postcode.python_parser.model_builders.function_model_builder import (\n        FunctionModelBuilder,\n    )\n    from postcode.python_parser.model_builders.module_model_builder import (\n        ModuleModelBuilder,\n    )\n    from postcode.python_parser.model_builders.standalone_block_model_builder import (\n        StandaloneBlockModelBuilder,\n    )\n\n\nclass BaseModelBuilder(ABC):\n    \"\"\"\n    Abstract base class for building models of different code blocks.\n\n    This class follows the builder pattern, providing a structured approach to constructing models for various types of code blocks (like modules, classes, functions). It defines common attributes and methods used across all specific model builders.\n\n    Attributes:\n        id (str): The unique identifier for the code block.\n        children_builders (list[Union[ClassModelBuilder, FunctionModelBuilder, StandaloneBlockModelBuilder]]):\n            A list of builders for the children code blocks.\n        common_attributes (BaseCodeBlockModel): An instance containing common attributes shared across different code block models.\n\n    Example:\n        # This example demonstrates how a derived builder might be initialized and used.\n        >>> class SomeModelBuilder(BaseModelBuilder):\n                def build(self):\n                    # Building logic specific to 'SomeModelBuilder'\n                    pass\n        >>> builder = SomeModelBuilder(id='123', block_type=BlockType.CLASS, parent_id='root')\n        >>> builder.set_start_line_num(1).set_end_line_num(10)\n        # Sets the start and end line numbers for the code block.\n    \"\"\"\n\n    def __init__(\n        self, *, id: str, block_type: BlockType, parent_id: str | None\n    ) -> None:\n        self.id: str = id\n        self.children_builders: list[\n            ClassModelBuilder | FunctionModelBuilder | StandaloneBlockModelBuilder\n        ] = []\n\n        self.common_attributes = BaseCodeBlockModel(\n            id=id,\n            parent_id=parent_id,\n            block_type=block_type,\n            start_line_num=0,\n            end_line_num=0,\n            code_content=\"\",\n            important_comments=None,\n            children=None,\n            dependencies=None,\n            summary=None,\n        )\n\n    def set_start_line_num(\n        self, line_num: int\n    ) -> Union[\n        \"BaseModelBuilder\",\n        \"ModuleModelBuilder\",\n        \"ClassModelBuilder\",\n        \"FunctionModelBuilder\",\n    ]:\n        \"\"\"Sets the start line number of the code block model instance.\"\"\"\n        self.common_attributes.start_line_num = line_num\n        return self\n\n    def set_end_line_num(\n        self, line_num: int\n    ) -> Union[\n        \"BaseModelBuilder\",\n        \"ModuleModelBuilder\",\n        \"ClassModelBuilder\",\n        \"FunctionModelBuilder\",\n    ]:\n        \"\"\"Sets the end line number of the code block model instance.\"\"\"\n        self.common_attributes.end_line_num = line_num\n        return self\n\n    def set_code_content(\n        self, code_content: str\n    ) -> Union[\n        \"BaseModelBuilder\",\n        \"ModuleModelBuilder\",\n        \"ClassModelBuilder\",\n        \"FunctionModelBuilder\",\n    ]:\n        \"\"\"Adds the string containing the content of the code block to the model instance.\"\"\"\n        self.common_attributes.code_content = code_content\n        return self\n\n    def add_important_comment(\n        self, comment: CommentModel\n    ) -> Union[\n        \"BaseModelBuilder\",\n        \"ModuleModelBuilder\",\n        \"ClassModelBuilder\",\n        \"FunctionModelBuilder\",\n    ]:\n        \"\"\"Adds an important comment to the model instance.\"\"\"\n        if not self.common_attributes.important_comments:\n            self.common_attributes.important_comments = []\n        self.common_attributes.important_comments.append(comment)\n        return self\n\n    def add_summary(\n        self, summary: str\n    ) -> Union[\n        \"BaseModelBuilder\",\n        \"ModuleModelBuilder\",\n        \"ClassModelBuilder\",\n        \"FunctionModelBuilder\",\n    ]:\n        \"\"\"Adds a summary to the model instance.\"\"\"\n        self.common_attributes.summary = summary\n        # print(f\"Added summary to {self.common_attributes.id}\")\n        return self\n\n    def add_child(\n        self,\n        child: Union[\n            \"ClassModelBuilder\", \"FunctionModelBuilder\", StandaloneBlockModelBuilder\n        ],\n    ) -> Union[\n        \"BaseModelBuilder\",\n        \"ModuleModelBuilder\",\n        \"ClassModelBuilder\",\n        \"FunctionModelBuilder\",\n    ]:\n        \"\"\"Adds a child code block to the model instance.\"\"\"\n        self.children_builders.append(child)\n        return self\n\n    def set_dependencies(\n        self, dependencies: list[ImportModel | DependencyModel] | None\n    ) -> Union[\n        \"BaseModelBuilder\",\n        \"ModuleModelBuilder\",\n        \"ClassModelBuilder\",\n        \"FunctionModelBuilder\",\n    ]:\n        \"\"\"Sets the dependencies of the model instance.\"\"\"\n        self.common_attributes.dependencies = dependencies\n        return self\n\n    def update_import_dependency(\n        self,\n        new_import_model: ImportModel,\n        old_import_model: ImportModel,\n    ) -> Union[\n        \"BaseModelBuilder\",\n        \"ModuleModelBuilder\",\n        \"ClassModelBuilder\",\n        \"FunctionModelBuilder\",\n    ]:\n        \"\"\"\n        Updates an import in the model instance.\n\n        Args:\n            new_import_model (ImportModel): The updated import model.\n            old_import_model\n\n        Returns:\n            BaseModelBuilder: The base model builder instance.\n        \"\"\"\n\n        if self.common_attributes.dependencies:\n            import_model_to_remove: ImportModel | None = None\n            for existing_import_model in self.common_attributes.dependencies:\n                if isinstance(existing_import_model, DependencyModel):\n                    continue\n\n                if (\n                    existing_import_model.import_names == old_import_model.import_names\n                    and existing_import_model.imported_from\n                    == old_import_model.imported_from\n                    and existing_import_model.import_module_type\n                    == old_import_model.import_module_type\n                ):\n                    import_model_to_remove = existing_import_model\n                    break\n\n            if not import_model_to_remove:\n                raise Exception(f\"Could not find import to remove: {old_import_model}\")\n\n            self.common_attributes.dependencies.remove(import_model_to_remove)\n            self.common_attributes.dependencies.append(new_import_model)\n        else:\n            raise Exception(\n                f\"No imports in the builders imports list: {self.common_attributes.dependencies}\"\n            )\n        return self\n\n    def build_and_set_children(self) -> None:\n        if self.children_builders:\n            self.common_attributes.children = [\n                child.build() for child in self.children_builders\n            ]\n\n    def _get_common_attributes(self) -> dict[str, Any]:\n        \"\"\"\n        Returns a dictionary containing the attributes common to all code block models.\n        \"\"\"\n        return self.common_attributes.model_dump()\n\n    @abstractmethod\n    def build(\n        self,\n    ) -> None:\n        \"\"\"\n        Builds and returns the code block model instance.\n\n        Returns:\n            CodeBlockModel: The built code block model instance.\n        \"\"\"\n        ...\n\n\nImported code block (postcode:utilities:logger:decorators.py__*__MODULE) code content:\nfrom functools import wraps\nimport inspect\nfrom inspect import FrameInfo\nimport logging\nfrom logging import LogRecord, Logger\nfrom typing import Callable\nimport libcst\n\n\nimport postcode.python_parser.visitors.node_processing.common_functions as common_functions\nfrom postcode.utilities.processing_context import LoggingCallerInfo, NodeAndPositionData\n\n\ndef logging_decorator(\n    level=logging.DEBUG,\n    *,\n    message: str | None = None,\n    syntax_highlighting: bool = False,\n) -> Callable:\n    \"\"\"\n    A decorator for adding enhanced logging to functions, with optional syntax highlighting.\n\n    This decorator logs the call to the decorated function at the specified logging level. If syntax_highlighting is enabled and the first argument of the function is a libcst.CSTNode, the decorator logs the node's content with syntax highlighting.\n\n    Args:\n        level (int): The logging level. Defaults to logging.DEBUG.\n        message (str | None): Custom log message. If None, a default message is generated.\n        syntax_highlighting (bool): If True, enables syntax highlighting for libcst.CSTNode arguments.\n\n    Returns:\n        Callable: The decorated function with enhanced logging capability.\n\n    Example:\n        >>> @logging_decorator(level=logging.INFO, message=\"Function start\", syntax_highlighting=True)\n        >>> def sample_function(arg1):\n        >>>     pass\n        # This decorates 'sample_function' with enhanced logging at INFO level.\n    \"\"\"\n\n    def decorator(func):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            log_message: str = (\n                message if message else (f\"Calling function: {func.__name__}\")\n            )\n            frame_info: inspect.FrameInfo = inspect.stack()[1]\n            caller_info: LoggingCallerInfo = _get_caller_info(frame_info)\n            code_content: str = _gather_code_content(syntax_highlighting, args)\n            logger: Logger = _get_logger(caller_info.caller_module_name)\n\n            _handle_logging(\n                logger,\n                caller_info,\n                level,\n                log_message,\n                syntax_highlighting,\n                code_content,\n            )\n\n            return func(*args, **kwargs)\n\n        return wrapper\n\n    return decorator\n\n\ndef _gather_log_record_context(\n    caller_info: LoggingCallerInfo, level: int, msg: str\n) -> logging.LogRecord:\n    \"\"\"Creates and returns a LogRecord with specified context information.\"\"\"\n\n    return logging.LogRecord(\n        name=caller_info.caller_module_name,\n        level=level,\n        pathname=caller_info.caller_file_path,\n        lineno=caller_info.caller_line_no,\n        msg=msg,\n        args=None,\n        exc_info=None,\n    )\n\n\ndef _get_caller_info(frame_info: FrameInfo) -> LoggingCallerInfo:\n    \"\"\"Extracts and returns caller information from a frame object.\"\"\"\n\n    caller_module_name: str = frame_info.filename.split(\"/\")[-1].split(\".\")[0]\n    caller_file_path: str = frame_info.filename\n    caller_line_no: int = frame_info.lineno\n    return LoggingCallerInfo(caller_module_name, caller_file_path, caller_line_no)\n\n\ndef _get_logger(caller_module_name: str) -> Logger:\n    \"\"\"Retrieves and returns a Logger instance for the specified module name.\"\"\"\n\n    return logging.getLogger(caller_module_name)\n\n\ndef _gather_code_content(syntax_highlighting: bool, args: tuple) -> str:\n    \"\"\"Gathers and returns code content for logging, if `syntax_highlighting` else returns empty string.\"\"\"\n\n    if not syntax_highlighting or not args:\n        return \"\"\n\n    arg_0 = args[0]\n    content: str = \"\"\n\n    if isinstance(arg_0, libcst.CSTNode):\n        content = common_functions.extract_code_content(arg_0)\n    elif isinstance(arg_0, list) and all(\n        isinstance(node, libcst.CSTNode) for node in arg_0\n    ):\n        content = \"\\n\".join(\n            common_functions.extract_stripped_code_content(node) for node in arg_0\n        )\n    elif isinstance(arg_0, NodeAndPositionData):\n        content = \"\\n\".join(\n            common_functions.extract_stripped_code_content(node) for node in arg_0.nodes\n        )\n\n    return content\n\n\ndef _handle_syntax_highlighting(\n    syntax_highlighting: bool,\n    log_record: logging.LogRecord,\n    logger: Logger,\n    content: str,\n) -> None:\n    \"\"\"Handles syntax highlighting for the log record if enabled.\"\"\"\n\n    if syntax_highlighting:\n        log_record.syntax_highlight = syntax_highlighting\n        log_record.content = content\n        logger.handle(log_record)\n\n\ndef _handle_logging(\n    logger: Logger,\n    caller_info: LoggingCallerInfo,\n    level: int,\n    log_message: str,\n    syntax_highlighting: bool,\n    code_content: str,\n) -> None:\n    \"\"\"Handles the logging process, including the creation and handling of log records.\"\"\"\n\n    if logger.isEnabledFor(level):\n        log_record: LogRecord = _gather_log_record_context(\n            caller_info, level, log_message\n        )\n        logger.handle(log_record)  # Print log message\n        _handle_syntax_highlighting(\n            syntax_highlighting, log_record, logger, code_content\n        )\n\n\nImported code block (postcode:models:models.py__*__MODULE) code content:\nfrom typing import Union\nfrom pydantic import BaseModel, Field, validator\n\nfrom postcode.models.enums import (\n    BlockType,\n    ImportModuleType,\n    CommentType,\n)\n\n\nclass ImportNameModel(BaseModel):\n    \"\"\"Class representing the name of an import.\"\"\"\n\n    name: str\n    as_name: str | None = None\n    local_block_id: str | None = None\n\n    # def convert_import_names_to_metadata(self) -> str:\n    #     \"\"\"Converts the import name to a metadata string.\"\"\"\n\n    #     return self.model_dump_json()\n\n\nclass ImportModel(BaseModel):\n    \"\"\"Class representing an import statement.\"\"\"\n\n    import_names: list[ImportNameModel]\n    imported_from: str | None = None\n    import_module_type: ImportModuleType = ImportModuleType.STANDARD_LIBRARY\n    local_module_id: str | None = None\n\n    def convert_import_to_metadata(self) -> str:\n        \"\"\"Converts the import to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass DependencyModel(BaseModel):\n    \"\"\"Class representing a module dependency.\"\"\"\n\n    code_block_id: str\n\n    def convert_dependency_to_metadata(self) -> str:\n        \"\"\"Converts the dependency to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass CommentModel(BaseModel):\n    \"\"\"Class representing a comment.\"\"\"\n\n    content: str\n    comment_types: list[CommentType]\n\n    def convert_comment_to_metadata(self) -> str:\n        \"\"\"Converts the comment to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass DecoratorModel(BaseModel):\n    \"\"\"Class representing a decorator.\"\"\"\n\n    content: str\n    decorator_name: str\n    decorator_args: list[str] | None = None\n\n    def convert_decorator_to_metadata(self) -> str:\n        \"\"\"Converts the decorator to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass ClassKeywordModel(BaseModel):\n    \"\"\"Class representing a class keyword.\"\"\"\n\n    content: str\n    keyword_name: str\n    args: str | None = None\n\n    def convert_class_keyword_to_metadata(self) -> str:\n        \"\"\"Converts the class keyword to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass ParameterModel(BaseModel):\n    \"\"\"Class representing a function parameter.\"\"\"\n\n    content: str\n\n\nclass ParameterListModel(BaseModel):\n    \"\"\"Class representing a list of parameters.\"\"\"\n\n    params: list[ParameterModel] | None = None\n    star_arg: ParameterModel | None = None\n    kwonly_params: list[ParameterModel] | None = None\n    star_kwarg: ParameterModel | None = None\n    posonly_params: list[ParameterModel] | None = None\n\n    def convert_parameters_to_metadata(self) -> str:\n        \"\"\"Converts the parameter list to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass BaseCodeBlockModel(BaseModel):\n    \"\"\"Attributes common to all code block models.\"\"\"\n\n    id: str\n    parent_id: str | None = None\n    block_type: BlockType\n    start_line_num: int\n    end_line_num: int\n    code_content: str = \"\"\n    important_comments: list[CommentModel] | None = None\n    dependencies: list[ImportModel | DependencyModel] | None = None\n    summary: str | None = None\n    children: list[\n        Union[\n            \"ClassModel\",\n            \"FunctionModel\",\n            \"StandaloneCodeBlockModel\",\n        ]\n    ] | None = []\n\n    @validator(\"parent_id\", always=True)\n    def check_parent_id(cls, v, values, **kwargs) -> str | None:\n        \"\"\"Validates that parent_id is a non-empty string unless block_type is MODULE.\"\"\"\n\n        if \"block_type\" in values and values[\"block_type\"] != BlockType.MODULE:\n            if len(v) < 1:\n                raise ValueError(\"parent_id is required!\")\n        return v\n\n    def _convert_parent_id_to_metadata(self) -> str:\n        \"\"\"Converts the parent_id to a metadata string.\"\"\"\n        return f\"{self.parent_id}\" if self.parent_id else \"\"\n\n    def _convert_block_type_to_metadata(self) -> str:\n        \"\"\"Converts the block_type to a metadata string.\"\"\"\n        return f\"{self.block_type.name}\"\n\n    def _convert_important_comments_to_metadata(self) -> str:\n        \"\"\"Converts the important comments to a metadata string.\"\"\"\n\n        important_comments: str = (\n            self.model_dump_json() if self.important_comments else \"\"\n        )\n\n        return f\"{important_comments}\"\n\n    def _convert_dependencies_to_metadata(self) -> str:\n        \"\"\"Converts the dependencies to a metadata string.\"\"\"\n\n        dependencies_str: str = \"\"\n\n        if self.dependencies:\n            for dependency in self.dependencies:\n                if isinstance(dependency, ImportModel):\n                    dependencies_str += f\"{dependency.convert_import_to_metadata()}\\n\"\n                elif isinstance(dependency, DependencyModel):\n                    dependencies_str += (\n                        f\"{dependency.convert_dependency_to_metadata()}\\n\"\n                    )\n\n        return dependencies_str\n\n    def _convert_summary_to_metadata(self) -> str:\n        \"\"\"Converts the summary to a metadata string.\"\"\"\n        return f\"{self.summary}\" if self.summary else \"\"\n\n    def _convert_children_to_metadata(self) -> str:\n        \"\"\"Converts the children to a metadata string.\"\"\"\n\n        children_str: str = \"\"\n\n        if self.children:\n            for child in self.children:\n                children_str += f\"{child.id}\\n\"\n\n        return children_str\n\n    def _convert_base_attributes_to_metadata_dict(self) -> dict[str, str | int]:\n        \"\"\"Converts the base attributes to a metadata dictionary.\"\"\"\n\n        return {\n            \"id\": self.id,\n            \"parent_id\": self._convert_parent_id_to_metadata(),\n            \"block_type\": self._convert_block_type_to_metadata(),\n            \"start_line_num\": self.start_line_num,\n            \"end_line_num\": self.end_line_num,\n            \"code_content\": self.code_content,\n            \"important_comments\": self._convert_important_comments_to_metadata(),\n            \"dependencies\": self._convert_dependencies_to_metadata(),\n            \"summary\": self._convert_summary_to_metadata(),\n            \"children\": self._convert_children_to_metadata(),\n        }\n\n\nclass ModuleSpecificAttributes(BaseModel):\n    \"\"\"Module specific attributes.\"\"\"\n\n    file_path: str = Field(min_length=1)\n    docstring: str | None = None\n    header: list[str] | None = None\n    footer: list[str] | None = None\n    imports: list[ImportModel] | None = None\n\n    def _convert_docstring_to_metadata(self) -> str:\n        \"\"\"Converts the docstring to a metadata string.\"\"\"\n        return f\"{self.docstring}\"\n\n    def _convert_header_to_metadata(self) -> str:\n        \"\"\"Converts the header and footer to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n    def _convert_footer_to_metadata(self) -> str:\n        \"\"\"Converts the header and footer to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n    def _convert_imports_to_metadata(self) -> str:\n        \"\"\"Converts the imports to a metadata string.\"\"\"\n        imports_str: str = self.model_dump_json() if self.imports else \"\"\n        return f\"{imports_str}\"\n\n    def _convert_module_attributes_to_metadata_dict(self) -> dict[str, str | int]:\n        \"\"\"Converts the module attributes to a metadata dictionary.\"\"\"\n\n        return {\n            \"file_path\": self.file_path,\n            \"docstring\": self._convert_docstring_to_metadata(),\n            \"header\": self._convert_header_to_metadata(),\n            \"footer\": self._convert_footer_to_metadata(),\n            \"imports\": self._convert_imports_to_metadata(),\n        }\n\n\nclass ModuleModel(BaseCodeBlockModel, ModuleSpecificAttributes):\n    \"\"\"Model for a module.\"\"\"\n\n    def convert_to_metadata(self) -> dict[str, str | int]:\n        \"\"\"Converts the module model to a metadata dictionary.\"\"\"\n\n        return {\n            **self._convert_base_attributes_to_metadata_dict(),\n            **self._convert_module_attributes_to_metadata_dict(),\n        }\n\n\nclass ClassSpecificAttributes(BaseModel):\n    \"\"\"Class specific attributes.\"\"\"\n\n    class_name: str = Field(min_length=1)\n    decorators: list[DecoratorModel] | None = None\n    bases: list[str] | None = None\n    docstring: str | None = None\n    keywords: list[ClassKeywordModel] | None = None\n    # attributes: list[dict] | None = None\n\n    def _convert_decorators_to_metadata(self) -> str:\n        \"\"\"Converts the decorators to a metadata string.\"\"\"\n        decorators_str: str = self.model_dump_json() if self.decorators else \"\"\n        return f\"{decorators_str}\"\n\n    def _convert_bases_to_metadata(self) -> str:\n        \"\"\"Converts the bases to a metadata string.\"\"\"\n        return self.model_dump_json() if self.bases else \"\"\n\n    def _convert_docstring_to_metadata(self) -> str:\n        \"\"\"Converts the docstring to a metadata string.\"\"\"\n        return f\"{self.docstring}\" if self.docstring else \"\"\n\n    def _convert_keywords_to_metadata(self) -> str:\n        \"\"\"Converts the keywords to a metadata string.\"\"\"\n        keywords_str: str = self.model_dump_json() if self.keywords else \"\"\n        return f\"{keywords_str}\"\n\n    def _convert_class_attributes_to_metadata_dict(self) -> dict[str, str | int]:\n        \"\"\"Converts the class attributes to a metadata dictionary.\"\"\"\n\n        return {\n            \"class_name\": self.class_name,\n            \"decorators\": self._convert_decorators_to_metadata(),\n            \"bases\": self._convert_bases_to_metadata(),\n            \"docstring\": self._convert_docstring_to_metadata(),\n            \"keywords\": self._convert_keywords_to_metadata(),\n        }\n\n\nclass ClassModel(BaseCodeBlockModel, ClassSpecificAttributes):\n    \"\"\"Model for a class.\"\"\"\n\n    def convert_to_metadata(self) -> dict[str, str | int]:\n        \"\"\"Converts the class model to a metadata dictionary.\"\"\"\n        return {\n            **self._convert_base_attributes_to_metadata_dict(),\n            **self._convert_class_attributes_to_metadata_dict(),\n        }\n\n\nclass FunctionSpecificAttributes(BaseModel):\n    \"\"\"Function specific attributes.\"\"\"\n\n    function_name: str = Field(min_length=1)\n    docstring: str | None = None\n    decorators: list[DecoratorModel] | None = None\n    parameters: ParameterListModel | None = None\n    returns: str | None = None\n    is_method: bool = False\n    is_async: bool = False\n\n    def _convert_docstring_to_metadata(self) -> str:\n        \"\"\"Converts the docstring to a metadata string.\"\"\"\n        return f\"{self.docstring}\" if self.docstring else \"\"\n\n    def _convert_decorators_to_metadata(self) -> str:\n        \"\"\"Converts the decorators to a metadata string.\"\"\"\n        decorators_str: str = self.model_dump_json() if self.decorators else \"\"\n        return f\"{decorators_str}\"\n\n    def _convert_parameters_to_metadata(self) -> str:\n        \"\"\"Converts the parameters to a metadata string.\"\"\"\n        return (\n            self.parameters.convert_parameters_to_metadata() if self.parameters else \"\"\n        )\n\n    def _convert_returns_to_metadata(self) -> str:\n        \"\"\"Converts the returns to a metadata string.\"\"\"\n        return f\"{self.returns}\" if self.returns else \"\"\n\n    def _convert_function_attributes_to_metadata_dict(self) -> dict[str, str | bool]:\n        \"\"\"Converts the function attributes to a metadata dictionary.\"\"\"\n\n        return {\n            \"function_name\": self.function_name,\n            \"docstring\": self._convert_docstring_to_metadata(),\n            \"decorators\": self._convert_decorators_to_metadata(),\n            \"parameters\": self._convert_parameters_to_metadata(),\n            \"returns\": self._convert_returns_to_metadata(),\n            \"is_method\": self.is_method,\n            \"is_async\": self.is_async,\n        }\n\n\nclass FunctionModel(BaseCodeBlockModel, FunctionSpecificAttributes):\n    \"\"\"Model for a function.\"\"\"\n\n    def convert_to_metadata(self) -> dict[str, str | int]:\n        \"\"\"Converts the function model to a metadata dictionary.\"\"\"\n\n        return {\n            **self._convert_base_attributes_to_metadata_dict(),\n            **self._convert_function_attributes_to_metadata_dict(),\n        }\n\n\nclass StandaloneCodeBlockSpecificAttributes(BaseModel):\n    \"\"\"Standalone code block specific attributes.\"\"\"\n\n    variable_assignments: list[str] | None = None\n\n    def _convert_variable_assignments_to_metadata(self) -> str:\n        \"\"\"Converts the variable assignments to a metadata string.\"\"\"\n        return self.model_dump_json() if self.variable_assignments else \"\"\n\n    def _convert_standalone_block_attributes_to_metadata_dict(\n        self,\n    ) -> dict[str, str | int]:\n        \"\"\"Converts the standalone code block attributes to a metadata dictionary.\"\"\"\n        return {\n            \"variable_assignments\": self._convert_variable_assignments_to_metadata(),\n        }\n\n\nclass StandaloneCodeBlockModel(\n    BaseCodeBlockModel, StandaloneCodeBlockSpecificAttributes\n):\n    \"\"\"Model for a standalone code block.\"\"\"\n\n    def convert_to_metadata(self) -> dict[str, str | int]:\n        \"\"\"Converts the standalone code block model to a metadata dictionary.\"\"\"\n\n        return {\n            **self._convert_base_attributes_to_metadata_dict(),\n            **self._convert_standalone_block_attributes_to_metadata_dict(),\n        }\n\n\nImported code block (postcode:models:enums.py__*__MODULE) code content:\nfrom enum import Enum\n\n\nclass ImportModuleType(str, Enum):\n    \"\"\"Enum of import module types.\"\"\"\n\n    STANDARD_LIBRARY = \"STANDARD_LIBRARY\"\n    LOCAL = \"LOCAL\"\n    THIRD_PARTY = \"THIRD_PARTY\"\n\n    def __str__(self) -> str:\n        return self.value\n\n\nclass CommentType(str, Enum):\n    \"\"\"Class representing the different types of important comments.\"\"\"\n\n    TODO = \"TODO\"\n    FIXME = \"FIXME\"\n    NOTE = \"NOTE\"\n    HACK = \"HACK\"\n    XXX = \"XXX\"\n    REVIEW = \"REVIEW\"\n    OPTIMIZE = \"OPTIMIZE\"\n    CHANGED = \"CHANGED\"\n    QUESTION = \"QUESTION\"\n    Q = \"Q\"\n    DEPRECATED = \"@deprecated\"\n    NOSONAR = \"NOSONAR\"\n    TODO_FIXME = \"TODO-FIXME\"\n\n    def __str__(self) -> str:\n        return self.value\n\n\nclass BlockType(str, Enum):\n    \"\"\"Enum of code block types.\"\"\"\n\n    STANDALONE_CODE_BLOCK = \"STANDALONE_BLOCK\"\n    CLASS = \"CLASS\"\n    FUNCTION = \"FUNCTION\"\n    MODULE = \"MODULE\"\n\n    def __str__(self) -> str:\n        return self.value\n\n, \nfrom typing import Any\n        "}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        c_persistent://default/default/e1c51cbe-072e-4965-8f8f-e05bc2d7a03fpostcode:updaters:git_updater.py__*__MODULE9sjqiT4=r<
{{Y< K=A=Rc<?4<} x:x=7!v=3v=w><*\=Qmxl:R=N=	=H<0=a=dEx={5jA=
7&{z<*Bt;Uzh=QE\<=_=>B=<'<?h_F<=><
"7B=<g[=U'J&<;:`==J+nVN;HR<e5=w>jx=a===< .=U@%}* F-<
|0=v<Yh<#i= =D=`OZ=|l4F2W=<"n<$=v=D=B><#PXJH4=g	=	={JD=	=f'=j=, S'/j=PV5<j^<u=&1:4<)~N<1=1V{$:7;i;{<}Jzxz$96,xE<=8qX>dV=$|E<=<=2<K61]0B|!P=B==.w+<h,<<`=#<x`<ttcN=I(0/w;aSO 5V)<@<;Z`=;=(=dd=<0~t=%w<<7Uqa[@)"<Y|`=a<R=C,;@4:r;=}=q=ZEJl=&aP=r<;#1NN(<7=n{<|=PP?<=?DD=XN=Nx=.!==:Hy=v4;O=@$(U}n<4|yV<L=]_J3d<yQ,=$Ew7w5=d)W^-Yi"=e~!=vvMVAH<T/<`=apB=7g=4_<:<^uo;yUQ<$;?
<;K<RP=x%=6<;*!<o%+;s QS $z=47J8<U
<PC=) <wPu1==	mcg>xtGmt<=vH<oD=<Q==>Vm
M<RDv0;C	?"H^<=I4\<$=J[F=LJ=|@M<FLOAT32{"id": "postcode:updaters:git_updater.py__*__MODULE", "parent_id": "", "block_type": "MODULE", "start_line_num": 1, "end_line_num": 114, "code_content": "import subprocess\n\n\nclass UpdateUsingGit:\n    \"\"\"\n    DO NOT USE: The necessary functionality for this class is not yet implemented.\n\n    A class that provides methods to get the names of the Python modules that have been changed using on version control.\n\n    Use this class to get all the file names for the Python modules that have been changes since the last commit or since\n    a specific commit. You can get the `commit_hash` for a specific commit by going to the commit on GitHub and copying\n    the hash from the URL. For example, the commit hash for the following commit is `e8856d2`, or you can use the terminal, for\n    instance: `git log --author=\"username\" --grep=\"commit message\" --format=\"%H\"` if you know all the details of the commit.\n\n    Methods:\n        - `get_module_names_updated_since_last_commit()`: Returns a list of the modules that have been changed since the last commit.\n        - `get_module_names_updated_since_commit(commit_hash: str)`: Returns a list of the modules that have been changed since the specified commit.\n\n    Examples:\n        ```Python\n        from postcode.updaters.git_updater import UpdateUsingGit\n\n        # Get the names of the modules that have been changed since the last commit\n        changed_modules_name_list = UpdateUsingGit.get_module_names_updated_since_last_commit()\n        ```\n    \"\"\"\n\n    @staticmethod\n    def get_module_names_updated_since_last_commit() -> list[str]:\n        \"\"\"\n        Returns a list of the modules that have been changed since the last commit.\n\n        Runs the following command using subprocess:\n            (git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\n\n        Returns:\n            - list[str]: A list of the modules that have been changed since the last commit.\n\n        Raises:\n            - Exception: If the git command fails.\n        \"\"\"\n\n        git_command = \"(git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\"\n\n        result: subprocess.CompletedProcess[str] = subprocess.run(\n            git_command, shell=True, capture_output=True, text=True\n        )\n        if result.returncode != 0:\n            raise Exception(\"Git command failed: \" + result.stderr)\n\n        changed_files: list[str] = result.stdout.strip().split(\"\\n\")\n\n        return [file for file in changed_files if file.endswith(\".py\")]\n\n    @staticmethod\n    def get_module_names_updated_since_commit(commit_hash: str) -> list[str]:\n        \"\"\"\n        Returns a list of the Python modules that have been changed since the specified commit.\n\n        Args:\n            - commit (str): The commit hash or reference to compare the current state against.\n\n        Runs the following command using subprocess:\n            (git ls-files --others --exclude-standard; git diff --name-only COMMIT) | sort | uniq\n\n        Returns:\n            - list[str]: A list of the modules that have been changed since the specified commit.\n\n        Raises:\n            - Exception: If the git command fails.\n        \"\"\"\n\n        git_command = f\"(git ls-files --others --exclude-standard; git diff --name-only {commit_hash}) | sort | uniq\"\n\n        result: subprocess.CompletedProcess[str] = subprocess.run(\n            git_command, shell=True, capture_output=True, text=True\n        )\n        if result.returncode != 0:\n            raise Exception(\"Git command failed: \" + result.stderr)\n\n        changed_files: list[str] = result.stdout.strip().split(\"\\n\")\n\n        return [file for file in changed_files if file.endswith(\".py\")]\n\n    @staticmethod\n    def __get_updated_modules(directory: str | None = None) -> list[str]:\n        \"\"\"\n        DO NOT USE: The necessary functionality for this method is not yet implemented.\n\n        Returns a list of the modules that have been changed since the last commit based on a directory path.\n        \"\"\"\n        git_ls_files_cmd = \"git ls-files --others --exclude-standard\"\n        git_diff_cmd = \"git diff --name-only HEAD\"\n\n        if directory:\n            git_ls_files_cmd += f\" '{directory}'\"\n            git_diff_cmd += f\" '{directory}'\"\n\n        git_command: str = f\"({git_ls_files_cmd}; {git_diff_cmd}) | sort | uniq\"\n\n        result: subprocess.CompletedProcess[str] = subprocess.run(\n            git_command, shell=True, capture_output=True, text=True\n        )\n        if result.returncode != 0:\n            raise Exception(\"Git command failed: \" + result.stderr)\n\n        changed_files: list[str] = result.stdout.strip().split(\"\\n\")\n\n        return [file for file in changed_files if file.endswith(\".py\")]\n\n\nif __name__ == \"__main__\":\n    print(UpdateUsingGit.get_module_names_updated_since_commit(\"e8856d2\"))\n", "important_comments": "", "dependencies": "", "summary": "\nSummary:\n\n        postcode:updaters:git_updater.py__*__MODULE\n\n        \nChild (postcode:updaters:git_updater.py__*__MODULE__*__STANDALONE_BLOCK-1) code content:\nif __name__ == \"__main__\":\n    print(UpdateUsingGit.get_module_names_updated_since_commit(\"e8856d2\"))\n\n\nChild (postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit) code content:\n\n\nclass UpdateUsingGit:\n    \"\"\"\n    DO NOT USE: The necessary functionality for this class is not yet implemented.\n\n    A class that provides methods to get the names of the Python modules that have been changed using on version control.\n\n    Use this class to get all the file names for the Python modules that have been changes since the last commit or since\n    a specific commit. You can get the `commit_hash` for a specific commit by going to the commit on GitHub and copying\n    the hash from the URL. For example, the commit hash for the following commit is `e8856d2`, or you can use the terminal, for\n    instance: `git log --author=\"username\" --grep=\"commit message\" --format=\"%H\"` if you know all the details of the commit.\n\n    Methods:\n        - `get_module_names_updated_since_last_commit()`: Returns a list of the modules that have been changed since the last commit.\n        - `get_module_names_updated_since_commit(commit_hash: str)`: Returns a list of the modules that have been changed since the specified commit.\n\n    Examples:\n        ```Python\n        from postcode.updaters.git_updater import UpdateUsingGit\n\n        # Get the names of the modules that have been changed since the last commit\n        changed_modules_name_list = UpdateUsingGit.get_module_names_updated_since_last_commit()\n        ```\n    \"\"\"\n\n    @staticmethod\n    def get_module_names_updated_since_last_commit() -> list[str]:\n        \"\"\"\n        Returns a list of the modules that have been changed since the last commit.\n\n        Runs the following command using subprocess:\n            (git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\n\n        Returns:\n            - list[str]: A list of the modules that have been changed since the last commit.\n\n        Raises:\n            - Exception: If the git command fails.\n        \"\"\"\n\n        git_command = \"(git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\"\n\n        result: subprocess.CompletedProcess[str] = subprocess.run(\n            git_command, shell=True, capture_output=True, text=True\n        )\n        if result.returncode != 0:\n            raise Exception(\"Git command failed: \" + result.stderr)\n\n        changed_files: list[str] = result.stdout.strip().split(\"\\n\")\n\n        return [file for file in changed_files if file.endswith(\".py\")]\n\n    @staticmethod\n    def get_module_names_updated_since_commit(commit_hash: str) -> list[str]:\n        \"\"\"\n        Returns a list of the Python modules that have been changed since the specified commit.\n\n        Args:\n            - commit (str): The commit hash or reference to compare the current state against.\n\n        Runs the following command using subprocess:\n            (git ls-files --others --exclude-standard; git diff --name-only COMMIT) | sort | uniq\n\n        Returns:\n            - list[str]: A list of the modules that have been changed since the specified commit.\n\n        Raises:\n            - Exception: If the git command fails.\n        \"\"\"\n\n        git_command = f\"(git ls-files --others --exclude-standard; git diff --name-only {commit_hash}) | sort | uniq\"\n\n        result: subprocess.CompletedProcess[str] = subprocess.run(\n            git_command, shell=True, capture_output=True, text=True\n        )\n        if result.returncode != 0:\n            raise Exception(\"Git command failed: \" + result.stderr)\n\n        changed_files: list[str] = result.stdout.strip().split(\"\\n\")\n\n        return [file for file in changed_files if file.endswith(\".py\")]\n\n    @staticmethod\n    def __get_updated_modules(directory: str | None = None) -> list[str]:\n        \"\"\"\n        DO NOT USE: The necessary functionality for this method is not yet implemented.\n\n        Returns a list of the modules that have been changed since the last commit based on a directory path.\n        \"\"\"\n        git_ls_files_cmd = \"git ls-files --others --exclude-standard\"\n        git_diff_cmd = \"git diff --name-only HEAD\"\n\n        if directory:\n            git_ls_files_cmd += f\" '{directory}'\"\n            git_diff_cmd += f\" '{directory}'\"\n\n        git_command: str = f\"({git_ls_files_cmd}; {git_diff_cmd}) | sort | uniq\"\n\n        result: subprocess.CompletedProcess[str] = subprocess.run(\n            git_command, shell=True, capture_output=True, text=True\n        )\n        if result.returncode != 0:\n            raise Exception(\"Git command failed: \" + result.stderr)\n\n        changed_files: list[str] = result.stdout.strip().split(\"\\n\")\n\n        return [file for file in changed_files if file.endswith(\".py\")]\n\n, None, \nimport subprocess\n        ", "children": "postcode:updaters:git_updater.py__*__MODULE__*__STANDALONE_BLOCK-1\npostcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit\n", "file_path": "postcode/updaters/git_updater.py", "docstring": "None", "header": "{\"file_path\":\"postcode/updaters/git_updater.py\",\"docstring\":null,\"header\":[],\"footer\":[],\"imports\":[{\"import_names\":[{\"name\":\"subprocess\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":null,\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null}],\"id\":\"postcode:updaters:git_updater.py__*__MODULE\",\"parent_id\":null,\"block_type\":\"MODULE\",\"start_line_num\":1,\"end_line_num\":114,\"code_content\":\"import subprocess\\n\\n\\nclass UpdateUsingGit:\\n    \\\"\\\"\\\"\\n    DO NOT USE: The necessary functionality for this class is not yet implemented.\\n\\n    A class that provides methods to get the names of the Python modules that have been changed using on version control.\\n\\n    Use this class to get all the file names for the Python modules that have been changes since the last commit or since\\n    a specific commit. You can get the `commit_hash` for a specific commit by going to the commit on GitHub and copying\\n    the hash from the URL. For example, the commit hash for the following commit is `e8856d2`, or you can use the terminal, for\\n    instance: `git log --author=\\\"username\\\" --grep=\\\"commit message\\\" --format=\\\"%H\\\"` if you know all the details of the commit.\\n\\n    Methods:\\n        - `get_module_names_updated_since_last_commit()`: Returns a list of the modules that have been changed since the last commit.\\n        - `get_module_names_updated_since_commit(commit_hash: str)`: Returns a list of the modules that have been changed since the specified commit.\\n\\n    Examples:\\n        ```Python\\n        from postcode.updaters.git_updater import UpdateUsingGit\\n\\n        # Get the names of the modules that have been changed since the last commit\\n        changed_modules_name_list = UpdateUsingGit.get_module_names_updated_since_last_commit()\\n        ```\\n    \\\"\\\"\\\"\\n\\n    @staticmethod\\n    def get_module_names_updated_since_last_commit() -> list[str]:\\n        \\\"\\\"\\\"\\n        Returns a list of the modules that have been changed since the last commit.\\n\\n        Runs the following command using subprocess:\\n            (git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\\n\\n        Returns:\\n            - list[str]: A list of the modules that have been changed since the last commit.\\n\\n        Raises:\\n            - Exception: If the git command fails.\\n        \\\"\\\"\\\"\\n\\n        git_command = \\\"(git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\\\"\\n\\n        result: subprocess.CompletedProcess[str] = subprocess.run(\\n            git_command, shell=True, capture_output=True, text=True\\n        )\\n        if result.returncode != 0:\\n            raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n        changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n        return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\\n    @staticmethod\\n    def get_module_names_updated_since_commit(commit_hash: str) -> list[str]:\\n        \\\"\\\"\\\"\\n        Returns a list of the Python modules that have been changed since the specified commit.\\n\\n        Args:\\n            - commit (str): The commit hash or reference to compare the current state against.\\n\\n        Runs the following command using subprocess:\\n            (git ls-files --others --exclude-standard; git diff --name-only COMMIT) | sort | uniq\\n\\n        Returns:\\n            - list[str]: A list of the modules that have been changed since the specified commit.\\n\\n        Raises:\\n            - Exception: If the git command fails.\\n        \\\"\\\"\\\"\\n\\n        git_command = f\\\"(git ls-files --others --exclude-standard; git diff --name-only {commit_hash}) | sort | uniq\\\"\\n\\n        result: subprocess.CompletedProcess[str] = subprocess.run(\\n            git_command, shell=True, capture_output=True, text=True\\n        )\\n        if result.returncode != 0:\\n            raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n        changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n        return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\\n    @staticmethod\\n    def __get_updated_modules(directory: str | None = None) -> list[str]:\\n        \\\"\\\"\\\"\\n        DO NOT USE: The necessary functionality for this method is not yet implemented.\\n\\n        Returns a list of the modules that have been changed since the last commit based on a directory path.\\n        \\\"\\\"\\\"\\n        git_ls_files_cmd = \\\"git ls-files --others --exclude-standard\\\"\\n        git_diff_cmd = \\\"git diff --name-only HEAD\\\"\\n\\n        if directory:\\n            git_ls_files_cmd += f\\\" '{directory}'\\\"\\n            git_diff_cmd += f\\\" '{directory}'\\\"\\n\\n        git_command: str = f\\\"({git_ls_files_cmd}; {git_diff_cmd}) | sort | uniq\\\"\\n\\n        result: subprocess.CompletedProcess[str] = subprocess.run(\\n            git_command, shell=True, capture_output=True, text=True\\n        )\\n        if result.returncode != 0:\\n            raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n        changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n        return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\\n\\nif __name__ == \\\"__main__\\\":\\n    print(UpdateUsingGit.get_module_names_updated_since_commit(\\\"e8856d2\\\"))\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":\"\\nSummary:\\n\\n        postcode:updaters:git_updater.py__*__MODULE\\n\\n        \\nChild (postcode:updaters:git_updater.py__*__MODULE__*__STANDALONE_BLOCK-1) code content:\\nif __name__ == \\\"__main__\\\":\\n    print(UpdateUsingGit.get_module_names_updated_since_commit(\\\"e8856d2\\\"))\\n\\n\\nChild (postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit) code content:\\n\\n\\nclass UpdateUsingGit:\\n    \\\"\\\"\\\"\\n    DO NOT USE: The necessary functionality for this class is not yet implemented.\\n\\n    A class that provides methods to get the names of the Python modules that have been changed using on version control.\\n\\n    Use this class to get all the file names for the Python modules that have been changes since the last commit or since\\n    a specific commit. You can get the `commit_hash` for a specific commit by going to the commit on GitHub and copying\\n    the hash from the URL. For example, the commit hash for the following commit is `e8856d2`, or you can use the terminal, for\\n    instance: `git log --author=\\\"username\\\" --grep=\\\"commit message\\\" --format=\\\"%H\\\"` if you know all the details of the commit.\\n\\n    Methods:\\n        - `get_module_names_updated_since_last_commit()`: Returns a list of the modules that have been changed since the last commit.\\n        - `get_module_names_updated_since_commit(commit_hash: str)`: Returns a list of the modules that have been changed since the specified commit.\\n\\n    Examples:\\n        ```Python\\n        from postcode.updaters.git_updater import UpdateUsingGit\\n\\n        # Get the names of the modules that have been changed since the last commit\\n        changed_modules_name_list = UpdateUsingGit.get_module_names_updated_since_last_commit()\\n        ```\\n    \\\"\\\"\\\"\\n\\n    @staticmethod\\n    def get_module_names_updated_since_last_commit() -> list[str]:\\n        \\\"\\\"\\\"\\n        Returns a list of the modules that have been changed since the last commit.\\n\\n        Runs the following command using subprocess:\\n            (git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\\n\\n        Returns:\\n            - list[str]: A list of the modules that have been changed since the last commit.\\n\\n        Raises:\\n            - Exception: If the git command fails.\\n        \\\"\\\"\\\"\\n\\n        git_command = \\\"(git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\\\"\\n\\n        result: subprocess.CompletedProcess[str] = subprocess.run(\\n            git_command, shell=True, capture_output=True, text=True\\n        )\\n        if result.returncode != 0:\\n            raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n        changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n        return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\\n    @staticmethod\\n    def get_module_names_updated_since_commit(commit_hash: str) -> list[str]:\\n        \\\"\\\"\\\"\\n        Returns a list of the Python modules that have been changed since the specified commit.\\n\\n        Args:\\n            - commit (str): The commit hash or reference to compare the current state against.\\n\\n        Runs the following command using subprocess:\\n            (git ls-files --others --exclude-standard; git diff --name-only COMMIT) | sort | uniq\\n\\n        Returns:\\n            - list[str]: A list of the modules that have been changed since the specified commit.\\n\\n        Raises:\\n            - Exception: If the git command fails.\\n        \\\"\\\"\\\"\\n\\n        git_command = f\\\"(git ls-files --others --exclude-standard; git diff --name-only {commit_hash}) | sort | uniq\\\"\\n\\n        result: subprocess.CompletedProcess[str] = subprocess.run(\\n            git_command, shell=True, capture_output=True, text=True\\n        )\\n        if result.returncode != 0:\\n            raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n        changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n        return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\\n    @staticmethod\\n    def __get_updated_modules(directory: str | None = None) -> list[str]:\\n        \\\"\\\"\\\"\\n        DO NOT USE: The necessary functionality for this method is not yet implemented.\\n\\n        Returns a list of the modules that have been changed since the last commit based on a directory path.\\n        \\\"\\\"\\\"\\n        git_ls_files_cmd = \\\"git ls-files --others --exclude-standard\\\"\\n        git_diff_cmd = \\\"git diff --name-only HEAD\\\"\\n\\n        if directory:\\n            git_ls_files_cmd += f\\\" '{directory}'\\\"\\n            git_diff_cmd += f\\\" '{directory}'\\\"\\n\\n        git_command: str = f\\\"({git_ls_files_cmd}; {git_diff_cmd}) | sort | uniq\\\"\\n\\n        result: subprocess.CompletedProcess[str] = subprocess.run(\\n            git_command, shell=True, capture_output=True, text=True\\n        )\\n        if result.returncode != 0:\\n            raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n        changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n        return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\\n, None, \\nimport subprocess\\n        \",\"children\":[{\"variable_assignments\":[],\"id\":\"postcode:updaters:git_updater.py__*__MODULE__*__STANDALONE_BLOCK-1\",\"parent_id\":\"postcode:updaters:git_updater.py__*__MODULE\",\"block_type\":\"STANDALONE_BLOCK\",\"start_line_num\":110,\"end_line_num\":114,\"code_content\":\"if __name__ == \\\"__main__\\\":\\n    print(UpdateUsingGit.get_module_names_updated_since_commit(\\\"e8856d2\\\"))\\n\",\"important_comments\":null,\"dependencies\":[{\"code_block_id\":\"postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit\"}],\"summary\":null,\"children\":null},{\"class_name\":\"UpdateUsingGit\",\"decorators\":null,\"bases\":null,\"docstring\":\"DO NOT USE: The necessary functionality for this class is not yet implemented.\\n\\nA class that provides methods to get the names of the Python modules that have been changed using on version control.\\n\\nUse this class to get all the file names for the Python modules that have been changes since the last commit or since\\na specific commit. You can get the `commit_hash` for a specific commit by going to the commit on GitHub and copying\\nthe hash from the URL. For example, the commit hash for the following commit is `e8856d2`, or you can use the terminal, for\\ninstance: `git log --author=\\\"username\\\" --grep=\\\"commit message\\\" --format=\\\"%H\\\"` if you know all the details of the commit.\\n\\nMethods:\\n    - `get_module_names_updated_since_last_commit()`: Returns a list of the modules that have been changed since the last commit.\\n    - `get_module_names_updated_since_commit(commit_hash: str)`: Returns a list of the modules that have been changed since the specified commit.\\n\\nExamples:\\n    ```Python\\n    from postcode.updaters.git_updater import UpdateUsingGit\\n\\n    # Get the names of the modules that have been changed since the last commit\\n    changed_modules_name_list = UpdateUsingGit.get_module_names_updated_since_last_commit()\\n    ```\",\"keywords\":null,\"id\":\"postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit\",\"parent_id\":\"postcode:updaters:git_updater.py__*__MODULE\",\"block_type\":\"CLASS\",\"start_line_num\":2,\"end_line_num\":110,\"code_content\":\"\\n\\nclass UpdateUsingGit:\\n    \\\"\\\"\\\"\\n    DO NOT USE: The necessary functionality for this class is not yet implemented.\\n\\n    A class that provides methods to get the names of the Python modules that have been changed using on version control.\\n\\n    Use this class to get all the file names for the Python modules that have been changes since the last commit or since\\n    a specific commit. You can get the `commit_hash` for a specific commit by going to the commit on GitHub and copying\\n    the hash from the URL. For example, the commit hash for the following commit is `e8856d2`, or you can use the terminal, for\\n    instance: `git log --author=\\\"username\\\" --grep=\\\"commit message\\\" --format=\\\"%H\\\"` if you know all the details of the commit.\\n\\n    Methods:\\n        - `get_module_names_updated_since_last_commit()`: Returns a list of the modules that have been changed since the last commit.\\n        - `get_module_names_updated_since_commit(commit_hash: str)`: Returns a list of the modules that have been changed since the specified commit.\\n\\n    Examples:\\n        ```Python\\n        from postcode.updaters.git_updater import UpdateUsingGit\\n\\n        # Get the names of the modules that have been changed since the last commit\\n        changed_modules_name_list = UpdateUsingGit.get_module_names_updated_since_last_commit()\\n        ```\\n    \\\"\\\"\\\"\\n\\n    @staticmethod\\n    def get_module_names_updated_since_last_commit() -> list[str]:\\n        \\\"\\\"\\\"\\n        Returns a list of the modules that have been changed since the last commit.\\n\\n        Runs the following command using subprocess:\\n            (git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\\n\\n        Returns:\\n            - list[str]: A list of the modules that have been changed since the last commit.\\n\\n        Raises:\\n            - Exception: If the git command fails.\\n        \\\"\\\"\\\"\\n\\n        git_command = \\\"(git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\\\"\\n\\n        result: subprocess.CompletedProcess[str] = subprocess.run(\\n            git_command, shell=True, capture_output=True, text=True\\n        )\\n        if result.returncode != 0:\\n            raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n        changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n        return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\\n    @staticmethod\\n    def get_module_names_updated_since_commit(commit_hash: str) -> list[str]:\\n        \\\"\\\"\\\"\\n        Returns a list of the Python modules that have been changed since the specified commit.\\n\\n        Args:\\n            - commit (str): The commit hash or reference to compare the current state against.\\n\\n        Runs the following command using subprocess:\\n            (git ls-files --others --exclude-standard; git diff --name-only COMMIT) | sort | uniq\\n\\n        Returns:\\n            - list[str]: A list of the modules that have been changed since the specified commit.\\n\\n        Raises:\\n            - Exception: If the git command fails.\\n        \\\"\\\"\\\"\\n\\n        git_command = f\\\"(git ls-files --others --exclude-standard; git diff --name-only {commit_hash}) | sort | uniq\\\"\\n\\n        result: subprocess.CompletedProcess[str] = subprocess.run(\\n            git_command, shell=True, capture_output=True, text=True\\n        )\\n        if result.returncode != 0:\\n            raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n        changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n        return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\\n    @staticmethod\\n    def __get_updated_modules(directory: str | None = None) -> list[str]:\\n        \\\"\\\"\\\"\\n        DO NOT USE: The necessary functionality for this method is not yet implemented.\\n\\n        Returns a list of the modules that have been changed since the last commit based on a directory path.\\n        \\\"\\\"\\\"\\n        git_ls_files_cmd = \\\"git ls-files --others --exclude-standard\\\"\\n        git_diff_cmd = \\\"git diff --name-only HEAD\\\"\\n\\n        if directory:\\n            git_ls_files_cmd += f\\\" '{directory}'\\\"\\n            git_diff_cmd += f\\\" '{directory}'\\\"\\n\\n        git_command: str = f\\\"({git_ls_files_cmd}; {git_diff_cmd}) | sort | uniq\\\"\\n\\n        result: subprocess.CompletedProcess[str] = subprocess.run(\\n            git_command, shell=True, capture_output=True, text=True\\n        )\\n        if result.returncode != 0:\\n            raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n        changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n        return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\",\"important_comments\":null,\"dependencies\":[{\"import_names\":[{\"name\":\"subprocess\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":null,\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null}],\"summary\":null,\"children\":[{\"function_name\":\"get_module_names_updated_since_last_commit\",\"docstring\":\"Returns a list of the modules that have been changed since the last commit.\\n\\nRuns the following command using subprocess:\\n    (git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\\n\\nReturns:\\n    - list[str]: A list of the modules that have been changed since the last commit.\\n\\nRaises:\\n    - Exception: If the git command fails.\",\"decorators\":[{\"content\":\"@staticmethod\",\"decorator_name\":\"staticmethod\",\"decorator_args\":null}],\"parameters\":null,\"returns\":\"list[str]\",\"is_method\":true,\"is_async\":false,\"id\":\"postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit__*__FUNCTION-get_module_names_updated_since_last_commit\",\"parent_id\":\"postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit\",\"block_type\":\"FUNCTION\",\"start_line_num\":27,\"end_line_num\":54,\"code_content\":\"\\n@staticmethod\\ndef get_module_names_updated_since_last_commit() -> list[str]:\\n    \\\"\\\"\\\"\\n        Returns a list of the modules that have been changed since the last commit.\\n\\n        Runs the following command using subprocess:\\n            (git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\\n\\n        Returns:\\n            - list[str]: A list of the modules that have been changed since the last commit.\\n\\n        Raises:\\n            - Exception: If the git command fails.\\n        \\\"\\\"\\\"\\n\\n    git_command = \\\"(git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\\\"\\n\\n    result: subprocess.CompletedProcess[str] = subprocess.run(\\n        git_command, shell=True, capture_output=True, text=True\\n    )\\n    if result.returncode != 0:\\n        raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n    changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n    return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":null,\"children\":null},{\"function_name\":\"get_module_names_updated_since_commit\",\"docstring\":\"Returns a list of the Python modules that have been changed since the specified commit.\\n\\nArgs:\\n    - commit (str): The commit hash or reference to compare the current state against.\\n\\nRuns the following command using subprocess:\\n    (git ls-files --others --exclude-standard; git diff --name-only COMMIT) | sort | uniq\\n\\nReturns:\\n    - list[str]: A list of the modules that have been changed since the specified commit.\\n\\nRaises:\\n    - Exception: If the git command fails.\",\"decorators\":[{\"content\":\"@staticmethod\",\"decorator_name\":\"staticmethod\",\"decorator_args\":null}],\"parameters\":null,\"returns\":\"list[str]\",\"is_method\":true,\"is_async\":false,\"id\":\"postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit__*__FUNCTION-get_module_names_updated_since_commit\",\"parent_id\":\"postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit\",\"block_type\":\"FUNCTION\",\"start_line_num\":54,\"end_line_num\":84,\"code_content\":\"\\n@staticmethod\\ndef get_module_names_updated_since_commit(commit_hash: str) -> list[str]:\\n    \\\"\\\"\\\"\\n        Returns a list of the Python modules that have been changed since the specified commit.\\n\\n        Args:\\n            - commit (str): The commit hash or reference to compare the current state against.\\n\\n        Runs the following command using subprocess:\\n            (git ls-files --others --exclude-standard; git diff --name-only COMMIT) | sort | uniq\\n\\n        Returns:\\n            - list[str]: A list of the modules that have been changed since the specified commit.\\n\\n        Raises:\\n            - Exception: If the git command fails.\\n        \\\"\\\"\\\"\\n\\n    git_command = f\\\"(git ls-files --others --exclude-standard; git diff --name-only {commit_hash}) | sort | uniq\\\"\\n\\n    result: subprocess.CompletedProcess[str] = subprocess.run(\\n        git_command, shell=True, capture_output=True, text=True\\n    )\\n    if result.returncode != 0:\\n        raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n    changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n    return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":null,\"children\":null},{\"function_name\":\"__get_updated_modules\",\"docstring\":\"DO NOT USE: The necessary functionality for this method is not yet implemented.\\n\\nReturns a list of the modules that have been changed since the last commit based on a directory path.\",\"decorators\":[{\"content\":\"@staticmethod\",\"decorator_name\":\"staticmethod\",\"decorator_args\":null}],\"parameters\":null,\"returns\":\"list[str]\",\"is_method\":true,\"is_async\":false,\"id\":\"postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit__*__FUNCTION-__get_updated_modules\",\"parent_id\":\"postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit\",\"block_type\":\"FUNCTION\",\"start_line_num\":84,\"end_line_num\":110,\"code_content\":\"\\n@staticmethod\\ndef __get_updated_modules(directory: str | None = None) -> list[str]:\\n    \\\"\\\"\\\"\\n        DO NOT USE: The necessary functionality for this method is not yet implemented.\\n\\n        Returns a list of the modules that have been changed since the last commit based on a directory path.\\n        \\\"\\\"\\\"\\n    git_ls_files_cmd = \\\"git ls-files --others --exclude-standard\\\"\\n    git_diff_cmd = \\\"git diff --name-only HEAD\\\"\\n\\n    if directory:\\n        git_ls_files_cmd += f\\\" '{directory}'\\\"\\n        git_diff_cmd += f\\\" '{directory}'\\\"\\n\\n    git_command: str = f\\\"({git_ls_files_cmd}; {git_diff_cmd}) | sort | uniq\\\"\\n\\n    result: subprocess.CompletedProcess[str] = subprocess.run(\\n        git_command, shell=True, capture_output=True, text=True\\n    )\\n    if result.returncode != 0:\\n        raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n    changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n    return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":null,\"children\":null}]}]}", "footer": "{\"file_path\":\"postcode/updaters/git_updater.py\",\"docstring\":null,\"header\":[],\"footer\":[],\"imports\":[{\"import_names\":[{\"name\":\"subprocess\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":null,\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null}],\"id\":\"postcode:updaters:git_updater.py__*__MODULE\",\"parent_id\":null,\"block_type\":\"MODULE\",\"start_line_num\":1,\"end_line_num\":114,\"code_content\":\"import subprocess\\n\\n\\nclass UpdateUsingGit:\\n    \\\"\\\"\\\"\\n    DO NOT USE: The necessary functionality for this class is not yet implemented.\\n\\n    A class that provides methods to get the names of the Python modules that have been changed using on version control.\\n\\n    Use this class to get all the file names for the Python modules that have been changes since the last commit or since\\n    a specific commit. You can get the `commit_hash` for a specific commit by going to the commit on GitHub and copying\\n    the hash from the URL. For example, the commit hash for the following commit is `e8856d2`, or you can use the terminal, for\\n    instance: `git log --author=\\\"username\\\" --grep=\\\"commit message\\\" --format=\\\"%H\\\"` if you know all the details of the commit.\\n\\n    Methods:\\n        - `get_module_names_updated_since_last_commit()`: Returns a list of the modules that have been changed since the last commit.\\n        - `get_module_names_updated_since_commit(commit_hash: str)`: Returns a list of the modules that have been changed since the specified commit.\\n\\n    Examples:\\n        ```Python\\n        from postcode.updaters.git_updater import UpdateUsingGit\\n\\n        # Get the names of the modules that have been changed since the last commit\\n        changed_modules_name_list = UpdateUsingGit.get_module_names_updated_since_last_commit()\\n        ```\\n    \\\"\\\"\\\"\\n\\n    @staticmethod\\n    def get_module_names_updated_since_last_commit() -> list[str]:\\n        \\\"\\\"\\\"\\n        Returns a list of the modules that have been changed since the last commit.\\n\\n        Runs the following command using subprocess:\\n            (git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\\n\\n        Returns:\\n            - list[str]: A list of the modules that have been changed since the last commit.\\n\\n        Raises:\\n            - Exception: If the git command fails.\\n        \\\"\\\"\\\"\\n\\n        git_command = \\\"(git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\\\"\\n\\n        result: subprocess.CompletedProcess[str] = subprocess.run(\\n            git_command, shell=True, capture_output=True, text=True\\n        )\\n        if result.returncode != 0:\\n            raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n        changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n        return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\\n    @staticmethod\\n    def get_module_names_updated_since_commit(commit_hash: str) -> list[str]:\\n        \\\"\\\"\\\"\\n        Returns a list of the Python modules that have been changed since the specified commit.\\n\\n        Args:\\n            - commit (str): The commit hash or reference to compare the current state against.\\n\\n        Runs the following command using subprocess:\\n            (git ls-files --others --exclude-standard; git diff --name-only COMMIT) | sort | uniq\\n\\n        Returns:\\n            - list[str]: A list of the modules that have been changed since the specified commit.\\n\\n        Raises:\\n            - Exception: If the git command fails.\\n        \\\"\\\"\\\"\\n\\n        git_command = f\\\"(git ls-files --others --exclude-standard; git diff --name-only {commit_hash}) | sort | uniq\\\"\\n\\n        result: subprocess.CompletedProcess[str] = subprocess.run(\\n            git_command, shell=True, capture_output=True, text=True\\n        )\\n        if result.returncode != 0:\\n            raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n        changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n        return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\\n    @staticmethod\\n    def __get_updated_modules(directory: str | None = None) -> list[str]:\\n        \\\"\\\"\\\"\\n        DO NOT USE: The necessary functionality for this method is not yet implemented.\\n\\n        Returns a list of the modules that have been changed since the last commit based on a directory path.\\n        \\\"\\\"\\\"\\n        git_ls_files_cmd = \\\"git ls-files --others --exclude-standard\\\"\\n        git_diff_cmd = \\\"git diff --name-only HEAD\\\"\\n\\n        if directory:\\n            git_ls_files_cmd += f\\\" '{directory}'\\\"\\n            git_diff_cmd += f\\\" '{directory}'\\\"\\n\\n        git_command: str = f\\\"({git_ls_files_cmd}; {git_diff_cmd}) | sort | uniq\\\"\\n\\n        result: subprocess.CompletedProcess[str] = subprocess.run(\\n            git_command, shell=True, capture_output=True, text=True\\n        )\\n        if result.returncode != 0:\\n            raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n        changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n        return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\\n\\nif __name__ == \\\"__main__\\\":\\n    print(UpdateUsingGit.get_module_names_updated_since_commit(\\\"e8856d2\\\"))\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":\"\\nSummary:\\n\\n        postcode:updaters:git_updater.py__*__MODULE\\n\\n        \\nChild (postcode:updaters:git_updater.py__*__MODULE__*__STANDALONE_BLOCK-1) code content:\\nif __name__ == \\\"__main__\\\":\\n    print(UpdateUsingGit.get_module_names_updated_since_commit(\\\"e8856d2\\\"))\\n\\n\\nChild (postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit) code content:\\n\\n\\nclass UpdateUsingGit:\\n    \\\"\\\"\\\"\\n    DO NOT USE: The necessary functionality for this class is not yet implemented.\\n\\n    A class that provides methods to get the names of the Python modules that have been changed using on version control.\\n\\n    Use this class to get all the file names for the Python modules that have been changes since the last commit or since\\n    a specific commit. You can get the `commit_hash` for a specific commit by going to the commit on GitHub and copying\\n    the hash from the URL. For example, the commit hash for the following commit is `e8856d2`, or you can use the terminal, for\\n    instance: `git log --author=\\\"username\\\" --grep=\\\"commit message\\\" --format=\\\"%H\\\"` if you know all the details of the commit.\\n\\n    Methods:\\n        - `get_module_names_updated_since_last_commit()`: Returns a list of the modules that have been changed since the last commit.\\n        - `get_module_names_updated_since_commit(commit_hash: str)`: Returns a list of the modules that have been changed since the specified commit.\\n\\n    Examples:\\n        ```Python\\n        from postcode.updaters.git_updater import UpdateUsingGit\\n\\n        # Get the names of the modules that have been changed since the last commit\\n        changed_modules_name_list = UpdateUsingGit.get_module_names_updated_since_last_commit()\\n        ```\\n    \\\"\\\"\\\"\\n\\n    @staticmethod\\n    def get_module_names_updated_since_last_commit() -> list[str]:\\n        \\\"\\\"\\\"\\n        Returns a list of the modules that have been changed since the last commit.\\n\\n        Runs the following command using subprocess:\\n            (git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\\n\\n        Returns:\\n            - list[str]: A list of the modules that have been changed since the last commit.\\n\\n        Raises:\\n            - Exception: If the git command fails.\\n        \\\"\\\"\\\"\\n\\n        git_command = \\\"(git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\\\"\\n\\n        result: subprocess.CompletedProcess[str] = subprocess.run(\\n            git_command, shell=True, capture_output=True, text=True\\n        )\\n        if result.returncode != 0:\\n            raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n        changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n        return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\\n    @staticmethod\\n    def get_module_names_updated_since_commit(commit_hash: str) -> list[str]:\\n        \\\"\\\"\\\"\\n        Returns a list of the Python modules that have been changed since the specified commit.\\n\\n        Args:\\n            - commit (str): The commit hash or reference to compare the current state against.\\n\\n        Runs the following command using subprocess:\\n            (git ls-files --others --exclude-standard; git diff --name-only COMMIT) | sort | uniq\\n\\n        Returns:\\n            - list[str]: A list of the modules that have been changed since the specified commit.\\n\\n        Raises:\\n            - Exception: If the git command fails.\\n        \\\"\\\"\\\"\\n\\n        git_command = f\\\"(git ls-files --others --exclude-standard; git diff --name-only {commit_hash}) | sort | uniq\\\"\\n\\n        result: subprocess.CompletedProcess[str] = subprocess.run(\\n            git_command, shell=True, capture_output=True, text=True\\n        )\\n        if result.returncode != 0:\\n            raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n        changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n        return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\\n    @staticmethod\\n    def __get_updated_modules(directory: str | None = None) -> list[str]:\\n        \\\"\\\"\\\"\\n        DO NOT USE: The necessary functionality for this method is not yet implemented.\\n\\n        Returns a list of the modules that have been changed since the last commit based on a directory path.\\n        \\\"\\\"\\\"\\n        git_ls_files_cmd = \\\"git ls-files --others --exclude-standard\\\"\\n        git_diff_cmd = \\\"git diff --name-only HEAD\\\"\\n\\n        if directory:\\n            git_ls_files_cmd += f\\\" '{directory}'\\\"\\n            git_diff_cmd += f\\\" '{directory}'\\\"\\n\\n        git_command: str = f\\\"({git_ls_files_cmd}; {git_diff_cmd}) | sort | uniq\\\"\\n\\n        result: subprocess.CompletedProcess[str] = subprocess.run(\\n            git_command, shell=True, capture_output=True, text=True\\n        )\\n        if result.returncode != 0:\\n            raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n        changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n        return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\\n, None, \\nimport subprocess\\n        \",\"children\":[{\"variable_assignments\":[],\"id\":\"postcode:updaters:git_updater.py__*__MODULE__*__STANDALONE_BLOCK-1\",\"parent_id\":\"postcode:updaters:git_updater.py__*__MODULE\",\"block_type\":\"STANDALONE_BLOCK\",\"start_line_num\":110,\"end_line_num\":114,\"code_content\":\"if __name__ == \\\"__main__\\\":\\n    print(UpdateUsingGit.get_module_names_updated_since_commit(\\\"e8856d2\\\"))\\n\",\"important_comments\":null,\"dependencies\":[{\"code_block_id\":\"postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit\"}],\"summary\":null,\"children\":null},{\"class_name\":\"UpdateUsingGit\",\"decorators\":null,\"bases\":null,\"docstring\":\"DO NOT USE: The necessary functionality for this class is not yet implemented.\\n\\nA class that provides methods to get the names of the Python modules that have been changed using on version control.\\n\\nUse this class to get all the file names for the Python modules that have been changes since the last commit or since\\na specific commit. You can get the `commit_hash` for a specific commit by going to the commit on GitHub and copying\\nthe hash from the URL. For example, the commit hash for the following commit is `e8856d2`, or you can use the terminal, for\\ninstance: `git log --author=\\\"username\\\" --grep=\\\"commit message\\\" --format=\\\"%H\\\"` if you know all the details of the commit.\\n\\nMethods:\\n    - `get_module_names_updated_since_last_commit()`: Returns a list of the modules that have been changed since the last commit.\\n    - `get_module_names_updated_since_commit(commit_hash: str)`: Returns a list of the modules that have been changed since the specified commit.\\n\\nExamples:\\n    ```Python\\n    from postcode.updaters.git_updater import UpdateUsingGit\\n\\n    # Get the names of the modules that have been changed since the last commit\\n    changed_modules_name_list = UpdateUsingGit.get_module_names_updated_since_last_commit()\\n    ```\",\"keywords\":null,\"id\":\"postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit\",\"parent_id\":\"postcode:updaters:git_updater.py__*__MODULE\",\"block_type\":\"CLASS\",\"start_line_num\":2,\"end_line_num\":110,\"code_content\":\"\\n\\nclass UpdateUsingGit:\\n    \\\"\\\"\\\"\\n    DO NOT USE: The necessary functionality for this class is not yet implemented.\\n\\n    A class that provides methods to get the names of the Python modules that have been changed using on version control.\\n\\n    Use this class to get all the file names for the Python modules that have been changes since the last commit or since\\n    a specific commit. You can get the `commit_hash` for a specific commit by going to the commit on GitHub and copying\\n    the hash from the URL. For example, the commit hash for the following commit is `e8856d2`, or you can use the terminal, for\\n    instance: `git log --author=\\\"username\\\" --grep=\\\"commit message\\\" --format=\\\"%H\\\"` if you know all the details of the commit.\\n\\n    Methods:\\n        - `get_module_names_updated_since_last_commit()`: Returns a list of the modules that have been changed since the last commit.\\n        - `get_module_names_updated_since_commit(commit_hash: str)`: Returns a list of the modules that have been changed since the specified commit.\\n\\n    Examples:\\n        ```Python\\n        from postcode.updaters.git_updater import UpdateUsingGit\\n\\n        # Get the names of the modules that have been changed since the last commit\\n        changed_modules_name_list = UpdateUsingGit.get_module_names_updated_since_last_commit()\\n        ```\\n    \\\"\\\"\\\"\\n\\n    @staticmethod\\n    def get_module_names_updated_since_last_commit() -> list[str]:\\n        \\\"\\\"\\\"\\n        Returns a list of the modules that have been changed since the last commit.\\n\\n        Runs the following command using subprocess:\\n            (git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\\n\\n        Returns:\\n            - list[str]: A list of the modules that have been changed since the last commit.\\n\\n        Raises:\\n            - Exception: If the git command fails.\\n        \\\"\\\"\\\"\\n\\n        git_command = \\\"(git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\\\"\\n\\n        result: subprocess.CompletedProcess[str] = subprocess.run(\\n            git_command, shell=True, capture_output=True, text=True\\n        )\\n        if result.returncode != 0:\\n            raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n        changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n        return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\\n    @staticmethod\\n    def get_module_names_updated_since_commit(commit_hash: str) -> list[str]:\\n        \\\"\\\"\\\"\\n        Returns a list of the Python modules that have been changed since the specified commit.\\n\\n        Args:\\n            - commit (str): The commit hash or reference to compare the current state against.\\n\\n        Runs the following command using subprocess:\\n            (git ls-files --others --exclude-standard; git diff --name-only COMMIT) | sort | uniq\\n\\n        Returns:\\n            - list[str]: A list of the modules that have been changed since the specified commit.\\n\\n        Raises:\\n            - Exception: If the git command fails.\\n        \\\"\\\"\\\"\\n\\n        git_command = f\\\"(git ls-files --others --exclude-standard; git diff --name-only {commit_hash}) | sort | uniq\\\"\\n\\n        result: subprocess.CompletedProcess[str] = subprocess.run(\\n            git_command, shell=True, capture_output=True, text=True\\n        )\\n        if result.returncode != 0:\\n            raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n        changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n        return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\\n    @staticmethod\\n    def __get_updated_modules(directory: str | None = None) -> list[str]:\\n        \\\"\\\"\\\"\\n        DO NOT USE: The necessary functionality for this method is not yet implemented.\\n\\n        Returns a list of the modules that have been changed since the last commit based on a directory path.\\n        \\\"\\\"\\\"\\n        git_ls_files_cmd = \\\"git ls-files --others --exclude-standard\\\"\\n        git_diff_cmd = \\\"git diff --name-only HEAD\\\"\\n\\n        if directory:\\n            git_ls_files_cmd += f\\\" '{directory}'\\\"\\n            git_diff_cmd += f\\\" '{directory}'\\\"\\n\\n        git_command: str = f\\\"({git_ls_files_cmd}; {git_diff_cmd}) | sort | uniq\\\"\\n\\n        result: subprocess.CompletedProcess[str] = subprocess.run(\\n            git_command, shell=True, capture_output=True, text=True\\n        )\\n        if result.returncode != 0:\\n            raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n        changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n        return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\",\"important_comments\":null,\"dependencies\":[{\"import_names\":[{\"name\":\"subprocess\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":null,\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null}],\"summary\":null,\"children\":[{\"function_name\":\"get_module_names_updated_since_last_commit\",\"docstring\":\"Returns a list of the modules that have been changed since the last commit.\\n\\nRuns the following command using subprocess:\\n    (git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\\n\\nReturns:\\n    - list[str]: A list of the modules that have been changed since the last commit.\\n\\nRaises:\\n    - Exception: If the git command fails.\",\"decorators\":[{\"content\":\"@staticmethod\",\"decorator_name\":\"staticmethod\",\"decorator_args\":null}],\"parameters\":null,\"returns\":\"list[str]\",\"is_method\":true,\"is_async\":false,\"id\":\"postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit__*__FUNCTION-get_module_names_updated_since_last_commit\",\"parent_id\":\"postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit\",\"block_type\":\"FUNCTION\",\"start_line_num\":27,\"end_line_num\":54,\"code_content\":\"\\n@staticmethod\\ndef get_module_names_updated_since_last_commit() -> list[str]:\\n    \\\"\\\"\\\"\\n        Returns a list of the modules that have been changed since the last commit.\\n\\n        Runs the following command using subprocess:\\n            (git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\\n\\n        Returns:\\n            - list[str]: A list of the modules that have been changed since the last commit.\\n\\n        Raises:\\n            - Exception: If the git command fails.\\n        \\\"\\\"\\\"\\n\\n    git_command = \\\"(git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\\\"\\n\\n    result: subprocess.CompletedProcess[str] = subprocess.run(\\n        git_command, shell=True, capture_output=True, text=True\\n    )\\n    if result.returncode != 0:\\n        raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n    changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n    return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":null,\"children\":null},{\"function_name\":\"get_module_names_updated_since_commit\",\"docstring\":\"Returns a list of the Python modules that have been changed since the specified commit.\\n\\nArgs:\\n    - commit (str): The commit hash or reference to compare the current state against.\\n\\nRuns the following command using subprocess:\\n    (git ls-files --others --exclude-standard; git diff --name-only COMMIT) | sort | uniq\\n\\nReturns:\\n    - list[str]: A list of the modules that have been changed since the specified commit.\\n\\nRaises:\\n    - Exception: If the git command fails.\",\"decorators\":[{\"content\":\"@staticmethod\",\"decorator_name\":\"staticmethod\",\"decorator_args\":null}],\"parameters\":null,\"returns\":\"list[str]\",\"is_method\":true,\"is_async\":false,\"id\":\"postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit__*__FUNCTION-get_module_names_updated_since_commit\",\"parent_id\":\"postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit\",\"block_type\":\"FUNCTION\",\"start_line_num\":54,\"end_line_num\":84,\"code_content\":\"\\n@staticmethod\\ndef get_module_names_updated_since_commit(commit_hash: str) -> list[str]:\\n    \\\"\\\"\\\"\\n        Returns a list of the Python modules that have been changed since the specified commit.\\n\\n        Args:\\n            - commit (str): The commit hash or reference to compare the current state against.\\n\\n        Runs the following command using subprocess:\\n            (git ls-files --others --exclude-standard; git diff --name-only COMMIT) | sort | uniq\\n\\n        Returns:\\n            - list[str]: A list of the modules that have been changed since the specified commit.\\n\\n        Raises:\\n            - Exception: If the git command fails.\\n        \\\"\\\"\\\"\\n\\n    git_command = f\\\"(git ls-files --others --exclude-standard; git diff --name-only {commit_hash}) | sort | uniq\\\"\\n\\n    result: subprocess.CompletedProcess[str] = subprocess.run(\\n        git_command, shell=True, capture_output=True, text=True\\n    )\\n    if result.returncode != 0:\\n        raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n    changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n    return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":null,\"children\":null},{\"function_name\":\"__get_updated_modules\",\"docstring\":\"DO NOT USE: The necessary functionality for this method is not yet implemented.\\n\\nReturns a list of the modules that have been changed since the last commit based on a directory path.\",\"decorators\":[{\"content\":\"@staticmethod\",\"decorator_name\":\"staticmethod\",\"decorator_args\":null}],\"parameters\":null,\"returns\":\"list[str]\",\"is_method\":true,\"is_async\":false,\"id\":\"postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit__*__FUNCTION-__get_updated_modules\",\"parent_id\":\"postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit\",\"block_type\":\"FUNCTION\",\"start_line_num\":84,\"end_line_num\":110,\"code_content\":\"\\n@staticmethod\\ndef __get_updated_modules(directory: str | None = None) -> list[str]:\\n    \\\"\\\"\\\"\\n        DO NOT USE: The necessary functionality for this method is not yet implemented.\\n\\n        Returns a list of the modules that have been changed since the last commit based on a directory path.\\n        \\\"\\\"\\\"\\n    git_ls_files_cmd = \\\"git ls-files --others --exclude-standard\\\"\\n    git_diff_cmd = \\\"git diff --name-only HEAD\\\"\\n\\n    if directory:\\n        git_ls_files_cmd += f\\\" '{directory}'\\\"\\n        git_diff_cmd += f\\\" '{directory}'\\\"\\n\\n    git_command: str = f\\\"({git_ls_files_cmd}; {git_diff_cmd}) | sort | uniq\\\"\\n\\n    result: subprocess.CompletedProcess[str] = subprocess.run(\\n        git_command, shell=True, capture_output=True, text=True\\n    )\\n    if result.returncode != 0:\\n        raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n    changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n    return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":null,\"children\":null}]}]}", "imports": "{\"file_path\":\"postcode/updaters/git_updater.py\",\"docstring\":null,\"header\":[],\"footer\":[],\"imports\":[{\"import_names\":[{\"name\":\"subprocess\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":null,\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null}],\"id\":\"postcode:updaters:git_updater.py__*__MODULE\",\"parent_id\":null,\"block_type\":\"MODULE\",\"start_line_num\":1,\"end_line_num\":114,\"code_content\":\"import subprocess\\n\\n\\nclass UpdateUsingGit:\\n    \\\"\\\"\\\"\\n    DO NOT USE: The necessary functionality for this class is not yet implemented.\\n\\n    A class that provides methods to get the names of the Python modules that have been changed using on version control.\\n\\n    Use this class to get all the file names for the Python modules that have been changes since the last commit or since\\n    a specific commit. You can get the `commit_hash` for a specific commit by going to the commit on GitHub and copying\\n    the hash from the URL. For example, the commit hash for the following commit is `e8856d2`, or you can use the terminal, for\\n    instance: `git log --author=\\\"username\\\" --grep=\\\"commit message\\\" --format=\\\"%H\\\"` if you know all the details of the commit.\\n\\n    Methods:\\n        - `get_module_names_updated_since_last_commit()`: Returns a list of the modules that have been changed since the last commit.\\n        - `get_module_names_updated_since_commit(commit_hash: str)`: Returns a list of the modules that have been changed since the specified commit.\\n\\n    Examples:\\n        ```Python\\n        from postcode.updaters.git_updater import UpdateUsingGit\\n\\n        # Get the names of the modules that have been changed since the last commit\\n        changed_modules_name_list = UpdateUsingGit.get_module_names_updated_since_last_commit()\\n        ```\\n    \\\"\\\"\\\"\\n\\n    @staticmethod\\n    def get_module_names_updated_since_last_commit() -> list[str]:\\n        \\\"\\\"\\\"\\n        Returns a list of the modules that have been changed since the last commit.\\n\\n        Runs the following command using subprocess:\\n            (git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\\n\\n        Returns:\\n            - list[str]: A list of the modules that have been changed since the last commit.\\n\\n        Raises:\\n            - Exception: If the git command fails.\\n        \\\"\\\"\\\"\\n\\n        git_command = \\\"(git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\\\"\\n\\n        result: subprocess.CompletedProcess[str] = subprocess.run(\\n            git_command, shell=True, capture_output=True, text=True\\n        )\\n        if result.returncode != 0:\\n            raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n        changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n        return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\\n    @staticmethod\\n    def get_module_names_updated_since_commit(commit_hash: str) -> list[str]:\\n        \\\"\\\"\\\"\\n        Returns a list of the Python modules that have been changed since the specified commit.\\n\\n        Args:\\n            - commit (str): The commit hash or reference to compare the current state against.\\n\\n        Runs the following command using subprocess:\\n            (git ls-files --others --exclude-standard; git diff --name-only COMMIT) | sort | uniq\\n\\n        Returns:\\n            - list[str]: A list of the modules that have been changed since the specified commit.\\n\\n        Raises:\\n            - Exception: If the git command fails.\\n        \\\"\\\"\\\"\\n\\n        git_command = f\\\"(git ls-files --others --exclude-standard; git diff --name-only {commit_hash}) | sort | uniq\\\"\\n\\n        result: subprocess.CompletedProcess[str] = subprocess.run(\\n            git_command, shell=True, capture_output=True, text=True\\n        )\\n        if result.returncode != 0:\\n            raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n        changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n        return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\\n    @staticmethod\\n    def __get_updated_modules(directory: str | None = None) -> list[str]:\\n        \\\"\\\"\\\"\\n        DO NOT USE: The necessary functionality for this method is not yet implemented.\\n\\n        Returns a list of the modules that have been changed since the last commit based on a directory path.\\n        \\\"\\\"\\\"\\n        git_ls_files_cmd = \\\"git ls-files --others --exclude-standard\\\"\\n        git_diff_cmd = \\\"git diff --name-only HEAD\\\"\\n\\n        if directory:\\n            git_ls_files_cmd += f\\\" '{directory}'\\\"\\n            git_diff_cmd += f\\\" '{directory}'\\\"\\n\\n        git_command: str = f\\\"({git_ls_files_cmd}; {git_diff_cmd}) | sort | uniq\\\"\\n\\n        result: subprocess.CompletedProcess[str] = subprocess.run(\\n            git_command, shell=True, capture_output=True, text=True\\n        )\\n        if result.returncode != 0:\\n            raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n        changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n        return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\\n\\nif __name__ == \\\"__main__\\\":\\n    print(UpdateUsingGit.get_module_names_updated_since_commit(\\\"e8856d2\\\"))\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":\"\\nSummary:\\n\\n        postcode:updaters:git_updater.py__*__MODULE\\n\\n        \\nChild (postcode:updaters:git_updater.py__*__MODULE__*__STANDALONE_BLOCK-1) code content:\\nif __name__ == \\\"__main__\\\":\\n    print(UpdateUsingGit.get_module_names_updated_since_commit(\\\"e8856d2\\\"))\\n\\n\\nChild (postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit) code content:\\n\\n\\nclass UpdateUsingGit:\\n    \\\"\\\"\\\"\\n    DO NOT USE: The necessary functionality for this class is not yet implemented.\\n\\n    A class that provides methods to get the names of the Python modules that have been changed using on version control.\\n\\n    Use this class to get all the file names for the Python modules that have been changes since the last commit or since\\n    a specific commit. You can get the `commit_hash` for a specific commit by going to the commit on GitHub and copying\\n    the hash from the URL. For example, the commit hash for the following commit is `e8856d2`, or you can use the terminal, for\\n    instance: `git log --author=\\\"username\\\" --grep=\\\"commit message\\\" --format=\\\"%H\\\"` if you know all the details of the commit.\\n\\n    Methods:\\n        - `get_module_names_updated_since_last_commit()`: Returns a list of the modules that have been changed since the last commit.\\n        - `get_module_names_updated_since_commit(commit_hash: str)`: Returns a list of the modules that have been changed since the specified commit.\\n\\n    Examples:\\n        ```Python\\n        from postcode.updaters.git_updater import UpdateUsingGit\\n\\n        # Get the names of the modules that have been changed since the last commit\\n        changed_modules_name_list = UpdateUsingGit.get_module_names_updated_since_last_commit()\\n        ```\\n    \\\"\\\"\\\"\\n\\n    @staticmethod\\n    def get_module_names_updated_since_last_commit() -> list[str]:\\n        \\\"\\\"\\\"\\n        Returns a list of the modules that have been changed since the last commit.\\n\\n        Runs the following command using subprocess:\\n            (git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\\n\\n        Returns:\\n            - list[str]: A list of the modules that have been changed since the last commit.\\n\\n        Raises:\\n            - Exception: If the git command fails.\\n        \\\"\\\"\\\"\\n\\n        git_command = \\\"(git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\\\"\\n\\n        result: subprocess.CompletedProcess[str] = subprocess.run(\\n            git_command, shell=True, capture_output=True, text=True\\n        )\\n        if result.returncode != 0:\\n            raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n        changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n        return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\\n    @staticmethod\\n    def get_module_names_updated_since_commit(commit_hash: str) -> list[str]:\\n        \\\"\\\"\\\"\\n        Returns a list of the Python modules that have been changed since the specified commit.\\n\\n        Args:\\n            - commit (str): The commit hash or reference to compare the current state against.\\n\\n        Runs the following command using subprocess:\\n            (git ls-files --others --exclude-standard; git diff --name-only COMMIT) | sort | uniq\\n\\n        Returns:\\n            - list[str]: A list of the modules that have been changed since the specified commit.\\n\\n        Raises:\\n            - Exception: If the git command fails.\\n        \\\"\\\"\\\"\\n\\n        git_command = f\\\"(git ls-files --others --exclude-standard; git diff --name-only {commit_hash}) | sort | uniq\\\"\\n\\n        result: subprocess.CompletedProcess[str] = subprocess.run(\\n            git_command, shell=True, capture_output=True, text=True\\n        )\\n        if result.returncode != 0:\\n            raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n        changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n        return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\\n    @staticmethod\\n    def __get_updated_modules(directory: str | None = None) -> list[str]:\\n        \\\"\\\"\\\"\\n        DO NOT USE: The necessary functionality for this method is not yet implemented.\\n\\n        Returns a list of the modules that have been changed since the last commit based on a directory path.\\n        \\\"\\\"\\\"\\n        git_ls_files_cmd = \\\"git ls-files --others --exclude-standard\\\"\\n        git_diff_cmd = \\\"git diff --name-only HEAD\\\"\\n\\n        if directory:\\n            git_ls_files_cmd += f\\\" '{directory}'\\\"\\n            git_diff_cmd += f\\\" '{directory}'\\\"\\n\\n        git_command: str = f\\\"({git_ls_files_cmd}; {git_diff_cmd}) | sort | uniq\\\"\\n\\n        result: subprocess.CompletedProcess[str] = subprocess.run(\\n            git_command, shell=True, capture_output=True, text=True\\n        )\\n        if result.returncode != 0:\\n            raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n        changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n        return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\\n, None, \\nimport subprocess\\n        \",\"children\":[{\"variable_assignments\":[],\"id\":\"postcode:updaters:git_updater.py__*__MODULE__*__STANDALONE_BLOCK-1\",\"parent_id\":\"postcode:updaters:git_updater.py__*__MODULE\",\"block_type\":\"STANDALONE_BLOCK\",\"start_line_num\":110,\"end_line_num\":114,\"code_content\":\"if __name__ == \\\"__main__\\\":\\n    print(UpdateUsingGit.get_module_names_updated_since_commit(\\\"e8856d2\\\"))\\n\",\"important_comments\":null,\"dependencies\":[{\"code_block_id\":\"postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit\"}],\"summary\":null,\"children\":null},{\"class_name\":\"UpdateUsingGit\",\"decorators\":null,\"bases\":null,\"docstring\":\"DO NOT USE: The necessary functionality for this class is not yet implemented.\\n\\nA class that provides methods to get the names of the Python modules that have been changed using on version control.\\n\\nUse this class to get all the file names for the Python modules that have been changes since the last commit or since\\na specific commit. You can get the `commit_hash` for a specific commit by going to the commit on GitHub and copying\\nthe hash from the URL. For example, the commit hash for the following commit is `e8856d2`, or you can use the terminal, for\\ninstance: `git log --author=\\\"username\\\" --grep=\\\"commit message\\\" --format=\\\"%H\\\"` if you know all the details of the commit.\\n\\nMethods:\\n    - `get_module_names_updated_since_last_commit()`: Returns a list of the modules that have been changed since the last commit.\\n    - `get_module_names_updated_since_commit(commit_hash: str)`: Returns a list of the modules that have been changed since the specified commit.\\n\\nExamples:\\n    ```Python\\n    from postcode.updaters.git_updater import UpdateUsingGit\\n\\n    # Get the names of the modules that have been changed since the last commit\\n    changed_modules_name_list = UpdateUsingGit.get_module_names_updated_since_last_commit()\\n    ```\",\"keywords\":null,\"id\":\"postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit\",\"parent_id\":\"postcode:updaters:git_updater.py__*__MODULE\",\"block_type\":\"CLASS\",\"start_line_num\":2,\"end_line_num\":110,\"code_content\":\"\\n\\nclass UpdateUsingGit:\\n    \\\"\\\"\\\"\\n    DO NOT USE: The necessary functionality for this class is not yet implemented.\\n\\n    A class that provides methods to get the names of the Python modules that have been changed using on version control.\\n\\n    Use this class to get all the file names for the Python modules that have been changes since the last commit or since\\n    a specific commit. You can get the `commit_hash` for a specific commit by going to the commit on GitHub and copying\\n    the hash from the URL. For example, the commit hash for the following commit is `e8856d2`, or you can use the terminal, for\\n    instance: `git log --author=\\\"username\\\" --grep=\\\"commit message\\\" --format=\\\"%H\\\"` if you know all the details of the commit.\\n\\n    Methods:\\n        - `get_module_names_updated_since_last_commit()`: Returns a list of the modules that have been changed since the last commit.\\n        - `get_module_names_updated_since_commit(commit_hash: str)`: Returns a list of the modules that have been changed since the specified commit.\\n\\n    Examples:\\n        ```Python\\n        from postcode.updaters.git_updater import UpdateUsingGit\\n\\n        # Get the names of the modules that have been changed since the last commit\\n        changed_modules_name_list = UpdateUsingGit.get_module_names_updated_since_last_commit()\\n        ```\\n    \\\"\\\"\\\"\\n\\n    @staticmethod\\n    def get_module_names_updated_since_last_commit() -> list[str]:\\n        \\\"\\\"\\\"\\n        Returns a list of the modules that have been changed since the last commit.\\n\\n        Runs the following command using subprocess:\\n            (git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\\n\\n        Returns:\\n            - list[str]: A list of the modules that have been changed since the last commit.\\n\\n        Raises:\\n            - Exception: If the git command fails.\\n        \\\"\\\"\\\"\\n\\n        git_command = \\\"(git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\\\"\\n\\n        result: subprocess.CompletedProcess[str] = subprocess.run(\\n            git_command, shell=True, capture_output=True, text=True\\n        )\\n        if result.returncode != 0:\\n            raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n        changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n        return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\\n    @staticmethod\\n    def get_module_names_updated_since_commit(commit_hash: str) -> list[str]:\\n        \\\"\\\"\\\"\\n        Returns a list of the Python modules that have been changed since the specified commit.\\n\\n        Args:\\n            - commit (str): The commit hash or reference to compare the current state against.\\n\\n        Runs the following command using subprocess:\\n            (git ls-files --others --exclude-standard; git diff --name-only COMMIT) | sort | uniq\\n\\n        Returns:\\n            - list[str]: A list of the modules that have been changed since the specified commit.\\n\\n        Raises:\\n            - Exception: If the git command fails.\\n        \\\"\\\"\\\"\\n\\n        git_command = f\\\"(git ls-files --others --exclude-standard; git diff --name-only {commit_hash}) | sort | uniq\\\"\\n\\n        result: subprocess.CompletedProcess[str] = subprocess.run(\\n            git_command, shell=True, capture_output=True, text=True\\n        )\\n        if result.returncode != 0:\\n            raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n        changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n        return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\\n    @staticmethod\\n    def __get_updated_modules(directory: str | None = None) -> list[str]:\\n        \\\"\\\"\\\"\\n        DO NOT USE: The necessary functionality for this method is not yet implemented.\\n\\n        Returns a list of the modules that have been changed since the last commit based on a directory path.\\n        \\\"\\\"\\\"\\n        git_ls_files_cmd = \\\"git ls-files --others --exclude-standard\\\"\\n        git_diff_cmd = \\\"git diff --name-only HEAD\\\"\\n\\n        if directory:\\n            git_ls_files_cmd += f\\\" '{directory}'\\\"\\n            git_diff_cmd += f\\\" '{directory}'\\\"\\n\\n        git_command: str = f\\\"({git_ls_files_cmd}; {git_diff_cmd}) | sort | uniq\\\"\\n\\n        result: subprocess.CompletedProcess[str] = subprocess.run(\\n            git_command, shell=True, capture_output=True, text=True\\n        )\\n        if result.returncode != 0:\\n            raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n        changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n        return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\",\"important_comments\":null,\"dependencies\":[{\"import_names\":[{\"name\":\"subprocess\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":null,\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null}],\"summary\":null,\"children\":[{\"function_name\":\"get_module_names_updated_since_last_commit\",\"docstring\":\"Returns a list of the modules that have been changed since the last commit.\\n\\nRuns the following command using subprocess:\\n    (git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\\n\\nReturns:\\n    - list[str]: A list of the modules that have been changed since the last commit.\\n\\nRaises:\\n    - Exception: If the git command fails.\",\"decorators\":[{\"content\":\"@staticmethod\",\"decorator_name\":\"staticmethod\",\"decorator_args\":null}],\"parameters\":null,\"returns\":\"list[str]\",\"is_method\":true,\"is_async\":false,\"id\":\"postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit__*__FUNCTION-get_module_names_updated_since_last_commit\",\"parent_id\":\"postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit\",\"block_type\":\"FUNCTION\",\"start_line_num\":27,\"end_line_num\":54,\"code_content\":\"\\n@staticmethod\\ndef get_module_names_updated_since_last_commit() -> list[str]:\\n    \\\"\\\"\\\"\\n        Returns a list of the modules that have been changed since the last commit.\\n\\n        Runs the following command using subprocess:\\n            (git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\\n\\n        Returns:\\n            - list[str]: A list of the modules that have been changed since the last commit.\\n\\n        Raises:\\n            - Exception: If the git command fails.\\n        \\\"\\\"\\\"\\n\\n    git_command = \\\"(git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\\\"\\n\\n    result: subprocess.CompletedProcess[str] = subprocess.run(\\n        git_command, shell=True, capture_output=True, text=True\\n    )\\n    if result.returncode != 0:\\n        raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n    changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n    return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":null,\"children\":null},{\"function_name\":\"get_module_names_updated_since_commit\",\"docstring\":\"Returns a list of the Python modules that have been changed since the specified commit.\\n\\nArgs:\\n    - commit (str): The commit hash or reference to compare the current state against.\\n\\nRuns the following command using subprocess:\\n    (git ls-files --others --exclude-standard; git diff --name-only COMMIT) | sort | uniq\\n\\nReturns:\\n    - list[str]: A list of the modules that have been changed since the specified commit.\\n\\nRaises:\\n    - Exception: If the git command fails.\",\"decorators\":[{\"content\":\"@staticmethod\",\"decorator_name\":\"staticmethod\",\"decorator_args\":null}],\"parameters\":null,\"returns\":\"list[str]\",\"is_method\":true,\"is_async\":false,\"id\":\"postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit__*__FUNCTION-get_module_names_updated_since_commit\",\"parent_id\":\"postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit\",\"block_type\":\"FUNCTION\",\"start_line_num\":54,\"end_line_num\":84,\"code_content\":\"\\n@staticmethod\\ndef get_module_names_updated_since_commit(commit_hash: str) -> list[str]:\\n    \\\"\\\"\\\"\\n        Returns a list of the Python modules that have been changed since the specified commit.\\n\\n        Args:\\n            - commit (str): The commit hash or reference to compare the current state against.\\n\\n        Runs the following command using subprocess:\\n            (git ls-files --others --exclude-standard; git diff --name-only COMMIT) | sort | uniq\\n\\n        Returns:\\n            - list[str]: A list of the modules that have been changed since the specified commit.\\n\\n        Raises:\\n            - Exception: If the git command fails.\\n        \\\"\\\"\\\"\\n\\n    git_command = f\\\"(git ls-files --others --exclude-standard; git diff --name-only {commit_hash}) | sort | uniq\\\"\\n\\n    result: subprocess.CompletedProcess[str] = subprocess.run(\\n        git_command, shell=True, capture_output=True, text=True\\n    )\\n    if result.returncode != 0:\\n        raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n    changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n    return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":null,\"children\":null},{\"function_name\":\"__get_updated_modules\",\"docstring\":\"DO NOT USE: The necessary functionality for this method is not yet implemented.\\n\\nReturns a list of the modules that have been changed since the last commit based on a directory path.\",\"decorators\":[{\"content\":\"@staticmethod\",\"decorator_name\":\"staticmethod\",\"decorator_args\":null}],\"parameters\":null,\"returns\":\"list[str]\",\"is_method\":true,\"is_async\":false,\"id\":\"postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit__*__FUNCTION-__get_updated_modules\",\"parent_id\":\"postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit\",\"block_type\":\"FUNCTION\",\"start_line_num\":84,\"end_line_num\":110,\"code_content\":\"\\n@staticmethod\\ndef __get_updated_modules(directory: str | None = None) -> list[str]:\\n    \\\"\\\"\\\"\\n        DO NOT USE: The necessary functionality for this method is not yet implemented.\\n\\n        Returns a list of the modules that have been changed since the last commit based on a directory path.\\n        \\\"\\\"\\\"\\n    git_ls_files_cmd = \\\"git ls-files --others --exclude-standard\\\"\\n    git_diff_cmd = \\\"git diff --name-only HEAD\\\"\\n\\n    if directory:\\n        git_ls_files_cmd += f\\\" '{directory}'\\\"\\n        git_diff_cmd += f\\\" '{directory}'\\\"\\n\\n    git_command: str = f\\\"({git_ls_files_cmd}; {git_diff_cmd}) | sort | uniq\\\"\\n\\n    result: subprocess.CompletedProcess[str] = subprocess.run(\\n        git_command, shell=True, capture_output=True, text=True\\n    )\\n    if result.returncode != 0:\\n        raise Exception(\\\"Git command failed: \\\" + result.stderr)\\n\\n    changed_files: list[str] = result.stdout.strip().split(\\\"\\\\n\\\")\\n\\n    return [file for file in changed_files if file.endswith(\\\".py\\\")]\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":null,\"children\":null}]}]}", "chroma:document": "\nSummary:\n\n        postcode:updaters:git_updater.py__*__MODULE\n\n        \nChild (postcode:updaters:git_updater.py__*__MODULE__*__STANDALONE_BLOCK-1) code content:\nif __name__ == \"__main__\":\n    print(UpdateUsingGit.get_module_names_updated_since_commit(\"e8856d2\"))\n\n\nChild (postcode:updaters:git_updater.py__*__MODULE__*__CLASS-UpdateUsingGit) code content:\n\n\nclass UpdateUsingGit:\n    \"\"\"\n    DO NOT USE: The necessary functionality for this class is not yet implemented.\n\n    A class that provides methods to get the names of the Python modules that have been changed using on version control.\n\n    Use this class to get all the file names for the Python modules that have been changes since the last commit or since\n    a specific commit. You can get the `commit_hash` for a specific commit by going to the commit on GitHub and copying\n    the hash from the URL. For example, the commit hash for the following commit is `e8856d2`, or you can use the terminal, for\n    instance: `git log --author=\"username\" --grep=\"commit message\" --format=\"%H\"` if you know all the details of the commit.\n\n    Methods:\n        - `get_module_names_updated_since_last_commit()`: Returns a list of the modules that have been changed since the last commit.\n        - `get_module_names_updated_since_commit(commit_hash: str)`: Returns a list of the modules that have been changed since the specified commit.\n\n    Examples:\n        ```Python\n        from postcode.updaters.git_updater import UpdateUsingGit\n\n        # Get the names of the modules that have been changed since the last commit\n        changed_modules_name_list = UpdateUsingGit.get_module_names_updated_since_last_commit()\n        ```\n    \"\"\"\n\n    @staticmethod\n    def get_module_names_updated_since_last_commit() -> list[str]:\n        \"\"\"\n        Returns a list of the modules that have been changed since the last commit.\n\n        Runs the following command using subprocess:\n            (git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\n\n        Returns:\n            - list[str]: A list of the modules that have been changed since the last commit.\n\n        Raises:\n            - Exception: If the git command fails.\n        \"\"\"\n\n        git_command = \"(git ls-files --others --exclude-standard; git diff --name-only HEAD) | sort | uniq\"\n\n        result: subprocess.CompletedProcess[str] = subprocess.run(\n            git_command, shell=True, capture_output=True, text=True\n        )\n        if result.returncode != 0:\n            raise Exception(\"Git command failed: \" + result.stderr)\n\n        changed_files: list[str] = result.stdout.strip().split(\"\\n\")\n\n        return [file for file in changed_files if file.endswith(\".py\")]\n\n    @staticmethod\n    def get_module_names_updated_since_commit(commit_hash: str) -> list[str]:\n        \"\"\"\n        Returns a list of the Python modules that have been changed since the specified commit.\n\n        Args:\n            - commit (str): The commit hash or reference to compare the current state against.\n\n        Runs the following command using subprocess:\n            (git ls-files --others --exclude-standard; git diff --name-only COMMIT) | sort | uniq\n\n        Returns:\n            - list[str]: A list of the modules that have been changed since the specified commit.\n\n        Raises:\n            - Exception: If the git command fails.\n        \"\"\"\n\n        git_command = f\"(git ls-files --others --exclude-standard; git diff --name-only {commit_hash}) | sort | uniq\"\n\n        result: subprocess.CompletedProcess[str] = subprocess.run(\n            git_command, shell=True, capture_output=True, text=True\n        )\n        if result.returncode != 0:\n            raise Exception(\"Git command failed: \" + result.stderr)\n\n        changed_files: list[str] = result.stdout.strip().split(\"\\n\")\n\n        return [file for file in changed_files if file.endswith(\".py\")]\n\n    @staticmethod\n    def __get_updated_modules(directory: str | None = None) -> list[str]:\n        \"\"\"\n        DO NOT USE: The necessary functionality for this method is not yet implemented.\n\n        Returns a list of the modules that have been changed since the last commit based on a directory path.\n        \"\"\"\n        git_ls_files_cmd = \"git ls-files --others --exclude-standard\"\n        git_diff_cmd = \"git diff --name-only HEAD\"\n\n        if directory:\n            git_ls_files_cmd += f\" '{directory}'\"\n            git_diff_cmd += f\" '{directory}'\"\n\n        git_command: str = f\"({git_ls_files_cmd}; {git_diff_cmd}) | sort | uniq\"\n\n        result: subprocess.CompletedProcess[str] = subprocess.run(\n            git_command, shell=True, capture_output=True, text=True\n        )\n        if result.returncode != 0:\n            raise Exception(\"Git command failed: \" + result.stderr)\n\n        changed_files: list[str] = result.stdout.strip().split(\"\\n\")\n\n        return [file for file in changed_files if file.endswith(\".py\")]\n\n, None, \nimport subprocess\n        "}n in the form of a TypedDict.\\n\\n        Args:\\n            - ids (list[str]): A list of ids to get from the collection.\\n            - where_filter (chroma_types.Where | None): A TypedDict used to filter the results.\\n            - limit (int | None): The maximum number of results to return.\\n            - where_document_filter (chroma_types.WhereDocument | None): A TypedDict used to filter the results by the document,\\n                e.g. `{$contains: {\\\"text\\\": \\\"hello\\\"}}`\\n            - include_in_result (chroma_types.Include | None): A list used of what to return from the results, e.g. `[\\\"metadatas\\\", \\\"embeddings\\\", \\\"documents\\\"]`\\n\\n        Returns:\\n            - embeddings (TypedDict): A typed dict of embedding data from the collection with the following keys:\\n                - ids: list[str]\\n                - embeddings: list[Embedding] | None\\n                - documents: list[str] | None\\n                - uris: chroma_types.URIs | None\\n                - data: chroma_types.Loadable | None\\n                - metadatas: list[chroma_types.Metadata]]\\n\\n        Raises:\\n            - ValueError: If the length of ids, embeddings, metadatas, or documents don't match.\\n            - ValueError: If you provide an id that doesn't exist.\\n\\n        Examples:\\n            ```Python\\n            import postcode.types.chromadb.types as chroma_types\\n\\n            # define the ids, filters to use to get embeddings from the collection\\n            ids: list[str] = [\\\"my_id\\\", \\\"my_id2\\\"]\\n            where_filter: chroma_types.Where = {\\\"my_metadata\\\": \\\"my_metadata_value\\\"}\\n            where_document_filter: chroma_types.WhereDocument = {\\\"$contains\\\": {\\\"text\\\": \\\"hello\\\"}}\\n\\n            # define the data to return from the collection\\n            include_in_result: chroma_types.Include = [\\\"metadatas\\\"]\\n\\n            # get the embeddings from the collection\\n            embeddings: chroma_types.GetResult = collection_manager.get_embeddings(\\n                ids,\\n                where_filter=where_filter,\\n                where_document_filter=where_document_filter,\\n                include_in_result=include_in_result\\n                )\\n            ```\\n        \\\"\\\"\\\"\\n\\n        try:\\n            logging.info(f\\\"Getting embeddings from collection {self.collection.name}\\\")\\n            return self.collection.get(\\n                ids,\\n                where=where_filter,\\n                limit=limit,\\n                where_document=where_document_filter,\\n                include=include_in_result,\\n            )\\n        except Exception as exception:\\n            raise exception\\n\\n    def query_collection(\\n        self,\\n        queries: list[str],\\n        n_results: int = 10,\\n        where_filter: Where | None = None,\\n        where_document_filter: WhereDocument | None = None,\\n        include_in_result: Include = [\\\"metadatas\\\", \\\"documents\\\"],\\n    ) -> QueryResult | None:\\n        \\\"\\\"\\\"\\n        Queries and returns the `n` nearest neighbors from the collection.\\n\\n        Args:\\n            - queries (list[str]): A list of queries to search the collection for.\\n            - n_results (int): The number of results to return.\\n            - where_filter (chroma_types.Where | None): A TypedDict used to filter the results.\\n                - e.g. `{\\\"block_type\\\": \\\"FUNCTION\\\", \\\"children\\\": None}`\\n            - where_document_filter (chroma_types.WhereDocument | None): A TypedDict used to filter the results by the document,\\n                - e.g. `{$contains: \\\"binary search\\\"}`\\n            - include_in_result (chroma_types.Include | None): A list used of what to return from the results, e.g. `[\\\"metadatas\\\", \\\"embeddings\\\", \\\"documents\\\"]`\\n\\n        Returns:\\n            - results (chroma_types.QueryResult | None): A typed dict of query results from the collection, can have the following keys based on the\\n                `include_in_result` parameter:\\n                - ids: list[str] # The ids are always returned.\\n                - embeddings: List[list[Embedding]] | None\\n                - documents: list[list[str]]] | None\\n                - uris: list[list[URI]]] | None\\n                - data: list[Loadable] | None\\n                - metadatas: list[list[Metadata]] | None\\n                - distances: list[list[float]] | None\\n\\n        Raises:\\n            - ValueError: If you don't provide query_texts.\\n\\n        Examples:\\n            ```Python\\n            import postcode.types.chromadb.types as chroma\\n\\n            # define the queries and filters used to search the collection\\n            queries: list[str] = [\\\"binary search\\\", \\\"linear search\\\"]\\n            where_filter: chroma_types.Where = {\\\"block_type\\\": \\\"FUNCTION\\\"}\\n\\n            # define the data to return from the collection\\n            include_in_result: chroma_types.Include = [\\\"metadatas\\\", \\\"documents\\\", \\\"distances\\\"]\\n\\n            # query the collection and return the results from the collection\\n            results: chroma_types.QueryResult = collection_manager.query_collection(\\n                queries,\\n                where_filter=where_filter,\\n                include_in_result=include_in_result\\n                )\\n            ```\\n        \\\"\\\"\\\"\\n\\n        try:\\n            logging.info(f\\\"Querying collection {self.collection.name}\\\")\\n\\n            if results := self.collection.query(\\n                query_texts=queries,\\n                n_results=n_results,\\n                where=where_filter,\\n                where_document=where_document_filter,\\n                include=include_in_result,\\n            ):\\n                return results\\n            else:\\n                logging.warning(\\n                    f\\\"No results found from collection {self.collection.name}.\\\"\\n                )\\n\\n        except Exception as exception:\\n            raise exception\\n\\n    def modify_collection_name(self, name: str) -> None:\\n        \\\"\\\"\\\"\\n        Modifies the name of the collection managed by this class.\\n\\n        Args:\\n            - name (str): The new name to assign to the collection.\\n\\n        Examples:\\n            ```Python\\n            # Rename the collection to 'new_collection_name'\\n            collection_manager.modify_collection_name('new_collection_name')\\n            ```\\n        \\\"\\\"\\\"\\n\\n        self.collection.modify(name=name)\\n\\n    def modify_collection_metadata(\\n        self, metadata: dict[str, Any] | None = None\\n    ) -> None:\\n        \\\"\\\"\\\"\\n        Modifies the metadata of the collection managed by this class.\\n\\n        Args:\\n            - metadata (dict[str, Any] | None): The new metadata to assign to the collection. If None, no change is made.\\n\\n        Examples:\\n            ```Python\\n            # Update metadata of the collection\\n            new_metadata = {\\\"description\\\": \\\"Updated collection metadata\\\"}\\n            collection_manager.modify_collection_metadata(new_metadata)\\n            ```\\n        \\\"\\\"\\\"\\n\\n        self.collection.modify(metadata=metadata)\\n\\n    def _update_metadata_or_documents_by_ids(\\n        self,\\n        ids: list[str],\\n        metadatas: list[Mapping[str, str | int | float | bool]] | None = None,\\n        documents: list[str] | None = None,\\n    ) -> None:\\n        \\\"\\\"\\\"\\n        Updates the metadata or documents of specific entries in the collection by their ids.\\n\\n        Args:\\n            - ids (list[str]): List of ids of the entries to be updated.\\n            - metadatas (list[Mapping[str, Any]] | None): List of metadata updates corresponding to the ids.\\n            - documents (list[str] | None): List of document updates corresponding to the ids.\\n\\n        Raises:\\n            - ValueError: If neither metadatas nor documents are provided.\\n            - ValueError: If the length of ids and documents don't match.\\n            - ValueError: If the length of ids and metadatas don't match.\\n            - ValueError: If the length of ids, metadatas, and documents don't match.\\n\\n        Notes:\\n            - As of now, ChromaDB doesn't raise an exception if you provide an id that doesn't exist.\\n\\n        Examples:\\n            ```Python\\n            # Update metadata and documents for specific ids\\n            ids_to_update = ['id1', 'id2']\\n            metadata_updates = [{\\\"key1\\\": \\\"value1\\\"}, {\\\"key2\\\": \\\"value2\\\"}]\\n            document_updates = [\\\"new document 1\\\", \\\"new document 2\\\"]\\n            collection_manager.update_metadata_or_documents_by_ids(ids_to_update, metadata_updates, document_updates)\\n            ```\\n        \\\"\\\"\\\"\\n\\n        if not metadatas and not documents:\\n            raise ValueError(\\\"You must provide either metadatas or documents.\\\")\\n        if not metadatas and documents:\\n            if len(ids) != len(documents):\\n                raise ValueError(\\\"The length of ids and documents must match.\\\")\\n        if metadatas and not documents:\\n            if len(ids) != len(metadatas):\\n                raise ValueError(\\\"The length of ids and metadatas must match.\\\")\\n        if metadatas and documents:\\n            if len(ids) != len(metadatas) != len(documents):\\n                raise ValueError(\\n                    \\\"The length of ids, metadatas, and documents must match.\\\"\\n                )\\n        for index, id in enumerate(ids):\\n            if not self.collection.get(id):\\n                logging.error(\\n                    f\\\"Id {id} does not exist in collection {self.collection.name}.\\\"\\n                )\\n                ids.pop(index)\\n                if metadatas:\\n                    popped_metadata = metadatas.pop(index)\\n                    if popped_metadata:\\n                        logging.warning(\\n                            f\\\"Removing metadata at index {index} from update.\\\"\\n                        )\\n                if documents:\\n                    popped_document = documents.pop(index)\\n                    if popped_document:\\n                        logging.warning(\\n                            f\\\"Removing document at index {index} from update.\\\"\\n                        )\\n\\n        if not ids:\\n            logging.warning(\\\"All updates failed.\\\")\\n            return None\\n        else:\\n            logging.info(f\\\"Updating collection {self.collection.name} with ids {ids}.\\\")\\n            self.collection.update(ids=ids, metadatas=metadatas, documents=documents)\\n\\n    def _upsert_documents(\\n        self,\\n        ids: list[str],\\n        documents: list[str],\\n        metadatas: list[Mapping[str, str | int | float | bool]],\\n        # embeddings: list[chroma_types.Embedding],\\n    ) -> None:\\n        \\\"\\\"\\\"\\n        Inserts or updates documents in the collection, based on the provided ids.\\n\\n        Args:\\n            - ids (list[str]): List of ids for the documents to be inserted or updated.\\n            - documents (list[str]): List of documents corresponding to the ids.\\n            - metadatas (list[Mapping[str, Any]]): List of metadata corresponding to the ids.\\n\\n        Raises:\\n            - ValueError: If the lengths of ids, documents, and metadatas don't match.\\n\\n        Examples:\\n            ```Python\\n            # Upsert documents in the collection\\n            ids = ['id1', 'id2']\\n            documents = ['doc1', 'doc2']\\n            metadatas = [{\\\"meta1\\\": \\\"value1\\\"}, {\\\"meta2\\\": \\\"value2\\\"}]\\n\\n            # Upsert documents in the collection\\n            collection_manager.upsert_documents(ids, documents, metadatas)\\n            ```\\n        \\\"\\\"\\\"\\n\\n        if len(ids) != len(documents) != len(metadatas):\\n            raise ValueError(\\\"The length of ids, documents, and metadatas must match.\\\")\\n\\n        logging.info(f\\\"Upserting collection {self.collection.name} with ids {ids}.\\\")\\n        self.collection.upsert(\\n            ids=ids,\\n            # embeddings=embeddings,\\n            metadatas=metadatas,\\n            documents=documents,\\n        )\\n\\n    def delete_embeddings(self, ids: list[str]) -> None:\\n        \\\"\\\"\\\"\\n        Deletes embeddings from the collection based on the provided ids.\\n\\n        Args:\\n            - ids (list[str]): List of ids corresponding to the embeddings to be deleted.\\n\\n        Examples:\\n            ```Python\\n            # Delete specific embeddings by ids\\n            ids_to_delete = ['id1', 'id2']\\n            collection_manager.delete_embeddings(ids_to_delete)\\n            ```\\n        \\\"\\\"\\\"\\n\\n        ids_to_delete: list[str] = ids.copy()\\n        for index, id in enumerate(ids_to_delete):\\n            if not self.collection.get(id):\\n                logging.error(\\n                    f\\\"Id {id} does not exist in collection {self.collection.name}.\\\"\\n                )\\n                ids_to_delete.pop(index)\\n\\n        if not ids_to_delete:\\n            logging.warning(\\\"No IDs given were in the database.\\\")\\n            return None\\n\\n        logging.info(\\n            f\\\"Deleting embeddings from collection {self.collection.name} with ids {ids_to_delete}.\\\"\\n        )\\n        self.collection.delete(ids_to_delete)\\n\\n    def upsert_models(self, module_models: tuple[ModuleModel, ...]) -> None:\\n        \\\"\\\"\\\"\\n        Loads or updates the embeddings of the provided module models into the collection.\\n\\n        The Pydantic models are converted to a dictionary with a format that ChromaDB can use, then the ids, documents, and metadatas\\n        are added to their respective lists. The lists are then either added to or updated in the collection depending on whether or\\n        not the code blocks were in the the collection to begin with.\\n\\n        Args:\\n            - module_models (tuple[ModuleModel, ...]): The module models to load or update into the collection.\\n\\n        Examples:\\n            ```Python\\n            # Upsert module models into the collection\\n            module_models = (module_model1, module_model2)\\n            collection_manager.upsert_models(module_models)\\n            ```\\n        \\\"\\\"\\\"\\n\\n        ids: list[str] = []\\n        documents: list[str] = []\\n        metadatas: list[Mapping[str, str | int | float | bool]] = []\\n\\n        for module_model in module_models:\\n            if module_model.summary:\\n                ids.append(module_model.id)\\n                documents.append(module_model.summary)\\n                metadatas.append(module_model.convert_to_metadata())\\n\\n            if module_model.children:\\n                for child in module_model.children:\\n                    child_data: dict[str, Any] = self._recursively_gather_child_data(\\n                        child\\n                    )\\n                    ids.extend(child_data[\\\"ids\\\"])\\n                    documents.extend(child_data[\\\"documents\\\"])\\n                    metadatas.extend(child_data[\\\"metadatas\\\"])\\n\\n        logging.info(\\n            f\\\"{self.collection.name} has {self.collection_embedding_count()} embeddings.\\\"\\n        )\\n        self._upsert_documents(ids=ids, documents=documents, metadatas=metadatas)\\n        logging.info(\\n            f\\\"After upsert {self.collection.name} has {self.collection_embedding_count()} embeddings.\\\"\\n        )\\n\\n    def _recursively_gather_child_data(self, model: ModelType) -> dict[str, Any]:\\n        ids: list[str] = []\\n        documents: list[str] = []\\n        metadatas: list[Mapping[str, str | int | float | bool]] = []\\n        if model.summary:\\n            ids.append(model.id)\\n            documents.append(model.summary)\\n            metadatas.append(model.convert_to_metadata())\\n        else:\\n            logging.warning(f\\\"Child {model.id} has no summary.\\\")\\n        if model.children:\\n            for child in model.children:\\n                child_data: dict[str, Any] = self._recursively_gather_child_data(child)\\n                ids.extend(child_data[\\\"ids\\\"])\\n                documents.extend(child_data[\\\"documents\\\"])\\n                metadatas.extend(child_data[\\\"metadatas\\\"])\\n\\n        return {\\n            \\\"ids\\\": ids,\\n            \\\"documents\\\": documents,\\n            \\\"metadatas\\\": metadatas,\\n        }\\n\\n\\nImported code block (postcode:updaters:standard_updater.py__*__MODULE) code content:\\n# Create method, `update_all`, that updates the whole project, it parses all code, wipes all databases, and summarizes all code blocks,\\n# then updates all the databases with the new information.\\n\\n\\nfrom logging import Logger\\n\\nfrom openai import OpenAI\\nfrom postcode.ai_services.summarizer.openai_summarizer import OpenAISummarizer\\nfrom postcode.ai_services.summarizer.standard_summarization_manager import (\\n    StandardSummarizationManager,\\n)\\n\\nfrom postcode.databases.chroma.setup_chroma import (\\n    ChromaSetupReturnContext,\\n    setup_chroma,\\n)\\nfrom postcode.json_management.json_handler import JSONHandler\\n\\nfrom postcode.models.models import ModuleModel\\nfrom postcode.python_parser.visitor_manager.visitor_manager import (\\n    VisitorManager,\\n    VisitorManagerProcessFilesReturn,\\n)\\n\\n\\nclass StandardUpdater:\\n    @staticmethod\\n    def update_all(\\n        directory: str, output_directory: str, logger: Logger\\n    ) -> ChromaSetupReturnContext:\\n        visitor_manager = VisitorManager(directory, output_directory)\\n        process_files_return: VisitorManagerProcessFilesReturn = (\\n            visitor_manager.process_files()\\n        )\\n\\n        module_models_tuple: tuple[ModuleModel, ...] = process_files_return.models_tuple\\n        client = OpenAI(max_retries=4)\\n        summarizer = OpenAISummarizer(client=client)\\n        summarization_manager = StandardSummarizationManager(\\n            module_models_tuple, summarizer\\n        )\\n        finalized_module_models: tuple[\\n            ModuleModel, ...\\n        ] = summarization_manager.create_summarizes_and_return_updated_models()\\n\\n        logger.info(\\\"Summarization complete\\\")\\n\\n        logger.info(\\\"Saving models as JSON\\\")\\n        directory_modules: dict[str, list[str]] = process_files_return.directory_modules\\n        json_manager = JSONHandler(directory, directory_modules, output_directory)\\n\\n        for module_model in module_models_tuple:\\n            json_manager.save_model_as_json(module_model, module_model.file_path)\\n\\n        json_manager.save_visited_directories()\\n        logger.info(\\\"JSON save complete\\\")\\n\\n        logger.info(\\\"Directory parsing completed.\\\")\\n\\n        chroma_context: ChromaSetupReturnContext = setup_chroma(\\n            finalized_module_models, logger\\n        )\\n\\n        return chroma_context\\n\\n, \\nimport logging\\nfrom logging import Logger\\nfrom typing import Union\\nfrom chromadb.api.types import QueryResult\\nfrom chromadb import Collection\\n        \",\"children\":[{\"variable_assignments\":[\"ModelType = Union[\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n]\"],\"id\":\"postcode:app.py__*__MODULE__*__STANDALONE_BLOCK-1\",\"parent_id\":\"postcode:app.py__*__MODULE\",\"block_type\":\"STANDALONE_BLOCK\",\"start_line_num\":16,\"end_line_num\":23,\"code_content\":\"ModelType = Union[\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n]\\n\",\"important_comments\":null,\"dependencies\":[{\"import_names\":[{\"name\":\"Union\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"typing\",\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"},{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ClassModel\"},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-FunctionModel\"},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-StandaloneCodeBlockModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"},{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ClassModel\"},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-FunctionModel\"},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-StandaloneCodeBlockModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"},{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ClassModel\"},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-FunctionModel\"},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-StandaloneCodeBlockModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"},{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ClassModel\"},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-FunctionModel\"},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-StandaloneCodeBlockModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"}],\"summary\":null,\"children\":null},{\"function_name\":\"query_chroma\",\"docstring\":null,\"decorators\":null,\"parameters\":null,\"returns\":\"None\",\"is_method\":false,\"is_async\":false,\"id\":\"postcode:app.py__*__MODULE__*__FUNCTION-query_chroma\",\"parent_id\":\"postcode:app.py__*__MODULE\",\"block_type\":\"FUNCTION\",\"start_line_num\":36,\"end_line_num\":58,\"code_content\":\"\\n\\ndef query_chroma(\\n    query: str,\\n    chroma_collection_manager: ChromaDBCollectionManager,\\n    chroma_collection: Collection,\\n    logger: Logger,\\n) -> None:\\n    logger.info(f\\\"Querying ChromaDB collection {chroma_collection.name}\\\")\\n    results: QueryResult | None = chroma_collection_manager.query_collection(\\n        [query],\\n        n_results=10,\\n        # where_filter={\\\"block_type\\\": \\\"MODULE\\\"},\\n        include_in_result=[\\\"metadatas\\\", \\\"documents\\\", \\\"embeddings\\\"],\\n    )\\n    logger.info(\\\"Query results:\\\")\\n    if results:\\n        if results[\\\"ids\\\"]:\\n            for document in results[\\\"ids\\\"][0]:\\n                print(document)\\n\\n            print(f\\\"Total results: {len(results['ids'][0])}\\\")\\n\",\"important_comments\":null,\"dependencies\":[{\"import_names\":[{\"name\":\"Logger\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"logging\",\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"ChromaDBCollectionManager\",\"as_name\":null,\"local_block_id\":\"postcode:databases:chroma:chromadb_collection_manager.py__*__MODULE__*__CLASS-ChromaDBCollectionManager\"}],\"imported_from\":\"postcode.databases.chroma.chromadb_collection_manager\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:databases:chroma:chromadb_collection_manager.py__*__MODULE\"},{\"import_names\":[{\"name\":\"QueryResult\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"chromadb.api.types\",\"import_module_type\":\"THIRD_PARTY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"Collection\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"chromadb\",\"import_module_type\":\"THIRD_PARTY\",\"local_module_id\":null}],\"summary\":null,\"children\":null},{\"function_name\":\"main\",\"docstring\":null,\"decorators\":null,\"parameters\":null,\"returns\":\"None\",\"is_method\":false,\"is_async\":false,\"id\":\"postcode:app.py__*__MODULE__*__FUNCTION-main\",\"parent_id\":\"postcode:app.py__*__MODULE\",\"block_type\":\"FUNCTION\",\"start_line_num\":58,\"end_line_num\":87,\"code_content\":\"\\n\\ndef main(\\n    directory: str = \\\".\\\",\\n    output_directory: str = \\\"output_json\\\",\\n) -> None:\\n    setup_logging()\\n    logger: Logger = logging.getLogger(__name__)\\n\\n    #   ==================== GraphDB ====================\\n    graph_db_updater = GraphDBUpdater(directory, output_directory, logger)\\n    chroma_context: ChromaSetupReturnContext = graph_db_updater.update_all(\\n        directory, output_directory, logger\\n    )\\n    # ==================== End GraphDB ====================\\n\\n    #   ==================== Standard ====================\\n    # chroma_context: ChromaSetupReturnContext = StandardUpdater.update_all(\\n    #     directory, output_directory, logger\\n    # )\\n    # ==================== End Standard ====================\\n\\n    query: str = \\\"summarizes code block\\\"\\n    query_chroma(\\n        query,\\n        chroma_context.chroma_collection_manager,\\n        chroma_context.chroma_collection,\\n        logger,\\n    )\\n\",\"important_comments\":null,\"dependencies\":[{\"code_block_id\":\"postcode:app.py__*__MODULE__*__FUNCTION-query_chroma\"},{\"import_names\":[{\"name\":\"logging\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":null,\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"Logger\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"logging\",\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"ChromaSetupReturnContext\",\"as_name\":null,\"local_block_id\":\"postcode:databases:chroma:setup_chroma.py__*__MODULE__*__CLASS-ChromaSetupReturnContext\"}],\"imported_from\":\"postcode.databases.chroma.setup_chroma\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:databases:chroma:setup_chroma.py__*__MODULE\"},{\"import_names\":[{\"name\":\"GraphDBUpdater\",\"as_name\":null,\"local_block_id\":\"postcode:updaters:graph_db_updater.py__*__MODULE__*__CLASS-GraphDBUpdater\"}],\"imported_from\":\"postcode.updaters.graph_db_updater\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:updaters:graph_db_updater.py__*__MODULE\"},{\"import_names\":[{\"name\":\"setup_logging\",\"as_name\":null,\"local_block_id\":\"postcode:utilities:logger:logging_config.py__*__MODULE__*__FUNCTION-setup_logging\"}],\"imported_from\":\"postcode.utilities.logger.logging_config\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:utilities:logger:logging_config.py__*__MODULE\"},{\"import_names\":[{\"name\":\"StandardUpdater\",\"as_name\":null,\"local_block_id\":\"postcode:updaters:standard_updater.py__*__MODULE__*__CLASS-StandardUpdater\"}],\"imported_from\":\"postcode.updaters.standard_updater\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:updaters:standard_updater.py__*__MODULE\"}],\"summary\":null,\"children\":null}]}", "footer": "{\"file_path\":\"postcode/app.py\",\"docstring\":null,\"header\":[],\"footer\":[],\"imports\":[{\"import_names\":[{\"name\":\"logging\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":null,\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"Logger\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"logging\",\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"Union\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"typing\",\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"QueryResult\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"chromadb.api.types\",\"import_module_type\":\"THIRD_PARTY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"Collection\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"chromadb\",\"import_module_type\":\"THIRD_PARTY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"},{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ClassModel\"},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-FunctionModel\"},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-StandaloneCodeBlockModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ChromaSetupReturnContext\",\"as_name\":null,\"local_block_id\":\"postcode:databases:chroma:setup_chroma.py__*__MODULE__*__CLASS-ChromaSetupReturnContext\"}],\"imported_from\":\"postcode.databases.chroma.setup_chroma\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:databases:chroma:setup_chroma.py__*__MODULE\"},{\"import_names\":[{\"name\":\"GraphDBUpdater\",\"as_name\":null,\"local_block_id\":\"postcode:updaters:graph_db_updater.py__*__MODULE__*__CLASS-GraphDBUpdater\"}],\"imported_from\":\"postcode.updaters.graph_db_updater\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:updaters:graph_db_updater.py__*__MODULE\"},{\"import_names\":[{\"name\":\"setup_logging\",\"as_name\":null,\"local_block_id\":\"postcode:utilities:logger:logging_config.py__*__MODULE__*__FUNCTION-setup_logging\"}],\"imported_from\":\"postcode.utilities.logger.logging_config\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:utilities:logger:logging_config.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ChromaDBCollectionManager\",\"as_name\":null,\"local_block_id\":\"postcode:databases:chroma:chromadb_collection_manager.py__*__MODULE__*__CLASS-ChromaDBCollectionManager\"}],\"imported_from\":\"postcode.databases.chroma.chromadb_collection_manager\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:databases:chroma:chromadb_collection_manager.py__*__MODULE\"},{\"import_names\":[{\"name\":\"StandardUpdater\",\"as_name\":null,\"local_block_id\":\"postcode:updaters:standard_updater.py__*__MODULE__*__CLASS-StandardUpdater\"}],\"imported_from\":\"postcode.updaters.standard_updater\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:updaters:standard_updater.py__*__MODULE\"}],\"id\":\"postcode:app.py__*__MODULE\",\"parent_id\":null,\"block_type\":\"MODULE\",\"start_line_num\":1,\"end_line_num\":87,\"code_content\":\"import logging\\nfrom logging import Logger\\nfrom typing import Union\\n\\nfrom postcode.models.models import (\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n)\\n\\nfrom postcode.databases.chroma.setup_chroma import (\\n    ChromaSetupReturnContext,\\n)\\nfrom postcode.updaters.graph_db_updater import GraphDBUpdater\\n\\nModelType = Union[\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n]\\n\\nfrom postcode.utilities.logger.logging_config import setup_logging\\n\\nfrom postcode.databases.chroma.chromadb_collection_manager import (\\n    ChromaDBCollectionManager,\\n)\\n\\nfrom chromadb.api.types import (\\n    QueryResult,\\n)\\nfrom chromadb import Collection\\n\\nfrom postcode.updaters.standard_updater import StandardUpdater\\n\\n\\ndef query_chroma(\\n    query: str,\\n    chroma_collection_manager: ChromaDBCollectionManager,\\n    chroma_collection: Collection,\\n    logger: Logger,\\n) -> None:\\n    logger.info(f\\\"Querying ChromaDB collection {chroma_collection.name}\\\")\\n    results: QueryResult | None = chroma_collection_manager.query_collection(\\n        [query],\\n        n_results=10,\\n        # where_filter={\\\"block_type\\\": \\\"MODULE\\\"},\\n        include_in_result=[\\\"metadatas\\\", \\\"documents\\\", \\\"embeddings\\\"],\\n    )\\n    logger.info(\\\"Query results:\\\")\\n    if results:\\n        if results[\\\"ids\\\"]:\\n            for document in results[\\\"ids\\\"][0]:\\n                print(document)\\n\\n            print(f\\\"Total results: {len(results['ids'][0])}\\\")\\n\\n\\ndef main(\\n    directory: str = \\\".\\\",\\n    output_directory: str = \\\"output_json\\\",\\n) -> None:\\n    setup_logging()\\n    logger: Logger = logging.getLogger(__name__)\\n\\n    #   ==================== GraphDB ====================\\n    graph_db_updater = GraphDBUpdater(directory, output_directory, logger)\\n    chroma_context: ChromaSetupReturnContext = graph_db_updater.update_all(\\n        directory, output_directory, logger\\n    )\\n    # ==================== End GraphDB ====================\\n\\n    #   ==================== Standard ====================\\n    # chroma_context: ChromaSetupReturnContext = StandardUpdater.update_all(\\n    #     directory, output_directory, logger\\n    # )\\n    # ==================== End Standard ====================\\n\\n    query: str = \\\"summarizes code block\\\"\\n    query_chroma(\\n        query,\\n        chroma_context.chroma_collection_manager,\\n        chroma_context.chroma_collection,\\n        logger,\\n    )\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":\"\\nSummary:\\n\\n        postcode:app.py__*__MODULE\\n\\n        \\nChild (postcode:app.py__*__MODULE__*__STANDALONE_BLOCK-1) code content:\\nModelType = Union[\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n]\\n\\n\\nChild (postcode:app.py__*__MODULE__*__FUNCTION-query_chroma) code content:\\n\\n\\ndef query_chroma(\\n    query: str,\\n    chroma_collection_manager: ChromaDBCollectionManager,\\n    chroma_collection: Collection,\\n    logger: Logger,\\n) -> None:\\n    logger.info(f\\\"Querying ChromaDB collection {chroma_collection.name}\\\")\\n    results: QueryResult | None = chroma_collection_manager.query_collection(\\n        [query],\\n        n_results=10,\\n        # where_filter={\\\"block_type\\\": \\\"MODULE\\\"},\\n        include_in_result=[\\\"metadatas\\\", \\\"documents\\\", \\\"embeddings\\\"],\\n    )\\n    logger.info(\\\"Query results:\\\")\\n    if results:\\n        if results[\\\"ids\\\"]:\\n            for document in results[\\\"ids\\\"][0]:\\n                print(document)\\n\\n            print(f\\\"Total results: {len(results['ids'][0])}\\\")\\n\\n\\nChild (postcode:app.py__*__MODULE__*__FUNCTION-main) code content:\\n\\n\\ndef main(\\n    directory: str = \\\".\\\",\\n    output_directory: str = \\\"output_json\\\",\\n) -> None:\\n    setup_logging()\\n    logger: Logger = logging.getLogger(__name__)\\n\\n    #   ==================== GraphDB ====================\\n    graph_db_updater = GraphDBUpdater(directory, output_directory, logger)\\n    chroma_context: ChromaSetupReturnContext = graph_db_updater.update_all(\\n        directory, output_directory, logger\\n    )\\n    # ==================== End GraphDB ====================\\n\\n    #   ==================== Standard ====================\\n    # chroma_context: ChromaSetupReturnContext = StandardUpdater.update_all(\\n    #     directory, output_directory, logger\\n    # )\\n    # ==================== End Standard ====================\\n\\n    query: str = \\\"summarizes code block\\\"\\n    query_chroma(\\n        query,\\n        chroma_context.chroma_collection_manager,\\n        chroma_context.chroma_collection,\\n        logger,\\n    )\\n\\n, \\nImported code block (postcode:models:models.py__*__MODULE) code content:\\nfrom typing import Union\\nfrom pydantic import BaseModel, Field, validator\\n\\nfrom postcode.models.enums import (\\n    BlockType,\\n    ImportModuleType,\\n    CommentType,\\n)\\n\\n\\nclass ImportNameModel(BaseModel):\\n    \\\"\\\"\\\"Class representing the name of an import.\\\"\\\"\\\"\\n\\n    name: str\\n    as_name: str | None = None\\n    local_block_id: str | None = None\\n\\n    # def convert_import_names_to_metadata(self) -> str:\\n    #     \\\"\\\"\\\"Converts the import name to a metadata string.\\\"\\\"\\\"\\n\\n    #     return self.model_dump_json()\\n\\n\\nclass ImportModel(BaseModel):\\n    \\\"\\\"\\\"Class representing an import statement.\\\"\\\"\\\"\\n\\n    import_names: list[ImportNameModel]\\n    imported_from: str | None = None\\n    import_module_type: ImportModuleType = ImportModuleType.STANDARD_LIBRARY\\n    local_module_id: str | None = None\\n\\n    def convert_import_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the import to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass DependencyModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a module dependency.\\\"\\\"\\\"\\n\\n    code_block_id: str\\n\\n    def convert_dependency_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the dependency to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass CommentModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a comment.\\\"\\\"\\\"\\n\\n    content: str\\n    comment_types: list[CommentType]\\n\\n    def convert_comment_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the comment to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass DecoratorModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a decorator.\\\"\\\"\\\"\\n\\n    content: str\\n    decorator_name: str\\n    decorator_args: list[str] | None = None\\n\\n    def convert_decorator_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the decorator to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass ClassKeywordModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a class keyword.\\\"\\\"\\\"\\n\\n    content: str\\n    keyword_name: str\\n    args: str | None = None\\n\\n    def convert_class_keyword_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the class keyword to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass ParameterModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a function parameter.\\\"\\\"\\\"\\n\\n    content: str\\n\\n\\nclass ParameterListModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a list of parameters.\\\"\\\"\\\"\\n\\n    params: list[ParameterModel] | None = None\\n    star_arg: ParameterModel | None = None\\n    kwonly_params: list[ParameterModel] | None = None\\n    star_kwarg: ParameterModel | None = None\\n    posonly_params: list[ParameterModel] | None = None\\n\\n    def convert_parameters_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the parameter list to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass BaseCodeBlockModel(BaseModel):\\n    \\\"\\\"\\\"Attributes common to all code block models.\\\"\\\"\\\"\\n\\n    id: str\\n    parent_id: str | None = None\\n    block_type: BlockType\\n    start_line_num: int\\n    end_line_num: int\\n    code_content: str = \\\"\\\"\\n    important_comments: list[CommentModel] | None = None\\n    dependencies: list[ImportModel | DependencyModel] | None = None\\n    summary: str | None = None\\n    children: list[\\n        Union[\\n            \\\"ClassModel\\\",\\n            \\\"FunctionModel\\\",\\n            \\\"StandaloneCodeBlockModel\\\",\\n        ]\\n    ] | None = []\\n\\n    @validator(\\\"parent_id\\\", always=True)\\n    def check_parent_id(cls, v, values, **kwargs) -> str | None:\\n        \\\"\\\"\\\"Validates that parent_id is a non-empty string unless block_type is MODULE.\\\"\\\"\\\"\\n\\n        if \\\"block_type\\\" in values and values[\\\"block_type\\\"] != BlockType.MODULE:\\n            if len(v) < 1:\\n                raise ValueError(\\\"parent_id is required!\\\")\\n        return v\\n\\n    def _convert_parent_id_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the parent_id to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.parent_id}\\\" if self.parent_id else \\\"\\\"\\n\\n    def _convert_block_type_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the block_type to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.block_type.name}\\\"\\n\\n    def _convert_important_comments_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the important comments to a metadata string.\\\"\\\"\\\"\\n\\n        important_comments: str = (\\n            self.model_dump_json() if self.important_comments else \\\"\\\"\\n        )\\n\\n        return f\\\"{important_comments}\\\"\\n\\n    def _convert_dependencies_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the dependencies to a metadata string.\\\"\\\"\\\"\\n\\n        dependencies_str: str = \\\"\\\"\\n\\n        if self.dependencies:\\n            for dependency in self.dependencies:\\n                if isinstance(dependency, ImportModel):\\n                    dependencies_str += f\\\"{dependency.convert_import_to_metadata()}\\\\n\\\"\\n                elif isinstance(dependency, DependencyModel):\\n                    dependencies_str += (\\n                        f\\\"{dependency.convert_dependency_to_metadata()}\\\\n\\\"\\n                    )\\n\\n        return dependencies_str\\n\\n    def _convert_summary_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the summary to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.summary}\\\" if self.summary else \\\"\\\"\\n\\n    def _convert_children_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the children to a metadata string.\\\"\\\"\\\"\\n\\n        children_str: str = \\\"\\\"\\n\\n        if self.children:\\n            for child in self.children:\\n                children_str += f\\\"{child.id}\\\\n\\\"\\n\\n        return children_str\\n\\n    def _convert_base_attributes_to_metadata_dict(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the base attributes to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            \\\"id\\\": self.id,\\n            \\\"parent_id\\\": self._convert_parent_id_to_metadata(),\\n            \\\"block_type\\\": self._convert_block_type_to_metadata(),\\n            \\\"start_line_num\\\": self.start_line_num,\\n            \\\"end_line_num\\\": self.end_line_num,\\n            \\\"code_content\\\": self.code_content,\\n            \\\"important_comments\\\": self._convert_important_comments_to_metadata(),\\n            \\\"dependencies\\\": self._convert_dependencies_to_metadata(),\\n            \\\"summary\\\": self._convert_summary_to_metadata(),\\n            \\\"children\\\": self._convert_children_to_metadata(),\\n        }\\n\\n\\nclass ModuleSpecificAttributes(BaseModel):\\n    \\\"\\\"\\\"Module specific attributes.\\\"\\\"\\\"\\n\\n    file_path: str = Field(min_length=1)\\n    docstring: str | None = None\\n    header: list[str] | None = None\\n    footer: list[str] | None = None\\n    imports: list[ImportModel] | None = None\\n\\n    def _convert_docstring_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the docstring to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.docstring}\\\"\\n\\n    def _convert_header_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the header and footer to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n    def _convert_footer_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the header and footer to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n    def _convert_imports_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the imports to a metadata string.\\\"\\\"\\\"\\n        imports_str: str = self.model_dump_json() if self.imports else \\\"\\\"\\n        return f\\\"{imports_str}\\\"\\n\\n    def _convert_module_attributes_to_metadata_dict(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the module attributes to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            \\\"file_path\\\": self.file_path,\\n            \\\"docstring\\\": self._convert_docstring_to_metadata(),\\n            \\\"header\\\": self._convert_header_to_metadata(),\\n            \\\"footer\\\": self._convert_footer_to_metadata(),\\n            \\\"imports\\\": self._convert_imports_to_metadata(),\\n        }\\n\\n\\nclass ModuleModel(BaseCodeBlockModel, ModuleSpecificAttributes):\\n    \\\"\\\"\\\"Model for a module.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the module model to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_module_attributes_to_metadata_dict(),\\n        }\\n\\n\\nclass ClassSpecificAttributes(BaseModel):\\n    \\\"\\\"\\\"Class specific attributes.\\\"\\\"\\\"\\n\\n    class_name: str = Field(min_length=1)\\n    decorators: list[DecoratorModel] | None = None\\n    bases: list[str] | None = None\\n    docstring: str | None = None\\n    keywords: list[ClassKeywordModel] | None = None\\n    # attributes: list[dict] | None = None\\n\\n    def _convert_decorators_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the decorators to a metadata string.\\\"\\\"\\\"\\n        decorators_str: str = self.model_dump_json() if self.decorators else \\\"\\\"\\n        return f\\\"{decorators_str}\\\"\\n\\n    def _convert_bases_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the bases to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json() if self.bases else \\\"\\\"\\n\\n    def _convert_docstring_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the docstring to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.docstring}\\\" if self.docstring else \\\"\\\"\\n\\n    def _convert_keywords_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the keywords to a metadata string.\\\"\\\"\\\"\\n        keywords_str: str = self.model_dump_json() if self.keywords else \\\"\\\"\\n        return f\\\"{keywords_str}\\\"\\n\\n    def _convert_class_attributes_to_metadata_dict(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the class attributes to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            \\\"class_name\\\": self.class_name,\\n            \\\"decorators\\\": self._convert_decorators_to_metadata(),\\n            \\\"bases\\\": self._convert_bases_to_metadata(),\\n            \\\"docstring\\\": self._convert_docstring_to_metadata(),\\n            \\\"keywords\\\": self._convert_keywords_to_metadata(),\\n        }\\n\\n\\nclass ClassModel(BaseCodeBlockModel, ClassSpecificAttributes):\\n    \\\"\\\"\\\"Model for a class.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the class model to a metadata dictionary.\\\"\\\"\\\"\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_class_attributes_to_metadata_dict(),\\n        }\\n\\n\\nclass FunctionSpecificAttributes(BaseModel):\\n    \\\"\\\"\\\"Function specific attributes.\\\"\\\"\\\"\\n\\n    function_name: str = Field(min_length=1)\\n    docstring: str | None = None\\n    decorators: list[DecoratorModel] | None = None\\n    parameters: ParameterListModel | None = None\\n    returns: str | None = None\\n    is_method: bool = False\\n    is_async: bool = False\\n\\n    def _convert_docstring_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the docstring to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.docstring}\\\" if self.docstring else \\\"\\\"\\n\\n    def _convert_decorators_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the decorators to a metadata string.\\\"\\\"\\\"\\n        decorators_str: str = self.model_dump_json() if self.decorators else \\\"\\\"\\n        return f\\\"{decorators_str}\\\"\\n\\n    def _convert_parameters_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the parameters to a metadata string.\\\"\\\"\\\"\\n        return (\\n            self.parameters.convert_parameters_to_metadata() if self.parameters else \\\"\\\"\\n        )\\n\\n    def _convert_returns_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the returns to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.returns}\\\" if self.returns else \\\"\\\"\\n\\n    def _convert_function_attributes_to_metadata_dict(self) -> dict[str, str | bool]:\\n        \\\"\\\"\\\"Converts the function attributes to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            \\\"function_name\\\": self.function_name,\\n            \\\"docstring\\\": self._convert_docstring_to_metadata(),\\n            \\\"decorators\\\": self._convert_decorators_to_metadata(),\\n            \\\"parameters\\\": self._convert_parameters_to_metadata(),\\n            \\\"returns\\\": self._convert_returns_to_metadata(),\\n            \\\"is_method\\\": self.is_method,\\n            \\\"is_async\\\": self.is_async,\\n        }\\n\\n\\nclass FunctionModel(BaseCodeBlockModel, FunctionSpecificAttributes):\\n    \\\"\\\"\\\"Model for a function.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the function model to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_function_attributes_to_metadata_dict(),\\n        }\\n\\n\\nclass StandaloneCodeBlockSpecificAttributes(BaseModel):\\n    \\\"\\\"\\\"Standalone code block specific attributes.\\\"\\\"\\\"\\n\\n    variable_assignments: list[str] | None = None\\n\\n    def _convert_variable_assignments_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the variable assignments to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json() if self.variable_assignments else \\\"\\\"\\n\\n    def _convert_standalone_block_attributes_to_metadata_dict(\\n        self,\\n    ) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the standalone code block attributes to a metadata dictionary.\\\"\\\"\\\"\\n        return {\\n            \\\"variable_assignments\\\": self._convert_variable_assignments_to_metadata(),\\n        }\\n\\n\\nclass StandaloneCodeBlockModel(\\n    BaseCodeBlockModel, StandaloneCodeBlockSpecificAttributes\\n):\\n    \\\"\\\"\\\"Model for a standalone code block.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the standalone code block model to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_standalone_block_attributes_to_metadata_dict(),\\n        }\\n\\n\\nImported code block (postcode:databases:chroma:setup_chroma.py__*__MODULE) code content:\\nfrom dataclasses import dataclass\\nfrom logging import Logger\\n\\nimport chromadb\\nfrom postcode.databases.chroma.chromadb_client_manager import ChromaDBClientManager\\n\\nfrom postcode.databases.chroma.chromadb_collection_manager import (\\n    ChromaDBCollectionManager,\\n)\\n\\nfrom chromadb.config import DEFAULT_DATABASE, DEFAULT_TENANT, Settings\\nfrom chromadb.api import ClientAPI\\nfrom chromadb.api.types import (\\n    DataLoader,\\n    CollectionMetadata,\\n    GetResult,\\n    QueryResult,\\n    Where,\\n    WhereDocument,\\n    Include,\\n    URIs,\\n    Loadable,\\n    Metadata,\\n    Embedding,\\n)\\nfrom chromadb import Collection\\nfrom chromadb import EmbeddingFunction\\n\\nfrom postcode.models.models import ModuleModel\\n\\n\\n@dataclass\\nclass ChromaSetupReturnContext:\\n    \\\"\\\"\\\"\\n    Represents the return value of the ChromaDB setup method.\\n\\n    Attributes:\\n        - chroma_collection_manager (ChromaDBCollectionManager): The ChromaDB collection manager.\\n        - chroma_collection (Collection): The ChromaDB collection.\\n    \\\"\\\"\\\"\\n\\n    chroma_collection_manager: ChromaDBCollectionManager\\n    chroma_collection: Collection\\n\\n\\ndef setup_chroma(\\n    module_models: list[ModuleModel], logger: Logger\\n) -> ChromaSetupReturnContext:\\n    chroma_settings = Settings(allow_reset=True)\\n    chroma_client: ClientAPI = chromadb.PersistentClient(settings=chroma_settings)\\n    chroma_client_manager = ChromaDBClientManager(chroma_client)\\n\\n    logger.debug(f\\\"Resetting Chroma client\\\")\\n    if chroma_client_manager.reset_client():\\n        logger.debug(\\\"Client reset\\\")\\n\\n    chroma_collection: Collection = chroma_client_manager.get_or_create_collection(\\n        \\\"postcode\\\"\\n    )\\n\\n    chroma_collection_manager = ChromaDBCollectionManager(chroma_collection)\\n    chroma_collection_manager.upsert_models(tuple(module_models))\\n\\n    return ChromaSetupReturnContext(chroma_collection_manager, chroma_collection)\\n\\n\\nImported code block (postcode:updaters:graph_db_updater.py__*__MODULE) code content:\\nfrom logging import Logger\\n\\nfrom openai import OpenAI\\nfrom postcode.ai_services.summarizer.graph_db_summarization_manager import (\\n    GraphDBSummarizationManager,\\n)\\nfrom postcode.ai_services.summarizer.openai_summarizer import OpenAISummarizer\\nfrom postcode.ai_services.summarizer.summarization_mapper import SummarizationMapper\\nfrom postcode.databases.arangodb.arangodb_connector import ArangoDBConnector\\n\\nfrom postcode.databases.arangodb.arangodb_manager import ArangoDBManager\\nfrom postcode.databases.chroma.setup_chroma import (\\n    ChromaSetupReturnContext,\\n    setup_chroma,\\n)\\nfrom postcode.json_management.json_handler import JSONHandler\\nfrom postcode.models.models import ModuleModel\\nfrom postcode.python_parser.visitor_manager.visitor_manager import (\\n    VisitorManager,\\n    VisitorManagerProcessFilesReturn,\\n)\\n\\n\\nclass GraphDBUpdater:\\n    def __init__(\\n        self,\\n        directory: str,\\n        output_directory: str,\\n        logger: Logger,\\n        arango_connector: ArangoDBConnector = ArangoDBConnector(),\\n    ) -> None:\\n        self.directory: str = directory\\n        self.output_directory: str = output_directory\\n        self.logger: Logger = logger\\n        self.arango_connector: ArangoDBConnector = arango_connector\\n\\n        self.arango_connector.delete_all_collections()\\n        self.arango_connector.ensure_collections()\\n        self.graph_manager = ArangoDBManager(arango_connector)\\n\\n    def update_all(\\n        self,\\n        directory: str,\\n        output_directory: str,\\n        logger: Logger,\\n    ) -> ChromaSetupReturnContext:\\n        logger.info(\\\"Starting the directory parsing.\\\")\\n\\n        visitor_manager = VisitorManager(directory, output_directory)\\n        process_files_return: VisitorManagerProcessFilesReturn = (\\n            visitor_manager.process_files()\\n        )\\n\\n        module_models_tuple: tuple[ModuleModel, ...] = process_files_return.models_tuple\\n        module_ids: list[str] = [model.id for model in module_models_tuple]\\n        directory_modules: dict[str, list[str]] = process_files_return.directory_modules\\n        self.graph_manager.upsert_models(\\n            list(module_models_tuple)\\n        ).process_imports_and_dependencies().get_or_create_graph()\\n        summarization_mapper = SummarizationMapper(\\n            module_ids, module_models_tuple, self.graph_manager\\n        )\\n        client = OpenAI(max_retries=4)\\n        summarizer = OpenAISummarizer(client=client)\\n        summarization_manager = GraphDBSummarizationManager(\\n            module_models_tuple, summarization_mapper, summarizer, self.graph_manager\\n        )\\n        finalized_module_models: list[\\n            ModuleModel\\n        ] | None = summarization_manager.create_summaries_and_return_updated_models()\\n        logger.info(\\\"Summarization complete\\\")\\n\\n        logger.info(\\\"Saving models as JSON\\\")\\n        json_manager = JSONHandler(directory, directory_modules, output_directory)\\n\\n        for module_model in module_models_tuple:\\n            json_manager.save_model_as_json(module_model, module_model.file_path)\\n\\n        json_manager.save_visited_directories()\\n        logger.info(\\\"JSON save complete\\\")\\n\\n        logger.info(\\\"Directory parsing completed.\\\")\\n\\n        # self.graph_manager.upsert_models(\\n        #     list(finalized_module_models)\\n        # ).process_imports_and_dependencies().get_or_create_graph()\\n\\n        if finalized_module_models:\\n            chroma_context: ChromaSetupReturnContext = setup_chroma(\\n                finalized_module_models, logger\\n            )\\n        else:\\n            raise Exception(\\\"No finalized models returned from summarization.\\\")\\n\\n        return chroma_context\\n\\n\\nImported code block (postcode:utilities:logger:logging_config.py__*__MODULE) code content:\\nimport logging\\n\\nfrom rich.logging import RichHandler\\nfrom rich.syntax import Syntax\\n\\n\\ndef setup_logging(level=logging.INFO) -> None:\\n    \\\"\\\"\\\"\\n    Configures the logging system to use RichSyntaxHandler for output.\\n\\n    This function sets up logging with a specific log level and format. It utilizes the RichSyntaxHandler to support rich text and syntax highlighting in log outputs.\\n\\n    Args:\\n        level (int, optional): The logging level to set for the root logger. Defaults to logging.INFO.\\n\\n    Example:\\n        >>> setup_logging(logging.DEBUG)\\n        # Configures logging at DEBUG level with RichSyntaxHandler.\\n    \\\"\\\"\\\"\\n\\n    format_str = \\\"%(message)s\\\"\\n    logging.basicConfig(level=level, format=format_str, handlers=[RichSyntaxHandler()])\\n\\n\\nclass RichSyntaxHandler(RichHandler):\\n    \\\"\\\"\\\"\\n    A custom logging handler that extends RichHandler to add syntax highlighting.\\n\\n    This handler checks if the log record contains a 'syntax_highlight' attribute and, if so, uses 'rich.syntax.Syntax' to render the message with Python syntax highlighting.\\n\\n    Inherits:\\n        RichHandler: The base handler provided by the rich library for rich text formatting.\\n    \\\"\\\"\\\"\\n\\n    def emit(self, record) -> None:\\n        \\\"\\\"\\\"\\n        Emits a logging record.\\n\\n        If the record has the 'syntax_highlight' attribute set to True, it renders the 'content' attribute of the record with syntax highlighting. Otherwise, it falls back to the standard behavior of RichHandler.\\n\\n        Args:\\n            record: The logging record to emit.\\n\\n        Example:\\n            # Assuming `logger` is a logger instance\\n            >>> logger.info(\\\"Regular log message\\\")\\n            # Outputs a regular log message.\\n\\n            >>> logger.info(\\\"Highlighted log message\\\", extra={\\\"syntax_highlight\\\": True, \\\"content\\\": \\\"print('Hello, world!')\\\"})\\n            # Outputs the message with syntax highlighting.\\n        \\\"\\\"\\\"\\n\\n        try:\\n            if hasattr(record, \\\"syntax_highlight\\\") and getattr(\\n                record, \\\"syntax_highlight\\\"\\n            ):\\n                content: str = getattr(record, \\\"content\\\", \\\"\\\")\\n                if isinstance(content, str):\\n                    syntax = Syntax(\\n                        content, \\\"python\\\", theme=\\\"material\\\", line_numbers=True\\n                    )\\n                    self.console.print(syntax)\\n                return\\n\\n        except Exception as e:\\n            self.handleError(record)\\n\\n        super().emit(record)\\n\\n\\nImported code block (postcode:databases:chroma:chromadb_collection_manager.py__*__MODULE) code content:\\nimport logging\\nfrom typing import Any, Mapping, Union\\n\\nfrom postcode.models.models import ModuleModel\\nimport postcode.types.chroma as chroma_types\\nfrom chromadb.config import DEFAULT_DATABASE, DEFAULT_TENANT, Settings\\nfrom chromadb.api import ClientAPI\\nfrom chromadb.api.types import (\\n    DataLoader,\\n    CollectionMetadata,\\n    GetResult,\\n    QueryResult,\\n    Where,\\n    WhereDocument,\\n    Include,\\n    URIs,\\n    Loadable,\\n    Metadata,\\n    Embedding,\\n)\\nfrom chromadb import Collection\\nfrom chromadb import EmbeddingFunction\\n# from postcode.types.postcode import ModelType\\nfrom postcode.models.models import ModuleModel, ClassModel, FunctionModel, StandaloneCodeBlockModel\\nModelType = Union[\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n]\\n\\n\\nclass ChromaDBCollectionManager:\\n    \\\"\\\"\\\"\\n    Manages a collection within ChromaDB instance, providing functionalities for adding, retrieving,\\n    and querying embeddings, and their associated metadata.\\n\\n    This class serves as an interface to interact with a specific collection in ChromaDB.\\n\\n    Attributes:\\n        - collection (chroma_types.Collection): An instance of the Collection class from ChromaDB\\n            which this manager is responsible for.\\n\\n    Methods:\\n        - `collection_embedding_count`: Gets the total number of embeddings in the collection.\\n        - `add_embeddings`: Adds embeddings to the collection.\\n        - `get_embeddings`: Gets embeddings and their metadata from the collection in the form of a TypedDict.\\n        - `query_collection`: Queries and returns the `n` nearest neighbors from the collection.\\n        - `upsert_models`: Loads or updates the embeddings of the provided module models into the collection.\\n\\n    Examples:\\n        ```Python\\n        from postcode.databases.chroma import ChromaDBClientBuilder\\n        import postcode.types.chromadb.types as chroma_types\\n\\n        # Create a persistent ChromaDB client\\n        client: chroma_types.ClientAPI = ChromaDBClientBuilder.create_persistent_client()\\n\\n        # Instantiate the ChromaDBCollectionManager with a specific collection\\n        collection_manager: ChromaDBCollectionManager = (\\n            ChromaDBCollectionManager(client.get_collection(\\\"my_collection\\\"))\\n        )\\n\\n        # Example usage of the collection manager\\n        embedding_count: int = collection_manager.collection_embedding_count()\\n        print(f\\\"Total embeddings: {embedding_count}\\\")\\n        ```\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, collection: Collection) -> None:\\n        self.collection: Collection = collection\\n\\n    def collection_embedding_count(self) -> int | None:\\n        \\\"\\\"\\\"\\n        Gets the total number of embeddings in the collection.\\n\\n        Returns:\\n            - embedding_count (int): The total number of embeddings in the collection.\\n\\n        Examples:\\n            ```Python\\n            embedding_count: int = collection_manager.get_collection_embedding_count()\\n            ```\\n        \\\"\\\"\\\"\\n        try:\\n            embedding_count: int = self.collection.count()\\n            logging.info(\\n                f\\\"Collection {self.collection.name} has {embedding_count} embeddings.\\\"\\n            )\\n            return embedding_count\\n        except Exception as exception:\\n            logging.error(exception)\\n\\n    def add_embeddings(\\n        self,\\n        ids: list[str],\\n        documents: list[str],\\n        metadatas: list[Mapping[str, str | int | float | bool]],\\n    ) -> None:\\n        \\\"\\\"\\\"\\n        Adds embeddings to the collection.\\n\\n        Args:\\n            - ids (list[str]): A list of ids to add to the collection.\\n            - documents (list[str]): A list of documents to add to the collection.\\n            - metadatas (list[dict[str, Any]]): A list of metadatas to add to the collection.\\n\\n        Raises:\\n            - ValueError - If you don't provide either embeddings or documents.\\n            - ValueError: If the length of ids, embeddings, metadatas, or documents don't match.\\n            - ValueError - If you provide an id that already exists.\\n\\n        Examples:\\n            ```Python\\n            # define the ids, metadatas, and documents to add to the collection\\n            id: list[str] = [\\\"my_id\\\", \\\"my_id2\\\"]\\n            metadatas: list[dict[str, Any]] = [\\n                {\\\"my_metadata\\\": \\\"my_metadata_value\\\"},\\n                {\\\"my_metadata2\\\": \\\"my_metadata_value2\\\"},\\n            ]\\n            documents: list[str] = [\\\"my_document\\\", \\\"my_document2\\\"]\\n\\n            # add the embeddings to the collection\\n            collection_manager.add_embeddings(id, metadatas, documents)\\n            ```\\n        \\\"\\\"\\\"\\n\\n        if not len(ids) == len(documents) == len(metadatas):\\n            raise ValueError(\\\"The length of ids, documents, and metadatas must match.\\\")\\n\\n        try:\\n            logging.info(f\\\"Adding embeddings to collection {self.collection.name}\\\")\\n            self.collection.add(ids, documents=documents, metadatas=metadatas)\\n        except Exception as exception:\\n            raise exception\\n\\n    def get_embeddings(\\n        self,\\n        ids: list[str] | None,\\n        *,\\n        where_filter: Where | None = None,\\n        limit: int | None = None,\\n        where_document_filter: WhereDocument | None = None,\\n        include_in_result: Include = [\\\"metadatas\\\", \\\"documents\\\"],\\n    ) -> GetResult | None:\\n        \\\"\\\"\\\"\\n        Gets embeddings and their metadata from the collection in the form of a TypedDict.\\n\\n        Args:\\n            - ids (list[str]): A list of ids to get from the collection.\\n            - where_filter (chroma_types.Where | None): A TypedDict used to filter the results.\\n            - limit (int | None): The maximum number of results to return.\\n            - where_document_filter (chroma_types.WhereDocument | None): A TypedDict used to filter the results by the document,\\n                e.g. `{$contains: {\\\"text\\\": \\\"hello\\\"}}`\\n            - include_in_result (chroma_types.Include | None): A list used of what to return from the results, e.g. `[\\\"metadatas\\\", \\\"embeddings\\\", \\\"documents\\\"]`\\n\\n        Returns:\\n            - embeddings (TypedDict): A typed dict of embedding data from the collection with the following keys:\\n                - ids: list[str]\\n                - embeddings: list[Embedding] | None\\n                - documents: list[str] | None\\n                - uris: chroma_types.URIs | None\\n                - data: chroma_types.Loadable | None\\n                - metadatas: list[chroma_types.Metadata]]\\n\\n        Raises:\\n            - ValueError: If the length of ids, embeddings, metadatas, or documents don't match.\\n            - ValueError: If you provide an id that doesn't exist.\\n\\n        Examples:\\n            ```Python\\n            import postcode.types.chromadb.types as chroma_types\\n\\n            # define the ids, filters to use to get embeddings from the collection\\n            ids: list[str] = [\\\"my_id\\\", \\\"my_id2\\\"]\\n            where_filter: chroma_types.Where = {\\\"my_metadata\\\": \\\"my_metadata_value\\\"}\\n            where_document_filter: chroma_types.WhereDocument = {\\\"$contains\\\": {\\\"text\\\": \\\"hello\\\"}}\\n\\n            # define the data to return from the collection\\n            include_in_result: chroma_types.Include = [\\\"metadatas\\\"]\\n\\n            # get the embeddings from the collection\\n            embeddings: chroma_types.GetResult = collection_manager.get_embeddings(\\n                ids,\\n                where_filter=where_filter,\\n                where_document_filter=where_document_filter,\\n                include_in_result=include_in_result\\n                )\\n            ```\\n        \\\"\\\"\\\"\\n\\n        try:\\n            logging.info(f\\\"Getting embeddings from collection {self.collection.name}\\\")\\n            return self.collection.get(\\n                ids,\\n                where=where_filter,\\n                limit=limit,\\n                where_document=where_document_filter,\\n                include=include_in_result,\\n            )\\n        except Exception as exception:\\n            raise exception\\n\\n    def query_collection(\\n        self,\\n        queries: list[str],\\n        n_results: int = 10,\\n        where_filter: Where | None = None,\\n        where_document_filter: WhereDocument | None = None,\\n        include_in_result: Include = [\\\"metadatas\\\", \\\"documents\\\"],\\n    ) -> QueryResult | None:\\n        \\\"\\\"\\\"\\n        Queries and returns the `n` nearest neighbors from the collection.\\n\\n        Args:\\n            - queries (list[str]): A list of queries to search the collection for.\\n            - n_results (int): The number of results to return.\\n            - where_filter (chroma_types.Where | None): A TypedDict used to filter the results.\\n                - e.g. `{\\\"block_type\\\": \\\"FUNCTION\\\", \\\"children\\\": None}`\\n            - where_document_filter (chroma_types.WhereDocument | None): A TypedDict used to filter the results by the document,\\n                - e.g. `{$contains: \\\"binary search\\\"}`\\n            - include_in_result (chroma_types.Include | None): A list used of what to return from the results, e.g. `[\\\"metadatas\\\", \\\"embeddings\\\", \\\"documents\\\"]`\\n\\n        Returns:\\n            - results (chroma_types.QueryResult | None): A typed dict of query results from the collection, can have the following keys based on the\\n                `include_in_result` parameter:\\n                - ids: list[str] # The ids are always returned.\\n                - embeddings: List[list[Embedding]] | None\\n                - documents: list[list[str]]] | None\\n                - uris: list[list[URI]]] | None\\n                - data: list[Loadable] | None\\n                - metadatas: list[list[Metadata]] | None\\n                - distances: list[list[float]] | None\\n\\n        Raises:\\n            - ValueError: If you don't provide query_texts.\\n\\n        Examples:\\n            ```Python\\n            import postcode.types.chromadb.types as chroma\\n\\n            # define the queries and filters used to search the collection\\n            queries: list[str] = [\\\"binary search\\\", \\\"linear search\\\"]\\n            where_filter: chroma_types.Where = {\\\"block_type\\\": \\\"FUNCTION\\\"}\\n\\n            # define the data to return from the collection\\n            include_in_result: chroma_types.Include = [\\\"metadatas\\\", \\\"documents\\\", \\\"distances\\\"]\\n\\n            # query the collection and return the results from the collection\\n            results: chroma_types.QueryResult = collection_manager.query_collection(\\n                queries,\\n                where_filter=where_filter,\\n                include_in_result=include_in_result\\n                )\\n            ```\\n        \\\"\\\"\\\"\\n\\n        try:\\n            logging.info(f\\\"Querying collection {self.collection.name}\\\")\\n\\n            if results := self.collection.query(\\n                query_texts=queries,\\n                n_results=n_results,\\n                where=where_filter,\\n                where_document=where_document_filter,\\n                include=include_in_result,\\n            ):\\n                return results\\n            else:\\n                logging.warning(\\n                    f\\\"No results found from collection {self.collection.name}.\\\"\\n                )\\n\\n        except Exception as exception:\\n            raise exception\\n\\n    def modify_collection_name(self, name: str) -> None:\\n        \\\"\\\"\\\"\\n        Modifies the name of the collection managed by this class.\\n\\n        Args:\\n            - name (str): The new name to assign to the collection.\\n\\n        Examples:\\n            ```Python\\n            # Rename the collection to 'new_collection_name'\\n            collection_manager.modify_collection_name('new_collection_name')\\n            ```\\n        \\\"\\\"\\\"\\n\\n        self.collection.modify(name=name)\\n\\n    def modify_collection_metadata(\\n        self, metadata: dict[str, Any] | None = None\\n    ) -> None:\\n        \\\"\\\"\\\"\\n        Modifies the metadata of the collection managed by this class.\\n\\n        Args:\\n            - metadata (dict[str, Any] | None): The new metadata to assign to the collection. If None, no change is made.\\n\\n        Examples:\\n            ```Python\\n            # Update metadata of the collection\\n            new_metadata = {\\\"description\\\": \\\"Updated collection metadata\\\"}\\n            collection_manager.modify_collection_metadata(new_metadata)\\n            ```\\n        \\\"\\\"\\\"\\n\\n        self.collection.modify(metadata=metadata)\\n\\n    def _update_metadata_or_documents_by_ids(\\n        self,\\n        ids: list[str],\\n        metadatas: list[Mapping[str, str | int | float | bool]] | None = None,\\n        documents: list[str] | None = None,\\n    ) -> None:\\n        \\\"\\\"\\\"\\n        Updates the metadata or documents of specific entries in the collection by their ids.\\n\\n        Args:\\n            - ids (list[str]): List of ids of the entries to be updated.\\n            - metadatas (list[Mapping[str, Any]] | None): List of metadata updates corresponding to the ids.\\n            - documents (list[str] | None): List of document updates corresponding to the ids.\\n\\n        Raises:\\n            - ValueError: If neither metadatas nor documents are provided.\\n            - ValueError: If the length of ids and documents don't match.\\n            - ValueError: If the length of ids and metadatas don't match.\\n            - ValueError: If the length of ids, metadatas, and documents don't match.\\n\\n        Notes:\\n            - As of now, ChromaDB doesn't raise an exception if you provide an id that doesn't exist.\\n\\n        Examples:\\n            ```Python\\n            # Update metadata and documents for specific ids\\n            ids_to_update = ['id1', 'id2']\\n            metadata_updates = [{\\\"key1\\\": \\\"value1\\\"}, {\\\"key2\\\": \\\"value2\\\"}]\\n            document_updates = [\\\"new document 1\\\", \\\"new document 2\\\"]\\n            collection_manager.update_metadata_or_documents_by_ids(ids_to_update, metadata_updates, document_updates)\\n            ```\\n        \\\"\\\"\\\"\\n\\n        if not metadatas and not documents:\\n            raise ValueError(\\\"You must provide either metadatas or documents.\\\")\\n        if not metadatas and documents:\\n            if len(ids) != len(documents):\\n                raise ValueError(\\\"The length of ids and documents must match.\\\")\\n        if metadatas and not documents:\\n            if len(ids) != len(metadatas):\\n                raise ValueError(\\\"The length of ids and metadatas must match.\\\")\\n        if metadatas and documents:\\n            if len(ids) != len(metadatas) != len(documents):\\n                raise ValueError(\\n                    \\\"The length of ids, metadatas, and documents must match.\\\"\\n                )\\n        for index, id in enumerate(ids):\\n            if not self.collection.get(id):\\n                logging.error(\\n                    f\\\"Id {id} does not exist in collection {self.collection.name}.\\\"\\n                )\\n                ids.pop(index)\\n                if metadatas:\\n                    popped_metadata = metadatas.pop(index)\\n                    if popped_metadata:\\n                        logging.warning(\\n                            f\\\"Removing metadata at index {index} from update.\\\"\\n                        )\\n                if documents:\\n                    popped_document = documents.pop(index)\\n                    if popped_document:\\n                        logging.warning(\\n                            f\\\"Removing document at index {index} from update.\\\"\\n                        )\\n\\n        if not ids:\\n            logging.warning(\\\"All updates failed.\\\")\\n            return None\\n        else:\\n            logging.info(f\\\"Updating collection {self.collection.name} with ids {ids}.\\\")\\n            self.collection.update(ids=ids, metadatas=metadatas, documents=documents)\\n\\n    def _upsert_documents(\\n        self,\\n        ids: list[str],\\n        documents: list[str],\\n        metadatas: list[Mapping[str, str | int | float | bool]],\\n        # embeddings: list[chroma_types.Embedding],\\n    ) -> None:\\n        \\\"\\\"\\\"\\n        Inserts or updates documents in the collection, based on the provided ids.\\n\\n        Args:\\n            - ids (list[str]): List of ids for the documents to be inserted or updated.\\n            - documents (list[str]): List of documents corresponding to the ids.\\n            - metadatas (list[Mapping[str, Any]]): List of metadata corresponding to the ids.\\n\\n        Raises:\\n            - ValueError: If the lengths of ids, documents, and metadatas don't match.\\n\\n        Examples:\\n            ```Python\\n            # Upsert documents in the collection\\n            ids = ['id1', 'id2']\\n            documents = ['doc1', 'doc2']\\n            metadatas = [{\\\"meta1\\\": \\\"value1\\\"}, {\\\"meta2\\\": \\\"value2\\\"}]\\n\\n            # Upsert documents in the collection\\n            collection_manager.upsert_documents(ids, documents, metadatas)\\n            ```\\n        \\\"\\\"\\\"\\n\\n        if len(ids) != len(documents) != len(metadatas):\\n            raise ValueError(\\\"The length of ids, documents, and metadatas must match.\\\")\\n\\n        logging.info(f\\\"Upserting collection {self.collection.name} with ids {ids}.\\\")\\n        self.collection.upsert(\\n            ids=ids,\\n            # embeddings=embeddings,\\n            metadatas=metadatas,\\n            documents=documents,\\n        )\\n\\n    def delete_embeddings(self, ids: list[str]) -> None:\\n        \\\"\\\"\\\"\\n        Deletes embeddings from the collection based on the provided ids.\\n\\n        Args:\\n            - ids (list[str]): List of ids corresponding to the embeddings to be deleted.\\n\\n        Examples:\\n            ```Python\\n            # Delete specific embeddings by ids\\n            ids_to_delete = ['id1', 'id2']\\n            collection_manager.delete_embeddings(ids_to_delete)\\n            ```\\n        \\\"\\\"\\\"\\n\\n        ids_to_delete: list[str] = ids.copy()\\n        for index, id in enumerate(ids_to_delete):\\n            if not self.collection.get(id):\\n                logging.error(\\n                    f\\\"Id {id} does not exist in collection {self.collection.name}.\\\"\\n                )\\n                ids_to_delete.pop(index)\\n\\n        if not ids_to_delete:\\n            logging.warning(\\\"No IDs given were in the database.\\\")\\n            return None\\n\\n        logging.info(\\n            f\\\"Deleting embeddings from collection {self.collection.name} with ids {ids_to_delete}.\\\"\\n        )\\n        self.collection.delete(ids_to_delete)\\n\\n    def upsert_models(self, module_models: tuple[ModuleModel, ...]) -> None:\\n        \\\"\\\"\\\"\\n        Loads or updates the embeddings of the provided module models into the collection.\\n\\n        The Pydantic models are converted to a dictionary with a format that ChromaDB can use, then the ids, documents, and metadatas\\n        are added to their respective lists. The lists are then either added to or updated in the collection depending on whether or\\n        not the code blocks were in the the collection to begin with.\\n\\n        Args:\\n            - module_models (tuple[ModuleModel, ...]): The module models to load or update into the collection.\\n\\n        Examples:\\n            ```Python\\n            # Upsert module models into the collection\\n            module_models = (module_model1, module_model2)\\n            collection_manager.upsert_models(module_models)\\n            ```\\n        \\\"\\\"\\\"\\n\\n        ids: list[str] = []\\n        documents: list[str] = []\\n        metadatas: list[Mapping[str, str | int | float | bool]] = []\\n\\n        for module_model in module_models:\\n            if module_model.summary:\\n                ids.append(module_model.id)\\n                documents.append(module_model.summary)\\n                metadatas.append(module_model.convert_to_metadata())\\n\\n            if module_model.children:\\n                for child in module_model.children:\\n                    child_data: dict[str, Any] = self._recursively_gather_child_data(\\n                        child\\n                    )\\n                    ids.extend(child_data[\\\"ids\\\"])\\n                    documents.extend(child_data[\\\"documents\\\"])\\n                    metadatas.extend(child_data[\\\"metadatas\\\"])\\n\\n        logging.info(\\n            f\\\"{self.collection.name} has {self.collection_embedding_count()} embeddings.\\\"\\n        )\\n        self._upsert_documents(ids=ids, documents=documents, metadatas=metadatas)\\n        logging.info(\\n            f\\\"After upsert {self.collection.name} has {self.collection_embedding_count()} embeddings.\\\"\\n        )\\n\\n    def _recursively_gather_child_data(self, model: ModelType) -> dict[str, Any]:\\n        ids: list[str] = []\\n        documents: list[str] = []\\n        metadatas: list[Mapping[str, str | int | float | bool]] = []\\n        if model.summary:\\n            ids.append(model.id)\\n            documents.append(model.summary)\\n            metadatas.append(model.convert_to_metadata())\\n        else:\\n            logging.warning(f\\\"Child {model.id} has no summary.\\\")\\n        if model.children:\\n            for child in model.children:\\n                child_data: dict[str, Any] = self._recursively_gather_child_data(child)\\n                ids.extend(child_data[\\\"ids\\\"])\\n                documents.extend(child_data[\\\"documents\\\"])\\n                metadatas.extend(child_data[\\\"metadatas\\\"])\\n\\n        return {\\n            \\\"ids\\\": ids,\\n            \\\"documents\\\": documents,\\n            \\\"metadatas\\\": metadatas,\\n        }\\n\\n\\nImported code block (postcode:updaters:standard_updater.py__*__MODULE) code content:\\n# Create method, `update_all`, that updates the whole project, it parses all code, wipes all databases, and summarizes all code blocks,\\n# then updates all the databases with the new information.\\n\\n\\nfrom logging import Logger\\n\\nfrom openai import OpenAI\\nfrom postcode.ai_services.summarizer.openai_summarizer import OpenAISummarizer\\nfrom postcode.ai_services.summarizer.standard_summarization_manager import (\\n    StandardSummarizationManager,\\n)\\n\\nfrom postcode.databases.chroma.setup_chroma import (\\n    ChromaSetupReturnContext,\\n    setup_chroma,\\n)\\nfrom postcode.json_management.json_handler import JSONHandler\\n\\nfrom postcode.models.models import ModuleModel\\nfrom postcode.python_parser.visitor_manager.visitor_manager import (\\n    VisitorManager,\\n    VisitorManagerProcessFilesReturn,\\n)\\n\\n\\nclass StandardUpdater:\\n    @staticmethod\\n    def update_all(\\n        directory: str, output_directory: str, logger: Logger\\n    ) -> ChromaSetupReturnContext:\\n        visitor_manager = VisitorManager(directory, output_directory)\\n        process_files_return: VisitorManagerProcessFilesReturn = (\\n            visitor_manager.process_files()\\n        )\\n\\n        module_models_tuple: tuple[ModuleModel, ...] = process_files_return.models_tuple\\n        client = OpenAI(max_retries=4)\\n        summarizer = OpenAISummarizer(client=client)\\n        summarization_manager = StandardSummarizationManager(\\n            module_models_tuple, summarizer\\n        )\\n        finalized_module_models: tuple[\\n            ModuleModel, ...\\n        ] = summarization_manager.create_summarizes_and_return_updated_models()\\n\\n        logger.info(\\\"Summarization complete\\\")\\n\\n        logger.info(\\\"Saving models as JSON\\\")\\n        directory_modules: dict[str, list[str]] = process_files_return.directory_modules\\n        json_manager = JSONHandler(directory, directory_modules, output_directory)\\n\\n        for module_model in module_models_tuple:\\n            json_manager.save_model_as_json(module_model, module_model.file_path)\\n\\n        json_manager.save_visited_directories()\\n        logger.info(\\\"JSON save complete\\\")\\n\\n        logger.info(\\\"Directory parsing completed.\\\")\\n\\n        chroma_context: ChromaSetupReturnContext = setup_chroma(\\n            finalized_module_models, logger\\n        )\\n\\n        return chroma_context\\n\\n, \\nimport logging\\nfrom logging import Logger\\nfrom typing import Union\\nfrom chromadb.api.types import QueryResult\\nfrom chromadb import Collection\\n        \",\"children\":[{\"variable_assignments\":[\"ModelType = Union[\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n]\"],\"id\":\"postcode:app.py__*__MODULE__*__STANDALONE_BLOCK-1\",\"parent_id\":\"postcode:app.py__*__MODULE\",\"block_type\":\"STANDALONE_BLOCK\",\"start_line_num\":16,\"end_line_num\":23,\"code_content\":\"ModelType = Union[\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n]\\n\",\"important_comments\":null,\"dependencies\":[{\"import_names\":[{\"name\":\"Union\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"typing\",\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"},{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ClassModel\"},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-FunctionModel\"},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-StandaloneCodeBlockModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"},{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ClassModel\"},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-FunctionModel\"},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-StandaloneCodeBlockModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"},{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ClassModel\"},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-FunctionModel\"},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-StandaloneCodeBlockModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"},{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ClassModel\"},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-FunctionModel\"},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-StandaloneCodeBlockModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"}],\"summary\":null,\"children\":null},{\"function_name\":\"query_chroma\",\"docstring\":null,\"decorators\":null,\"parameters\":null,\"returns\":\"None\",\"is_method\":false,\"is_async\":false,\"id\":\"postcode:app.py__*__MODULE__*__FUNCTION-query_chroma\",\"parent_id\":\"postcode:app.py__*__MODULE\",\"block_type\":\"FUNCTION\",\"start_line_num\":36,\"end_line_num\":58,\"code_content\":\"\\n\\ndef query_chroma(\\n    query: str,\\n    chroma_collection_manager: ChromaDBCollectionManager,\\n    chroma_collection: Collection,\\n    logger: Logger,\\n) -> None:\\n    logger.info(f\\\"Querying ChromaDB collection {chroma_collection.name}\\\")\\n    results: QueryResult | None = chroma_collection_manager.query_collection(\\n        [query],\\n        n_results=10,\\n        # where_filter={\\\"block_type\\\": \\\"MODULE\\\"},\\n        include_in_result=[\\\"metadatas\\\", \\\"documents\\\", \\\"embeddings\\\"],\\n    )\\n    logger.info(\\\"Query results:\\\")\\n    if results:\\n        if results[\\\"ids\\\"]:\\n            for document in results[\\\"ids\\\"][0]:\\n                print(document)\\n\\n            print(f\\\"Total results: {len(results['ids'][0])}\\\")\\n\",\"important_comments\":null,\"dependencies\":[{\"import_names\":[{\"name\":\"Logger\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"logging\",\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"ChromaDBCollectionManager\",\"as_name\":null,\"local_block_id\":\"postcode:databases:chroma:chromadb_collection_manager.py__*__MODULE__*__CLASS-ChromaDBCollectionManager\"}],\"imported_from\":\"postcode.databases.chroma.chromadb_collection_manager\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:databases:chroma:chromadb_collection_manager.py__*__MODULE\"},{\"import_names\":[{\"name\":\"QueryResult\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"chromadb.api.types\",\"import_module_type\":\"THIRD_PARTY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"Collection\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"chromadb\",\"import_module_type\":\"THIRD_PARTY\",\"local_module_id\":null}],\"summary\":null,\"children\":null},{\"function_name\":\"main\",\"docstring\":null,\"decorators\":null,\"parameters\":null,\"returns\":\"None\",\"is_method\":false,\"is_async\":false,\"id\":\"postcode:app.py__*__MODULE__*__FUNCTION-main\",\"parent_id\":\"postcode:app.py__*__MODULE\",\"block_type\":\"FUNCTION\",\"start_line_num\":58,\"end_line_num\":87,\"code_content\":\"\\n\\ndef main(\\n    directory: str = \\\".\\\",\\n    output_directory: str = \\\"output_json\\\",\\n) -> None:\\n    setup_logging()\\n    logger: Logger = logging.getLogger(__name__)\\n\\n    #   ==================== GraphDB ====================\\n    graph_db_updater = GraphDBUpdater(directory, output_directory, logger)\\n    chroma_context: ChromaSetupReturnContext = graph_db_updater.update_all(\\n        directory, output_directory, logger\\n    )\\n    # ==================== End GraphDB ====================\\n\\n    #   ==================== Standard ====================\\n    # chroma_context: ChromaSetupReturnContext = StandardUpdater.update_all(\\n    #     directory, output_directory, logger\\n    # )\\n    # ==================== End Standard ====================\\n\\n    query: str = \\\"summarizes code block\\\"\\n    query_chroma(\\n        query,\\n        chroma_context.chroma_collection_manager,\\n        chroma_context.chroma_collection,\\n        logger,\\n    )\\n\",\"important_comments\":null,\"dependencies\":[{\"code_block_id\":\"postcode:app.py__*__MODULE__*__FUNCTION-query_chroma\"},{\"import_names\":[{\"name\":\"logging\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":null,\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"Logger\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"logging\",\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"ChromaSetupReturnContext\",\"as_name\":null,\"local_block_id\":\"postcode:databases:chroma:setup_chroma.py__*__MODULE__*__CLASS-ChromaSetupReturnContext\"}],\"imported_from\":\"postcode.databases.chroma.setup_chroma\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:databases:chroma:setup_chroma.py__*__MODULE\"},{\"import_names\":[{\"name\":\"GraphDBUpdater\",\"as_name\":null,\"local_block_id\":\"postcode:updaters:graph_db_updater.py__*__MODULE__*__CLASS-GraphDBUpdater\"}],\"imported_from\":\"postcode.updaters.graph_db_updater\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:updaters:graph_db_updater.py__*__MODULE\"},{\"import_names\":[{\"name\":\"setup_logging\",\"as_name\":null,\"local_block_id\":\"postcode:utilities:logger:logging_config.py__*__MODULE__*__FUNCTION-setup_logging\"}],\"imported_from\":\"postcode.utilities.logger.logging_config\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:utilities:logger:logging_config.py__*__MODULE\"},{\"import_names\":[{\"name\":\"StandardUpdater\",\"as_name\":null,\"local_block_id\":\"postcode:updaters:standard_updater.py__*__MODULE__*__CLASS-StandardUpdater\"}],\"imported_from\":\"postcode.updaters.standard_updater\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:updaters:standard_updater.py__*__MODULE\"}],\"summary\":null,\"children\":null}]}", "imports": "{\"file_path\":\"postcode/app.py\",\"docstring\":null,\"header\":[],\"footer\":[],\"imports\":[{\"import_names\":[{\"name\":\"logging\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":null,\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"Logger\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"logging\",\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"Union\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"typing\",\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"QueryResult\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"chromadb.api.types\",\"import_module_type\":\"THIRD_PARTY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"Collection\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"chromadb\",\"import_module_type\":\"THIRD_PARTY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"},{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ClassModel\"},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-FunctionModel\"},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-StandaloneCodeBlockModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ChromaSetupReturnContext\",\"as_name\":null,\"local_block_id\":\"postcode:databases:chroma:setup_chroma.py__*__MODULE__*__CLASS-ChromaSetupReturnContext\"}],\"imported_from\":\"postcode.databases.chroma.setup_chroma\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:databases:chroma:setup_chroma.py__*__MODULE\"},{\"import_names\":[{\"name\":\"GraphDBUpdater\",\"as_name\":null,\"local_block_id\":\"postcode:updaters:graph_db_updater.py__*__MODULE__*__CLASS-GraphDBUpdater\"}],\"imported_from\":\"postcode.updaters.graph_db_updater\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:updaters:graph_db_updater.py__*__MODULE\"},{\"import_names\":[{\"name\":\"setup_logging\",\"as_name\":null,\"local_block_id\":\"postcode:utilities:logger:logging_config.py__*__MODULE__*__FUNCTION-setup_logging\"}],\"imported_from\":\"postcode.utilities.logger.logging_config\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:utilities:logger:logging_config.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ChromaDBCollectionManager\",\"as_name\":null,\"local_block_id\":\"postcode:databases:chroma:chromadb_collection_manager.py__*__MODULE__*__CLASS-ChromaDBCollectionManager\"}],\"imported_from\":\"postcode.databases.chroma.chromadb_collection_manager\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:databases:chroma:chromadb_collection_manager.py__*__MODULE\"},{\"import_names\":[{\"name\":\"StandardUpdater\",\"as_name\":null,\"local_block_id\":\"postcode:updaters:standard_updater.py__*__MODULE__*__CLASS-StandardUpdater\"}],\"imported_from\":\"postcode.updaters.standard_updater\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:updaters:standard_updater.py__*__MODULE\"}],\"id\":\"postcode:app.py__*__MODULE\",\"parent_id\":null,\"block_type\":\"MODULE\",\"start_line_num\":1,\"end_line_num\":87,\"code_content\":\"import logging\\nfrom logging import Logger\\nfrom typing import Union\\n\\nfrom postcode.models.models import (\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n)\\n\\nfrom postcode.databases.chroma.setup_chroma import (\\n    ChromaSetupReturnContext,\\n)\\nfrom postcode.updaters.graph_db_updater import GraphDBUpdater\\n\\nModelType = Union[\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n]\\n\\nfrom postcode.utilities.logger.logging_config import setup_logging\\n\\nfrom postcode.databases.chroma.chromadb_collection_manager import (\\n    ChromaDBCollectionManager,\\n)\\n\\nfrom chromadb.api.types import (\\n    QueryResult,\\n)\\nfrom chromadb import Collection\\n\\nfrom postcode.updaters.standard_updater import StandardUpdater\\n\\n\\ndef query_chroma(\\n    query: str,\\n    chroma_collection_manager: ChromaDBCollectionManager,\\n    chroma_collection: Collection,\\n    logger: Logger,\\n) -> None:\\n    logger.info(f\\\"Querying ChromaDB collection {chroma_collection.name}\\\")\\n    results: QueryResult | None = chroma_collection_manager.query_collection(\\n        [query],\\n        n_results=10,\\n        # where_filter={\\\"block_type\\\": \\\"MODULE\\\"},\\n        include_in_result=[\\\"metadatas\\\", \\\"documents\\\", \\\"embeddings\\\"],\\n    )\\n    logger.info(\\\"Query results:\\\")\\n    if results:\\n        if results[\\\"ids\\\"]:\\n            for document in results[\\\"ids\\\"][0]:\\n                print(document)\\n\\n            print(f\\\"Total results: {len(results['ids'][0])}\\\")\\n\\n\\ndef main(\\n    directory: str = \\\".\\\",\\n    output_directory: str = \\\"output_json\\\",\\n) -> None:\\n    setup_logging()\\n    logger: Logger = logging.getLogger(__name__)\\n\\n    #   ==================== GraphDB ====================\\n    graph_db_updater = GraphDBUpdater(directory, output_directory, logger)\\n    chroma_context: ChromaSetupReturnContext = graph_db_updater.update_all(\\n        directory, output_directory, logger\\n    )\\n    # ==================== End GraphDB ====================\\n\\n    #   ==================== Standard ====================\\n    # chroma_context: ChromaSetupReturnContext = StandardUpdater.update_all(\\n    #     directory, output_directory, logger\\n    # )\\n    # ==================== End Standard ====================\\n\\n    query: str = \\\"summarizes code block\\\"\\n    query_chroma(\\n        query,\\n        chroma_context.chroma_collection_manager,\\n        chroma_context.chroma_collection,\\n        logger,\\n    )\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":\"\\nSummary:\\n\\n        postcode:app.py__*__MODULE\\n\\n        \\nChild (postcode:app.py__*__MODULE__*__STANDALONE_BLOCK-1) code content:\\nModelType = Union[\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n]\\n\\n\\nChild (postcode:app.py__*__MODULE__*__FUNCTION-query_chroma) code content:\\n\\n\\ndef query_chroma(\\n    query: str,\\n    chroma_collection_manager: ChromaDBCollectionManager,\\n    chroma_collection: Collection,\\n    logger: Logger,\\n) -> None:\\n    logger.info(f\\\"Querying ChromaDB collection {chroma_collection.name}\\\")\\n    results: QueryResult | None = chroma_collection_manager.query_collection(\\n        [query],\\n        n_results=10,\\n        # where_filter={\\\"block_type\\\": \\\"MODULE\\\"},\\n        include_in_result=[\\\"metadatas\\\", \\\"documents\\\", \\\"embeddings\\\"],\\n    )\\n    logger.info(\\\"Query results:\\\")\\n    if results:\\n        if results[\\\"ids\\\"]:\\n            for document in results[\\\"ids\\\"][0]:\\n                print(document)\\n\\n            print(f\\\"Total results: {len(results['ids'][0])}\\\")\\n\\n\\nChild (postcode:app.py__*__MODULE__*__FUNCTION-main) code content:\\n\\n\\ndef main(\\n    directory: str = \\\".\\\",\\n    output_directory: str = \\\"output_json\\\",\\n) -> None:\\n    setup_logging()\\n    logger: Logger = logging.getLogger(__name__)\\n\\n    #   ==================== GraphDB ====================\\n    graph_db_updater = GraphDBUpdater(directory, output_directory, logger)\\n    chroma_context: ChromaSetupReturnContext = graph_db_updater.update_all(\\n        directory, output_directory, logger\\n    )\\n    # ==================== End GraphDB ====================\\n\\n    #   ==================== Standard ====================\\n    # chroma_context: ChromaSetupReturnContext = StandardUpdater.update_all(\\n    #     directory, output_directory, logger\\n    # )\\n    # ==================== End Standard ====================\\n\\n    query: str = \\\"summarizes code block\\\"\\n    query_chroma(\\n        query,\\n        chroma_context.chroma_collection_manager,\\n        chroma_context.chroma_collection,\\n        logger,\\n    )\\n\\n, \\nImported code block (postcode:models:models.py__*__MODULE) code content:\\nfrom typing import Union\\nfrom pydantic import BaseModel, Field, validator\\n\\nfrom postcode.models.enums import (\\n    BlockType,\\n    ImportModuleType,\\n    CommentType,\\n)\\n\\n\\nclass ImportNameModel(BaseModel):\\n    \\\"\\\"\\\"Class representing the name of an import.\\\"\\\"\\\"\\n\\n    name: str\\n    as_name: str | None = None\\n    local_block_id: str | None = None\\n\\n    # def convert_import_names_to_metadata(self) -> str:\\n    #     \\\"\\\"\\\"Converts the import name to a metadata string.\\\"\\\"\\\"\\n\\n    #     return self.model_dump_json()\\n\\n\\nclass ImportModel(BaseModel):\\n    \\\"\\\"\\\"Class representing an import statement.\\\"\\\"\\\"\\n\\n    import_names: list[ImportNameModel]\\n    imported_from: str | None = None\\n    import_module_type: ImportModuleType = ImportModuleType.STANDARD_LIBRARY\\n    local_module_id: str | None = None\\n\\n    def convert_import_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the import to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass DependencyModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a module dependency.\\\"\\\"\\\"\\n\\n    code_block_id: str\\n\\n    def convert_dependency_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the dependency to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass CommentModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a comment.\\\"\\\"\\\"\\n\\n    content: str\\n    comment_types: list[CommentType]\\n\\n    def convert_comment_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the comment to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass DecoratorModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a decorator.\\\"\\\"\\\"\\n\\n    content: str\\n    decorator_name: str\\n    decorator_args: list[str] | None = None\\n\\n    def convert_decorator_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the decorator to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass ClassKeywordModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a class keyword.\\\"\\\"\\\"\\n\\n    content: str\\n    keyword_name: str\\n    args: str | None = None\\n\\n    def convert_class_keyword_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the class keyword to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass ParameterModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a function parameter.\\\"\\\"\\\"\\n\\n    content: str\\n\\n\\nclass ParameterListModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a list of parameters.\\\"\\\"\\\"\\n\\n    params: list[ParameterModel] | None = None\\n    star_arg: ParameterModel | None = None\\n    kwonly_params: list[ParameterModel] | None = None\\n    star_kwarg: ParameterModel | None = None\\n    posonly_params: list[ParameterModel] | None = None\\n\\n    def convert_parameters_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the parameter list to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass BaseCodeBlockModel(BaseModel):\\n    \\\"\\\"\\\"Attributes common to all code block models.\\\"\\\"\\\"\\n\\n    id: str\\n    parent_id: str | None = None\\n    block_type: BlockType\\n    start_line_num: int\\n    end_line_num: int\\n    code_content: str = \\\"\\\"\\n    important_comments: list[CommentModel] | None = None\\n    dependencies: list[ImportModel | DependencyModel] | None = None\\n    summary: str | None = None\\n    children: list[\\n        Union[\\n            \\\"ClassModel\\\",\\n            \\\"FunctionModel\\\",\\n            \\\"StandaloneCodeBlockModel\\\",\\n        ]\\n    ] | None = []\\n\\n    @validator(\\\"parent_id\\\", always=True)\\n    def check_parent_id(cls, v, values, **kwargs) -> str | None:\\n        \\\"\\\"\\\"Validates that parent_id is a non-empty string unless block_type is MODULE.\\\"\\\"\\\"\\n\\n        if \\\"block_type\\\" in values and values[\\\"block_type\\\"] != BlockType.MODULE:\\n            if len(v) < 1:\\n                raise ValueError(\\\"parent_id is required!\\\")\\n        return v\\n\\n    def _convert_parent_id_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the parent_id to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.parent_id}\\\" if self.parent_id else \\\"\\\"\\n\\n    def _convert_block_type_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the block_type to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.block_type.name}\\\"\\n\\n    def _convert_important_comments_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the important comments to a metadata string.\\\"\\\"\\\"\\n\\n        important_comments: str = (\\n            self.model_dump_json() if self.important_comments else \\\"\\\"\\n        )\\n\\n        return f\\\"{important_comments}\\\"\\n\\n    def _convert_dependencies_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the dependencies to a metadata string.\\\"\\\"\\\"\\n\\n        dependencies_str: str = \\\"\\\"\\n\\n        if self.dependencies:\\n            for dependency in self.dependencies:\\n                if isinstance(dependency, ImportModel):\\n                    dependencies_str += f\\\"{dependency.convert_import_to_metadata()}\\\\n\\\"\\n                elif isinstance(dependency, DependencyModel):\\n                    dependencies_str += (\\n                        f\\\"{dependency.convert_dependency_to_metadata()}\\\\n\\\"\\n                    )\\n\\n        return dependencies_str\\n\\n    def _convert_summary_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the summary to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.summary}\\\" if self.summary else \\\"\\\"\\n\\n    def _convert_children_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the children to a metadata string.\\\"\\\"\\\"\\n\\n        children_str: str = \\\"\\\"\\n\\n        if self.children:\\n            for child in self.children:\\n                children_str += f\\\"{child.id}\\\\n\\\"\\n\\n        return children_str\\n\\n    def _convert_base_attributes_to_metadata_dict(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the base attributes to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            \\\"id\\\": self.id,\\n            \\\"parent_id\\\": self._convert_parent_id_to_metadata(),\\n            \\\"block_type\\\": self._convert_block_type_to_metadata(),\\n            \\\"start_line_num\\\": self.start_line_num,\\n            \\\"end_line_num\\\": self.end_line_num,\\n            \\\"code_content\\\": self.code_content,\\n            \\\"important_comments\\\": self._convert_important_comments_to_metadata(),\\n            \\\"dependencies\\\": self._convert_dependencies_to_metadata(),\\n            \\\"summary\\\": self._convert_summary_to_metadata(),\\n            \\\"children\\\": self._convert_children_to_metadata(),\\n        }\\n\\n\\nclass ModuleSpecificAttributes(BaseModel):\\n    \\\"\\\"\\\"Module specific attributes.\\\"\\\"\\\"\\n\\n    file_path: str = Field(min_length=1)\\n    docstring: str | None = None\\n    header: list[str] | None = None\\n    footer: list[str] | None = None\\n    imports: list[ImportModel] | None = None\\n\\n    def _convert_docstring_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the docstring to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.docstring}\\\"\\n\\n    def _convert_header_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the header and footer to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n    def _convert_footer_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the header and footer to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n    def _convert_imports_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the imports to a metadata string.\\\"\\\"\\\"\\n        imports_str: str = self.model_dump_json() if self.imports else \\\"\\\"\\n        return f\\\"{imports_str}\\\"\\n\\n    def _convert_module_attributes_to_metadata_dict(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the module attributes to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            \\\"file_path\\\": self.file_path,\\n            \\\"docstring\\\": self._convert_docstring_to_metadata(),\\n            \\\"header\\\": self._convert_header_to_metadata(),\\n            \\\"footer\\\": self._convert_footer_to_metadata(),\\n            \\\"imports\\\": self._convert_imports_to_metadata(),\\n        }\\n\\n\\nclass ModuleModel(BaseCodeBlockModel, ModuleSpecificAttributes):\\n    \\\"\\\"\\\"Model for a module.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the module model to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_module_attributes_to_metadata_dict(),\\n        }\\n\\n\\nclass ClassSpecificAttributes(BaseModel):\\n    \\\"\\\"\\\"Class specific attributes.\\\"\\\"\\\"\\n\\n    class_name: str = Field(min_length=1)\\n    decorators: list[DecoratorModel] | None = None\\n    bases: list[str] | None = None\\n    docstring: str | None = None\\n    keywords: list[ClassKeywordModel] | None = None\\n    # attributes: list[dict] | None = None\\n\\n    def _convert_decorators_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the decorators to a metadata string.\\\"\\\"\\\"\\n        decorators_str: str = self.model_dump_json() if self.decorators else \\\"\\\"\\n        return f\\\"{decorators_str}\\\"\\n\\n    def _convert_bases_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the bases to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json() if self.bases else \\\"\\\"\\n\\n    def _convert_docstring_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the docstring to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.docstring}\\\" if self.docstring else \\\"\\\"\\n\\n    def _convert_keywords_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the keywords to a metadata string.\\\"\\\"\\\"\\n        keywords_str: str = self.model_dump_json() if self.keywords else \\\"\\\"\\n        return f\\\"{keywords_str}\\\"\\n\\n    def _convert_class_attributes_to_metadata_dict(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the class attributes to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            \\\"class_name\\\": self.class_name,\\n            \\\"decorators\\\": self._convert_decorators_to_metadata(),\\n            \\\"bases\\\": self._convert_bases_to_metadata(),\\n            \\\"docstring\\\": self._convert_docstring_to_metadata(),\\n            \\\"keywords\\\": self._convert_keywords_to_metadata(),\\n        }\\n\\n\\nclass ClassModel(BaseCodeBlockModel, ClassSpecificAttributes):\\n    \\\"\\\"\\\"Model for a class.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the class model to a metadata dictionary.\\\"\\\"\\\"\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_class_attributes_to_metadata_dict(),\\n        }\\n\\n\\nclass FunctionSpecificAttributes(BaseModel):\\n    \\\"\\\"\\\"Function specific attributes.\\\"\\\"\\\"\\n\\n    function_name: str = Field(min_length=1)\\n    docstring: str | None = None\\n    decorators: list[DecoratorModel] | None = None\\n    parameters: ParameterListModel | None = None\\n    returns: str | None = None\\n    is_method: bool = False\\n    is_async: bool = False\\n\\n    def _convert_docstring_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the docstring to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.docstring}\\\" if self.docstring else \\\"\\\"\\n\\n    def _convert_decorators_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the decorators to a metadata string.\\\"\\\"\\\"\\n        decorators_str: str = self.model_dump_json() if self.decorators else \\\"\\\"\\n        return f\\\"{decorators_str}\\\"\\n\\n    def _convert_parameters_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the parameters to a metadata string.\\\"\\\"\\\"\\n        return (\\n            self.parameters.convert_parameters_to_metadata() if self.parameters else \\\"\\\"\\n        )\\n\\n    def _convert_returns_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the returns to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.returns}\\\" if self.returns else \\\"\\\"\\n\\n    def _convert_function_attributes_to_metadata_dict(self) -> dict[str, str | bool]:\\n        \\\"\\\"\\\"Converts the function attributes to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            \\\"function_name\\\": self.function_name,\\n            \\\"docstring\\\": self._convert_docstring_to_metadata(),\\n            \\\"decorators\\\": self._convert_decorators_to_metadata(),\\n            \\\"parameters\\\": self._convert_parameters_to_metadata(),\\n            \\\"returns\\\": self._convert_returns_to_metadata(),\\n            \\\"is_method\\\": self.is_method,\\n            \\\"is_async\\\": self.is_async,\\n        }\\n\\n\\nclass FunctionModel(BaseCodeBlockModel, FunctionSpecificAttributes):\\n    \\\"\\\"\\\"Model for a function.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the function model to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_function_attributes_to_metadata_dict(),\\n        }\\n\\n\\nclass StandaloneCodeBlockSpecificAttributes(BaseModel):\\n    \\\"\\\"\\\"Standalone code block specific attributes.\\\"\\\"\\\"\\n\\n    variable_assignments: list[str] | None = None\\n\\n    def _convert_variable_assignments_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the variable assignments to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json() if self.variable_assignments else \\\"\\\"\\n\\n    def _convert_standalone_block_attributes_to_metadata_dict(\\n        self,\\n    ) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the standalone code block attributes to a metadata dictionary.\\\"\\\"\\\"\\n        return {\\n            \\\"variable_assignments\\\": self._convert_variable_assignments_to_metadata(),\\n        }\\n\\n\\nclass StandaloneCodeBlockModel(\\n    BaseCodeBlockModel, StandaloneCodeBlockSpecificAttributes\\n):\\n    \\\"\\\"\\\"Model for a standalone code block.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the standalone code block model to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_standalone_block_attributes_to_metadata_dict(),\\n        }\\n\\n\\nImported code block (postcode:databases:chroma:setup_chroma.py__*__MODULE) code content:\\nfrom dataclasses import dataclass\\nfrom logging import Logger\\n\\nimport chromadb\\nfrom postcode.databases.chroma.chromadb_client_manager import ChromaDBClientManager\\n\\nfrom postcode.databases.chroma.chromadb_collection_manager import (\\n    ChromaDBCollectionManager,\\n)\\n\\nfrom chromadb.config import DEFAULT_DATABASE, DEFAULT_TENANT, Settings\\nfrom chromadb.api import ClientAPI\\nfrom chromadb.api.types import (\\n    DataLoader,\\n    CollectionMetadata,\\n    GetResult,\\n    QueryResult,\\n    Where,\\n    WhereDocument,\\n    Include,\\n    URIs,\\n    Loadable,\\n    Metadata,\\n    Embedding,\\n)\\nfrom chromadb import Collection\\nfrom chromadb import EmbeddingFunction\\n\\nfrom postcode.models.models import ModuleModel\\n\\n\\n@dataclass\\nclass ChromaSetupReturnContext:\\n    \\\"\\\"\\\"\\n    Represents the return value of the ChromaDB setup method.\\n\\n    Attributes:\\n        - chroma_collection_manager (ChromaDBCollectionManager): The ChromaDB collection manager.\\n        - chroma_collection (Collection): The ChromaDB collection.\\n    \\\"\\\"\\\"\\n\\n    chroma_collection_manager: ChromaDBCollectionManager\\n    chroma_collection: Collection\\n\\n\\ndef setup_chroma(\\n    module_models: list[ModuleModel], logger: Logger\\n) -> ChromaSetupReturnContext:\\n    chroma_settings = Settings(allow_reset=True)\\n    chroma_client: ClientAPI = chromadb.PersistentClient(settings=chroma_settings)\\n    chroma_client_manager = ChromaDBClientManager(chroma_client)\\n\\n    logger.debug(f\\\"Resetting Chroma client\\\")\\n    if chroma_client_manager.reset_client():\\n        logger.debug(\\\"Client reset\\\")\\n\\n    chroma_collection: Collection = chroma_client_manager.get_or_create_collection(\\n        \\\"postcode\\\"\\n    )\\n\\n    chroma_collection_manager = ChromaDBCollectionManager(chroma_collection)\\n    chroma_collection_manager.upsert_models(tuple(module_models))\\n\\n    return ChromaSetupReturnContext(chroma_collection_manager, chroma_collection)\\n\\n\\nImported code block (postcode:updaters:graph_db_updater.py__*__MODULE) code content:\\nfrom logging import Logger\\n\\nfrom openai import OpenAI\\nfrom postcode.ai_services.summarizer.graph_db_summarization_manager import (\\n    GraphDBSummarizationManager,\\n)\\nfrom postcode.ai_services.summarizer.openai_summarizer import OpenAISummarizer\\nfrom postcode.ai_services.summarizer.summarization_mapper import SummarizationMapper\\nfrom postcode.databases.arangodb.arangodb_connector import ArangoDBConnector\\n\\nfrom postcode.databases.arangodb.arangodb_manager import ArangoDBManager\\nfrom postcode.databases.chroma.setup_chroma import (\\n    ChromaSetupReturnContext,\\n    setup_chroma,\\n)\\nfrom postcode.json_management.json_handler import JSONHandler\\nfrom postcode.models.models import ModuleModel\\nfrom postcode.python_parser.visitor_manager.visitor_manager import (\\n    VisitorManager,\\n    VisitorManagerProcessFilesReturn,\\n)\\n\\n\\nclass GraphDBUpdater:\\n    def __init__(\\n        self,\\n        directory: str,\\n        output_directory: str,\\n        logger: Logger,\\n        arango_connector: ArangoDBConnector = ArangoDBConnector(),\\n    ) -> None:\\n        self.directory: str = directory\\n        self.output_directory: str = output_directory\\n        self.logger: Logger = logger\\n        self.arango_connector: ArangoDBConnector = arango_connector\\n\\n        self.arango_connector.delete_all_collections()\\n        self.arango_connector.ensure_collections()\\n        self.graph_manager = ArangoDBManager(arango_connector)\\n\\n    def update_all(\\n        self,\\n        directory: str,\\n        output_directory: str,\\n        logger: Logger,\\n    ) -> ChromaSetupReturnContext:\\n        logger.info(\\\"Starting the directory parsing.\\\")\\n\\n        visitor_manager = VisitorManager(directory, output_directory)\\n        process_files_return: VisitorManagerProcessFilesReturn = (\\n            visitor_manager.process_files()\\n        )\\n\\n        module_models_tuple: tuple[ModuleModel, ...] = process_files_return.models_tuple\\n        module_ids: list[str] = [model.id for model in module_models_tuple]\\n        directory_modules: dict[str, list[str]] = process_files_return.directory_modules\\n        self.graph_manager.upsert_models(\\n            list(module_models_tuple)\\n        ).process_imports_and_dependencies().get_or_create_graph()\\n        summarization_mapper = SummarizationMapper(\\n            module_ids, module_models_tuple, self.graph_manager\\n        )\\n        client = OpenAI(max_retries=4)\\n        summarizer = OpenAISummarizer(client=client)\\n        summarization_manager = GraphDBSummarizationManager(\\n            module_models_tuple, summarization_mapper, summarizer, self.graph_manager\\n        )\\n        finalized_module_models: list[\\n            ModuleModel\\n        ] | None = summarization_manager.create_summaries_and_return_updated_models()\\n        logger.info(\\\"Summarization complete\\\")\\n\\n        logger.info(\\\"Saving models as JSON\\\")\\n        json_manager = JSONHandler(directory, directory_modules, output_directory)\\n\\n        for module_model in module_models_tuple:\\n            json_manager.save_model_as_json(module_model, module_model.file_path)\\n\\n        json_manager.save_visited_directories()\\n        logger.info(\\\"JSON save complete\\\")\\n\\n        logger.info(\\\"Directory parsing completed.\\\")\\n\\n        # self.graph_manager.upsert_models(\\n        #     list(finalized_module_models)\\n        # ).process_imports_and_dependencies().get_or_create_graph()\\n\\n        if finalized_module_models:\\n            chroma_context: ChromaSetupReturnContext = setup_chroma(\\n                finalized_module_models, logger\\n            )\\n        else:\\n            raise Exception(\\\"No finalized models returned from summarization.\\\")\\n\\n        return chroma_context\\n\\n\\nImported code block (postcode:utilities:logger:logging_config.py__*__MODULE) code content:\\nimport logging\\n\\nfrom rich.logging import RichHandler\\nfrom rich.syntax import Syntax\\n\\n\\ndef setup_logging(level=logging.INFO) -> None:\\n    \\\"\\\"\\\"\\n    Configures the logging system to use RichSyntaxHandler for output.\\n\\n    This function sets up logging with a specific log level and format. It utilizes the RichSyntaxHandler to support rich text and syntax highlighting in log outputs.\\n\\n    Args:\\n        level (int, optional): The logging level to set for the root logger. Defaults to logging.INFO.\\n\\n    Example:\\n        >>> setup_logging(logging.DEBUG)\\n        # Configures logging at DEBUG level with RichSyntaxHandler.\\n    \\\"\\\"\\\"\\n\\n    format_str = \\\"%(message)s\\\"\\n    logging.basicConfig(level=level, format=format_str, handlers=[RichSyntaxHandler()])\\n\\n\\nclass RichSyntaxHandler(RichHandler):\\n    \\\"\\\"\\\"\\n    A custom logging handler that extends RichHandler to add syntax highlighting.\\n\\n    This handler checks if the log record contains a 'syntax_highlight' attribute and, if so, uses 'rich.syntax.Syntax' to render the message with Python syntax highlighting.\\n\\n    Inherits:\\n        RichHandler: The base handler provided by the rich library for rich text formatting.\\n    \\\"\\\"\\\"\\n\\n    def emit(self, record) -> None:\\n        \\\"\\\"\\\"\\n        Emits a logging record.\\n\\n        If the record has the 'syntax_highlight' attribute set to True, it renders the 'content' attribute of the record with syntax highlighting. Otherwise, it falls back to the standard behavior of RichHandler.\\n\\n        Args:\\n            record: The logging record to emit.\\n\\n        Example:\\n            # Assuming `logger` is a logger instance\\n            >>> logger.info(\\\"Regular log message\\\")\\n            # Outputs a regular log message.\\n\\n            >>> logger.info(\\\"Highlighted log message\\\", extra={\\\"syntax_highlight\\\": True, \\\"content\\\": \\\"print('Hello, world!')\\\"})\\n            # Outputs the message with syntax highlighting.\\n        \\\"\\\"\\\"\\n\\n        try:\\n            if hasattr(record, \\\"syntax_highlight\\\") and getattr(\\n                record, \\\"syntax_highlight\\\"\\n            ):\\n                content: str = getattr(record, \\\"content\\\", \\\"\\\")\\n                if isinstance(content, str):\\n                    syntax = Syntax(\\n                        content, \\\"python\\\", theme=\\\"material\\\", line_numbers=True\\n                    )\\n                    self.console.print(syntax)\\n                return\\n\\n        except Exception as e:\\n            self.handleError(record)\\n\\n        super().emit(record)\\n\\n\\nImported code block (postcode:databases:chroma:chromadb_collection_manager.py__*__MODULE) code content:\\nimport logging\\nfrom typing import Any, Mapping, Union\\n\\nfrom postcode.models.models import ModuleModel\\nimport postcode.types.chroma as chroma_types\\nfrom chromadb.config import DEFAULT_DATABASE, DEFAULT_TENANT, Settings\\nfrom chromadb.api import ClientAPI\\nfrom chromadb.api.types import (\\n    DataLoader,\\n    CollectionMetadata,\\n    GetResult,\\n    QueryResult,\\n    Where,\\n    WhereDocument,\\n    Include,\\n    URIs,\\n    Loadable,\\n    Metadata,\\n    Embedding,\\n)\\nfrom chromadb import Collection\\nfrom chromadb import EmbeddingFunction\\n# from postcode.types.postcode import ModelType\\nfrom postcode.models.models import ModuleModel, ClassModel, FunctionModel, StandaloneCodeBlockModel\\nModelType = Union[\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n]\\n\\n\\nclass ChromaDBCollectionManager:\\n    \\\"\\\"\\\"\\n    Manages a collection within ChromaDB instance, providing functionalities for adding, retrieving,\\n    and querying embeddings, and their associated metadata.\\n\\n    This class serves as an interface to interact with a specific collection in ChromaDB.\\n\\n    Attributes:\\n        - collection (chroma_types.Collection): An instance of the Collection class from ChromaDB\\n            which this manager is responsible for.\\n\\n    Methods:\\n        - `collection_embedding_count`: Gets the total number of embeddings in the collection.\\n        - `add_embeddings`: Adds embeddings to the collection.\\n        - `get_embeddings`: Gets embeddings and their metadata from the collection in the form of a TypedDict.\\n        - `query_collection`: Queries and returns the `n` nearest neighbors from the collection.\\n        - `upsert_models`: Loads or updates the embeddings of the provided module models into the collection.\\n\\n    Examples:\\n        ```Python\\n        from postcode.databases.chroma import ChromaDBClientBuilder\\n        import postcode.types.chromadb.types as chroma_types\\n\\n        # Create a persistent ChromaDB client\\n        client: chroma_types.ClientAPI = ChromaDBClientBuilder.create_persistent_client()\\n\\n        # Instantiate the ChromaDBCollectionManager with a specific collection\\n        collection_manager: ChromaDBCollectionManager = (\\n            ChromaDBCollectionManager(client.get_collection(\\\"my_collection\\\"))\\n        )\\n\\n        # Example usage of the collection manager\\n        embedding_count: int = collection_manager.collection_embedding_count()\\n        print(f\\\"Total embeddings: {embedding_count}\\\")\\n        ```\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, collection: Collection) -> None:\\n        self.collection: Collection = collection\\n\\n    def collection_embedding_count(self) -> int | None:\\n        \\\"\\\"\\\"\\n        Gets the total number of embeddings in the collection.\\n\\n        Returns:\\n            - embedding_count (int): The total number of embeddings in the collection.\\n\\n        Examples:\\n            ```Python\\n            embedding_count: int = collection_manager.get_collection_embedding_count()\\n            ```\\n        \\\"\\\"\\\"\\n        try:\\n            embedding_count: int = self.collection.count()\\n            logging.info(\\n                f\\\"Collection {self.collection.name} has {embedding_count} embeddings.\\\"\\n            )\\n            return embedding_count\\n        except Exception as exception:\\n            logging.error(exception)\\n\\n    def add_embeddings(\\n        self,\\n        ids: list[str],\\n        documents: list[str],\\n        metadatas: list[Mapping[str, str | int | float | bool]],\\n    ) -> None:\\n        \\\"\\\"\\\"\\n        Adds embeddings to the collection.\\n\\n        Args:\\n            - ids (list[str]): A list of ids to add to the collection.\\n            - documents (list[str]): A list of documents to add to the collection.\\n            - metadatas (list[dict[str, Any]]): A list of metadatas to add to the collection.\\n\\n        Raises:\\n            - ValueError - If you don't provide either embeddings or documents.\\n            - ValueError: If the length of ids, embeddings, metadatas, or documents don't match.\\n            - ValueError - If you provide an id that already exists.\\n\\n        Examples:\\n            ```Python\\n            # define the ids, metadatas, and documents to add to the collection\\n            id: list[str] = [\\\"my_id\\\", \\\"my_id2\\\"]\\n            metadatas: list[dict[str, Any]] = [\\n                {\\\"my_metadata\\\": \\\"my_metadata_value\\\"},\\n                {\\\"my_metadata2\\\": \\\"my_metadata_value2\\\"},\\n            ]\\n            documents: list[str] = [\\\"my_document\\\", \\\"my_document2\\\"]\\n\\n            # add the embeddings to the collection\\n            collection_manager.add_embeddings(id, metadatas, documents)\\n            ```\\n        \\\"\\\"\\\"\\n\\n        if not len(ids) == len(documents) == len(metadatas):\\n            raise ValueError(\\\"The length of ids, documents, and metadatas must match.\\\")\\n\\n        try:\\n            logging.info(f\\\"Adding embeddings to collection {self.collection.name}\\\")\\n            self.collection.add(ids, documents=documents, metadatas=metadatas)\\n        except Exception as exception:\\n            raise exception\\n\\n    def get_embeddings(\\n        self,\\n        ids: list[str] | None,\\n        *,\\n        where_filter: Where | None = None,\\n        limit: int | None = None,\\n        where_document_filter: WhereDocument | None = None,\\n        include_in_result: Include = [\\\"metadatas\\\", \\\"documents\\\"],\\n    ) -> GetResult | None:\\n        \\\"\\\"\\\"\\n        Gets embeddings and their metadata from the collection in the form of a TypedDict.\\n\\n        Args:\\n            - ids (list[str]): A list of ids to get from the collection.\\n            - where_filter (chroma_types.Where | None): A TypedDict used to filter the results.\\n            - limit (int | None): The maximum number of results to return.\\n            - where_document_filter (chroma_types.WhereDocument | None): A TypedDict used to filter the results by the document,\\n                e.g. `{$contains: {\\\"text\\\": \\\"hello\\\"}}`\\n            - include_in_result (chroma_types.Include | None): A list used of what to return from the results, e.g. `[\\\"metadatas\\\", \\\"embeddings\\\", \\\"documents\\\"]`\\n\\n        Returns:\\n            - embeddings (TypedDict): A typed dict of embedding data from the collection with the following keys:\\n                - ids: list[str]\\n                - embeddings: list[Embedding] | None\\n                - documents: list[str] | None\\n                - uris: chroma_types.URIs | None\\n                - data: chroma_types.Loadable | None\\n                - metadatas: list[chroma_types.Metadata]]\\n\\n        Raises:\\n            - ValueError: If the length of ids, embeddings, metadatas, or documents don't match.\\n            - ValueError: If you provide an id that doesn't exist.\\n\\n        Examples:\\n            ```Python\\n            import postcode.types.chromadb.types as chroma_types\\n\\n            # define the ids, filters to use to get embeddings from the collection\\n            ids: list[str] = [\\\"my_id\\\", \\\"my_id2\\\"]\\n            where_filter: chroma_types.Where = {\\\"my_metadata\\\": \\\"my_metadata_value\\\"}\\n            where_document_filter: chroma_types.WhereDocument = {\\\"$contains\\\": {\\\"text\\\": \\\"hello\\\"}}\\n\\n            # define the data to return from the collection\\n            include_in_result: chroma_types.Include = [\\\"metadatas\\\"]\\n\\n            # get the embeddings from the collection\\n            embeddings: chroma_types.GetResult = collection_manager.get_embeddings(\\n                ids,\\n                where_filter=where_filter,\\n                where_document_filter=where_document_filter,\\n                include_in_result=include_in_result\\n                )\\n            ```\\n        \\\"\\\"\\\"\\n\\n        try:\\n            logging.info(f\\\"Getting embeddings from collection {self.collection.name}\\\")\\n            return self.collection.get(\\n                ids,\\n                where=where_filter,\\n                limit=limit,\\n                where_document=where_document_filter,\\n                include=include_in_result,\\n            )\\n        except Exception as exception:\\n            raise exception\\n\\n    def query_collection(\\n        self,\\n        queries: list[str],\\n        n_results: int = 10,\\n        where_filter: Where | None = None,\\n        where_document_filter: WhereDocument | None = None,\\n        include_in_result: Include = [\\\"metadatas\\\", \\\"documents\\\"],\\n    ) -> QueryResult | None:\\n        \\\"\\\"\\\"\\n        Queries and returns the `n` nearest neighbors from the collection.\\n\\n        Args:\\n            - queries (list[str]): A list of queries to search the collection for.\\n            - n_results (int): The number of results to return.\\n            - where_filter (chroma_types.Where | None): A TypedDict used to filter the results.\\n                - e.g. `{\\\"block_type\\\": \\\"FUNCTION\\\", \\\"children\\\": None}`\\n            - where_document_filter (chroma_types.WhereDocument | None): A TypedDict used to filter the results by the document,\\n                - e.g. `{$contains: \\\"binary search\\\"}`\\n            - include_in_result (chroma_types.Include | None): A list used of what to return from the results, e.g. `[\\\"metadatas\\\", \\\"embeddings\\\", \\\"documents\\\"]`\\n\\n        Returns:\\n            - results (chroma_types.QueryResult | None): A typed dict of query results from the collection, can have the following keys based on the\\n                `include_in_result` parameter:\\n                - ids: list[str] # The ids are always returned.\\n                - embeddings: List[list[Embedding]] | None\\n                - documents: list[list[str]]] | None\\n                - uris: list[list[URI]]] | None\\n                - data: list[Loadable] | None\\n                - metadatas: list[list[Metadata]] | None\\n                - distances: list[list[float]] | None\\n\\n        Raises:\\n            - ValueError: If you don't provide query_texts.\\n\\n        Examples:\\n            ```Python\\n            import postcode.types.chromadb.types as chroma\\n\\n            # define the queries and filters used to search the collection\\n            queries: list[str] = [\\\"binary search\\\", \\\"linear search\\\"]\\n            where_filter: chroma_types.Where = {\\\"block_type\\\": \\\"FUNCTION\\\"}\\n\\n            # define the data to return from the collection\\n            include_in_result: chroma_types.Include = [\\\"metadatas\\\", \\\"documents\\\", \\\"distances\\\"]\\n\\n            # query the collection and return the results from the collection\\n            results: chroma_types.QueryResult = collection_manager.query_collection(\\n                queries,\\n                where_filter=where_filter,\\n                include_in_result=include_in_result\\n                )\\n            ```\\n        \\\"\\\"\\\"\\n\\n        try:\\n            logging.info(f\\\"Querying collection {self.collection.name}\\\")\\n\\n            if results := self.collection.query(\\n                query_texts=queries,\\n                n_results=n_results,\\n                where=where_filter,\\n                where_document=where_document_filter,\\n                include=include_in_result,\\n            ):\\n                return results\\n            else:\\n                logging.warning(\\n                    f\\\"No results found from collection {self.collection.name}.\\\"\\n                )\\n\\n        except Exception as exception:\\n            raise exception\\n\\n    def modify_collection_name(self, name: str) -> None:\\n        \\\"\\\"\\\"\\n        Modifies the name of the collection managed by this class.\\n\\n        Args:\\n            - name (str): The new name to assign to the collection.\\n\\n        Examples:\\n            ```Python\\n            # Rename the collection to 'new_collection_name'\\n            collection_manager.modify_collection_name('new_collection_name')\\n            ```\\n        \\\"\\\"\\\"\\n\\n        self.collection.modify(name=name)\\n\\n    def modify_collection_metadata(\\n        self, metadata: dict[str, Any] | None = None\\n    ) -> None:\\n        \\\"\\\"\\\"\\n        Modifies the metadata of the collection managed by this class.\\n\\n        Args:\\n            - metadata (dict[str, Any] | None): The new metadata to assign to the collection. If None, no change is made.\\n\\n        Examples:\\n            ```Python\\n            # Update metadata of the collection\\n            new_metadata = {\\\"description\\\": \\\"Updated collection metadata\\\"}\\n            collection_manager.modify_collection_metadata(new_metadata)\\n            ```\\n        \\\"\\\"\\\"\\n\\n        self.collection.modify(metadata=metadata)\\n\\n    def _update_metadata_or_documents_by_ids(\\n        self,\\n        ids: list[str],\\n        metadatas: list[Mapping[str, str | int | float | bool]] | None = None,\\n        documents: list[str] | None = None,\\n    ) -> None:\\n        \\\"\\\"\\\"\\n        Updates the metadata or documents of specific entries in the collection by their ids.\\n\\n        Args:\\n            - ids (list[str]): List of ids of the entries to be updated.\\n            - metadatas (list[Mapping[str, Any]] | None): List of metadata updates corresponding to the ids.\\n            - documents (list[str] | None): List of document updates corresponding to the ids.\\n\\n        Raises:\\n            - ValueError: If neither metadatas nor documents are provided.\\n            - ValueError: If the length of ids and documents don't match.\\n            - ValueError: If the length of ids and metadatas don't match.\\n            - ValueError: If the length of ids, metadatas, and documents don't match.\\n\\n        Notes:\\n            - As of now, ChromaDB doesn't raise an exception if you provide an id that doesn't exist.\\n\\n        Examples:\\n            ```Python\\n            # Update metadata and documents for specific ids\\n            ids_to_update = ['id1', 'id2']\\n            metadata_updates = [{\\\"key1\\\": \\\"value1\\\"}, {\\\"key2\\\": \\\"value2\\\"}]\\n            document_updates = [\\\"new document 1\\\", \\\"new document 2\\\"]\\n            collection_manager.update_metadata_or_documents_by_ids(ids_to_update, metadata_updates, document_updates)\\n            ```\\n        \\\"\\\"\\\"\\n\\n        if not metadatas and not documents:\\n            raise ValueError(\\\"You must provide either metadatas or documents.\\\")\\n        if not metadatas and documents:\\n            if len(ids) != len(documents):\\n                raise ValueError(\\\"The length of ids and documents must match.\\\")\\n        if metadatas and not documents:\\n            if len(ids) != len(metadatas):\\n                raise ValueError(\\\"The length of ids and metadatas must match.\\\")\\n        if metadatas and documents:\\n            if len(ids) != len(metadatas) != len(documents):\\n                raise ValueError(\\n                    \\\"The length of ids, metadatas, and documents must match.\\\"\\n                )\\n        for index, id in enumerate(ids):\\n            if not self.collection.get(id):\\n                logging.error(\\n                    f\\\"Id {id} does not exist in collection {self.collection.name}.\\\"\\n                )\\n                ids.pop(index)\\n                if metadatas:\\n                    popped_metadata = metadatas.pop(index)\\n                    if popped_metadata:\\n                        logging.warning(\\n                            f\\\"Removing metadata at index {index} from update.\\\"\\n                        )\\n                if documents:\\n                    popped_document = documents.pop(index)\\n                    if popped_document:\\n                        logging.warning(\\n                            f\\\"Removing document at index {index} from update.\\\"\\n                        )\\n\\n        if not ids:\\n            logging.warning(\\\"All updates failed.\\\")\\n            return None\\n        else:\\n            logging.info(f\\\"Updating collection {self.collection.name} with ids {ids}.\\\")\\n            self.collection.update(ids=ids, metadatas=metadatas, documents=documents)\\n\\n    def _upsert_documents(\\n        self,\\n        ids: list[str],\\n        documents: list[str],\\n        metadatas: list[Mapping[str, str | int | float | bool]],\\n        # embeddings: list[chroma_types.Embedding],\\n    ) -> None:\\n        \\\"\\\"\\\"\\n        Inserts or updates documents in the collection, based on the provided ids.\\n\\n        Args:\\n            - ids (list[str]): List of ids for the documents to be inserted or updated.\\n            - documents (list[str]): List of documents corresponding to the ids.\\n            - metadatas (list[Mapping[str, Any]]): List of metadata corresponding to the ids.\\n\\n        Raises:\\n            - ValueError: If the lengths of ids, documents, and metadatas don't match.\\n\\n        Examples:\\n            ```Python\\n            # Upsert documents in the collection\\n            ids = ['id1', 'id2']\\n            documents = ['doc1', 'doc2']\\n            metadatas = [{\\\"meta1\\\": \\\"value1\\\"}, {\\\"meta2\\\": \\\"value2\\\"}]\\n\\n            # Upsert documents in the collection\\n            collection_manager.upsert_documents(ids, documents, metadatas)\\n            ```\\n        \\\"\\\"\\\"\\n\\n        if len(ids) != len(documents) != len(metadatas):\\n            raise ValueError(\\\"The length of ids, documents, and metadatas must match.\\\")\\n\\n        logging.info(f\\\"Upserting collection {self.collection.name} with ids {ids}.\\\")\\n        self.collection.upsert(\\n            ids=ids,\\n            # embeddings=embeddings,\\n            metadatas=metadatas,\\n            documents=documents,\\n        )\\n\\n    def delete_embeddings(self, ids: list[str]) -> None:\\n        \\\"\\\"\\\"\\n        Deletes embeddings from the collection based on the provided ids.\\n\\n        Args:\\n            - ids (list[str]): List of ids corresponding to the embeddings to be deleted.\\n\\n        Examples:\\n            ```Python\\n            # Delete specific embeddings by ids\\n            ids_to_delete = ['id1', 'id2']\\n            collection_manager.delete_embeddings(ids_to_delete)\\n            ```\\n        \\\"\\\"\\\"\\n\\n        ids_to_delete: list[str] = ids.copy()\\n        for index, id in enumerate(ids_to_delete):\\n            if not self.collection.get(id):\\n                logging.error(\\n                    f\\\"Id {id} does not exist in collection {self.collection.name}.\\\"\\n                )\\n                ids_to_delete.pop(index)\\n\\n        if not ids_to_delete:\\n            logging.warning(\\\"No IDs given were in the database.\\\")\\n            return None\\n\\n        logging.info(\\n            f\\\"Deleting embeddings from collection {self.collection.name} with ids {ids_to_delete}.\\\"\\n        )\\n        self.collection.delete(ids_to_delete)\\n\\n    def upsert_models(self, module_models: tuple[ModuleModel, ...]) -> None:\\n        \\\"\\\"\\\"\\n        Loads or updates the embeddings of the provided module models into the collection.\\n\\n        The Pydantic models are converted to a dictionary with a format that ChromaDB can use, then the ids, documents, and metadatas\\n        are added to their respective lists. The lists are then either added to or updated in the collection depending on whether or\\n        not the code blocks were in the the collection to begin with.\\n\\n        Args:\\n            - module_models (tuple[ModuleModel, ...]): The module models to load or update into the collection.\\n\\n        Examples:\\n            ```Python\\n            # Upsert module models into the collection\\n            module_models = (module_model1, module_model2)\\n            collection_manager.upsert_models(module_models)\\n            ```\\n        \\\"\\\"\\\"\\n\\n        ids: list[str] = []\\n        documents: list[str] = []\\n        metadatas: list[Mapping[str, str | int | float | bool]] = []\\n\\n        for module_model in module_models:\\n            if module_model.summary:\\n                ids.append(module_model.id)\\n                documents.append(module_model.summary)\\n                metadatas.append(module_model.convert_to_metadata())\\n\\n            if module_model.children:\\n                for child in module_model.children:\\n                    child_data: dict[str, Any] = self._recursively_gather_child_data(\\n                        child\\n                    )\\n                    ids.extend(child_data[\\\"ids\\\"])\\n                    documents.extend(child_data[\\\"documents\\\"])\\n                    metadatas.extend(child_data[\\\"metadatas\\\"])\\n\\n        logging.info(\\n            f\\\"{self.collection.name} has {self.collection_embedding_count()} embeddings.\\\"\\n        )\\n        self._upsert_documents(ids=ids, documents=documents, metadatas=metadatas)\\n        logging.info(\\n            f\\\"After upsert {self.collection.name} has {self.collection_embedding_count()} embeddings.\\\"\\n        )\\n\\n    def _recursively_gather_child_data(self, model: ModelType) -> dict[str, Any]:\\n        ids: list[str] = []\\n        documents: list[str] = []\\n        metadatas: list[Mapping[str, str | int | float | bool]] = []\\n        if model.summary:\\n            ids.append(model.id)\\n            documents.append(model.summary)\\n            metadatas.append(model.convert_to_metadata())\\n        else:\\n            logging.warning(f\\\"Child {model.id} has no summary.\\\")\\n        if model.children:\\n            for child in model.children:\\n                child_data: dict[str, Any] = self._recursively_gather_child_data(child)\\n                ids.extend(child_data[\\\"ids\\\"])\\n                documents.extend(child_data[\\\"documents\\\"])\\n                metadatas.extend(child_data[\\\"metadatas\\\"])\\n\\n        return {\\n            \\\"ids\\\": ids,\\n            \\\"documents\\\": documents,\\n            \\\"metadatas\\\": metadatas,\\n        }\\n\\n\\nImported code block (postcode:updaters:standard_updater.py__*__MODULE) code content:\\n# Create method, `update_all`, that updates the whole project, it parses all code, wipes all databases, and summarizes all code blocks,\\n# then updates all the databases with the new information.\\n\\n\\nfrom logging import Logger\\n\\nfrom openai import OpenAI\\nfrom postcode.ai_services.summarizer.openai_summarizer import OpenAISummarizer\\nfrom postcode.ai_services.summarizer.standard_summarization_manager import (\\n    StandardSummarizationManager,\\n)\\n\\nfrom postcode.databases.chroma.setup_chroma import (\\n    ChromaSetupReturnContext,\\n    setup_chroma,\\n)\\nfrom postcode.json_management.json_handler import JSONHandler\\n\\nfrom postcode.models.models import ModuleModel\\nfrom postcode.python_parser.visitor_manager.visitor_manager import (\\n    VisitorManager,\\n    VisitorManagerProcessFilesReturn,\\n)\\n\\n\\nclass StandardUpdater:\\n    @staticmethod\\n    def update_all(\\n        directory: str, output_directory: str, logger: Logger\\n    ) -> ChromaSetupReturnContext:\\n        visitor_manager = VisitorManager(directory, output_directory)\\n        process_files_return: VisitorManagerProcessFilesReturn = (\\n            visitor_manager.process_files()\\n        )\\n\\n        module_models_tuple: tuple[ModuleModel, ...] = process_files_return.models_tuple\\n        client = OpenAI(max_retries=4)\\n        summarizer = OpenAISummarizer(client=client)\\n        summarization_manager = StandardSummarizationManager(\\n            module_models_tuple, summarizer\\n        )\\n        finalized_module_models: tuple[\\n            ModuleModel, ...\\n        ] = summarization_manager.create_summarizes_and_return_updated_models()\\n\\n        logger.info(\\\"Summarization complete\\\")\\n\\n        logger.info(\\\"Saving models as JSON\\\")\\n        directory_modules: dict[str, list[str]] = process_files_return.directory_modules\\n        json_manager = JSONHandler(directory, directory_modules, output_directory)\\n\\n        for module_model in module_models_tuple:\\n            json_manager.save_model_as_json(module_model, module_model.file_path)\\n\\n        json_manager.save_visited_directories()\\n        logger.info(\\\"JSON save complete\\\")\\n\\n        logger.info(\\\"Directory parsing completed.\\\")\\n\\n        chroma_context: ChromaSetupReturnContext = setup_chroma(\\n            finalized_module_models, logger\\n        )\\n\\n        return chroma_context\\n\\n, \\nimport logging\\nfrom logging import Logger\\nfrom typing import Union\\nfrom chromadb.api.types import QueryResult\\nfrom chromadb import Collection\\n        \",\"children\":[{\"variable_assignments\":[\"ModelType = Union[\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n]\"],\"id\":\"postcode:app.py__*__MODULE__*__STANDALONE_BLOCK-1\",\"parent_id\":\"postcode:app.py__*__MODULE\",\"block_type\":\"STANDALONE_BLOCK\",\"start_line_num\":16,\"end_line_num\":23,\"code_content\":\"ModelType = Union[\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n]\\n\",\"important_comments\":null,\"dependencies\":[{\"import_names\":[{\"name\":\"Union\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"typing\",\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"},{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ClassModel\"},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-FunctionModel\"},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-StandaloneCodeBlockModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"},{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ClassModel\"},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-FunctionModel\"},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-StandaloneCodeBlockModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"},{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ClassModel\"},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-FunctionModel\"},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-StandaloneCodeBlockModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"},{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ClassModel\"},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-FunctionModel\"},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-StandaloneCodeBlockModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"}],\"summary\":null,\"children\":null},{\"function_name\":\"query_chroma\",\"docstring\":null,\"decorators\":null,\"parameters\":null,\"returns\":\"None\",\"is_method\":false,\"is_async\":false,\"id\":\"postcode:app.py__*__MODULE__*__FUNCTION-query_chroma\",\"parent_id\":\"postcode:app.py__*__MODULE\",\"block_type\":\"FUNCTION\",\"start_line_num\":36,\"end_line_num\":58,\"code_content\":\"\\n\\ndef query_chroma(\\n    query: str,\\n    chroma_collection_manager: ChromaDBCollectionManager,\\n    chroma_collection: Collection,\\n    logger: Logger,\\n) -> None:\\n    logger.info(f\\\"Querying ChromaDB collection {chroma_collection.name}\\\")\\n    results: QueryResult | None = chroma_collection_manager.query_collection(\\n        [query],\\n        n_results=10,\\n        # where_filter={\\\"block_type\\\": \\\"MODULE\\\"},\\n        include_in_result=[\\\"metadatas\\\", \\\"documents\\\", \\\"embeddings\\\"],\\n    )\\n    logger.info(\\\"Query results:\\\")\\n    if results:\\n        if results[\\\"ids\\\"]:\\n            for document in results[\\\"ids\\\"][0]:\\n                print(document)\\n\\n            print(f\\\"Total results: {len(results['ids'][0])}\\\")\\n\",\"important_comments\":null,\"dependencies\":[{\"import_names\":[{\"name\":\"Logger\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"logging\",\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"ChromaDBCollectionManager\",\"as_name\":null,\"local_block_id\":\"postcode:databases:chroma:chromadb_collection_manager.py__*__MODULE__*__CLASS-ChromaDBCollectionManager\"}],\"imported_from\":\"postcode.databases.chroma.chromadb_collection_manager\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:databases:chroma:chromadb_collection_manager.py__*__MODULE\"},{\"import_names\":[{\"name\":\"QueryResult\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"chromadb.api.types\",\"import_module_type\":\"THIRD_PARTY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"Collection\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"chromadb\",\"import_module_type\":\"THIRD_PARTY\",\"local_module_id\":null}],\"summary\":null,\"children\":null},{\"function_name\":\"main\",\"docstring\":null,\"decorators\":null,\"parameters\":null,\"returns\":\"None\",\"is_method\":false,\"is_async\":false,\"id\":\"postcode:app.py__*__MODULE__*__FUNCTION-main\",\"parent_id\":\"postcode:app.py__*__MODULE\",\"block_type\":\"FUNCTION\",\"start_line_num\":58,\"end_line_num\":87,\"code_content\":\"\\n\\ndef main(\\n    directory: str = \\\".\\\",\\n    output_directory: str = \\\"output_json\\\",\\n) -> None:\\n    setup_logging()\\n    logger: Logger = logging.getLogger(__name__)\\n\\n    #   ==================== GraphDB ====================\\n    graph_db_updater = GraphDBUpdater(directory, output_directory, logger)\\n    chroma_context: ChromaSetupReturnContext = graph_db_updater.update_all(\\n        directory, output_directory, logger\\n    )\\n    # ==================== End GraphDB ====================\\n\\n    #   ==================== Standard ====================\\n    # chroma_context: ChromaSetupReturnContext = StandardUpdater.update_all(\\n    #     directory, output_directory, logger\\n    # )\\n    # ==================== End Standard ====================\\n\\n    query: str = \\\"summarizes code block\\\"\\n    query_chroma(\\n        query,\\n        chroma_context.chroma_collection_manager,\\n        chroma_context.chroma_collection,\\n        logger,\\n    )\\n\",\"important_comments\":null,\"dependencies\":[{\"code_block_id\":\"postcode:app.py__*__MODULE__*__FUNCTION-query_chroma\"},{\"import_names\":[{\"name\":\"logging\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":null,\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"Logger\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"logging\",\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"ChromaSetupReturnContext\",\"as_name\":null,\"local_block_id\":\"postcode:databases:chroma:setup_chroma.py__*__MODULE__*__CLASS-ChromaSetupReturnContext\"}],\"imported_from\":\"postcode.databases.chroma.setup_chroma\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:databases:chroma:setup_chroma.py__*__MODULE\"},{\"import_names\":[{\"name\":\"GraphDBUpdater\",\"as_name\":null,\"local_block_id\":\"postcode:updaters:graph_db_updater.py__*__MODULE__*__CLASS-GraphDBUpdater\"}],\"imported_from\":\"postcode.updaters.graph_db_updater\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:updaters:graph_db_updater.py__*__MODULE\"},{\"import_names\":[{\"name\":\"setup_logging\",\"as_name\":null,\"local_block_id\":\"postcode:utilities:logger:logging_config.py__*__MODULE__*__FUNCTION-setup_logging\"}],\"imported_from\":\"postcode.utilities.logger.logging_config\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:utilities:logger:logging_config.py__*__MODULE\"},{\"import_names\":[{\"name\":\"StandardUpdater\",\"as_name\":null,\"local_block_id\":\"postcode:updaters:standard_updater.py__*__MODULE__*__CLASS-StandardUpdater\"}],\"imported_from\":\"postcode.updaters.standard_updater\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:updaters:standard_updater.py__*__MODULE\"}],\"summary\":null,\"children\":null}]}", "chroma:document": "\nSummary:\n\n        postcode:app.py__*__MODULE\n\n        \nChild (postcode:app.py__*__MODULE__*__STANDALONE_BLOCK-1) code content:\nModelType = Union[\n    ModuleModel,\n    ClassModel,\n    FunctionModel,\n    StandaloneCodeBlockModel,\n]\n\n\nChild (postcode:app.py__*__MODULE__*__FUNCTION-query_chroma) code content:\n\n\ndef query_chroma(\n    query: str,\n    chroma_collection_manager: ChromaDBCollectionManager,\n    chroma_collection: Collection,\n    logger: Logger,\n) -> None:\n    logger.info(f\"Querying ChromaDB collection {chroma_collection.name}\")\n    results: QueryResult | None = chroma_collection_manager.query_collection(\n        [query],\n        n_results=10,\n        # where_filter={\"block_type\": \"MODULE\"},\n        include_in_result=[\"metadatas\", \"documents\", \"embeddings\"],\n    )\n    logger.info(\"Query results:\")\n    if results:\n        if results[\"ids\"]:\n            for document in results[\"ids\"][0]:\n                print(document)\n\n            print(f\"Total results: {len(results['ids'][0])}\")\n\n\nChild (postcode:app.py__*__MODULE__*__FUNCTION-main) code content:\n\n\ndef main(\n    directory: str = \".\",\n    output_directory: str = \"output_json\",\n) -> None:\n    setup_logging()\n    logger: Logger = logging.getLogger(__name__)\n\n    #   ==================== GraphDB ====================\n    graph_db_updater = GraphDBUpdater(directory, output_directory, logger)\n    chroma_context: ChromaSetupReturnContext = graph_db_updater.update_all(\n        directory, output_directory, logger\n    )\n    # ==================== End GraphDB ====================\n\n    #   ==================== Standard ====================\n    # chroma_context: ChromaSetupReturnContext = StandardUpdater.update_all(\n    #     directory, output_directory, logger\n    # )\n    # ==================== End Standard ====================\n\n    query: str = \"summarizes code block\"\n    query_chroma(\n        query,\n        chroma_context.chroma_collection_manager,\n        chroma_context.chroma_collection,\n        logger,\n    )\n\n, \nImported code block (postcode:models:models.py__*__MODULE) code content:\nfrom typing import Union\nfrom pydantic import BaseModel, Field, validator\n\nfrom postcode.models.enums import (\n    BlockType,\n    ImportModuleType,\n    CommentType,\n)\n\n\nclass ImportNameModel(BaseModel):\n    \"\"\"Class representing the name of an import.\"\"\"\n\n    name: str\n    as_name: str | None = None\n    local_block_id: str | None = None\n\n    # def convert_import_names_to_metadata(self) -> str:\n    #     \"\"\"Converts the import name to a metadata string.\"\"\"\n\n    #     return self.model_dump_json()\n\n\nclass ImportModel(BaseModel):\n    \"\"\"Class representing an import statement.\"\"\"\n\n    import_names: list[ImportNameModel]\n    imported_from: str | None = None\n    import_module_type: ImportModuleType = ImportModuleType.STANDARD_LIBRARY\n    local_module_id: str | None = None\n\n    def convert_import_to_metadata(self) -> str:\n        \"\"\"Converts the import to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass DependencyModel(BaseModel):\n    \"\"\"Class representing a module dependency.\"\"\"\n\n    code_block_id: str\n\n    def convert_dependency_to_metadata(self) -> str:\n        \"\"\"Converts the dependency to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass CommentModel(BaseModel):\n    \"\"\"Class representing a comment.\"\"\"\n\n    content: str\n    comment_types: list[CommentType]\n\n    def convert_comment_to_metadata(self) -> str:\n        \"\"\"Converts the comment to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass DecoratorModel(BaseModel):\n    \"\"\"Class representing a decorator.\"\"\"\n\n    content: str\n    decorator_name: str\n    decorator_args: list[str] | None = None\n\n    def convert_decorator_to_metadata(self) -> str:\n        \"\"\"Converts the decorator to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass ClassKeywordModel(BaseModel):\n    \"\"\"Class representing a class keyword.\"\"\"\n\n    content: str\n    keyword_name: str\n    args: str | None = None\n\n    def convert_class_keyword_to_metadata(self) -> str:\n        \"\"\"Converts the class keyword to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass ParameterModel(BaseModel):\n    \"\"\"Class representing a function parameter.\"\"\"\n\n    content: str\n\n\nclass ParameterListModel(BaseModel):\n    \"\"\"Class representing a list of parameters.\"\"\"\n\n    params: list[ParameterModel] | None = None\n    star_arg: ParameterModel | None = None\n    kwonly_params: list[ParameterModel] | None = None\n    star_kwarg: ParameterModel | None = None\n    posonly_params: list[ParameterModel] | None = None\n\n    def convert_parameters_to_metadata(self) -> str:\n        \"\"\"Converts the parameter list to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass BaseCodeBlockModel(BaseModel):\n    \"\"\"Attributes common to all code block models.\"\"\"\n\n    id: str\n    parent_id: str | None = None\n    block_type: BlockType\n    start_line_num: int\n    end_line_num: int\n    code_content: str = \"\"\n    important_comments: list[CommentModel] | None = None\n    dependencies: list[ImportModel | DependencyModel] | None = None\n    summary: str | None = None\n    children: list[\n        Union[\n            \"ClassModel\",\n            \"FunctionModel\",\n            \"StandaloneCodeBlockModel\",\n        ]\n    ] | None = []\n\n    @validator(\"parent_id\", always=True)\n    def check_parent_id(cls, v, values, **kwargs) -> str | None:\n        \"\"\"Validates that parent_id is a non-empty string unless block_type is MODULE.\"\"\"\n\n        if \"block_type\" in values and values[\"block_type\"] != BlockType.MODULE:\n            if len(v) < 1:\n                raise ValueError(\"parent_id is required!\")\n        return v\n\n    def _convert_parent_id_to_metadata(self) -> str:\n        \"\"\"Converts the parent_id to a metadata string.\"\"\"\n        return f\"{self.parent_id}\" if self.parent_id else \"\"\n\n    def _convert_block_type_to_metadata(self) -> str:\n        \"\"\"Converts the block_type to a metadata string.\"\"\"\n        return f\"{self.block_type.name}\"\n\n    def _convert_important_comments_to_metadata(self) -> str:\n        \"\"\"Converts the important comments to a metadata string.\"\"\"\n\n        important_comments: str = (\n            self.model_dump_json() if self.important_comments else \"\"\n        )\n\n        return f\"{important_comments}\"\n\n    def _convert_dependencies_to_metadata(self) -> str:\n        \"\"\"Converts the dependencies to a metadata string.\"\"\"\n\n        dependencies_str: str = \"\"\n\n        if self.dependencies:\n            for dependency in self.dependencies:\n                if isinstance(dependency, ImportModel):\n                    dependencies_str += f\"{dependency.convert_import_to_metadata()}\\n\"\n                elif isinstance(dependency, DependencyModel):\n                    dependencies_str += (\n                        f\"{dependency.convert_dependency_to_metadata()}\\n\"\n                    )\n\n        return dependencies_str\n\n    def _convert_summary_to_metadata(self) -> str:\n        \"\"\"Converts the summary to a metadata string.\"\"\"\n        return f\"{self.summary}\" if self.summary else \"\"\n\n    def _convert_children_to_metadata(self) -> str:\n        \"\"\"Converts the children to a metadata string.\"\"\"\n\n        children_str: str = \"\"\n\n        if self.children:\n            for child in self.children:\n                children_str += f\"{child.id}\\n\"\n\n        return children_str\n\n    def _convert_base_attributes_to_metadata_dict(self) -> dict[str, str | int]:\n        \"\"\"Converts the base attributes to a metadata dictionary.\"\"\"\n\n        return {\n            \"id\": self.id,\n            \"parent_id\": self._convert_parent_id_to_metadata(),\n            \"block_type\": self._convert_block_type_to_metadata(),\n            \"start_line_num\": self.start_line_num,\n            \"end_line_num\": self.end_line_num,\n            \"code_content\": self.code_content,\n            \"important_comments\": self._convert_important_comments_to_metadata(),\n            \"dependencies\": self._convert_dependencies_to_metadata(),\n            \"summary\": self._convert_summary_to_metadata(),\n            \"children\": self._convert_children_to_metadata(),\n        }\n\n\nclass ModuleSpecificAttributes(BaseModel):\n    \"\"\"Module specific attributes.\"\"\"\n\n    file_path: str = Field(min_length=1)\n    docstring: str | None = None\n    header: list[str] | None = None\n    footer: list[str] | None = None\n    imports: list[ImportModel] | None = None\n\n    def _convert_docstring_to_metadata(self) -> str:\n        \"\"\"Converts the docstring to a metadata string.\"\"\"\n        return f\"{self.docstring}\"\n\n    def _convert_header_to_metadata(self) -> str:\n        \"\"\"Converts the header and footer to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n    def _convert_footer_to_metadata(self) -> str:\n        \"\"\"Converts the header and footer to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n    def _convert_imports_to_metadata(self) -> str:\n        \"\"\"Converts the imports to a metadata string.\"\"\"\n        imports_str: str = self.model_dump_json() if self.imports else \"\"\n        return f\"{imports_str}\"\n\n    def _convert_module_attributes_to_metadata_dict(self) -> dict[str, str | int]:\n        \"\"\"Converts the module attributes to a metadata dictionary.\"\"\"\n\n        return {\n            \"file_path\": self.file_path,\n            \"docstring\": self._convert_docstring_to_metadata(),\n            \"header\": self._convert_header_to_metadata(),\n            \"footer\": self._convert_footer_to_metadata(),\n            \"imports\": self._convert_imports_to_metadata(),\n        }\n\n\nclass ModuleModel(BaseCodeBlockModel, ModuleSpecificAttributes):\n    \"\"\"Model for a module.\"\"\"\n\n    def convert_to_metadata(self) -> dict[str, str | int]:\n        \"\"\"Converts the module model to a metadata dictionary.\"\"\"\n\n        return {\n            **self._convert_base_attributes_to_metadata_dict(),\n            **self._convert_module_attributes_to_metadata_dict(),\n        }\n\n\nclass ClassSpecificAttributes(BaseModel):\n    \"\"\"Class specific attributes.\"\"\"\n\n    class_name: str = Field(min_length=1)\n    decorators: list[DecoratorModel] | None = None\n    bases: list[str] | None = None\n    docstring: str | None = None\n    keywords: list[ClassKeywordModel] | None = None\n    # attributes: list[dict] | None = None\n\n    def _convert_decorators_to_metadata(self) -> str:\n        \"\"\"Converts the decorators to a metadata string.\"\"\"\n        decorators_str: str = self.model_dump_json() if self.decorators else \"\"\n        return f\"{decorators_str}\"\n\n    def _convert_bases_to_metadata(self) -> str:\n        \"\"\"Converts the bases to a metadata string.\"\"\"\n        return self.model_dump_json() if self.bases else \"\"\n\n    def _convert_docstring_to_metadata(self) -> str:\n        \"\"\"Converts the docstring to a metadata string.\"\"\"\n        return f\"{self.docstring}\" if self.docstring else \"\"\n\n    def _convert_keywords_to_metadata(self) -> str:\n        \"\"\"Converts the keywords to a metadata string.\"\"\"\n        keywords_str: str = self.model_dump_json() if self.keywords else \"\"\n        return f\"{keywords_str}\"\n\n    def _convert_class_attributes_to_metadata_dict(self) -> dict[str, str | int]:\n        \"\"\"Converts the class attributes to a metadata dictionary.\"\"\"\n\n        return {\n            \"class_name\": self.class_name,\n            \"decorators\": self._convert_decorators_to_metadata(),\n            \"bases\": self._convert_bases_to_metadata(),\n            \"docstring\": self._convert_docstring_to_metadata(),\n            \"keywords\": self._convert_keywords_to_metadata(),\n        }\n\n\nclass ClassModel(BaseCodeBlockModel, ClassSpecificAttributes):\n    \"\"\"Model for a class.\"\"\"\n\n    def convert_to_metadata(self) -> dict[str, str | int]:\n        \"\"\"Converts the class model to a metadata dictionary.\"\"\"\n        return {\n            **self._convert_base_attributes_to_metadata_dict(),\n            **self._convert_class_attributes_to_metadata_dict(),\n        }\n\n\nclass FunctionSpecificAttributes(BaseModel):\n    \"\"\"Function specific attributes.\"\"\"\n\n    function_name: str = Field(min_length=1)\n    docstring: str | None = None\n    decorators: list[DecoratorModel] | None = None\n    parameters: ParameterListModel | None = None\n    returns: str | None = None\n    is_method: bool = False\n    is_async: bool = False\n\n    def _convert_docstring_to_metadata(self) -> str:\n        \"\"\"Converts the docstring to a metadata string.\"\"\"\n        return f\"{self.docstring}\" if self.docstring else \"\"\n\n    def _convert_decorators_to_metadata(self) -> str:\n        \"\"\"Converts the decorators to a metadata string.\"\"\"\n        decorators_str: str = self.model_dump_json() if self.decorators else \"\"\n        return f\"{decorators_str}\"\n\n    def _convert_parameters_to_metadata(self) -> str:\n        \"\"\"Converts the parameters to a metadata string.\"\"\"\n        return (\n            self.parameters.convert_parameters_to_metadata() if self.parameters else \"\"\n        )\n\n    def _convert_returns_to_metadata(self) -> str:\n        \"\"\"Converts the returns to a metadata string.\"\"\"\n        return f\"{self.returns}\" if self.returns else \"\"\n\n    def _convert_function_attributes_to_metadata_dict(self) -> dict[str, str | bool]:\n        \"\"\"Converts the function attributes to a metadata dictionary.\"\"\"\n\n        return {\n            \"function_name\": self.function_name,\n            \"docstring\": self._convert_docstring_to_metadata(),\n            \"decorators\": self._convert_decorators_to_metadata(),\n            \"parameters\": self._convert_parameters_to_metadata(),\n            \"returns\": self._convert_returns_to_metadata(),\n            \"is_method\": self.is_method,\n            \"is_async\": self.is_async,\n        }\n\n\nclass FunctionModel(BaseCodeBlockModel, FunctionSpecificAttributes):\n    \"\"\"Model for a function.\"\"\"\n\n    def convert_to_metadata(self) -> dict[str, str | int]:\n        \"\"\"Converts the function model to a metadata dictionary.\"\"\"\n\n        return {\n            **self._convert_base_attributes_to_metadata_dict(),\n            **self._convert_function_attributes_to_metadata_dict(),\n        }\n\n\nclass StandaloneCodeBlockSpecificAttributes(BaseModel):\n    \"\"\"Standalone code block specific attributes.\"\"\"\n\n    variable_assignments: list[str] | None = None\n\n    def _convert_variable_assignments_to_metadata(self) -> str:\n        \"\"\"Converts the variable assignments to a metadata string.\"\"\"\n        return self.model_dump_json() if self.variable_assignments else \"\"\n\n    def _convert_standalone_block_attributes_to_metadata_dict(\n        self,\n    ) -> dict[str, str | int]:\n        \"\"\"Converts the standalone code block attributes to a metadata dictionary.\"\"\"\n        return {\n            \"variable_assignments\": self._convert_variable_assignments_to_metadata(),\n        }\n\n\nclass StandaloneCodeBlockModel(\n    BaseCodeBlockModel, StandaloneCodeBlockSpecificAttributes\n):\n    \"\"\"Model for a standalone code block.\"\"\"\n\n    def convert_to_metadata(self) -> dict[str, str | int]:\n        \"\"\"Converts the standalone code block model to a metadata dictionary.\"\"\"\n\n        return {\n            **self._convert_base_attributes_to_metadata_dict(),\n            **self._convert_standalone_block_attributes_to_metadata_dict(),\n        }\n\n\nImported code block (postcode:databases:chroma:setup_chroma.py__*__MODULE) code content:\nfrom dataclasses import dataclass\nfrom logging import Logger\n\nimport chromadb\nfrom postcode.databases.chroma.chromadb_client_manager import ChromaDBClientManager\n\nfrom postcode.databases.chroma.chromadb_collection_manager import (\n    ChromaDBCollectionManager,\n)\n\nfrom chromadb.config import DEFAULT_DATABASE, DEFAULT_TENANT, Settings\nfrom chromadb.api import ClientAPI\nfrom chromadb.api.types import (\n    DataLoader,\n    CollectionMetadata,\n    GetResult,\n    QueryResult,\n    Where,\n    WhereDocument,\n    Include,\n    URIs,\n    Loadable,\n    Metadata,\n    Embedding,\n)\nfrom chromadb import Collection\nfrom chromadb import EmbeddingFunction\n\nfrom postcode.models.models import ModuleModel\n\n\n@dataclass\nclass ChromaSetupReturnContext:\n    \"\"\"\n    Represents the return value of the ChromaDB setup method.\n\n    Attributes:\n        - chroma_collection_manager (ChromaDBCollectionManager): The ChromaDB collection manager.\n        - chroma_collection (Collection): The ChromaDB collection.\n    \"\"\"\n\n    chroma_collection_manager: ChromaDBCollectionManager\n    chroma_collection: Collection\n\n\ndef setup_chroma(\n    module_models: list[ModuleModel], logger: Logger\n) -> ChromaSetupReturnContext:\n    chroma_settings = Settings(allow_reset=True)\n    chroma_client: ClientAPI = chromadb.PersistentClient(settings=chroma_settings)\n    chroma_client_manager = ChromaDBClientManager(chroma_client)\n\n    logger.debug(f\"Resetting Chroma client\")\n    if chroma_client_manager.reset_client():\n        logger.debug(\"Client reset\")\n\n    chroma_collection: Collection = chroma_client_manager.get_or_create_collection(\n        \"postcode\"\n    )\n\n    chroma_collection_manager = ChromaDBCollectionManager(chroma_collection)\n    chroma_collection_manager.upsert_models(tuple(module_models))\n\n    return ChromaSetupReturnContext(chroma_collection_manager, chroma_collection)\n\n\nImported code block (postcode:updaters:graph_db_updater.py__*__MODULE) code content:\nfrom logging import Logger\n\nfrom openai import OpenAI\nfrom postcode.ai_services.summarizer.graph_db_summarization_manager import (\n    GraphDBSummarizationManager,\n)\nfrom postcode.ai_services.summarizer.openai_summarizer import OpenAISummarizer\nfrom postcode.ai_services.summarizer.summarization_mapper import SummarizationMapper\nfrom postcode.databases.arangodb.arangodb_connector import ArangoDBConnector\n\nfrom postcode.databases.arangodb.arangodb_manager import ArangoDBManager\nfrom postcode.databases.chroma.setup_chroma import (\n    ChromaSetupReturnContext,\n    setup_chroma,\n)\nfrom postcode.json_management.json_handler import JSONHandler\nfrom postcode.models.models import ModuleModel\nfrom postcode.python_parser.visitor_manager.visitor_manager import (\n    VisitorManager,\n    VisitorManagerProcessFilesReturn,\n)\n\n\nclass GraphDBUpdater:\n    def __init__(\n        self,\n        directory: str,\n        output_directory: str,\n        logger: Logger,\n        arango_connector: ArangoDBConnector = ArangoDBConnector(),\n    ) -> None:\n        self.directory: str = directory\n        self.output_directory: str = output_directory\n        self.logger: Logger = logger\n        self.arango_connector: ArangoDBConnector = arango_connector\n\n        self.arango_connector.delete_all_collections()\n        self.arango_connector.ensure_collections()\n        self.graph_manager = ArangoDBManager(arango_connector)\n\n    def update_all(\n        self,\n        directory: str,\n        output_directory: str,\n        logger: Logger,\n    ) -> ChromaSetupReturnContext:\n        logger.info(\"Starting the directory parsing.\")\n\n        visitor_manager = VisitorManager(directory, output_directory)\n        process_files_return: VisitorManagerProcessFilesReturn = (\n            visitor_manager.process_files()\n        )\n\n        module_models_tuple: tuple[ModuleModel, ...] = process_files_return.models_tuple\n        module_ids: list[str] = [model.id for model in module_models_tuple]\n        directory_modules: dict[str, list[str]] = process_files_return.directory_modules\n        self.graph_manager.upsert_models(\n            list(module_models_tuple)\n        ).process_imports_and_dependencies().get_or_create_graph()\n        summarization_mapper = SummarizationMapper(\n            module_ids, module_models_tuple, self.graph_manager\n        )\n        client = OpenAI(max_retries=4)\n        summarizer = OpenAISummarizer(client=client)\n        summarization_manager = GraphDBSummarizationManager(\n            module_models_tuple, summarization_mapper, summarizer, self.graph_manager\n        )\n        finalized_module_models: list[\n            ModuleModel\n        ] | None = summarization_manager.create_summaries_and_return_updated_models()\n        logger.info(\"Summarization complete\")\n\n        logger.info(\"Saving models as JSON\")\n        json_manager = JSONHandler(directory, directory_modules, output_directory)\n\n        for module_model in module_models_tuple:\n            json_manager.save_model_as_json(module_model, module_model.file_path)\n\n        json_manager.save_visited_directories()\n        logger.info(\"JSON save complete\")\n\n        logger.info(\"Directory parsing completed.\")\n\n        # self.graph_manager.upsert_models(\n        #     list(finalized_module_models)\n        # ).process_imports_and_dependencies().get_or_create_graph()\n\n        if finalized_module_models:\n            chroma_context: ChromaSetupReturnContext = setup_chroma(\n                finalized_module_models, logger\n            )\n        else:\n            raise Exception(\"No finalized models returned from summarization.\")\n\n        return chroma_context\n\n\nImported code block (postcode:utilities:logger:logging_config.py__*__MODULE) code content:\nimport logging\n\nfrom rich.logging import RichHandler\nfrom rich.syntax import Syntax\n\n\ndef setup_logging(level=logging.INFO) -> None:\n    \"\"\"\n    Configures the logging system to use RichSyntaxHandler for output.\n\n    This function sets up logging with a specific log level and format. It utilizes the RichSyntaxHandler to support rich text and syntax highlighting in log outputs.\n\n    Args:\n        level (int, optional): The logging level to set for the root logger. Defaults to logging.INFO.\n\n    Example:\n        >>> setup_logging(logging.DEBUG)\n        # Configures logging at DEBUG level with RichSyntaxHandler.\n    \"\"\"\n\n    format_str = \"%(message)s\"\n    logging.basicConfig(level=level, format=format_str, handlers=[RichSyntaxHandler()])\n\n\nclass RichSyntaxHandler(RichHandler):\n    \"\"\"\n    A custom logging handler that extends RichHandler to add syntax highlighting.\n\n    This handler checks if the log record contains a 'syntax_highlight' attribute and, if so, uses 'rich.syntax.Syntax' to render the message with Python syntax highlighting.\n\n    Inherits:\n        RichHandler: The base handler provided by the rich library for rich text formatting.\n    \"\"\"\n\n    def emit(self, record) -> None:\n        \"\"\"\n        Emits a logging record.\n\n        If the record has the 'syntax_highlight' attribute set to True, it renders the 'content' attribute of the record with syntax highlighting. Otherwise, it falls back to the standard behavior of RichHandler.\n\n        Args:\n            record: The logging record to emit.\n\n        Example:\n            # Assuming `logger` is a logger instance\n            >>> logger.info(\"Regular log message\")\n            # Outputs a regular log message.\n\n            >>> logger.info(\"Highlighted log message\", extra={\"syntax_highlight\": True, \"content\": \"print('Hello, world!')\"})\n            # Outputs the message with syntax highlighting.\n        \"\"\"\n\n        try:\n            if hasattr(record, \"syntax_highlight\") and getattr(\n                record, \"syntax_highlight\"\n            ):\n                content: str = getattr(record, \"content\", \"\")\n                if isinstance(content, str):\n                    syntax = Syntax(\n                        content, \"python\", theme=\"material\", line_numbers=True\n                    )\n                    self.console.print(syntax)\n                return\n\n        except Exception as e:\n            self.handleError(record)\n\n        super().emit(record)\n\n\nImported code block (postcode:databases:chroma:chromadb_collection_manager.py__*__MODULE) code content:\nimport logging\nfrom typing import Any, Mapping, Union\n\nfrom postcode.models.models import ModuleModel\nimport postcode.types.chroma as chroma_types\nfrom chromadb.config import DEFAULT_DATABASE, DEFAULT_TENANT, Settings\nfrom chromadb.api import ClientAPI\nfrom chromadb.api.types import (\n    DataLoader,\n    CollectionMetadata,\n    GetResult,\n    QueryResult,\n    Where,\n    WhereDocument,\n    Include,\n    URIs,\n    Loadable,\n    Metadata,\n    Embedding,\n)\nfrom chromadb import Collection\nfrom chromadb import EmbeddingFunction\n# from postcode.types.postcode import ModelType\nfrom postcode.models.models import ModuleModel, ClassModel, FunctionModel, StandaloneCodeBlockModel\nModelType = Union[\n    ModuleModel,\n    ClassModel,\n    FunctionModel,\n    StandaloneCodeBlockModel,\n]\n\n\nclass ChromaDBCollectionManager:\n    \"\"\"\n    Manages a collection within ChromaDB instance, providing functionalities for adding, retrieving,\n    and querying embeddings, and their associated metadata.\n\n    This class serves as an interface to interact with a specific collection in ChromaDB.\n\n    Attributes:\n        - collection (chroma_types.Collection): An instance of the Collection class from ChromaDB\n            which this manager is responsible for.\n\n    Methods:\n        - `collection_embedding_count`: Gets the total number of embeddings in the collection.\n        - `add_embeddings`: Adds embeddings to the collection.\n        - `get_embeddings`: Gets embeddings and their metadata from the collection in the form of a TypedDict.\n        - `query_collection`: Queries and returns the `n` nearest neighbors from the collection.\n        - `upsert_models`: Loads or updates the embeddings of the provided module models into the collection.\n\n    Examples:\n        ```Python\n        from postcode.databases.chroma import ChromaDBClientBuilder\n        import postcode.types.chromadb.types as chroma_types\n\n        # Create a persistent ChromaDB client\n        client: chroma_types.ClientAPI = ChromaDBClientBuilder.create_persistent_client()\n\n        # Instantiate the ChromaDBCollectionManager with a specific collection\n        collection_manager: ChromaDBCollectionManager = (\n            ChromaDBCollectionManager(client.get_collection(\"my_collection\"))\n        )\n\n        # Example usage of the collection manager\n        embedding_count: int = collection_manager.collection_embedding_count()\n        print(f\"Total embeddings: {embedding_count}\")\n        ```\n    \"\"\"\n\n    def __init__(self, collection: Collection) -> None:\n        self.collection: Collection = collection\n\n    def collection_embedding_count(self) -> int | None:\n        \"\"\"\n        Gets the total number of embeddings in the collection.\n\n        Returns:\n            - embedding_count (int): The total number of embeddings in the collection.\n\n        Examples:\n            ```Python\n            embedding_count: int = collection_manager.get_collection_embedding_count()\n            ```\n        \"\"\"\n        try:\n            embedding_count: int = self.collection.count()\n            logging.info(\n                f\"Collection {self.collection.name} has {embedding_count} embeddings.\"\n            )\n            return embedding_count\n        except Exception as exception:\n            logging.error(exception)\n\n    def add_embeddings(\n        self,\n        ids: list[str],\n        documents: list[str],\n        metadatas: list[Mapping[str, str | int | float | bool]],\n    ) -> None:\n        \"\"\"\n        Adds embeddings to the collection.\n\n        Args:\n            - ids (list[str]): A list of ids to add to the collection.\n            - documents (list[str]): A list of documents to add to the collection.\n            - metadatas (list[dict[str, Any]]): A list of metadatas to add to the collection.\n\n        Raises:\n            - ValueError - If you don't provide either embeddings or documents.\n            - ValueError: If the length of ids, embeddings, metadatas, or documents don't match.\n            - ValueError - If you provide an id that already exists.\n\n        Examples:\n            ```Python\n            # define the ids, metadatas, and documents to add to the collection\n            id: list[str] = [\"my_id\", \"my_id2\"]\n            metadatas: list[dict[str, Any]] = [\n                {\"my_metadata\": \"my_metadata_value\"},\n                {\"my_metadata2\": \"my_metadata_value2\"},\n            ]\n            documents: list[str] = [\"my_document\", \"my_document2\"]\n\n            # add the embeddings to the collection\n            collection_manager.add_embeddings(id, metadatas, documents)\n            ```\n        \"\"\"\n\n        if not len(ids) == len(documents) == len(metadatas):\n            raise ValueError(\"The length of ids, documents, and metadatas must match.\")\n\n        try:\n            logging.info(f\"Adding embeddings to collection {self.collection.name}\")\n            self.collection.add(ids, documents=documents, metadatas=metadatas)\n        except Exception as exception:\n            raise exception\n\n    def get_embeddings(\n        self,\n        ids: list[str] | None,\n        *,\n        where_filter: Where | None = None,\n        limit: int | None = None,\n        where_document_filter: WhereDocument | None = None,\n        include_in_result: Include = [\"metadatas\", \"documents\"],\n    ) -> GetResult | None:\n        \"\"\"\n        Gets embeddings and their metadata from the collection in the form of a TypedDict.\n\n        Args:\n            - ids (list[str]): A list of ids to get from the collection.\n            - where_filter (chroma_types.Where | None): A TypedDict used to filter the results.\n            - limit (int | None): The maximum number of results to return.\n            - where_document_filter (chroma_types.WhereDocument | None): A TypedDict used to filter the results by the document,\n                e.g. `{$contains: {\"text\": \"hello\"}}`\n            - include_in_result (chroma_types.Include | None): A list used of what to return from the results, e.g. `[\"metadatas\", \"embeddings\", \"documents\"]`\n\n        Returns:\n            - embeddings (TypedDict): A typed dict of embedding data from the collection with the following keys:\n                - ids: list[str]\n                - embeddings: list[Embedding] | None\n                - documents: list[str] | None\n                - uris: chroma_types.URIs | None\n                - data: chroma_types.Loadable | None\n                - metadatas: list[chroma_types.Metadata]]\n\n        Raises:\n            - ValueError: If the length of ids, embeddings, metadatas, or documents don't match.\n            - ValueError: If you provide an id that doesn't exist.\n\n        Examples:\n            ```Python\n            import postcode.types.chromadb.types as chroma_types\n\n            # define the ids, filters to use to get embeddings from the collection\n            ids: list[str] = [\"my_id\", \"my_id2\"]\n            where_filter: chroma_types.Where = {\"my_metadata\": \"my_metadata_value\"}\n            where_document_filter: chroma_types.WhereDocument = {\"$contains\": {\"text\": \"hello\"}}\n\n            # define the data to return from the collection\n            include_in_result: chroma_types.Include = [\"metadatas\"]\n\n            # get the embeddings from the collection\n            embeddings: chroma_types.GetResult = collection_manager.get_embeddings(\n                ids,\n                where_filter=where_filter,\n                where_document_filter=where_document_filter,\n                include_in_result=include_in_result\n                )\n            ```\n        \"\"\"\n\n        try:\n            logging.info(f\"Getting embeddings from collection {self.collection.name}\")\n            return self.collection.get(\n                ids,\n                where=where_filter,\n                limit=limit,\n                where_document=where_document_filter,\n                include=include_in_result,\n            )\n        except Exception as exception:\n            raise exception\n\n    def query_collection(\n        self,\n        queries: list[str],\n        n_results: int = 10,\n        where_filter: Where | None = None,\n        where_document_filter: WhereDocument | None = None,\n        include_in_result: Include = [\"metadatas\", \"documents\"],\n    ) -> QueryResult | None:\n        \"\"\"\n        Queries and returns the `n` nearest neighbors from the collection.\n\n        Args:\n            - queries (list[str]): A list of queries to search the collection for.\n            - n_results (int): The number of results to return.\n            - where_filter (chroma_types.Where | None): A TypedDict used to filter the results.\n                - e.g. `{\"block_type\": \"FUNCTION\", \"children\": None}`\n            - where_document_filter (chroma_types.WhereDocument | None): A TypedDict used to filter the results by the document,\n                - e.g. `{$contains: \"binary search\"}`\n            - include_in_result (chroma_types.Include | None): A list used of what to return from the results, e.g. `[\"metadatas\", \"embeddings\", \"documents\"]`\n\n        Returns:\n            - results (chroma_types.QueryResult | None): A typed dict of query results from the collection, can have the following keys based on the\n                `include_in_result` parameter:\n                - ids: list[str] # The ids are always returned.\n                - embeddings: List[list[Embedding]] | None\n                - documents: list[list[str]]] | None\n                - uris: list[list[URI]]] | None\n                - data: list[Loadable] | None\n                - metadatas: list[list[Metadata]] | None\n                - distances: list[list[float]] | None\n\n        Raises:\n            - ValueError: If you don't provide query_texts.\n\n        Examples:\n            ```Python\n            import postcode.types.chromadb.types as chroma\n\n            # define the queries and filters used to search the collection\n            queries: list[str] = [\"binary search\", \"linear search\"]\n            where_filter: chroma_types.Where = {\"block_type\": \"FUNCTION\"}\n\n            # define the data to return from the collection\n            include_in_result: chroma_types.Include = [\"metadatas\", \"documents\", \"distances\"]\n\n            # query the collection and return the results from the collection\n            results: chroma_types.QueryResult = collection_manager.query_collection(\n                queries,\n                where_filter=where_filter,\n                include_in_result=include_in_result\n                )\n            ```\n        \"\"\"\n\n        try:\n            logging.info(f\"Querying collection {self.collection.name}\")\n\n            if results := self.collection.query(\n                query_texts=queries,\n                n_results=n_results,\n                where=where_filter,\n                where_document=where_document_filter,\n                include=include_in_result,\n            ):\n                return results\n            else:\n                logging.warning(\n                    f\"No results found from collection {self.collection.name}.\"\n                )\n\n        except Exception as exception:\n            raise exception\n\n    def modify_collection_name(self, name: str) -> None:\n        \"\"\"\n        Modifies the name of the collection managed by this class.\n\n        Args:\n            - name (str): The new name to assign to the collection.\n\n        Examples:\n            ```Python\n            # Rename the collection to 'new_collection_name'\n            collection_manager.modify_collection_name('new_collection_name')\n            ```\n        \"\"\"\n\n        self.collection.modify(name=name)\n\n    def modify_collection_metadata(\n        self, metadata: dict[str, Any] | None = None\n    ) -> None:\n        \"\"\"\n        Modifies the metadata of the collection managed by this class.\n\n        Args:\n            - metadata (dict[str, Any] | None): The new metadata to assign to the collection. If None, no change is made.\n\n        Examples:\n            ```Python\n            # Update metadata of the collection\n            new_metadata = {\"description\": \"Updated collection metadata\"}\n            collection_manager.modify_collection_metadata(new_metadata)\n            ```\n        \"\"\"\n\n        self.collection.modify(metadata=metadata)\n\n    def _update_metadata_or_documents_by_ids(\n        self,\n        ids: list[str],\n        metadatas: list[Mapping[str, str | int | float | bool]] | None = None,\n        documents: list[str] | None = None,\n    ) -> None:\n        \"\"\"\n        Updates the metadata or documents of specific entries in the collection by their ids.\n\n        Args:\n            - ids (list[str]): List of ids of the entries to be updated.\n            - metadatas (list[Mapping[str, Any]] | None): List of metadata updates corresponding to the ids.\n            - documents (list[str] | None): List of document updates corresponding to the ids.\n\n        Raises:\n            - ValueError: If neither metadatas nor documents are provided.\n            - ValueError: If the length of ids and documents don't match.\n            - ValueError: If the length of ids and metadatas don't match.\n            - ValueError: If the length of ids, metadatas, and documents don't match.\n\n        Notes:\n            - As of now, ChromaDB doesn't raise an exception if you provide an id that doesn't exist.\n\n        Examples:\n            ```Python\n            # Update metadata and documents for specific ids\n            ids_to_update = ['id1', 'id2']\n            metadata_updates = [{\"key1\": \"value1\"}, {\"key2\": \"value2\"}]\n            document_updates = [\"new document 1\", \"new document 2\"]\n            collection_manager.update_metadata_or_documents_by_ids(ids_to_update, metadata_updates, document_updates)\n            ```\n        \"\"\"\n\n        if not metadatas and not documents:\n            raise ValueError(\"You must provide either metadatas or documents.\")\n        if not metadatas and documents:\n            if len(ids) != len(documents):\n                raise ValueError(\"The length of ids and documents must match.\")\n        if metadatas and not documents:\n            if len(ids) != len(metadatas):\n                raise ValueError(\"The length of ids and metadatas must match.\")\n        if metadatas and documents:\n            if len(ids) != len(metadatas) != len(documents):\n                raise ValueError(\n                    \"The length of ids, metadatas, and documents must match.\"\n                )\n        for index, id in enumerate(ids):\n            if not self.collection.get(id):\n                logging.error(\n                    f\"Id {id} does not exist in collection {self.collection.name}.\"\n                )\n                ids.pop(index)\n                if metadatas:\n                    popped_metadata = metadatas.pop(index)\n                    if popped_metadata:\n                        logging.warning(\n                            f\"Removing metadata at index {index} from update.\"\n                        )\n                if documents:\n                    popped_document = documents.pop(index)\n                    if popped_document:\n                        logging.warning(\n                            f\"Removing document at index {index} from update.\"\n                        )\n\n        if not ids:\n            logging.warning(\"All updates failed.\")\n            return None\n        else:\n            logging.info(f\"Updating collection {self.collection.name} with ids {ids}.\")\n            self.collection.update(ids=ids, metadatas=metadatas, documents=documents)\n\n    def _upsert_documents(\n        self,\n        ids: list[str],\n        documents: list[str],\n        metadatas: list[Mapping[str, str | int | float | bool]],\n        # embeddings: list[chroma_types.Embedding],\n    ) -> None:\n        \"\"\"\n        Inserts or updates documents in the collection, based on the provided ids.\n\n        Args:\n            - ids (list[str]): List of ids for the documents to be inserted or updated.\n            - documents (list[str]): List of documents corresponding to the ids.\n            - metadatas (list[Mapping[str, Any]]): List of metadata corresponding to the ids.\n\n        Raises:\n            - ValueError: If the lengths of ids, documents, and metadatas don't match.\n\n        Examples:\n            ```Python\n            # Upsert documents in the collection\n            ids = ['id1', 'id2']\n            documents = ['doc1', 'doc2']\n            metadatas = [{\"meta1\": \"value1\"}, {\"meta2\": \"value2\"}]\n\n            # Upsert documents in the collection\n            collection_manager.upsert_documents(ids, documents, metadatas)\n            ```\n        \"\"\"\n\n        if len(ids) != len(documents) != len(metadatas):\n            raise ValueError(\"The length of ids, documents, and metadatas must match.\")\n\n        logging.info(f\"Upserting collection {self.collection.name} with ids {ids}.\")\n        self.collection.upsert(\n            ids=ids,\n            # embeddings=embeddings,\n            metadatas=metadatas,\n            documents=documents,\n        )\n\n    def delete_embeddings(self, ids: list[str]) -> None:\n        \"\"\"\n        Deletes embeddings from the collection based on the provided ids.\n\n        Args:\n            - ids (list[str]): List of ids corresponding to the embeddings to be deleted.\n\n        Examples:\n            ```Python\n            # Delete specific embeddings by ids\n            ids_to_delete = ['id1', 'id2']\n            collection_manager.delete_embeddings(ids_to_delete)\n            ```\n        \"\"\"\n\n        ids_to_delete: list[str] = ids.copy()\n        for index, id in enumerate(ids_to_delete):\n            if not self.collection.get(id):\n                logging.error(\n                    f\"Id {id} does not exist in collection {self.collection.name}.\"\n                )\n                ids_to_delete.pop(index)\n\n        if not ids_to_delete:\n            logging.warning(\"No IDs given were in the database.\")\n            return None\n\n        logging.info(\n            f\"Deleting embeddings from collection {self.collection.name} with ids {ids_to_delete}.\"\n        )\n        self.collection.delete(ids_to_delete)\n\n    def upsert_models(self, module_models: tuple[ModuleModel, ...]) -> None:\n        \"\"\"\n        Loads or updates the embeddings of the provided module models into the collection.\n\n        The Pydantic models are converted to a dictionary with a format that ChromaDB can use, then the ids, documents, and metadatas\n        are added to their respective lists. The lists are then either added to or updated in the collection depending on whether or\n        not the code blocks were in the the collection to begin with.\n\n        Args:\n            - module_models (tuple[ModuleModel, ...]): The module models to load or update into the collection.\n\n        Examples:\n            ```Python\n            # Upsert module models into the collection\n            module_models = (module_model1, module_model2)\n            collection_manager.upsert_models(module_models)\n            ```\n        \"\"\"\n\n        ids: list[str] = []\n        documents: list[str] = []\n        metadatas: list[Mapping[str, str | int | float | bool]] = []\n\n        for module_model in module_models:\n            if module_model.summary:\n                ids.append(module_model.id)\n                documents.append(module_model.summary)\n                metadatas.append(module_model.convert_to_metadata())\n\n            if module_model.children:\n                for child in module_model.children:\n                    child_data: dict[str, Any] = self._recursively_gather_child_data(\n                        child\n                    )\n                    ids.extend(child_data[\"ids\"])\n                    documents.extend(child_data[\"documents\"])\n                    metadatas.extend(child_data[\"metadatas\"])\n\n        logging.info(\n            f\"{self.collection.name} has {self.collection_embedding_count()} embeddings.\"\n        )\n        self._upsert_documents(ids=ids, documents=documents, metadatas=metadatas)\n        logging.info(\n            f\"After upsert {self.collection.name} has {self.collection_embedding_count()} embeddings.\"\n        )\n\n    def _recursively_gather_child_data(self, model: ModelType) -> dict[str, Any]:\n        ids: list[str] = []\n        documents: list[str] = []\n        metadatas: list[Mapping[str, str | int | float | bool]] = []\n        if model.summary:\n            ids.append(model.id)\n            documents.append(model.summary)\n            metadatas.append(model.convert_to_metadata())\n        else:\n            logging.warning(f\"Child {model.id} has no summary.\")\n        if model.children:\n            for child in model.children:\n                child_data: dict[str, Any] = self._recursively_gather_child_data(child)\n                ids.extend(child_data[\"ids\"])\n                documents.extend(child_data[\"documents\"])\n                metadatas.extend(child_data[\"metadatas\"])\n\n        return {\n            \"ids\": ids,\n            \"documents\": documents,\n            \"metadatas\": metadatas,\n        }\n\n\nImported code block (postcode:updaters:standard_updater.py__*__MODULE) code content:\n# Create method, `update_all`, that updates the whole project, it parses all code, wipes all databases, and summarizes all code blocks,\n# then updates all the databases with the new information.\n\n\nfrom logging import Logger\n\nfrom openai import OpenAI\nfrom postcode.ai_services.summarizer.openai_summarizer import OpenAISummarizer\nfrom postcode.ai_services.summarizer.standard_summarization_manager import (\n    StandardSummarizationManager,\n)\n\nfrom postcode.databases.chroma.setup_chroma import (\n    ChromaSetupReturnContext,\n    setup_chroma,\n)\nfrom postcode.json_management.json_handler import JSONHandler\n\nfrom postcode.models.models import ModuleModel\nfrom postcode.python_parser.visitor_manager.visitor_manager import (\n    VisitorManager,\n    VisitorManagerProcessFilesReturn,\n)\n\n\nclass StandardUpdater:\n    @staticmethod\n    def update_all(\n        directory: str, output_directory: str, logger: Logger\n    ) -> ChromaSetupReturnContext:\n        visitor_manager = VisitorManager(directory, output_directory)\n        process_files_return: VisitorManagerProcessFilesReturn = (\n            visitor_manager.process_files()\n        )\n\n        module_models_tuple: tuple[ModuleModel, ...] = process_files_return.models_tuple\n        client = OpenAI(max_retries=4)\n        summarizer = OpenAISummarizer(client=client)\n        summarization_manager = StandardSummarizationManager(\n            module_models_tuple, summarizer\n        )\n        finalized_module_models: tuple[\n            ModuleModel, ...\n        ] = summarization_manager.create_summarizes_and_return_updated_models()\n\n        logger.info(\"Summarization complete\")\n\n        logger.info(\"Saving models as JSON\")\n        directory_modules: dict[str, list[str]] = process_files_return.directory_modules\n        json_manager = JSONHandler(directory, directory_modules, output_directory)\n\n        for module_model in module_models_tuple:\n            json_manager.save_model_as_json(module_model, module_model.file_path)\n\n        json_manager.save_visited_directories()\n        logger.info(\"JSON save complete\")\n\n        logger.info(\"Directory parsing completed.\")\n\n        chroma_context: ChromaSetupReturnContext = setup_chroma(\n            finalized_module_models, logger\n        )\n\n        return chroma_context\n\n, \nimport logging\nfrom logging import Logger\nfrom typing import Union\nfrom chromadb.api.types import QueryResult\nfrom chromadb import Collection\n        "}he summarization mapper isn't getting returning all of the project models.\\n\\nimport logging\\nfrom pprint import pprint\\nfrom typing import Union\\n\\nfrom postcode.ai_services.summarizer.summarization_context import (\\n    Summarizer,\\n    OpenAIReturnContext,\\n)\\nfrom postcode.ai_services.summarizer.summarization_mapper import SummarizationMapper\\nfrom postcode.databases.arangodb.arangodb_manager import ArangoDBManager\\n\\n# from postcode.types.postcode import ModelType\\n\\nfrom postcode.models.models import (\\n    ClassModel,\\n    DependencyModel,\\n    FunctionModel,\\n    ImportModel,\\n    ModuleModel,\\n    StandaloneCodeBlockModel,\\n)\\n\\nModelType = Union[\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n]\\n\\n\\nclass GraphDBSummarizationManager:\\n    def __init__(\\n        self,\\n        module_models_tuple: tuple[ModuleModel, ...],\\n        summarization_mapper: SummarizationMapper,\\n        summarizer: Summarizer,\\n        graph_manager: ArangoDBManager,\\n    ) -> None:\\n        self.module_models_tuple: tuple[ModuleModel, ...] = module_models_tuple\\n        self.summarization_mapper: SummarizationMapper = summarization_mapper\\n        self.summarizer: Summarizer = summarizer\\n        self.summarized_code_block_ids: set[str] = set()\\n        self.prompt_tokens: int = 0\\n        self.completion_tokens: int = 0\\n        self.graph_manager: ArangoDBManager = graph_manager\\n\\n    @property\\n    def total_cost(self) -> float:\\n        \\\"\\\"\\\"Provides the total cost of the summarization process.\\\"\\\"\\\"\\n        prompt_cost: int = self.prompt_tokens * 1  # Costs 1 cent per 1,000 tokens\\n        completion_cost: int = (\\n            self.completion_tokens * 3\\n        )  # Costs 3 cents per 1,000 tokens\\n        return (prompt_cost + completion_cost) / 100_000  # Convert to dollars\\n\\n    def create_summaries_and_return_updated_models(self) -> list[ModuleModel] | None:\\n        summarization_map: list[\\n            ModelType\\n        ] = self.summarization_mapper.create_summarization_map()\\n        models_to_summarize_count: int = len(summarization_map)\\n        models_summarized_count: int = 0\\n\\n        for model in summarization_map:\\n            children_summaries: str | None = None\\n            dependency_summaries: str | None = None\\n            import_details: str | None = None\\n\\n            if model.children:\\n                children_summaries: str | None = self._stringify_children_summaries(\\n                    self._get_child_summaries(model)\\n                )\\n            if isinstance(model, ModuleModel):\\n                if model.imports:\\n                    dependency_summaries = self._get_dependencies_summaries(model)\\n                    import_details = \\\"\\\"\\n                    for _import in model.imports:\\n                        if import_summary := self._get_import_details(_import):\\n                            import_details += f\\\"\\\\n{import_summary}\\\"\\n            else:\\n                if model.dependencies:\\n                    dependency_summaries = self._get_dependencies_summaries(model)\\n                    import_details = \\\"\\\"\\n                    for dependency in model.dependencies:\\n                        if isinstance(dependency, DependencyModel):\\n                            continue\\n                        if import_summary := self._get_import_details(dependency):\\n                            import_details += f\\\"\\\\n{import_summary}\\\"\\n\\n            models_summarized_count += 1\\n            logging.info(\\n                f\\\"Summarizing model {models_summarized_count} out of {models_to_summarize_count}; {model.id}.\\\"\\n            )\\n\\n            summary_return_context: OpenAIReturnContext | None = (\\n                self.summarizer.test_summarize_code(\\n                    model.code_content,\\n                    model_id=model.id,\\n                    children_summaries=children_summaries,\\n                    dependency_summaries=dependency_summaries,\\n                    import_details=import_details,\\n                )\\n            )\\n            if summary_return_context:\\n                if summary_return_context.summary:\\n                    self.graph_manager.update_vertex_by_id(\\n                        model.id, summary_return_context.summary\\n                    )\\n                self.prompt_tokens += summary_return_context.prompt_tokens\\n                self.completion_tokens += summary_return_context.completion_tokens\\n\\n                # for module_model in self.module_models_tuple:\\n                #     if isinstance(model, ModuleModel):\\n                #         if module_model.id == model.id:\\n                #             module_model.summary = model.summary\\n                #             break\\n                #         else:\\n                #             continue\\n                #     else:\\n                #         module_id_for_model: str = model.id.split(\\\"MODULE\\\")[0]\\n                #         if (\\n                #             module_model.children\\n                #             and module_id_for_model in module_model.id\\n                #         ):\\n                #             for child_model in module_model.children:\\n                #                 if child_model.id == model.id:\\n                #                     # child_model.summary = model.summary\\n                #                     break\\n                #         else:\\n                #             continue\\n\\n        pprint([model.id for model in summarization_map[::-1]])\\n        print(len(summarization_map))\\n\\n        return self.graph_manager.get_all_modules() if self.graph_manager else None\\n\\n    def _get_child_summaries(self, model: ModelType) -> list[str]:\\n        \\\"\\\"\\\"Gathers summaries of child models.\\\"\\\"\\\"\\n        child_summary_list: list[str] = []\\n        if model.children:\\n            for child in model.children:\\n                if child.summary:\\n                    child_summary: str = child.summary\\n                else:\\n                    child_summary = (\\n                        f\\\"Child ({child.id}) code content:\\\\n{child.code_content}\\\\n\\\"\\n                    )\\n                child_summary_list.append(child_summary)\\n        return child_summary_list\\n\\n    def _stringify_children_summaries(self, children_summary_list: list[str]) -> str:\\n        \\\"\\\"\\\"Converts all of the child summaries to a single string to be used in the prompt.\\\"\\\"\\\"\\n\\n        children_summaries: str = \\\"\\\"\\n        for child_summary in children_summary_list:\\n            children_summaries += f\\\"\\\\n{child_summary}\\\"\\n        return children_summaries\\n\\n    def _get_dependencies_summaries(self, model: ModelType) -> str | None:\\n        dependency_list: list[ImportModel | DependencyModel] | list[ImportModel] = []\\n        dependency_summary_list: list[str] = []\\n\\n        if isinstance(model, ModuleModel):\\n            if not model.imports:\\n                return None\\n\\n            dependency_list = model.imports\\n        else:\\n            if not model.dependencies:\\n                return None\\n\\n            dependency_list = model.dependencies\\n        for dependency in dependency_list:\\n            if isinstance(dependency, DependencyModel) and dependency.code_block_id:\\n                if module_local_dependency_summary := self._get_local_dependency_summary(\\n                    dependency, model\\n                ):\\n                    dependency_summary_list.append(module_local_dependency_summary)\\n\\n            elif isinstance(dependency, ImportModel):\\n                if dependency.import_module_type == \\\"LOCAL\\\":\\n                    if not dependency.import_names:\\n                        if module_import_dependency := self._get_local_import_summary(\\n                            dependency\\n                        ):\\n                            dependency_summary_list.append(module_import_dependency)\\n                    else:\\n                        if import_from_dependency := self._get_local_import_from_summary(\\n                            dependency\\n                        ):\\n                            dependency_summary_list.append(import_from_dependency)\\n\\n        dependency_summaries = self._stringify_dependencies_summaries(\\n            dependency_summary_list\\n        )\\n\\n        return dependency_summaries\\n\\n    # def _get_import_details_for_dependencies(\\n    #     self, dependencies: list[ImportModel | DependencyModel]\\n    # ) -> str | None:\\n    #     import_details: str | None = None\\n    #     for dependency in dependencies:\\n    #         if isinstance(dependency, ImportModel):\\n    #             if dependency.import_module_type == \\\"LOCAL\\\":\\n    #                 continue\\n    #             else:\\n    #                 import_detail: str | None = self._get_import_details(dependency)\\n    #                 if not import_detail:\\n    #                     continue\\n    #                 if not import_details:\\n    #                     import_details = \\\"\\\"\\n    #                 import_details += f\\\"\\\\n{import_detail}\\\"\\n    #     return import_details\\n\\n    def _get_local_dependency_summary(\\n        self,\\n        dependency: DependencyModel,\\n        model: ModelType,\\n    ) -> str | None:\\n        \\\"\\\"\\\"Gets a summary for a dependency local to the module.\\\"\\\"\\\"\\n        if not model.children:\\n            return None\\n\\n        for child_model in model.children:\\n            if child_model.id == dependency.code_block_id:\\n                child_summary: str | None = None\\n\\n                if child_model.summary:\\n                    child_summary = child_model.summary\\n                else:\\n                    child_summary = f\\\"Dependency ({dependency.code_block_id}) code content:\\\\n{child_model.code_content}\\\\n\\\"\\n\\n                return child_summary\\n        return None\\n\\n    def _stringify_dependencies_summaries(\\n        self, dependencies_summary_list: list[str] | None\\n    ) -> str | None:\\n        \\\"\\\"\\\"Converts all of the dependency summaries to a single string to be used in the prompt.\\\"\\\"\\\"\\n        if not dependencies_summary_list:\\n            return None\\n\\n        dependency_summaries: str = \\\"\\\"\\n        for dependency_summary in dependencies_summary_list:\\n            dependency_summaries += f\\\"\\\\n{dependency_summary}\\\"\\n        return dependency_summaries\\n\\n    def _get_local_import_summary(self, dependency: ImportModel) -> str | None:\\n        for module_model in self.module_models_tuple:\\n            if module_model.id == dependency.local_module_id:\\n                import_summary: str | None = None\\n                if module_model.summary:\\n                    import_summary = module_model.summary\\n                else:\\n                    import_summary = f\\\"Imported module ({dependency.local_module_id}) code content:\\\\n{module_model.code_content}\\\\n\\\"\\n                return import_summary\\n        return None\\n\\n    def _get_local_import_from_summary(self, dependency: ImportModel) -> str | None:\\n        for import_name in dependency.import_names:\\n            for module_model in self.module_models_tuple:\\n                if module_model.id == dependency.local_module_id:\\n                    if module_model.children:\\n                        for child_model in module_model.children:\\n                            if (\\n                                child_model.id == import_name.local_block_id\\n                                and child_model.id\\n                            ):\\n                                import_summary: str | None = None\\n                                if child_model.summary:\\n                                    import_summary = child_model.summary\\n                                else:\\n                                    import_summary = f\\\"Imported code block ({dependency.local_module_id}) code content:\\\\n{module_model.code_content}\\\\n\\\"\\n                                return import_summary\\n        return None\\n\\n    def _get_import_details(self, import_model: ImportModel) -> str | None:\\n        \\\"\\\"\\\"Retrieves details of import statements to be used in the prompt.\\\"\\\"\\\"\\n        if import_model.import_module_type == \\\"LOCAL\\\" or not import_model.import_names:\\n            return None\\n\\n        import_names_list: list[str] = []\\n        for import_name in import_model.import_names:\\n            if import_name.as_name:\\n                import_names_list.append(f\\\"{import_name.name} as {import_name.as_name}\\\")\\n            else:\\n                import_names_list.append(f\\\"{import_name.name}\\\")\\n\\n        if import_model.imported_from:\\n            import_details: str = f\\\"from {import_model.imported_from} import {', '.join(import_names_list)}\\\"\\n        else:\\n            import_details = f\\\"import {', '.join(import_names_list)}\\\"\\n\\n        return import_details\\n\\n\\nImported code block (postcode:ai_services:summarizer:openai_summarizer.py__*__MODULE) code content:\\nimport logging\\n\\nfrom openai import OpenAI\\nfrom openai.types.chat.chat_completion_system_message_param import (\\n    ChatCompletionSystemMessageParam,\\n)\\nfrom openai.types.chat.chat_completion_user_message_param import (\\n    ChatCompletionUserMessageParam,\\n)\\nfrom openai.types.chat.chat_completion_message_param import ChatCompletionMessageParam\\nfrom openai.types.chat.chat_completion import ChatCompletion\\n\\nfrom postcode.ai_services.summarizer.prompts.prompt_creator import PromptCreator\\nfrom postcode.ai_services.summarizer.summarization_context import (\\n    OpenAIReturnContext,\\n    SummaryCompletionConfigs,\\n)\\n\\n# from postcode.ai_services.summarizer.temp import code_example\\n\\n\\nclass OpenAISummarizer:\\n    \\\"\\\"\\\"\\n    A class for summarizing code snippets using the OpenAI API.\\n\\n    Args:\\n        - client (OpenAI): The OpenAI client used for making API requests.\\n\\n    Attributes:\\n        - client (OpenAI): The OpenAI client used for making API requests.\\n        - prompt_list (list[str]): A list of summary prompts.\\n        - default_prompt (str): The default summary prompt.\\n\\n    Methods:\\n        - `summarize_code`: Summarizes the provided code snippet using the OpenAI API.\\n\\n    Examples:\\n        ```Python\\n        client = OpenAI()\\n\\n        # Create a summarizer instance with the OpenAI client\\n        summarizer = Summarizer(client=client)\\n        code_example = \\\"print('Hello, world')\\\"\\n\\n        # Summarize the code snippet\\n        summary = summarizer.summarize_code(code_example)\\n        print(summary)\\n        ```\\n    \\\"\\\"\\\"\\n\\n    def __init__(\\n        self,\\n        client: OpenAI,\\n        # *, summary_prompt_list: list[str] = summary_prompt_list\\n    ) -> None:\\n        self.client: OpenAI = client\\n        # self.prompt_list: list[str] = summary_prompt_list\\n        # self.default_prompt: str = self.prompt_list[0]\\n\\n    def _create_system_message(self, content: str) -> ChatCompletionSystemMessageParam:\\n        \\\"\\\"\\\"Creates a system message for chat completion using OpenAi's ChatCompletionSystemMessageParam class.\\\"\\\"\\\"\\n        return ChatCompletionSystemMessageParam(content=content, role=\\\"system\\\")\\n\\n    def _create_user_message(self, content: str) -> ChatCompletionUserMessageParam:\\n        \\\"\\\"\\\"Creates a user message for chat completion using OpenAi's ChatCompletionUserMessageParam class.\\\"\\\"\\\"\\n        return ChatCompletionUserMessageParam(content=content, role=\\\"user\\\")\\n\\n    def _create_messages_list(\\n        self,\\n        system_message: str,\\n        user_message: str,\\n    ) -> list[ChatCompletionMessageParam]:\\n        \\\"\\\"\\\"\\n        Creates a list of messages for chat completion, including both system and user messages.\\n\\n        Args:\\n            - system_message (str): The system message content.\\n            - user_message (str): The user message content.\\n\\n        Returns:\\n            - list[ChatCompletionMessageParam]: A list containing the system and user messages as OpenAI's\\n                ChatCompletionMessageParam classes.\\n        \\\"\\\"\\\"\\n\\n        return [\\n            self._create_system_message(system_message),\\n            self._create_user_message(user_message),\\n        ]\\n\\n    def _create_prompt(\\n        self,\\n        code: str,\\n        children_summaries: str | None,\\n        dependency_summaries: str | None,\\n        import_details: str | None,\\n    ) -> str:\\n        prompt_creator: PromptCreator = PromptCreator()\\n        prompt: str | None = prompt_creator.create_prompt(\\n            code,\\n            children_summaries,\\n            dependency_summaries,\\n            import_details,\\n        )\\n\\n        if prompt:\\n            return prompt\\n        else:\\n            raise Exception(\\\"Prompt creation failed.\\\")\\n\\n    def _get_summary(\\n        self,\\n        messages: list[ChatCompletionMessageParam],\\n        *,\\n        configs: SummaryCompletionConfigs,\\n    ) -> OpenAIReturnContext | None:\\n        \\\"\\\"\\\"\\n        Retrieves the summary from the OpenAI API based on the provided messages and configuration settings.\\n\\n        Args:\\n            - messages (list[ChatCompletionMessageParam]): A list of messages for chat completion.\\n            - configs (SummaryCompletionConfigs): Configuration settings for the summarization completion.\\n\\n        Returns:\\n            str | None: The summary generated by the OpenAI API, or None if no summary is found.\\n        \\\"\\\"\\\"\\n\\n        try:\\n            response: ChatCompletion = self.client.chat.completions.create(\\n                messages=messages,\\n                model=configs.model,\\n                max_tokens=configs.max_tokens,\\n                temperature=configs.temperature,\\n            )\\n            prompt_tokens: int = 0\\n            completion_tokens: int = 0\\n            summary: str | None = response.choices[0].message.content\\n            if response.usage:\\n                prompt_tokens = response.usage.prompt_tokens\\n                completion_tokens = response.usage.completion_tokens\\n\\n            return OpenAIReturnContext(\\n                prompt_tokens=prompt_tokens,\\n                completion_tokens=completion_tokens,\\n                summary=summary,\\n            )\\n\\n        except Exception as e:\\n            logging.error(e)\\n            return None\\n\\n    def summarize_code(\\n        self,\\n        code: str,\\n        *,\\n        model_id: str,\\n        children_summaries: str | None,\\n        dependency_summaries: str | None,\\n        import_details: str | None,\\n        configs: SummaryCompletionConfigs = SummaryCompletionConfigs(),\\n    ) -> OpenAIReturnContext | None:\\n        \\\"\\\"\\\"\\n        Summarizes the provided code snippet using the OpenAI API.\\n\\n        Args:\\n            - code (str): The code snippet to summarize.\\n            - configs (SummaryCompletionConfigs, optional): Configuration settings for the summarization.\\n                Defaults to SummaryCompletionConfigs().\\n\\n        Returns:\\n            - str: The summary of the provided code snippet.\\n\\n        Examples:\\n            ```Python\\n            client = OpenAI()\\n\\n            # Create a summarizer instance with the OpenAI client\\n            summarizer = Summarizer(client=client)\\n            code_example = \\\"print('Hello, world')\\\"\\n\\n            # Summarize the code snippet\\n            summary = summarizer.summarize_code(code_example)\\n            print(summary)\\n            ```\\n        \\\"\\\"\\\"\\n\\n        logging.info(f\\\"Summarizing code for model: {model_id}\\\")\\n        prompt: str = self._create_prompt(\\n            code, children_summaries, dependency_summaries, import_details\\n        )\\n        messages: list[ChatCompletionMessageParam] = self._create_messages_list(\\n            system_message=configs.system_message, user_message=prompt\\n        )\\n\\n        if summary_return_context := self._get_summary(messages, configs=configs):\\n            if summary_return_context:\\n                if summary_return_context.summary:\\n                    summary_return_context.summary = (\\n                        summary_return_context.summary.split(\\\"FINAL SUMMARY:\\\")[-1]\\n                    )\\n                    return summary_return_context\\n        return None\\n\\n    def test_summarize_code(\\n        self,\\n        code: str,\\n        *,\\n        model_id: str,\\n        children_summaries: str | None,\\n        dependency_summaries: str | None,\\n        import_details: str | None,\\n        configs: SummaryCompletionConfigs = SummaryCompletionConfigs(),\\n    ) -> OpenAIReturnContext | None:\\n        \\\"\\\"\\\"\\n        Summarizes the provided code snippet using the OpenAI API.\\n\\n        Args:\\n            - code (str): The code snippet to summarize.\\n            - configs (SummaryCompletionConfigs, optional): Configuration settings for the summarization.\\n                Defaults to SummaryCompletionConfigs().\\n\\n        Returns:\\n            - str: The summary of the provided code snippet.\\n        \\\"\\\"\\\"\\n\\n        summary = f\\\"\\\"\\\"\\\\nSummary:\\\\n\\n        {model_id}\\\\n\\n        {children_summaries}, {dependency_summaries}, {import_details}\\n        \\\"\\\"\\\"\\n        summary_context = OpenAIReturnContext(\\n            summary=summary,\\n            prompt_tokens=1,\\n            completion_tokens=1,\\n        )\\n\\n        return summary_context\\n\\n\\n# if __name__ == \\\"__main__\\\":\\n#     client = OpenAI()\\n#     summarizer = OpenAISummarizer(client=client)\\n#     children_summaries = \\\"\\\"\\n#     dependency_summaries = \\\"\\\"\\n#     summary = summarizer.summarize_code(\\n#         code_example,\\n#         model_id=\\\"test\\\",\\n#         children_summaries=children_summaries,\\n#         dependency_summaries=dependency_summaries,\\n#         import_details=None,\\n#     )\\n#     print(summary)\\n\\n\\nImported code block (postcode:ai_services:summarizer:summarization_mapper.py__*__MODULE) code content:\\nimport logging\\nfrom pprint import pprint\\nfrom typing import Union\\nfrom postcode.databases.arangodb.arangodb_manager import ArangoDBManager\\nfrom postcode.models.models import (\\n    ClassModel,\\n    FunctionModel,\\n    ModuleModel,\\n    StandaloneCodeBlockModel,\\n)\\n\\n# from postcode.types.postcode import ModelType\\n\\nModelType = Union[\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n]\\n\\n\\nclass SummarizationMapper:\\n    def __init__(\\n        self,\\n        module_ids_to_update: list[str],\\n        module_models: tuple[ModuleModel, ...],\\n        arangodb_manager: ArangoDBManager,\\n    ) -> None:\\n        self.module_ids_to_update: list[str] = module_ids_to_update\\n        self.module_models: tuple[ModuleModel, ...] = module_models\\n        self.arangodb_manager: ArangoDBManager = arangodb_manager\\n        self.models_to_update: list[ModelType] = []\\n        self.model_visited_in_db: set[str] = set()\\n        self.summarization_map: list[ModelType] = []\\n        self.temp_map: list[ModelType] = []\\n\\n    def _set_child_models_to_update(self, model: ModelType) -> None:\\n        if model.children:\\n            for child in model.children:\\n                # logging.info(f\\\"Setting child model to update: {child.id}\\\")\\n                self._set_child_models_to_update(child)\\n                child.summary = None\\n                self.models_to_update.append(child)\\n            self.models_to_update.append(model)\\n\\n    def _set_models_to_update(self) -> None:\\n        for model in self.module_models:\\n            if model.id in self.module_ids_to_update:\\n                if model.children:\\n                    for child in model.children:\\n                        self._set_child_models_to_update(child)\\n\\n                model.summary = None\\n                self.models_to_update.append(model)\\n\\n    def _set_inbound_models_in_summarization_map(self, model_id: str) -> None:\\n        if model_id in self.model_visited_in_db:\\n            return\\n        self.model_visited_in_db.add(model_id)\\n        if inbound_models := self.arangodb_manager.get_inbound_models(model_id):\\n            for model in inbound_models:\\n                # logging.info(f\\\"Setting inbound models in summarization map: {model.id}\\\")\\n                self.model_visited_in_db.add(model_id)\\n                self._set_inbound_models_in_summarization_map(model.id)\\n\\n                self.temp_map.append(model)\\n\\n    def _set_outbound_models_in_summarization_map(self, model_id: str) -> None:\\n        if model_id in self.model_visited_in_db:\\n            return\\n\\n        if outbound_models := self.arangodb_manager.get_outbound_models(model_id):\\n            for model in outbound_models[::-1]:\\n                # logging.info(\\n                #     f\\\"Setting outbound models in summarization map: {model.id}\\\"\\n                # )\\n                self.model_visited_in_db.add(model_id)\\n                # self._set_outbound_models_in_summarization_map(model.id)``\\n\\n                if model.id in self.models_to_update:\\n                    model.summary = None\\n                self.temp_map.append(model)\\n\\n    def create_summarization_map(self) -> list[ModelType]:\\n        self._set_models_to_update()\\n        logging.info(\\\"Set models to update\\\")\\n\\n        # pprint([model.id for model in self.models_to_update])\\n\\n        for model in self.models_to_update:\\n            # self.model_visited_in_db = set()\\n            # logging.info(f\\\"Setting inbound models in summarization map: {model.id}\\\")\\n            self._set_inbound_models_in_summarization_map(model.id)\\n            self.temp_map.append(model)\\n\\n            self.model_visited_in_db.remove(model.id)\\n            # logging.info(f\\\"Setting outbound models in summarization map: {model.id}\\\")\\n            # self._set_outbound_models_in_summarization_map(model.id)\\n            self.summarization_map.extend(self.temp_map)\\n            self.temp_map = []\\n\\n        for model in self.models_to_update:\\n            self.model_visited_in_db = set()\\n            # logging.info(f\\\"Setting outbound models in summarization map: {model.id}\\\")\\n            self._set_outbound_models_in_summarization_map(model.id)\\n            self.summarization_map.extend(self.temp_map)\\n            self.temp_map = []\\n\\n        logging.info(\\\"Created summarization map\\\")\\n        summary_ids: set[str] = set()\\n        summary_map: list[ModelType] = []\\n        for model in self.summarization_map[::-1]:\\n            if model.id not in summary_ids:\\n                summary_map.append(model)\\n                summary_ids.add(model.id)\\n\\n        # return summary_map[::-1]\\n        pprint([model.id for model in summary_map[::-1]])\\n        return summary_map[::-1]\\n\\n    # def old_create_summarization_map(self) -> list[list[ModelType]]:\\n    #     for module_id in self.module_ids_to_update:\\n    #         models_to_update: list[ModelType] = []\\n\\n    #         upstream_models: list[\\n    #             ModelType\\n    #         ] | None = self.arangodb_manager.get_all_upstream_vertices(module_id)\\n    #         downstream_models: list[\\n    #             ModelType\\n    #         ] | None = self.arangodb_manager.get_all_downstream_vertices(module_id)\\n\\n    #         ids_from_db: list[str] = []\\n    #         if upstream_models:\\n    #             upstream_ids_to_update: list[str] = [\\n    #                 model.id for model in upstream_models\\n    #             ]\\n    #             ids_from_db.extend(upstream_ids_to_update)\\n\\n    #         ids_from_db.append(module_id)\\n\\n    #         if downstream_models:\\n    #             downstream_ids_to_update: list[str] = [\\n    #                 model.id for model in downstream_models\\n    #             ]\\n    #             ids_from_db.extend(downstream_ids_to_update)\\n\\n    #         for id in ids_from_db:\\n    #             for model in self.module_models:\\n    #                 if model.id == id:\\n    #                     models_to_update.append(model)\\n    #                 elif model.children:\\n    #                     for child in model.children:\\n    #                         if child.id == id:\\n    #                             models_to_update.append(child)\\n\\n    #         self.summarization_map.append(models_to_update)\\n\\n    #     return self.summarization_map\\n\\n\\nImported code block (postcode:databases:arangodb:arangodb_connector.py__*__MODULE) code content:\\nimport logging\\nfrom typing import Any\\nfrom arango.client import ArangoClient\\nfrom arango.database import StandardDatabase\\nfrom arango.result import Result\\nfrom arango.typings import Jsons, Json\\n\\nimport postcode.databases.arangodb.helper_functions as helper_functions\\n\\n# from postcode.models import (\\n#     ModuleModel,\\n#     ClassModel,\\n#     FunctionModel,\\n#     StandaloneCodeBlockModel,\\n# )\\n\\n\\n# test = ArangoClient(hosts=\\\"http://localhost:8529\\\")\\nclass ArangoDBConnector:\\n    def __init__(\\n        self,\\n        url: str = \\\"http://localhost:8529\\\",\\n        username: str = \\\"root\\\",\\n        password: str = \\\"openSesame\\\",\\n        db_name: str = \\\"postcode\\\",\\n    ) -> None:\\n        self.client = ArangoClient(hosts=url)\\n        self.username: str = username\\n        self.password: str = password\\n        self.db_name: str = db_name\\n        self.db: StandardDatabase = self._ensure_database()\\n\\n    def _ensure_database(self) -> StandardDatabase:\\n        sys_db: StandardDatabase = self.client.db(\\n            \\\"_system\\\", username=self.username, password=self.password\\n        )\\n        if not sys_db.has_database(self.db_name):\\n            sys_db.create_database(self.db_name)\\n        return self.client.db(\\n            self.db_name, username=self.username, password=self.password\\n        )\\n\\n    # def _ensure_vertex_collections(self, vertex_collections: list[str]) -> None:\\n    #     for collection in vertex_collections:\\n    #         if not self.db.has_collection(collection):\\n    #             self.db.create_collection(collection)\\n\\n    def _get_current_schema(self, collection_name: str) -> dict:\\n        collection = self.db.collection(collection_name)\\n        try:\\n            properties: Result[Json] = collection.properties()\\n            return properties.get(\\\"schema\\\", {})  # type: ignore # FIXME: Fix type error\\n        except Exception as e:\\n            logging.error(f\\\"Error retrieving current schema for {collection_name}: {e}\\\")\\n            return {}\\n\\n    def ensure_collection(\\n        self, collection_name: str, schema: dict[str, Any] | None = None\\n    ) -> None:\\n        if not self.db.has_collection(collection_name) and not schema:\\n            self.db.create_collection(collection_name)\\n            logging.info(f\\\"Created collection: {collection_name}\\\")\\n        # else:\\n        #     current_schema = self._get_current_schema(collection_name)\\n        #     self.db.collection(collection_name)\\n        # if current_schema != schema:\\n        #     collection = self.db.collection(collection_name)\\n        #     try:\\n        #         collection.configure(schema=schema)\\n        #         logging.info(f\\\"Updated schema for collection: {collection_name}\\\")\\n        #     except Exception as e:\\n        #         logging.error(f\\\"Error updating schema for {collection_name}: {e}\\\")\\n\\n    def ensure_edge_collection(self, collection_name: str) -> None:\\n        if not self.db.has_collection(collection_name):\\n            self.db.create_collection(collection_name, edge=True)\\n            logging.info(f\\\"Created edge collection: {collection_name}\\\")\\n\\n    def delete_all_collections(self) -> None:\\n        collections: Result[Jsons] = self.db.collections()\\n\\n        for collection in collections:  # type: ignore # FIXME: Fix type error\\n            if not collection[\\\"name\\\"].startswith(\\\"_\\\"):  # Skip system collections\\n                self.db.delete_collection(collection[\\\"name\\\"])\\n                logging.info(f\\\"Deleted collection: {collection['name']}\\\")\\n\\n    def ensure_collections(self) -> None:\\n        # model_schemas: dict[str, dict[str, Any]] = self._get_model_schemas()\\n        required_collections: list[\\n            str\\n        ] = helper_functions.pluralized_and_lowered_block_types()\\n\\n        for collection_name in required_collections:\\n            # schema: dict[str, Any] = model_schemas[collection_name]\\n            # self.ensure_collection(collection_name, schema)\\n            self.ensure_collection(collection_name)\\n\\n        self.ensure_edge_collection(\\\"code_edges\\\")\\n\\n    # def _get_model_schemas(self) -> dict[str, dict[str, Any]]:\\n    #     return {\\n    #         \\\"modules\\\": ModuleModel.model_json_schema(),\\n    #         \\\"classes\\\": ClassModel.model_json_schema(),\\n    #         \\\"functions\\\": FunctionModel.model_json_schema(),\\n    #         \\\"standalone_blocks\\\": StandaloneCodeBlockModel.model_json_schema(),\\n    #     }\\n\\n\\nImported code block (postcode:databases:arangodb:arangodb_manager.py__*__MODULE) code content:\\nimport logging\\nfrom typing import Any, Callable, Union\\n\\nfrom arango.result import Result\\nfrom arango.cursor import Cursor\\nfrom arango.graph import Graph\\nfrom arango.collection import StandardCollection\\nfrom arango.typings import Json\\n\\nfrom postcode.databases.arangodb.arangodb_connector import ArangoDBConnector\\n\\n# from postcode.types.postcode import ModelType\\nfrom postcode.models.models import (\\n    ClassModel,\\n    FunctionModel,\\n    ModuleModel,\\n    StandaloneCodeBlockModel,\\n)\\nimport postcode.databases.arangodb.helper_functions as helper_functions\\n\\nModelType = Union[\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n]\\n\\n# NOTE: Remember, when adding logic to connect dependencies, the `from` the external dependency `to` the internal definition using it\\n\\n\\nclass ArangoDBManager:\\n    def __init__(\\n        self,\\n        db_connector: ArangoDBConnector,\\n        default_graph_name: str = \\\"codebase_graph\\\",\\n    ) -> None:\\n        self.db_connector: ArangoDBConnector = db_connector\\n\\n        self.processed_id_set = set()\\n        self.default_graph_name: str = default_graph_name\\n\\n    def upsert_models(self, module_models: list[ModuleModel]) -> \\\"ArangoDBManager\\\":\\n        for model in module_models:\\n            self._upsert_model(model)\\n        return self\\n\\n    def _upsert_model(self, module_model: ModuleModel) -> None:\\n        self._upsert_vertex(module_model, \\\"modules\\\")\\n        self._process_children(module_model)\\n\\n    def _process_children(self, parent_model: ModelType) -> None:\\n        if not parent_model.children:\\n            return None\\n\\n        for child in parent_model.children:\\n            # if child.id in self.processed_id_set:\\n            #     continue\\n\\n            self.processed_id_set.add(child.id)\\n            self._upsert_vertex(\\n                child, helper_functions.pluralize_block_type(child.block_type)\\n            )\\n\\n            if child.children:\\n                self._process_children(child)\\n\\n    def _upsert_vertex(self, model: ModelType, collection_name: str) -> None:\\n        model_data: dict[str, Any] = model.model_dump()\\n        model_data[\\\"_key\\\"] = model.id\\n\\n        try:\\n            self.db_connector.ensure_collection(\\n                collection_name, model.model_json_schema()\\n            )\\n            query: str = f\\\"\\\"\\\"\\n            UPSERT {{_key: @key}}\\n            INSERT @doc\\n            UPDATE @doc\\n            IN {collection_name}\\n            \\\"\\\"\\\"\\n            bind_vars: dict[str, Any] = {\\\"key\\\": model.id, \\\"doc\\\": model_data}\\n            self.db_connector.db.aql.execute(query, bind_vars=bind_vars)\\n\\n            if not isinstance(model, ModuleModel) and model.parent_id:\\n                parent_type: str = self._get_collection_from_id(model.parent_id)\\n                self._upsert_edge(\\n                    model.id, model.parent_id, collection_name, parent_type\\n                )\\n        except Exception as e:\\n            logging.error(f\\\"Error upserting {collection_name} vertex (ArangoDB): {e}\\\")\\n\\n    def _upsert_edge(\\n        self, from_key: str, to_key: str, source_type: str, target_type: str\\n    ) -> None:\\n        source_string: str = f\\\"{source_type}/{from_key}\\\"\\n        target_string: str = f\\\"{target_type}/{to_key}\\\"\\n\\n        edge_data: dict[str, str] = {\\n            \\\"_from\\\": source_string,\\n            \\\"_to\\\": target_string,\\n            \\\"source_type\\\": source_type,\\n            \\\"target_type\\\": target_type,\\n        }\\n\\n        try:\\n            self.db_connector.ensure_edge_collection(\\\"code_edges\\\")\\n            query = f\\\"\\\"\\\"\\n            UPSERT {{_from: @from, _to: @to}}\\n            INSERT @doc\\n            UPDATE @doc\\n            IN code_edges\\n            \\\"\\\"\\\"\\n            bind_vars = {\\n                \\\"from\\\": edge_data[\\\"_from\\\"],\\n                \\\"to\\\": edge_data[\\\"_to\\\"],\\n                \\\"doc\\\": edge_data,\\n            }\\n            self.db_connector.db.aql.execute(query, bind_vars=bind_vars)\\n        except Exception as e:\\n            logging.error(f\\\"Error upserting edge (ArangoDB): {e}\\\")\\n\\n    def _get_collection_from_id(self, block_id: str) -> str:\\n        block_id_parts: list[str] = block_id.split(\\\"__*__\\\")\\n        block_type_part: str = block_id_parts[-1]\\n\\n        block_type_functions: dict[str, Callable[..., str]] = {\\n            \\\"MODULE\\\": lambda: \\\"modules\\\",\\n            \\\"CLASS\\\": lambda: \\\"classes\\\",\\n            \\\"FUNCTION\\\": lambda: \\\"functions\\\",\\n            \\\"STANDALONE_BLOCK\\\": lambda: \\\"standalone_blocks\\\",\\n        }\\n\\n        for key, func in block_type_functions.items():\\n            if block_type_part.startswith(key):\\n                return func()\\n\\n        return \\\"unknown\\\"\\n\\n    def process_imports_and_dependencies(self) -> \\\"ArangoDBManager\\\":\\n        for vertex_collection in helper_functions.pluralized_and_lowered_block_types():\\n            cursor: Result[Cursor] = self.db_connector.db.collection(\\n                vertex_collection\\n            ).all()\\n            if isinstance(cursor, Cursor):\\n                for vertex in cursor:\\n                    vertex_key = vertex[\\\"_key\\\"]\\n                    if vertex_collection == \\\"modules\\\":\\n                        self._create_edges_for_imports(\\n                            vertex_key, vertex.get(\\\"imports\\\", [])\\n                        )\\n                    else:\\n                        self._create_edges_for_dependencies(\\n                            vertex_key, vertex.get(\\\"dependencies\\\", [])\\n                        )\\n            else:\\n                logging.error(\\n                    f\\\"Error getting cursor for vertex collection: {vertex_collection}\\\"\\n                )\\n        return self\\n\\n    def _create_edges_for_imports(\\n        self, module_key: str, imports: list[dict[str, Any]]\\n    ) -> None:\\n        if not imports:\\n            # logging.debug(f\\\"No imports found for module {module_key}\\\")\\n            return\\n\\n        # logging.info(f\\\"Processing imports for module {module_key}\\\")\\n\\n        for _import in imports:\\n            import_names: list[dict[str, str]] = _import.get(\\\"import_names\\\", [])\\n            if not import_names:\\n                # logging.debug(f\\\"No import names found in import {_import}\\\")\\n                continue\\n\\n            for import_name in import_names:\\n                local_block_id: str | None = import_name.get(\\\"local_block_id\\\")\\n\\n                if local_block_id:\\n                    target_type = self._get_collection_from_id(local_block_id)\\n                    try:\\n                        self._upsert_edge(\\n                            local_block_id, module_key, target_type, \\\"modules\\\"\\n                        )\\n\\n                        # logging.info(\\n                        #     f\\\"Upserted edge for import {module_key} to {local_block_id}\\\"\\n                        # )\\n                    except Exception as e:\\n                        logging.error(\\n                            f\\\"Error creating edge for import {module_key} to {local_block_id}: {e}\\\"\\n                        )\\n                else:\\n                    # logging.warning(\\n                    #     f\\\"Skipped import {import_name} in module {module_key}\\\"\\n                    # )\\n                    ...\\n\\n    def _create_edges_for_dependencies(\\n        self, block_key: str, dependencies: list[dict[str, Any]]\\n    ) -> None:\\n        if not dependencies:\\n            return\\n\\n        for dependency in dependencies:\\n            code_block_id: str | None = dependency.get(\\\"code_block_id\\\")\\n            if code_block_id:\\n                source_type: str = self._get_collection_from_id(code_block_id)\\n                target_type: str = self._get_collection_from_id(block_key)\\n                try:\\n                    self._upsert_edge(\\n                        code_block_id, block_key, source_type, target_type\\n                    )\\n                    # logging.info(\\n                    #     f\\\"Upserted edge for dependency {block_key} to {code_block_id}\\\"\\n                    # )\\n                except Exception as e:\\n                    logging.error(\\n                        f\\\"Error creating edge for dependency {block_key} to {code_block_id}: {e}\\\"\\n                    )\\n\\n    def delete_vertex_by_id(\\n        self, vertex_key: str, graph_name: str | None = None\\n    ) -> None:\\n        collection_name: str = self._get_collection_from_id(vertex_key)\\n        if collection_name == \\\"unknown\\\":\\n            logging.error(f\\\"Unknown vertex type for key: {vertex_key}\\\")\\n            return None\\n\\n        if not graph_name:\\n            graph_name = self.default_graph_name\\n\\n        try:\\n            vertex_coll = self.db_connector.db.graph(graph_name).vertex_collection(\\n                collection_name\\n            )\\n\\n            vertex_coll.delete(vertex_key)\\n\\n            # logging.info(\\n            #     f\\\"Vertex '{vertex_key}' from collection '{collection_name}' was successfully deleted.\\\"\\n            # )\\n\\n        except Exception as e:\\n            logging.error(\\n                f\\\"Error deleting vertex '{vertex_key}' from collection '{collection_name}': {e}\\\"\\n            )\\n\\n    def get_graph(self, graph_name: str | None = None) -> Graph | None:\\n        if not graph_name:\\n            graph_name = self.default_graph_name\\n        try:\\n            return self.db_connector.db.graph(self.default_graph_name)\\n        except Exception as e:\\n            logging.error(f\\\"Error getting graph '{self.default_graph_name}': {e}\\\")\\n            return None\\n\\n    def get_or_create_graph(self, graph_name: str | None = None) -> Result[Graph]:\\n        if not graph_name:\\n            graph_name = self.default_graph_name\\n\\n        try:\\n            if not self.db_connector.db.has_graph(graph_name):\\n                edge_definitions: list[dict[str, str | list[str]]] = [\\n                    {\\n                        \\\"edge_collection\\\": \\\"code_edges\\\",\\n                        \\\"from_vertex_collections\\\": helper_functions.pluralized_and_lowered_block_types(),\\n                        \\\"to_vertex_collections\\\": helper_functions.pluralized_and_lowered_block_types(),\\n                    }\\n                ]\\n\\n                # logging.info(f\\\"Graph '{graph_name}' created successfully.\\\")\\n                return self.db_connector.db.create_graph(\\n                    graph_name, edge_definitions=edge_definitions\\n                )\\n\\n            else:\\n                return self.get_graph()\\n\\n        except Exception as e:\\n            logging.error(f\\\"Error creating graph '{graph_name}': {e}\\\")\\n\\n    def delete_graph(self, graph_name: str | None = None) -> None:\\n        if not graph_name:\\n            graph_name = self.default_graph_name\\n        try:\\n            self.db_connector.db.delete_graph(graph_name)\\n            logging.info(f\\\"Graph '{graph_name}' deleted successfully.\\\")\\n        except Exception as e:\\n            logging.error(f\\\"Error deleting graph '{graph_name}': {e}\\\")\\n\\n    def get_outbound_models(self, start_key: str) -> list[ModelType] | None:\\n        vertex_type: str = self._get_collection_from_id(start_key)\\n\\n        query: str = f\\\"\\\"\\\"\\n        FOR v, e, p IN 1..100 OUTBOUND '{vertex_type}/{start_key}' GRAPH '{self.default_graph_name}'\\n        RETURN DISTINCT v\\n        \\\"\\\"\\\"\\n        # query: str = f\\\"\\\"\\\"\\n        # FOR v, e, p IN 1..100 OUTBOUND '{vertex_type}/{start_key}' GRAPH '{self.default_graph_name}'\\n        # FILTER LENGTH(p.edges[* FILTER CURRENT != e]) == 0\\n        # RETURN DISTINCT v\\n        # \\\"\\\"\\\"\\n        # query: str = f\\\"\\\"\\\"\\n        # FOR v, e, p IN 1..100 OUTBOUND '{vertex_type}/{start_key}' GRAPH '{self.default_graph_name}'\\n        # FILTER LENGTH(p.edges[* FILTER CURRENT != e]) == 0\\n        #     AND p.edges[*].distance ALL == 1\\n        # RETURN DISTINCT v\\n        # \\\"\\\"\\\"\\n\\n        try:\\n            cursor = self.db_connector.db.aql.execute(query)\\n            if isinstance(cursor, Cursor):\\n                return [\\n                    helper_functions.create_model_from_vertex(doc) for doc in cursor\\n                ]\\n            else:\\n                logging.error(f\\\"Error getting cursor for query: {query}\\\")\\n                return None\\n        except Exception as e:\\n            logging.error(f\\\"Error in get_all_downstream_vertices: {e}\\\")\\n            return None\\n\\n    def get_inbound_models(self, end_key: str) -> list[ModelType] | None:\\n        vertex_type: str = self._get_collection_from_id(end_key)\\n\\n        query: str = f\\\"\\\"\\\"\\n        FOR v, e, p IN 1..100 INBOUND '{vertex_type}/{end_key}' GRAPH '{self.default_graph_name}'\\n        RETURN DISTINCT v\\n        \\\"\\\"\\\"\\n\\n        # query: str = f\\\"\\\"\\\"\\n        # FOR v, e, p IN 1..100 INBOUND '{vertex_type}/{end_key}' GRAPH '{self.default_graph_name}'\\n        # FILTER LENGTH(p.edges[* FILTER CURRENT != e]) == 0\\n        # RETURN DISTINCT v\\n        # \\\"\\\"\\\"\\n\\n        try:\\n            cursor: Result[Cursor] = self.db_connector.db.aql.execute(query)\\n            if isinstance(cursor, Cursor):\\n                return [\\n                    helper_functions.create_model_from_vertex(doc) for doc in cursor\\n                ]\\n            else:\\n                logging.error(f\\\"Error getting cursor for query: {query}\\\")\\n                return None\\n        except Exception as e:\\n            logging.error(f\\\"Error in get_all_upstream_vertices: {e}\\\")\\n            return None\\n\\n    def update_vertex_by_id(self, id: str, new_summary: str) -> None:\\n        try:\\n            collection_name: str = self._get_collection_from_id(id)\\n            if collection_name == \\\"unknown\\\":\\n                logging.error(f\\\"Unknown vertex type for id: {id}\\\")\\n                return\\n\\n            vertex_collection: StandardCollection = self.db_connector.db.collection(\\n                collection_name\\n            )\\n            vertex_result: Result[Json | None] = vertex_collection.get(id)\\n\\n            if not vertex_result:\\n                logging.error(f\\\"Vertex with id {id} not found.\\\")\\n                return\\n\\n            if isinstance(vertex_result, dict):\\n                vertex = vertex_result\\n            else:\\n                logging.error(\\\"Retrieved vertex is not in a mutable format.\\\")\\n                return None\\n\\n            vertex[\\\"summary\\\"] = new_summary\\n\\n            vertex_collection.update(vertex)\\n            logging.info(f\\\"Vertex with id {id} updated successfully.\\\")\\n\\n        except Exception as e:\\n            logging.error(f\\\"Error in `update_vertex_by_id`: {e}\\\")\\n\\n    def get_all_modules(self) -> list[ModuleModel] | None:\\n        try:\\n            # Define the collection name for modules.\\n            collection_name = \\\"modules\\\"\\n            module_collection: StandardCollection = self.db_connector.db.collection(\\n                collection_name\\n            )\\n\\n            # Retrieve all documents from the modules collection.\\n            cursor: Result[Cursor] = module_collection.all()\\n\\n            # Convert each document to a ModuleModel instance.\\n            modules: list[ModuleModel] = []\\n            for doc in cursor:  # type: ignore # FIXME: Fix type error\\n                # Ensure the document is a dictionary.\\n                try:\\n                    # Convert the document to a ModuleModel instance and add it to the list.\\n                    module = ModuleModel(**doc)\\n                    modules.append(module)\\n                except Exception as e:\\n                    logging.error(f\\\"Retrieved document is not in a valid format: {e}\\\")\\n                    continue\\n\\n            return modules\\n\\n        except Exception as e:\\n            logging.error(f\\\"Error in get_all_modules: {e}\\\")\\n            return None\\n\\n\\nImported code block (postcode:databases:chroma:setup_chroma.py__*__MODULE) code content:\\nfrom dataclasses import dataclass\\nfrom logging import Logger\\n\\nimport chromadb\\nfrom postcode.databases.chroma.chromadb_client_manager import ChromaDBClientManager\\n\\nfrom postcode.databases.chroma.chromadb_collection_manager import (\\n    ChromaDBCollectionManager,\\n)\\n\\nfrom chromadb.config import DEFAULT_DATABASE, DEFAULT_TENANT, Settings\\nfrom chromadb.api import ClientAPI\\nfrom chromadb.api.types import (\\n    DataLoader,\\n    CollectionMetadata,\\n    GetResult,\\n    QueryResult,\\n    Where,\\n    WhereDocument,\\n    Include,\\n    URIs,\\n    Loadable,\\n    Metadata,\\n    Embedding,\\n)\\nfrom chromadb import Collection\\nfrom chromadb import EmbeddingFunction\\n\\nfrom postcode.models.models import ModuleModel\\n\\n\\n@dataclass\\nclass ChromaSetupReturnContext:\\n    \\\"\\\"\\\"\\n    Represents the return value of the ChromaDB setup method.\\n\\n    Attributes:\\n        - chroma_collection_manager (ChromaDBCollectionManager): The ChromaDB collection manager.\\n        - chroma_collection (Collection): The ChromaDB collection.\\n    \\\"\\\"\\\"\\n\\n    chroma_collection_manager: ChromaDBCollectionManager\\n    chroma_collection: Collection\\n\\n\\ndef setup_chroma(\\n    module_models: list[ModuleModel], logger: Logger\\n) -> ChromaSetupReturnContext:\\n    chroma_settings = Settings(allow_reset=True)\\n    chroma_client: ClientAPI = chromadb.PersistentClient(settings=chroma_settings)\\n    chroma_client_manager = ChromaDBClientManager(chroma_client)\\n\\n    logger.debug(f\\\"Resetting Chroma client\\\")\\n    if chroma_client_manager.reset_client():\\n        logger.debug(\\\"Client reset\\\")\\n\\n    chroma_collection: Collection = chroma_client_manager.get_or_create_collection(\\n        \\\"postcode\\\"\\n    )\\n\\n    chroma_collection_manager = ChromaDBCollectionManager(chroma_collection)\\n    chroma_collection_manager.upsert_models(tuple(module_models))\\n\\n    return ChromaSetupReturnContext(chroma_collection_manager, chroma_collection)\\n\\n\\nImported code block (postcode:json_management:json_handler.py__*__MODULE) code content:\\nimport json\\nfrom pathlib import Path\\n\\nfrom postcode.models.models import ModuleModel\\nfrom postcode.utilities.logger.decorators import logging_decorator\\n\\n\\nclass JSONHandler:\\n    def __init__(\\n        self,\\n        directory: str,\\n        directory_modules: dict[str, list[str]],\\n        output_directory: str = \\\"../output\\\",\\n    ) -> None:\\n        self.directory: str = directory\\n        self.output_directory: str = output_directory\\n        self.directory_modules: dict[str, list[str]] = directory_modules\\n\\n        self._create_output_directory()\\n\\n    @logging_decorator(message=\\\"Saving model as JSON\\\")\\n    def save_model_as_json(self, module_model: ModuleModel, file_path: str) -> None:\\n        \\\"\\\"\\\"Saves a parsed ModuleModel as JSON.\\\"\\\"\\\"\\n\\n        json_output_directory: str = self._create_json_output_directory()\\n        output_path: str = self._get_json_output_path(file_path, json_output_directory)\\n        self._write_json_file(module_model, output_path)\\n\\n    @logging_decorator(message=\\\"Saving visited directories\\\")\\n    def save_visited_directories(\\n        self, directory_mape_name: str = \\\"directory_map.json\\\"\\n    ) -> None:\\n        \\\"\\\"\\\"\\n        Saves a JSON file mapping each visited directory to its Python files.\\n\\n        The output is saved in a file named '00_directory_module_map.json' within the specified output directory.\\n\\n        Args:\\n            directory_mape_name (str): The name of the output file for the directory map.\\n\\n        Example:\\n            >>> visitor_manager.save_visited_directories(\\\"directory_map.json\\\")\\n            # Saves a mapping of directories to Python files as JSON.\\n        \\\"\\\"\\\"\\n\\n        output_path: str = self._get_directory_map_output_path(directory_mape_name)\\n        self._write_json_directory_map(output_path)\\n\\n    def _create_output_directory(self) -> None:\\n        \\\"\\\"\\\"Creates the output directory if it does not already exist.\\\"\\\"\\\"\\n\\n        Path(self.output_directory).mkdir(exist_ok=True)\\n\\n    def _create_json_output_directory(self) -> str:\\n        \\\"\\\"\\\"Creates the JSON output directory if it does not already exist.\\\"\\\"\\\"\\n\\n        json_output_directory: Path = Path(self.output_directory) / \\\"json\\\"\\n        json_output_directory.mkdir(exist_ok=True)\\n        return str(json_output_directory)\\n\\n    def _get_json_output_path(self, file_path: str, json_output_directory: str) -> str:\\n        \\\"\\\"\\\"Gets the output path for a JSON file.\\\"\\\"\\\"\\n\\n        relative_path: Path = Path(file_path).relative_to(Path(self.directory))\\n        safe_relative_path: str = str(relative_path).replace(\\\"/\\\", \\\":\\\").rstrip(\\\".py\\\")\\n        return str(Path(json_output_directory) / f\\\"{safe_relative_path}.json\\\")\\n\\n    def _write_json_file(self, module_model: ModuleModel, output_path: str) -> None:\\n        \\\"\\\"\\\"Writes a JSON file containing the parsed data from a ModuleModel.\\\"\\\"\\\"\\n\\n        parsed_data_json: str = module_model.model_dump_json(indent=4)\\n        with open(output_path, \\\"w\\\") as json_file:\\n            json_file.write(parsed_data_json)\\n\\n    def _get_directory_map_output_path(self, directory_output_name: str) -> str:\\n        \\\"\\\"\\\"Gets the output path for the directory map JSON file.\\\"\\\"\\\"\\n\\n        return str(Path(self.output_directory) / directory_output_name)\\n\\n    def _write_json_directory_map(self, output_path: str) -> None:\\n        \\\"\\\"\\\"Writes the directory map JSON file.\\\"\\\"\\\"\\n\\n        with open(output_path, \\\"w\\\") as json_file:\\n            json.dump(self.directory_modules, json_file, indent=4)\\n\\n\\nImported code block (postcode:models:models.py__*__MODULE) code content:\\nfrom typing import Union\\nfrom pydantic import BaseModel, Field, validator\\n\\nfrom postcode.models.enums import (\\n    BlockType,\\n    ImportModuleType,\\n    CommentType,\\n)\\n\\n\\nclass ImportNameModel(BaseModel):\\n    \\\"\\\"\\\"Class representing the name of an import.\\\"\\\"\\\"\\n\\n    name: str\\n    as_name: str | None = None\\n    local_block_id: str | None = None\\n\\n    # def convert_import_names_to_metadata(self) -> str:\\n    #     \\\"\\\"\\\"Converts the import name to a metadata string.\\\"\\\"\\\"\\n\\n    #     return self.model_dump_json()\\n\\n\\nclass ImportModel(BaseModel):\\n    \\\"\\\"\\\"Class representing an import statement.\\\"\\\"\\\"\\n\\n    import_names: list[ImportNameModel]\\n    imported_from: str | None = None\\n    import_module_type: ImportModuleType = ImportModuleType.STANDARD_LIBRARY\\n    local_module_id: str | None = None\\n\\n    def convert_import_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the import to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass DependencyModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a module dependency.\\\"\\\"\\\"\\n\\n    code_block_id: str\\n\\n    def convert_dependency_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the dependency to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass CommentModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a comment.\\\"\\\"\\\"\\n\\n    content: str\\n    comment_types: list[CommentType]\\n\\n    def convert_comment_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the comment to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass DecoratorModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a decorator.\\\"\\\"\\\"\\n\\n    content: str\\n    decorator_name: str\\n    decorator_args: list[str] | None = None\\n\\n    def convert_decorator_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the decorator to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass ClassKeywordModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a class keyword.\\\"\\\"\\\"\\n\\n    content: str\\n    keyword_name: str\\n    args: str | None = None\\n\\n    def convert_class_keyword_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the class keyword to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass ParameterModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a function parameter.\\\"\\\"\\\"\\n\\n    content: str\\n\\n\\nclass ParameterListModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a list of parameters.\\\"\\\"\\\"\\n\\n    params: list[ParameterModel] | None = None\\n    star_arg: ParameterModel | None = None\\n    kwonly_params: list[ParameterModel] | None = None\\n    star_kwarg: ParameterModel | None = None\\n    posonly_params: list[ParameterModel] | None = None\\n\\n    def convert_parameters_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the parameter list to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass BaseCodeBlockModel(BaseModel):\\n    \\\"\\\"\\\"Attributes common to all code block models.\\\"\\\"\\\"\\n\\n    id: str\\n    parent_id: str | None = None\\n    block_type: BlockType\\n    start_line_num: int\\n    end_line_num: int\\n    code_content: str = \\\"\\\"\\n    important_comments: list[CommentModel] | None = None\\n    dependencies: list[ImportModel | DependencyModel] | None = None\\n    summary: str | None = None\\n    children: list[\\n        Union[\\n            \\\"ClassModel\\\",\\n            \\\"FunctionModel\\\",\\n            \\\"StandaloneCodeBlockModel\\\",\\n        ]\\n    ] | None = []\\n\\n    @validator(\\\"parent_id\\\", always=True)\\n    def check_parent_id(cls, v, values, **kwargs) -> str | None:\\n        \\\"\\\"\\\"Validates that parent_id is a non-empty string unless block_type is MODULE.\\\"\\\"\\\"\\n\\n        if \\\"block_type\\\" in values and values[\\\"block_type\\\"] != BlockType.MODULE:\\n            if len(v) < 1:\\n                raise ValueError(\\\"parent_id is required!\\\")\\n        return v\\n\\n    def _convert_parent_id_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the parent_id to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.parent_id}\\\" if self.parent_id else \\\"\\\"\\n\\n    def _convert_block_type_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the block_type to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.block_type.name}\\\"\\n\\n    def _convert_important_comments_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the important comments to a metadata string.\\\"\\\"\\\"\\n\\n        important_comments: str = (\\n            self.model_dump_json() if self.important_comments else \\\"\\\"\\n        )\\n\\n        return f\\\"{important_comments}\\\"\\n\\n    def _convert_dependencies_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the dependencies to a metadata string.\\\"\\\"\\\"\\n\\n        dependencies_str: str = \\\"\\\"\\n\\n        if self.dependencies:\\n            for dependency in self.dependencies:\\n                if isinstance(dependency, ImportModel):\\n                    dependencies_str += f\\\"{dependency.convert_import_to_metadata()}\\\\n\\\"\\n                elif isinstance(dependency, DependencyModel):\\n                    dependencies_str += (\\n                        f\\\"{dependency.convert_dependency_to_metadata()}\\\\n\\\"\\n                    )\\n\\n        return dependencies_str\\n\\n    def _convert_summary_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the summary to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.summary}\\\" if self.summary else \\\"\\\"\\n\\n    def _convert_children_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the children to a metadata string.\\\"\\\"\\\"\\n\\n        children_str: str = \\\"\\\"\\n\\n        if self.children:\\n            for child in self.children:\\n                children_str += f\\\"{child.id}\\\\n\\\"\\n\\n        return children_str\\n\\n    def _convert_base_attributes_to_metadata_dict(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the base attributes to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            \\\"id\\\": self.id,\\n            \\\"parent_id\\\": self._convert_parent_id_to_metadata(),\\n            \\\"block_type\\\": self._convert_block_type_to_metadata(),\\n            \\\"start_line_num\\\": self.start_line_num,\\n            \\\"end_line_num\\\": self.end_line_num,\\n            \\\"code_content\\\": self.code_content,\\n            \\\"important_comments\\\": self._convert_important_comments_to_metadata(),\\n            \\\"dependencies\\\": self._convert_dependencies_to_metadata(),\\n            \\\"summary\\\": self._convert_summary_to_metadata(),\\n            \\\"children\\\": self._convert_children_to_metadata(),\\n        }\\n\\n\\nclass ModuleSpecificAttributes(BaseModel):\\n    \\\"\\\"\\\"Module specific attributes.\\\"\\\"\\\"\\n\\n    file_path: str = Field(min_length=1)\\n    docstring: str | None = None\\n    header: list[str] | None = None\\n    footer: list[str] | None = None\\n    imports: list[ImportModel] | None = None\\n\\n    def _convert_docstring_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the docstring to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.docstring}\\\"\\n\\n    def _convert_header_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the header and footer to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n    def _convert_footer_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the header and footer to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n    def _convert_imports_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the imports to a metadata string.\\\"\\\"\\\"\\n        imports_str: str = self.model_dump_json() if self.imports else \\\"\\\"\\n        return f\\\"{imports_str}\\\"\\n\\n    def _convert_module_attributes_to_metadata_dict(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the module attributes to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            \\\"file_path\\\": self.file_path,\\n            \\\"docstring\\\": self._convert_docstring_to_metadata(),\\n            \\\"header\\\": self._convert_header_to_metadata(),\\n            \\\"footer\\\": self._convert_footer_to_metadata(),\\n            \\\"imports\\\": self._convert_imports_to_metadata(),\\n        }\\n\\n\\nclass ModuleModel(BaseCodeBlockModel, ModuleSpecificAttributes):\\n    \\\"\\\"\\\"Model for a module.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the module model to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_module_attributes_to_metadata_dict(),\\n        }\\n\\n\\nclass ClassSpecificAttributes(BaseModel):\\n    \\\"\\\"\\\"Class specific attributes.\\\"\\\"\\\"\\n\\n    class_name: str = Field(min_length=1)\\n    decorators: list[DecoratorModel] | None = None\\n    bases: list[str] | None = None\\n    docstring: str | None = None\\n    keywords: list[ClassKeywordModel] | None = None\\n    # attributes: list[dict] | None = None\\n\\n    def _convert_decorators_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the decorators to a metadata string.\\\"\\\"\\\"\\n        decorators_str: str = self.model_dump_json() if self.decorators else \\\"\\\"\\n        return f\\\"{decorators_str}\\\"\\n\\n    def _convert_bases_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the bases to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json() if self.bases else \\\"\\\"\\n\\n    def _convert_docstring_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the docstring to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.docstring}\\\" if self.docstring else \\\"\\\"\\n\\n    def _convert_keywords_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the keywords to a metadata string.\\\"\\\"\\\"\\n        keywords_str: str = self.model_dump_json() if self.keywords else \\\"\\\"\\n        return f\\\"{keywords_str}\\\"\\n\\n    def _convert_class_attributes_to_metadata_dict(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the class attributes to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            \\\"class_name\\\": self.class_name,\\n            \\\"decorators\\\": self._convert_decorators_to_metadata(),\\n            \\\"bases\\\": self._convert_bases_to_metadata(),\\n            \\\"docstring\\\": self._convert_docstring_to_metadata(),\\n            \\\"keywords\\\": self._convert_keywords_to_metadata(),\\n        }\\n\\n\\nclass ClassModel(BaseCodeBlockModel, ClassSpecificAttributes):\\n    \\\"\\\"\\\"Model for a class.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the class model to a metadata dictionary.\\\"\\\"\\\"\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_class_attributes_to_metadata_dict(),\\n        }\\n\\n\\nclass FunctionSpecificAttributes(BaseModel):\\n    \\\"\\\"\\\"Function specific attributes.\\\"\\\"\\\"\\n\\n    function_name: str = Field(min_length=1)\\n    docstring: str | None = None\\n    decorators: list[DecoratorModel] | None = None\\n    parameters: ParameterListModel | None = None\\n    returns: str | None = None\\n    is_method: bool = False\\n    is_async: bool = False\\n\\n    def _convert_docstring_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the docstring to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.docstring}\\\" if self.docstring else \\\"\\\"\\n\\n    def _convert_decorators_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the decorators to a metadata string.\\\"\\\"\\\"\\n        decorators_str: str = self.model_dump_json() if self.decorators else \\\"\\\"\\n        return f\\\"{decorators_str}\\\"\\n\\n    def _convert_parameters_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the parameters to a metadata string.\\\"\\\"\\\"\\n        return (\\n            self.parameters.convert_parameters_to_metadata() if self.parameters else \\\"\\\"\\n        )\\n\\n    def _convert_returns_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the returns to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.returns}\\\" if self.returns else \\\"\\\"\\n\\n    def _convert_function_attributes_to_metadata_dict(self) -> dict[str, str | bool]:\\n        \\\"\\\"\\\"Converts the function attributes to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            \\\"function_name\\\": self.function_name,\\n            \\\"docstring\\\": self._convert_docstring_to_metadata(),\\n            \\\"decorators\\\": self._convert_decorators_to_metadata(),\\n            \\\"parameters\\\": self._convert_parameters_to_metadata(),\\n            \\\"returns\\\": self._convert_returns_to_metadata(),\\n            \\\"is_method\\\": self.is_method,\\n            \\\"is_async\\\": self.is_async,\\n        }\\n\\n\\nclass FunctionModel(BaseCodeBlockModel, FunctionSpecificAttributes):\\n    \\\"\\\"\\\"Model for a function.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the function model to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_function_attributes_to_metadata_dict(),\\n        }\\n\\n\\nclass StandaloneCodeBlockSpecificAttributes(BaseModel):\\n    \\\"\\\"\\\"Standalone code block specific attributes.\\\"\\\"\\\"\\n\\n    variable_assignments: list[str] | None = None\\n\\n    def _convert_variable_assignments_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the variable assignments to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json() if self.variable_assignments else \\\"\\\"\\n\\n    def _convert_standalone_block_attributes_to_metadata_dict(\\n        self,\\n    ) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the standalone code block attributes to a metadata dictionary.\\\"\\\"\\\"\\n        return {\\n            \\\"variable_assignments\\\": self._convert_variable_assignments_to_metadata(),\\n        }\\n\\n\\nclass StandaloneCodeBlockModel(\\n    BaseCodeBlockModel, StandaloneCodeBlockSpecificAttributes\\n):\\n    \\\"\\\"\\\"Model for a standalone code block.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the standalone code block model to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_standalone_block_attributes_to_metadata_dict(),\\n        }\\n\\n\\nImported code block (postcode:python_parser:visitor_manager:visitor_manager.py__*__MODULE) code content:\\nfrom dataclasses import dataclass\\nimport logging\\nfrom pathlib import Path\\n\\nfrom postcode.python_parser.model_builders.module_model_builder import (\\n    ModuleModelBuilder,\\n)\\nfrom postcode.utilities.logger.decorators import logging_decorator\\n\\nfrom postcode.python_parser.parsers.python_parser import PythonParser\\nfrom postcode.python_parser.visitor_manager.import_and_dependency_updater import (\\n    ImportAndDependencyUpdater,\\n)\\nfrom postcode.models.models import ModuleModel\\n\\nfrom postcode.ai_services.summarizer.summarization_context import Summarizer\\n\\nEXCLUDED_DIRECTORIES: set[str] = {\\\".venv\\\", \\\"node_modules\\\", \\\"__pycache__\\\", \\\".git\\\"}\\n\\n\\n@dataclass\\nclass VisitorManagerProcessFilesReturn:\\n    \\\"\\\"\\\"\\n    Represents the return value of the VisitorManager.process_files() method.\\n\\n    Attributes:\\n        - models_tuple (tuple[ModuleModel, ...]): A tuple of ModuleModel objects representing the parsed modules.\\n        - directory_modules (dict[str, list[str]]): A dictionary mapping directory paths to lists of module names.\\n            This is used to keep track of the modules present in each directory.\\n    \\\"\\\"\\\"\\n\\n    models_tuple: tuple[ModuleModel, ...]\\n    directory_modules: dict[str, list[str]]\\n\\n\\nclass VisitorManager:\\n    \\\"\\\"\\\"\\n    Manages the visiting and processing of Python files in a given directory.\\n\\n    This class scans a specified directory, filters for Python files, parses them, and saves the parsed data in a structured JSON format. It also maintains a mapping of directories to the Python files they contain.\\n\\n    Attributes:\\n        directory (str): The root directory to scan for Python files.\\n        output_directory (str): The directory where output JSON files will be saved.\\n        directory_modules (dict): A mapping of directories to their contained Python files.\\n\\n    Example:\\n        >>> visitor_manager = VisitorManager(\\\"/path/to/python/code\\\", \\\"output\\\")\\n        >>> visitor_manager.process_files()\\n        # This will process all Python files in /path/to/python/code and save their parsed data in the output directory.\\n    \\\"\\\"\\\"\\n\\n    @logging_decorator(message=\\\"Initializing VisitorManager\\\")\\n    def __init__(self, directory: str, output_directory: str = \\\"output_json\\\") -> None:\\n        self.directory: str = directory\\n        self.output_directory: str = output_directory\\n        self.directory_modules: dict[str, list[str]] = {}\\n\\n    def process_files(self) -> VisitorManagerProcessFilesReturn:\\n        \\\"\\\"\\\"\\n        Process the files in the directory and return the module models.\\n\\n        This function iterates through all the Python files in the directory, processes each file,\\n        updates the imports, and builds module models for each file. It returns a tuple of module models\\n        and a dictionary of directory modules.\\n\\n        Returns:\\n            A named tuple (VisitorManagerProcessFilesReturn) containing:\\n            - models_tuple (tuple[ModuleModel, ...]): A tuple of module models.\\n            - directory_modules (dict[str, ModuleModel]): A dictionary of directory modules.\\n\\n        Examples:\\n            >>> visitor_manager = VisitorManager()\\n            >>> result = visitor_manager.process_files()\\n            >>> print(result.models_tuple)\\n            (ModuleModel(file_path='/path/to/file1.py'), ModuleModel(file_path='/path/to/file2.py'))\\n            >>> print(result.directory_modules)\\n            {'/path/to/directory1': ModuleModel(file_path='/path/to/directory1/__init__.py')}\\n        \\\"\\\"\\\"\\n\\n        logging.info(\\\"Processing files\\\")\\n        python_files: list[str] = self._get_python_files()\\n        model_builder_list: list[ModuleModelBuilder] = []\\n        for file_path in python_files:\\n            if model_builder := self._process_file(file_path):\\n                model_builder_list.append((model_builder))\\n\\n        logging.info(\\\"File processing completed\\\")\\n        logging.info(\\\"Updating imports\\\")\\n\\n        # TODO: Test making this a tuple of tuples, see if that solves the double update import issue\\n        model_builder_tuple: tuple[ModuleModelBuilder, ...] = tuple(model_builder_list)\\n\\n        import_and_dependency_updater = ImportAndDependencyUpdater(model_builder_tuple)\\n        import_and_dependency_updater.update_imports()\\n        logging.info(\\\"Updated imports\\\")\\n\\n        module_models_list: list[ModuleModel] = []\\n        for module_model_builder in model_builder_tuple:\\n            module_model: ModuleModel = self._build_module_model(module_model_builder)\\n            module_models_list.append(module_model)\\n\\n        module_models_tuple: tuple[ModuleModel, ...] = tuple(module_models_list)\\n\\n        return VisitorManagerProcessFilesReturn(\\n            models_tuple=module_models_tuple, directory_modules=self.directory_modules\\n        )\\n\\n    def _walk_directories(self) -> list[str]:\\n        \\\"\\\"\\\"Walks the specified directory and returns a list of all files.\\\"\\\"\\\"\\n\\n        all_files: list[str] = []\\n        for file_path in Path(self.directory).rglob(\\\"*\\\"):\\n            if not any(\\n                excluded in file_path.parts for excluded in EXCLUDED_DIRECTORIES\\n            ):\\n                all_files.append(str(file_path))\\n        return all_files\\n\\n    def _filter_python_files(self, files: list[str]) -> list[str]:\\n        \\\"\\\"\\\"Filters a list of files to only include Python files.\\\"\\\"\\\"\\n\\n        return [file for file in files if file.endswith(\\\".py\\\")]\\n\\n    @logging_decorator(message=\\\"Getting Python files\\\")\\n    def _get_python_files(self) -> list[str]:\\n        \\\"\\\"\\\"Gets all Python files in the specified directory.\\\"\\\"\\\"\\n\\n        all_files: list[str] = self._walk_directories()\\n        return self._filter_python_files(all_files)\\n\\n    def _process_file(self, file_path: str) -> ModuleModelBuilder | None:\\n        \\\"\\\"\\\"Processes a single Python file.\\\"\\\"\\\"\\n\\n        file_path_obj = Path(file_path)\\n        root = str(file_path_obj.parent)\\n        self.directory_modules.setdefault(root, []).append(file_path_obj.name)\\n        return self._parse_file(file_path)\\n\\n    @logging_decorator(message=\\\"Processing file\\\")\\n    def _parse_file(self, file_path: str) -> ModuleModelBuilder | None:\\n        \\\"\\\"\\\"Parses a Python file and saves the parsed data as JSON.\\\"\\\"\\\"\\n\\n        parser = PythonParser(file_path)\\n        code: str = parser.open_file()\\n        module_model_builder: ModuleModelBuilder | None = parser.parse(code)\\n\\n        return module_model_builder\\n\\n    def _build_module_model(\\n        self, visitor_stack: ModuleModelBuilder | None\\n    ) -> ModuleModel:\\n        \\\"\\\"\\\"\\n        Builds a module model from the provided module builder.\\n\\n        Args:\\n            visitor_stack (ModuleModelBuilder): The module builder to build the model from.\\n\\n        Returns:\\n            ModuleModel: A structured module model.\\n\\n        Example:\\n            >>> module_model = python_parser.build_module_model(visitor_stack)\\n            # Builds a module model from the provided module builder.\\n        \\\"\\\"\\\"\\n\\n        if not isinstance(visitor_stack, ModuleModelBuilder):\\n            raise TypeError(\\\"Expected the first builder to be a ModuleModelBuilder\\\")\\n\\n        return visitor_stack.build()\\n\\n, \\nfrom logging import Logger\\nfrom openai import OpenAI\\n        \",\"children\":[{\"class_name\":\"GraphDBUpdater\",\"decorators\":null,\"bases\":null,\"docstring\":null,\"keywords\":null,\"id\":\"postcode:updaters:graph_db_updater.py__*__MODULE__*__CLASS-GraphDBUpdater\",\"parent_id\":\"postcode:updaters:graph_db_updater.py__*__MODULE\",\"block_type\":\"CLASS\",\"start_line_num\":22,\"end_line_num\":96,\"code_content\":\"\\n\\nclass GraphDBUpdater:\\n    def __init__(\\n        self,\\n        directory: str,\\n        output_directory: str,\\n        logger: Logger,\\n        arango_connector: ArangoDBConnector = ArangoDBConnector(),\\n    ) -> None:\\n        self.directory: str = directory\\n        self.output_directory: str = output_directory\\n        self.logger: Logger = logger\\n        self.arango_connector: ArangoDBConnector = arango_connector\\n\\n        self.arango_connector.delete_all_collections()\\n        self.arango_connector.ensure_collections()\\n        self.graph_manager = ArangoDBManager(arango_connector)\\n\\n    def update_all(\\n        self,\\n        directory: str,\\n        output_directory: str,\\n        logger: Logger,\\n    ) -> ChromaSetupReturnContext:\\n        logger.info(\\\"Starting the directory parsing.\\\")\\n\\n        visitor_manager = VisitorManager(directory, output_directory)\\n        process_files_return: VisitorManagerProcessFilesReturn = (\\n            visitor_manager.process_files()\\n        )\\n\\n        module_models_tuple: tuple[ModuleModel, ...] = process_files_return.models_tuple\\n        module_ids: list[str] = [model.id for model in module_models_tuple]\\n        directory_modules: dict[str, list[str]] = process_files_return.directory_modules\\n        self.graph_manager.upsert_models(\\n            list(module_models_tuple)\\n        ).process_imports_and_dependencies().get_or_create_graph()\\n        summarization_mapper = SummarizationMapper(\\n            module_ids, module_models_tuple, self.graph_manager\\n        )\\n        client = OpenAI(max_retries=4)\\n        summarizer = OpenAISummarizer(client=client)\\n        summarization_manager = GraphDBSummarizationManager(\\n            module_models_tuple, summarization_mapper, summarizer, self.graph_manager\\n        )\\n        finalized_module_models: list[\\n            ModuleModel\\n        ] | None = summarization_manager.create_summaries_and_return_updated_models()\\n        logger.info(\\\"Summarization complete\\\")\\n\\n        logger.info(\\\"Saving models as JSON\\\")\\n        json_manager = JSONHandler(directory, directory_modules, output_directory)\\n\\n        for module_model in module_models_tuple:\\n            json_manager.save_model_as_json(module_model, module_model.file_path)\\n\\n        json_manager.save_visited_directories()\\n        logger.info(\\\"JSON save complete\\\")\\n\\n        logger.info(\\\"Directory parsing completed.\\\")\\n\\n        # self.graph_manager.upsert_models(\\n        #     list(finalized_module_models)\\n        # ).process_imports_and_dependencies().get_or_create_graph()\\n\\n        if finalized_module_models:\\n            chroma_context: ChromaSetupReturnContext = setup_chroma(\\n                finalized_module_models, logger\\n            )\\n        else:\\n            raise Exception(\\\"No finalized models returned from summarization.\\\")\\n\\n        return chroma_context\\n\",\"important_comments\":null,\"dependencies\":[{\"import_names\":[{\"name\":\"VisitorManager\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"VisitorManagerProcessFilesReturn\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"postcode.python_parser.visitor_manager.visitor_manager\",\"import_module_type\":\"LOCAL\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"VisitorManager\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"VisitorManagerProcessFilesReturn\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"postcode.python_parser.visitor_manager.visitor_manager\",\"import_module_type\":\"LOCAL\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"Logger\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"logging\",\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"OpenAI\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"openai\",\"import_module_type\":\"THIRD_PARTY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"GraphDBSummarizationManager\",\"as_name\":null,\"local_block_id\":\"postcode:ai_services:summarizer:graph_db_summarization_manager.py__*__MODULE__*__CLASS-GraphDBSummarizationManager\"}],\"imported_from\":\"postcode.ai_services.summarizer.graph_db_summarization_manager\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:ai_services:summarizer:graph_db_summarization_manager.py__*__MODULE\"},{\"import_names\":[{\"name\":\"OpenAISummarizer\",\"as_name\":null,\"local_block_id\":\"postcode:ai_services:summarizer:openai_summarizer.py__*__MODULE__*__CLASS-OpenAISummarizer\"}],\"imported_from\":\"postcode.ai_services.summarizer.openai_summarizer\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:ai_services:summarizer:openai_summarizer.py__*__MODULE\"},{\"import_names\":[{\"name\":\"SummarizationMapper\",\"as_name\":null,\"local_block_id\":\"postcode:ai_services:summarizer:summarization_mapper.py__*__MODULE__*__CLASS-SummarizationMapper\"}],\"imported_from\":\"postcode.ai_services.summarizer.summarization_mapper\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:ai_services:summarizer:summarization_mapper.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ArangoDBConnector\",\"as_name\":null,\"local_block_id\":\"postcode:databases:arangodb:arangodb_connector.py__*__MODULE__*__CLASS-ArangoDBConnector\"}],\"imported_from\":\"postcode.databases.arangodb.arangodb_connector\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:databases:arangodb:arangodb_connector.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ArangoDBManager\",\"as_name\":null,\"local_block_id\":\"postcode:databases:arangodb:arangodb_manager.py__*__MODULE__*__CLASS-ArangoDBManager\"}],\"imported_from\":\"postcode.databases.arangodb.arangodb_manager\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:databases:arangodb:arangodb_manager.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ChromaSetupReturnContext\",\"as_name\":null,\"local_block_id\":\"postcode:databases:chroma:setup_chroma.py__*__MODULE__*__CLASS-ChromaSetupReturnContext\"},{\"name\":\"setup_chroma\",\"as_name\":null,\"local_block_id\":\"postcode:databases:chroma:setup_chroma.py__*__MODULE__*__FUNCTION-setup_chroma\"}],\"imported_from\":\"postcode.databases.chroma.setup_chroma\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:databases:chroma:setup_chroma.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ChromaSetupReturnContext\",\"as_name\":null,\"local_block_id\":\"postcode:databases:chroma:setup_chroma.py__*__MODULE__*__CLASS-ChromaSetupReturnContext\"},{\"name\":\"setup_chroma\",\"as_name\":null,\"local_block_id\":\"postcode:databases:chroma:setup_chroma.py__*__MODULE__*__FUNCTION-setup_chroma\"}],\"imported_from\":\"postcode.databases.chroma.setup_chroma\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:databases:chroma:setup_chroma.py__*__MODULE\"},{\"import_names\":[{\"name\":\"JSONHandler\",\"as_name\":null,\"local_block_id\":\"postcode:json_management:json_handler.py__*__MODULE__*__CLASS-JSONHandler\"}],\"imported_from\":\"postcode.json_management.json_handler\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:json_management:json_handler.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"}],\"summary\":null,\"children\":[{\"function_name\":\"__init__\",\"docstring\":null,\"decorators\":null,\"parameters\":null,\"returns\":\"None\",\"is_method\":true,\"is_async\":false,\"id\":\"postcode:updaters:graph_db_updater.py__*__MODULE__*__CLASS-GraphDBUpdater__*__FUNCTION-__init__\",\"parent_id\":\"postcode:updaters:graph_db_updater.py__*__MODULE__*__CLASS-GraphDBUpdater\",\"block_type\":\"FUNCTION\",\"start_line_num\":25,\"end_line_num\":40,\"code_content\":\"def __init__(\\n    self,\\n    directory: str,\\n    output_directory: str,\\n    logger: Logger,\\n    arango_connector: ArangoDBConnector = ArangoDBConnector(),\\n) -> None:\\n    self.directory: str = directory\\n    self.output_directory: str = output_directory\\n    self.logger: Logger = logger\\n    self.arango_connector: ArangoDBConnector = arango_connector\\n\\n    self.arango_connector.delete_all_collections()\\n    self.arango_connector.ensure_collections()\\n    self.graph_manager = ArangoDBManager(arango_connector)\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":null,\"children\":null},{\"function_name\":\"update_all\",\"docstring\":null,\"decorators\":null,\"parameters\":null,\"returns\":\"ChromaSetupReturnContext\",\"is_method\":true,\"is_async\":false,\"id\":\"postcode:updaters:graph_db_updater.py__*__MODULE__*__CLASS-GraphDBUpdater__*__FUNCTION-update_all\",\"parent_id\":\"postcode:updaters:graph_db_updater.py__*__MODULE__*__CLASS-GraphDBUpdater\",\"block_type\":\"FUNCTION\",\"start_line_num\":40,\"end_line_num\":96,\"code_content\":\"\\ndef update_all(\\n    self,\\n    directory: str,\\n    output_directory: str,\\n    logger: Logger,\\n) -> ChromaSetupReturnContext:\\n    logger.info(\\\"Starting the directory parsing.\\\")\\n\\n    visitor_manager = VisitorManager(directory, output_directory)\\n    process_files_return: VisitorManagerProcessFilesReturn = (\\n        visitor_manager.process_files()\\n    )\\n\\n    module_models_tuple: tuple[ModuleModel, ...] = process_files_return.models_tuple\\n    module_ids: list[str] = [model.id for model in module_models_tuple]\\n    directory_modules: dict[str, list[str]] = process_files_return.directory_modules\\n    self.graph_manager.upsert_models(\\n        list(module_models_tuple)\\n    ).process_imports_and_dependencies().get_or_create_graph()\\n    summarization_mapper = SummarizationMapper(\\n        module_ids, module_models_tuple, self.graph_manager\\n    )\\n    client = OpenAI(max_retries=4)\\n    summarizer = OpenAISummarizer(client=client)\\n    summarization_manager = GraphDBSummarizationManager(\\n        module_models_tuple, summarization_mapper, summarizer, self.graph_manager\\n    )\\n    finalized_module_models: list[\\n        ModuleModel\\n    ] | None = summarization_manager.create_summaries_and_return_updated_models()\\n    logger.info(\\\"Summarization complete\\\")\\n\\n    logger.info(\\\"Saving models as JSON\\\")\\n    json_manager = JSONHandler(directory, directory_modules, output_directory)\\n\\n    for module_model in module_models_tuple:\\n        json_manager.save_model_as_json(module_model, module_model.file_path)\\n\\n    json_manager.save_visited_directories()\\n    logger.info(\\\"JSON save complete\\\")\\n\\n    logger.info(\\\"Directory parsing completed.\\\")\\n\\n    # self.graph_manager.upsert_models(\\n    #     list(finalized_module_models)\\n    # ).process_imports_and_dependencies().get_or_create_graph()\\n\\n    if finalized_module_models:\\n        chroma_context: ChromaSetupReturnContext = setup_chroma(\\n            finalized_module_models, logger\\n        )\\n    else:\\n        raise Exception(\\\"No finalized models returned from summarization.\\\")\\n\\n    return chroma_context\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":null,\"children\":null}]}]}", "chroma:document": "\nSummary:\n\n        postcode:updaters:graph_db_updater.py__*__MODULE\n\n        \nChild (postcode:updaters:graph_db_updater.py__*__MODULE__*__CLASS-GraphDBUpdater) code content:\n\n\nclass GraphDBUpdater:\n    def __init__(\n        self,\n        directory: str,\n        output_directory: str,\n        logger: Logger,\n        arango_connector: ArangoDBConnector = ArangoDBConnector(),\n    ) -> None:\n        self.directory: str = directory\n        self.output_directory: str = output_directory\n        self.logger: Logger = logger\n        self.arango_connector: ArangoDBConnector = arango_connector\n\n        self.arango_connector.delete_all_collections()\n        self.arango_connector.ensure_collections()\n        self.graph_manager = ArangoDBManager(arango_connector)\n\n    def update_all(\n        self,\n        directory: str,\n        output_directory: str,\n        logger: Logger,\n    ) -> ChromaSetupReturnContext:\n        logger.info(\"Starting the directory parsing.\")\n\n        visitor_manager = VisitorManager(directory, output_directory)\n        process_files_return: VisitorManagerProcessFilesReturn = (\n            visitor_manager.process_files()\n        )\n\n        module_models_tuple: tuple[ModuleModel, ...] = process_files_return.models_tuple\n        module_ids: list[str] = [model.id for model in module_models_tuple]\n        directory_modules: dict[str, list[str]] = process_files_return.directory_modules\n        self.graph_manager.upsert_models(\n            list(module_models_tuple)\n        ).process_imports_and_dependencies().get_or_create_graph()\n        summarization_mapper = SummarizationMapper(\n            module_ids, module_models_tuple, self.graph_manager\n        )\n        client = OpenAI(max_retries=4)\n        summarizer = OpenAISummarizer(client=client)\n        summarization_manager = GraphDBSummarizationManager(\n            module_models_tuple, summarization_mapper, summarizer, self.graph_manager\n        )\n        finalized_module_models: list[\n            ModuleModel\n        ] | None = summarization_manager.create_summaries_and_return_updated_models()\n        logger.info(\"Summarization complete\")\n\n        logger.info(\"Saving models as JSON\")\n        json_manager = JSONHandler(directory, directory_modules, output_directory)\n\n        for module_model in module_models_tuple:\n            json_manager.save_model_as_json(module_model, module_model.file_path)\n\n        json_manager.save_visited_directories()\n        logger.info(\"JSON save complete\")\n\n        logger.info(\"Directory parsing completed.\")\n\n        # self.graph_manager.upsert_models(\n        #     list(finalized_module_models)\n        # ).process_imports_and_dependencies().get_or_create_graph()\n\n        if finalized_module_models:\n            chroma_context: ChromaSetupReturnContext = setup_chroma(\n                finalized_module_models, logger\n            )\n        else:\n            raise Exception(\"No finalized models returned from summarization.\")\n\n        return chroma_context\n\n, \nImported code block (postcode:ai_services:summarizer:graph_db_summarization_manager.py__*__MODULE) code content:\n# FIXME: This file is not currently being used. It is a work in progress as the summarization mapper isn't getting returning all of the project models.\n\nimport logging\nfrom pprint import pprint\nfrom typing import Union\n\nfrom postcode.ai_services.summarizer.summarization_context import (\n    Summarizer,\n    OpenAIReturnContext,\n)\nfrom postcode.ai_services.summarizer.summarization_mapper import SummarizationMapper\nfrom postcode.databases.arangodb.arangodb_manager import ArangoDBManager\n\n# from postcode.types.postcode import ModelType\n\nfrom postcode.models.models import (\n    ClassModel,\n    DependencyModel,\n    FunctionModel,\n    ImportModel,\n    ModuleModel,\n    StandaloneCodeBlockModel,\n)\n\nModelType = Union[\n    ModuleModel,\n    ClassModel,\n    FunctionModel,\n    StandaloneCodeBlockModel,\n]\n\n\nclass GraphDBSummarizationManager:\n    def __init__(\n        self,\n        module_models_tuple: tuple[ModuleModel, ...],\n        summarization_mapper: SummarizationMapper,\n        summarizer: Summarizer,\n        graph_manager: ArangoDBManager,\n    ) -> None:\n        self.module_models_tuple: tuple[ModuleModel, ...] = module_models_tuple\n        self.summarization_mapper: SummarizationMapper = summarization_mapper\n        self.summarizer: Summarizer = summarizer\n        self.summarized_code_block_ids: set[str] = set()\n        self.prompt_tokens: int = 0\n        self.completion_tokens: int = 0\n        self.graph_manager: ArangoDBManager = graph_manager\n\n    @property\n    def total_cost(self) -> float:\n        \"\"\"Provides the total cost of the summarization process.\"\"\"\n        prompt_cost: int = self.prompt_tokens * 1  # Costs 1 cent per 1,000 tokens\n        completion_cost: int = (\n            self.completion_tokens * 3\n        )  # Costs 3 cents per 1,000 tokens\n        return (prompt_cost + completion_cost) / 100_000  # Convert to dollars\n\n    def create_summaries_and_return_updated_models(self) -> list[ModuleModel] | None:\n        summarization_map: list[\n            ModelType\n        ] = self.summarization_mapper.create_summarization_map()\n        models_to_summarize_count: int = len(summarization_map)\n        models_summarized_count: int = 0\n\n        for model in summarization_map:\n            children_summaries: str | None = None\n            dependency_summaries: str | None = None\n            import_details: str | None = None\n\n            if model.children:\n                children_summaries: str | None = self._stringify_children_summaries(\n                    self._get_child_summaries(model)\n                )\n            if isinstance(model, ModuleModel):\n                if model.imports:\n                    dependency_summaries = self._get_dependencies_summaries(model)\n                    import_details = \"\"\n                    for _import in model.imports:\n                        if import_summary := self._get_import_details(_import):\n                            import_details += f\"\\n{import_summary}\"\n            else:\n                if model.dependencies:\n                    dependency_summaries = self._get_dependencies_summaries(model)\n                    import_details = \"\"\n                    for dependency in model.dependencies:\n                        if isinstance(dependency, DependencyModel):\n                            continue\n                        if import_summary := self._get_import_details(dependency):\n                            import_details += f\"\\n{import_summary}\"\n\n            models_summarized_count += 1\n            logging.info(\n                f\"Summarizing model {models_summarized_count} out of {models_to_summarize_count}; {model.id}.\"\n            )\n\n            summary_return_context: OpenAIReturnContext | None = (\n                self.summarizer.test_summarize_code(\n                    model.code_content,\n                    model_id=model.id,\n                    children_summaries=children_summaries,\n                    dependency_summaries=dependency_summaries,\n                    import_details=import_details,\n                )\n            )\n            if summary_return_context:\n                if summary_return_context.summary:\n                    self.graph_manager.update_vertex_by_id(\n                        model.id, summary_return_context.summary\n                    )\n                self.prompt_tokens += summary_return_context.prompt_tokens\n                self.completion_tokens += summary_return_context.completion_tokens\n\n                # for module_model in self.module_models_tuple:\n                #     if isinstance(model, ModuleModel):\n                #         if module_model.id == model.id:\n                #             module_model.summary = model.summary\n                #             break\n                #         else:\n                #             continue\n                #     else:\n                #         module_id_for_model: str = model.id.split(\"MODULE\")[0]\n                #         if (\n                #             module_model.children\n                #             and module_id_for_model in module_model.id\n                #         ):\n                #             for child_model in module_model.children:\n                #                 if child_model.id == model.id:\n                #                     # child_model.summary = model.summary\n                #                     break\n                #         else:\n                #             continue\n\n        pprint([model.id for model in summarization_map[::-1]])\n        print(len(summarization_map))\n\n        return self.graph_manager.get_all_modules() if self.graph_manager else None\n\n    def _get_child_summaries(self, model: ModelType) -> list[str]:\n        \"\"\"Gathers summaries of child models.\"\"\"\n        child_summary_list: list[str] = []\n        if model.children:\n            for child in model.children:\n                if child.summary:\n                    child_summary: str = child.summary\n                else:\n                    child_summary = (\n                        f\"Child ({child.id}) code content:\\n{child.code_content}\\n\"\n                    )\n                child_summary_list.append(child_summary)\n        return child_summary_list\n\n    def _stringify_children_summaries(self, children_summary_list: list[str]) -> str:\n        \"\"\"Converts all of the child summaries to a single string to be used in the prompt.\"\"\"\n\n        children_summaries: str = \"\"\n        for child_summary in children_summary_list:\n            children_summaries += f\"\\n{child_summary}\"\n        return children_summaries\n\n    def _get_dependencies_summaries(self, model: ModelType) -> str | None:\n        dependency_list: list[ImportModel | DependencyModel] | list[ImportModel] = []\n        dependency_summary_list: list[str] = []\n\n        if isinstance(model, ModuleModel):\n            if not model.imports:\n                return None\n\n            dependency_list = model.imports\n        else:\n            if not model.dependencies:\n                return None\n\n            dependency_list = model.dependencies\n        for dependency in dependency_list:\n            if isinstance(dependency, DependencyModel) and dependency.code_block_id:\n                if module_local_dependency_summary := self._get_local_dependency_summary(\n                    dependency, model\n                ):\n                    dependency_summary_list.append(module_local_dependency_summary)\n\n            elif isinstance(dependency, ImportModel):\n                if dependency.import_module_type == \"LOCAL\":\n                    if not dependency.import_names:\n                        if module_import_dependency := self._get_local_import_summary(\n                            dependency\n                        ):\n                            dependency_summary_list.append(module_import_dependency)\n                    else:\n                        if import_from_dependency := self._get_local_import_from_summary(\n                            dependency\n                        ):\n                            dependency_summary_list.append(import_from_dependency)\n\n        dependency_summaries = self._stringify_dependencies_summaries(\n            dependency_summary_list\n        )\n\n        return dependency_summaries\n\n    # def _get_import_details_for_dependencies(\n    #     self, dependencies: list[ImportModel | DependencyModel]\n    # ) -> str | None:\n    #     import_details: str | None = None\n    #     for dependency in dependencies:\n    #         if isinstance(dependency, ImportModel):\n    #             if dependency.import_module_type == \"LOCAL\":\n    #                 continue\n    #             else:\n    #                 import_detail: str | None = self._get_import_details(dependency)\n    #                 if not import_detail:\n    #                     continue\n    #                 if not import_details:\n    #                     import_details = \"\"\n    #                 import_details += f\"\\n{import_detail}\"\n    #     return import_details\n\n    def _get_local_dependency_summary(\n        self,\n        dependency: DependencyModel,\n        model: ModelType,\n    ) -> str | None:\n        \"\"\"Gets a summary for a dependency local to the module.\"\"\"\n        if not model.children:\n            return None\n\n        for child_model in model.children:\n            if child_model.id == dependency.code_block_id:\n                child_summary: str | None = None\n\n                if child_model.summary:\n                    child_summary = child_model.summary\n                else:\n                    child_summary = f\"Dependency ({dependency.code_block_id}) code content:\\n{child_model.code_content}\\n\"\n\n                return child_summary\n        return None\n\n    def _stringify_dependencies_summaries(\n        self, dependencies_summary_list: list[str] | None\n    ) -> str | None:\n        \"\"\"Converts all of the dependency summaries to a single string to be used in the prompt.\"\"\"\n        if not dependencies_summary_list:\n            return None\n\n        dependency_summaries: str = \"\"\n        for dependency_summary in dependencies_summary_list:\n            dependency_summaries += f\"\\n{dependency_summary}\"\n        return dependency_summaries\n\n    def _get_local_import_summary(self, dependency: ImportModel) -> str | None:\n        for module_model in self.module_models_tuple:\n            if module_model.id == dependency.local_module_id:\n                import_summary: str | None = None\n                if module_model.summary:\n                    import_summary = module_model.summary\n                else:\n                    import_summary = f\"Imported module ({dependency.local_module_id}) code content:\\n{module_model.code_content}\\n\"\n                return import_summary\n        return None\n\n    def _get_local_import_from_summary(self, dependency: ImportModel) -> str | None:\n        for import_name in dependency.import_names:\n            for module_model in self.module_models_tuple:\n                if module_model.id == dependency.local_module_id:\n                    if module_model.children:\n                        for child_model in module_model.children:\n                            if (\n                                child_model.id == import_name.local_block_id\n                                and child_model.id\n                            ):\n                                import_summary: str | None = None\n                                if child_model.summary:\n                                    import_summary = child_model.summary\n                                else:\n                                    import_summary = f\"Imported code block ({dependency.local_module_id}) code content:\\n{module_model.code_content}\\n\"\n                                return import_summary\n        return None\n\n    def _get_import_details(self, import_model: ImportModel) -> str | None:\n        \"\"\"Retrieves details of import statements to be used in the prompt.\"\"\"\n        if import_model.import_module_type == \"LOCAL\" or not import_model.import_names:\n            return None\n\n        import_names_list: list[str] = []\n        for import_name in import_model.import_names:\n            if import_name.as_name:\n                import_names_list.append(f\"{import_name.name} as {import_name.as_name}\")\n            else:\n                import_names_list.append(f\"{import_name.name}\")\n\n        if import_model.imported_from:\n            import_details: str = f\"from {import_model.imported_from} import {', '.join(import_names_list)}\"\n        else:\n            import_details = f\"import {', '.join(import_names_list)}\"\n\n        return import_details\n\n\nImported code block (postcode:ai_services:summarizer:openai_summarizer.py__*__MODULE) code content:\nimport logging\n\nfrom openai import OpenAI\nfrom openai.types.chat.chat_completion_system_message_param import (\n    ChatCompletionSystemMessageParam,\n)\nfrom openai.types.chat.chat_completion_user_message_param import (\n    ChatCompletionUserMessageParam,\n)\nfrom openai.types.chat.chat_completion_message_param import ChatCompletionMessageParam\nfrom openai.types.chat.chat_completion import ChatCompletion\n\nfrom postcode.ai_services.summarizer.prompts.prompt_creator import PromptCreator\nfrom postcode.ai_services.summarizer.summarization_context import (\n    OpenAIReturnContext,\n    SummaryCompletionConfigs,\n)\n\n# from postcode.ai_services.summarizer.temp import code_example\n\n\nclass OpenAISummarizer:\n    \"\"\"\n    A class for summarizing code snippets using the OpenAI API.\n\n    Args:\n        - client (OpenAI): The OpenAI client used for making API requests.\n\n    Attributes:\n        - client (OpenAI): The OpenAI client used for making API requests.\n        - prompt_list (list[str]): A list of summary prompts.\n        - default_prompt (str): The default summary prompt.\n\n    Methods:\n        - `summarize_code`: Summarizes the provided code snippet using the OpenAI API.\n\n    Examples:\n        ```Python\n        client = OpenAI()\n\n        # Create a summarizer instance with the OpenAI client\n        summarizer = Summarizer(client=client)\n        code_example = \"print('Hello, world')\"\n\n        # Summarize the code snippet\n        summary = summarizer.summarize_code(code_example)\n        print(summary)\n        ```\n    \"\"\"\n\n    def __init__(\n        self,\n        client: OpenAI,\n        # *, summary_prompt_list: list[str] = summary_prompt_list\n    ) -> None:\n        self.client: OpenAI = client\n        # self.prompt_list: list[str] = summary_prompt_list\n        # self.default_prompt: str = self.prompt_list[0]\n\n    def _create_system_message(self, content: str) -> ChatCompletionSystemMessageParam:\n        \"\"\"Creates a system message for chat completion using OpenAi's ChatCompletionSystemMessageParam class.\"\"\"\n        return ChatCompletionSystemMessageParam(content=content, role=\"system\")\n\n    def _create_user_message(self, content: str) -> ChatCompletionUserMessageParam:\n        \"\"\"Creates a user message for chat completion using OpenAi's ChatCompletionUserMessageParam class.\"\"\"\n        return ChatCompletionUserMessageParam(content=content, role=\"user\")\n\n    def _create_messages_list(\n        self,\n        system_message: str,\n        user_message: str,\n    ) -> list[ChatCompletionMessageParam]:\n        \"\"\"\n        Creates a list of messages for chat completion, including both system and user messages.\n\n        Args:\n            - system_message (str): The system message content.\n            - user_message (str): The user message content.\n\n        Returns:\n            - list[ChatCompletionMessageParam]: A list containing the system and user messages as OpenAI's\n                ChatCompletionMessageParam classes.\n        \"\"\"\n\n        return [\n            self._create_system_message(system_message),\n            self._create_user_message(user_message),\n        ]\n\n    def _create_prompt(\n        self,\n        code: str,\n        children_summaries: str | None,\n        dependency_summaries: str | None,\n        import_details: str | None,\n    ) -> str:\n        prompt_creator: PromptCreator = PromptCreator()\n        prompt: str | None = prompt_creator.create_prompt(\n            code,\n            children_summaries,\n            dependency_summaries,\n            import_details,\n        )\n\n        if prompt:\n            return prompt\n        else:\n            raise Exception(\"Prompt creation failed.\")\n\n    def _get_summary(\n        self,\n        messages: list[ChatCompletionMessageParam],\n        *,\n        configs: SummaryCompletionConfigs,\n    ) -> OpenAIReturnContext | None:\n        \"\"\"\n        Retrieves the summary from the OpenAI API based on the provided messages and configuration settings.\n\n        Args:\n            - messages (list[ChatCompletionMessageParam]): A list of messages for chat completion.\n            - configs (SummaryCompletionConfigs): Configuration settings for the summarization completion.\n\n        Returns:\n            str | None: The summary generated by the OpenAI API, or None if no summary is found.\n        \"\"\"\n\n        try:\n            response: ChatCompletion = self.client.chat.completions.create(\n                messages=messages,\n                model=configs.model,\n                max_tokens=configs.max_tokens,\n                temperature=configs.temperature,\n            )\n            prompt_tokens: int = 0\n            completion_tokens: int = 0\n            summary: str | None = response.choices[0].message.content\n            if response.usage:\n                prompt_tokens = response.usage.prompt_tokens\n                completion_tokens = response.usage.completion_tokens\n\n            return OpenAIReturnContext(\n                prompt_tokens=prompt_tokens,\n                completion_tokens=completion_tokens,\n                summary=summary,\n            )\n\n        except Exception as e:\n            logging.error(e)\n            return None\n\n    def summarize_code(\n        self,\n        code: str,\n        *,\n        model_id: str,\n        children_summaries: str | None,\n        dependency_summaries: str | None,\n        import_details: str | None,\n        configs: SummaryCompletionConfigs = SummaryCompletionConfigs(),\n    ) -> OpenAIReturnContext | None:\n        \"\"\"\n        Summarizes the provided code snippet using the OpenAI API.\n\n        Args:\n            - code (str): The code snippet to summarize.\n            - configs (SummaryCompletionConfigs, optional): Configuration settings for the summarization.\n                Defaults to SummaryCompletionConfigs().\n\n        Returns:\n            - str: The summary of the provided code snippet.\n\n        Examples:\n            ```Python\n            client = OpenAI()\n\n            # Create a summarizer instance with the OpenAI client\n            summarizer = Summarizer(client=client)\n            code_example = \"print('Hello, world')\"\n\n            # Summarize the code snippet\n            summary = summarizer.summarize_code(code_example)\n            print(summary)\n            ```\n        \"\"\"\n\n        logging.info(f\"Summarizing code for model: {model_id}\")\n        prompt: str = self._create_prompt(\n            code, children_summaries, dependency_summaries, import_details\n        )\n        messages: list[ChatCompletionMessageParam] = self._create_messages_list(\n            system_message=configs.system_message, user_message=prompt\n        )\n\n        if summary_return_context := self._get_summary(messages, configs=configs):\n            if summary_return_context:\n                if summary_return_context.summary:\n                    summary_return_context.summary = (\n                        summary_return_context.summary.split(\"FINAL SUMMARY:\")[-1]\n                    )\n                    return summary_return_context\n        return None\n\n    def test_summarize_code(\n        self,\n        code: str,\n        *,\n        model_id: str,\n        children_summaries: str | None,\n        dependency_summaries: str | None,\n        import_details: str | None,\n        configs: SummaryCompletionConfigs = SummaryCompletionConfigs(),\n    ) -> OpenAIReturnContext | None:\n        \"\"\"\n        Summarizes the provided code snippet using the OpenAI API.\n\n        Args:\n            - code (str): The code snippet to summarize.\n            - configs (SummaryCompletionConfigs, optional): Configuration settings for the summarization.\n                Defaults to SummaryCompletionConfigs().\n\n        Returns:\n            - str: The summary of the provided code snippet.\n        \"\"\"\n\n        summary = f\"\"\"\\nSummary:\\n\n        {model_id}\\n\n        {children_summaries}, {dependency_summaries}, {import_details}\n        \"\"\"\n        summary_context = OpenAIReturnContext(\n            summary=summary,\n            prompt_tokens=1,\n            completion_tokens=1,\n        )\n\n        return summary_context\n\n\n# if __name__ == \"__main__\":\n#     client = OpenAI()\n#     summarizer = OpenAISummarizer(client=client)\n#     children_summaries = \"\"\n#     dependency_summaries = \"\"\n#     summary = summarizer.summarize_code(\n#         code_example,\n#         model_id=\"test\",\n#         children_summaries=children_summaries,\n#         dependency_summaries=dependency_summaries,\n#         import_details=None,\n#     )\n#     print(summary)\n\n\nImported code block (postcode:ai_services:summarizer:summarization_mapper.py__*__MODULE) code content:\nimport logging\nfrom pprint import pprint\nfrom typing import Union\nfrom postcode.databases.arangodb.arangodb_manager import ArangoDBManager\nfrom postcode.models.models import (\n    ClassModel,\n    FunctionModel,\n    ModuleModel,\n    StandaloneCodeBlockModel,\n)\n\n# from postcode.types.postcode import ModelType\n\nModelType = Union[\n    ModuleModel,\n    ClassModel,\n    FunctionModel,\n    StandaloneCodeBlockModel,\n]\n\n\nclass SummarizationMapper:\n    def __init__(\n        self,\n        module_ids_to_update: list[str],\n        module_models: tuple[ModuleModel, ...],\n        arangodb_manager: ArangoDBManager,\n    ) -> None:\n        self.module_ids_to_update: list[str] = module_ids_to_update\n        self.module_models: tuple[ModuleModel, ...] = module_models\n        self.arangodb_manager: ArangoDBManager = arangodb_manager\n        self.models_to_update: list[ModelType] = []\n        self.model_visited_in_db: set[str] = set()\n        self.summarization_map: list[ModelType] = []\n        self.temp_map: list[ModelType] = []\n\n    def _set_child_models_to_update(self, model: ModelType) -> None:\n        if model.children:\n            for child in model.children:\n                # logging.info(f\"Setting child model to update: {child.id}\")\n                self._set_child_models_to_update(child)\n                child.summary = None\n                self.models_to_update.append(child)\n            self.models_to_update.append(model)\n\n    def _set_models_to_update(self) -> None:\n        for model in self.module_models:\n            if model.id in self.module_ids_to_update:\n                if model.children:\n                    for child in model.children:\n                        self._set_child_models_to_update(child)\n\n                model.summary = None\n                self.models_to_update.append(model)\n\n    def _set_inbound_models_in_summarization_map(self, model_id: str) -> None:\n        if model_id in self.model_visited_in_db:\n            return\n        self.model_visited_in_db.add(model_id)\n        if inbound_models := self.arangodb_manager.get_inbound_models(model_id):\n            for model in inbound_models:\n                # logging.info(f\"Setting inbound models in summarization map: {model.id}\")\n                self.model_visited_in_db.add(model_id)\n                self._set_inbound_models_in_summarization_map(model.id)\n\n                self.temp_map.append(model)\n\n    def _set_outbound_models_in_summarization_map(self, model_id: str) -> None:\n        if model_id in self.model_visited_in_db:\n            return\n\n        if outbound_models := self.arangodb_manager.get_outbound_models(model_id):\n            for model in outbound_models[::-1]:\n                # logging.info(\n                #     f\"Setting outbound models in summarization map: {model.id}\"\n                # )\n                self.model_visited_in_db.add(model_id)\n                # self._set_outbound_models_in_summarization_map(model.id)``\n\n                if model.id in self.models_to_update:\n                    model.summary = None\n                self.temp_map.append(model)\n\n    def create_summarization_map(self) -> list[ModelType]:\n        self._set_models_to_update()\n        logging.info(\"Set models to update\")\n\n        # pprint([model.id for model in self.models_to_update])\n\n        for model in self.models_to_update:\n            # self.model_visited_in_db = set()\n            # logging.info(f\"Setting inbound models in summarization map: {model.id}\")\n            self._set_inbound_models_in_summarization_map(model.id)\n            self.temp_map.append(model)\n\n            self.model_visited_in_db.remove(model.id)\n            # logging.info(f\"Setting outbound models in summarization map: {model.id}\")\n            # self._set_outbound_models_in_summarization_map(model.id)\n            self.summarization_map.extend(self.temp_map)\n            self.temp_map = []\n\n        for model in self.models_to_update:\n            self.model_visited_in_db = set()\n            # logging.info(f\"Setting outbound models in summarization map: {model.id}\")\n            self._set_outbound_models_in_summarization_map(model.id)\n            self.summarization_map.extend(self.temp_map)\n            self.temp_map = []\n\n        logging.info(\"Created summarization map\")\n        summary_ids: set[str] = set()\n        summary_map: list[ModelType] = []\n        for model in self.summarization_map[::-1]:\n            if model.id not in summary_ids:\n                summary_map.append(model)\n                summary_ids.add(model.id)\n\n        # return summary_map[::-1]\n        pprint([model.id for model in summary_map[::-1]])\n        return summary_map[::-1]\n\n    # def old_create_summarization_map(self) -> list[list[ModelType]]:\n    #     for module_id in self.module_ids_to_update:\n    #         models_to_update: list[ModelType] = []\n\n    #         upstream_models: list[\n    #             ModelType\n    #         ] | None = self.arangodb_manager.get_all_upstream_vertices(module_id)\n    #         downstream_models: list[\n    #             ModelType\n    #         ] | None = self.arangodb_manager.get_all_downstream_vertices(module_id)\n\n    #         ids_from_db: list[str] = []\n    #         if upstream_models:\n    #             upstream_ids_to_update: list[str] = [\n    #                 model.id for model in upstream_models\n    #             ]\n    #             ids_from_db.extend(upstream_ids_to_update)\n\n    #         ids_from_db.append(module_id)\n\n    #         if downstream_models:\n    #             downstream_ids_to_update: list[str] = [\n    #                 model.id for model in downstream_models\n    #             ]\n    #             ids_from_db.extend(downstream_ids_to_update)\n\n    #         for id in ids_from_db:\n    #             for model in self.module_models:\n    #                 if model.id == id:\n    #                     models_to_update.append(model)\n    #                 elif model.children:\n    #                     for child in model.children:\n    #                         if child.id == id:\n    #                             models_to_update.append(child)\n\n    #         self.summarization_map.append(models_to_update)\n\n    #     return self.summarization_map\n\n\nImported code block (postcode:databases:arangodb:arangodb_connector.py__*__MODULE) code content:\nimport logging\nfrom typing import Any\nfrom arango.client import ArangoClient\nfrom arango.database import StandardDatabase\nfrom arango.result import Result\nfrom arango.typings import Jsons, Json\n\nimport postcode.databases.arangodb.helper_functions as helper_functions\n\n# from postcode.models import (\n#     ModuleModel,\n#     ClassModel,\n#     FunctionModel,\n#     StandaloneCodeBlockModel,\n# )\n\n\n# test = ArangoClient(hosts=\"http://localhost:8529\")\nclass ArangoDBConnector:\n    def __init__(\n        self,\n        url: str = \"http://localhost:8529\",\n        username: str = \"root\",\n        password: str = \"openSesame\",\n        db_name: str = \"postcode\",\n    ) -> None:\n        self.client = ArangoClient(hosts=url)\n        self.username: str = username\n        self.password: str = password\n        self.db_name: str = db_name\n        self.db: StandardDatabase = self._ensure_database()\n\n    def _ensure_database(self) -> StandardDatabase:\n        sys_db: StandardDatabase = self.client.db(\n            \"_system\", username=self.username, password=self.password\n        )\n        if not sys_db.has_database(self.db_name):\n            sys_db.create_database(self.db_name)\n        return self.client.db(\n            self.db_name, username=self.username, password=self.password\n        )\n\n    # def _ensure_vertex_collections(self, vertex_collections: list[str]) -> None:\n    #     for collection in vertex_collections:\n    #         if not self.db.has_collection(collection):\n    #             self.db.create_collection(collection)\n\n    def _get_current_schema(self, collection_name: str) -> dict:\n        collection = self.db.collection(collection_name)\n        try:\n            properties: Result[Json] = collection.properties()\n            return properties.get(\"schema\", {})  # type: ignore # FIXME: Fix type error\n        except Exception as e:\n            logging.error(f\"Error retrieving current schema for {collection_name}: {e}\")\n            return {}\n\n    def ensure_collection(\n        self, collection_name: str, schema: dict[str, Any] | None = None\n    ) -> None:\n        if not self.db.has_collection(collection_name) and not schema:\n            self.db.create_collection(collection_name)\n            logging.info(f\"Created collection: {collection_name}\")\n        # else:\n        #     current_schema = self._get_current_schema(collection_name)\n        #     self.db.collection(collection_name)\n        # if current_schema != schema:\n        #     collection = self.db.collection(collection_name)\n        #     try:\n        #         collection.configure(schema=schema)\n        #         logging.info(f\"Updated schema for collection: {collection_name}\")\n        #     except Exception as e:\n        #         logging.error(f\"Error updating schema for {collection_name}: {e}\")\n\n    def ensure_edge_collection(self, collection_name: str) -> None:\n        if not self.db.has_collection(collection_name):\n            self.db.create_collection(collection_name, edge=True)\n            logging.info(f\"Created edge collection: {collection_name}\")\n\n    def delete_all_collections(self) -> None:\n        collections: Result[Jsons] = self.db.collections()\n\n        for collection in collections:  # type: ignore # FIXME: Fix type error\n            if not collection[\"name\"].startswith(\"_\"):  # Skip system collections\n                self.db.delete_collection(collection[\"name\"])\n                logging.info(f\"Deleted collection: {collection['name']}\")\n\n    def ensure_collections(self) -> None:\n        # model_schemas: dict[str, dict[str, Any]] = self._get_model_schemas()\n        required_collections: list[\n            str\n        ] = helper_functions.pluralized_and_lowered_block_types()\n\n        for collection_name in required_collections:\n            # schema: dict[str, Any] = model_schemas[collection_name]\n            # self.ensure_collection(collection_name, schema)\n            self.ensure_collection(collection_name)\n\n        self.ensure_edge_collection(\"code_edges\")\n\n    # def _get_model_schemas(self) -> dict[str, dict[str, Any]]:\n    #     return {\n    #         \"modules\": ModuleModel.model_json_schema(),\n    #         \"classes\": ClassModel.model_json_schema(),\n    #         \"functions\": FunctionModel.model_json_schema(),\n    #         \"standalone_blocks\": StandaloneCodeBlockModel.model_json_schema(),\n    #     }\n\n\nImported code block (postcode:databases:arangodb:arangodb_manager.py__*__MODULE) code content:\nimport logging\nfrom typing import Any, Callable, Union\n\nfrom arango.result import Result\nfrom arango.cursor import Cursor\nfrom arango.graph import Graph\nfrom arango.collection import StandardCollection\nfrom arango.typings import Json\n\nfrom postcode.databases.arangodb.arangodb_connector import ArangoDBConnector\n\n# from postcode.types.postcode import ModelType\nfrom postcode.models.models import (\n    ClassModel,\n    FunctionModel,\n    ModuleModel,\n    StandaloneCodeBlockModel,\n)\nimport postcode.databases.arangodb.helper_functions as helper_functions\n\nModelType = Union[\n    ModuleModel,\n    ClassModel,\n    FunctionModel,\n    StandaloneCodeBlockModel,\n]\n\n# NOTE: Remember, when adding logic to connect dependencies, the `from` the external dependency `to` the internal definition using it\n\n\nclass ArangoDBManager:\n    def __init__(\n        self,\n        db_connector: ArangoDBConnector,\n        default_graph_name: str = \"codebase_graph\",\n    ) -> None:\n        self.db_connector: ArangoDBConnector = db_connector\n\n        self.processed_id_set = set()\n        self.default_graph_name: str = default_graph_name\n\n    def upsert_models(self, module_models: list[ModuleModel]) -> \"ArangoDBManager\":\n        for model in module_models:\n            self._upsert_model(model)\n        return self\n\n    def _upsert_model(self, module_model: ModuleModel) -> None:\n        self._upsert_vertex(module_model, \"modules\")\n        self._process_children(module_model)\n\n    def _process_children(self, parent_model: ModelType) -> None:\n        if not parent_model.children:\n            return None\n\n        for child in parent_model.children:\n            # if child.id in self.processed_id_set:\n            #     continue\n\n            self.processed_id_set.add(child.id)\n            self._upsert_vertex(\n                child, helper_functions.pluralize_block_type(child.block_type)\n            )\n\n            if child.children:\n                self._process_children(child)\n\n    def _upsert_vertex(self, model: ModelType, collection_name: str) -> None:\n        model_data: dict[str, Any] = model.model_dump()\n        model_data[\"_key\"] = model.id\n\n        try:\n            self.db_connector.ensure_collection(\n                collection_name, model.model_json_schema()\n            )\n            query: str = f\"\"\"\n            UPSERT {{_key: @key}}\n            INSERT @doc\n            UPDATE @doc\n            IN {collection_name}\n            \"\"\"\n            bind_vars: dict[str, Any] = {\"key\": model.id, \"doc\": model_data}\n            self.db_connector.db.aql.execute(query, bind_vars=bind_vars)\n\n            if not isinstance(model, ModuleModel) and model.parent_id:\n                parent_type: str = self._get_collection_from_id(model.parent_id)\n                self._upsert_edge(\n                    model.id, model.parent_id, collection_name, parent_type\n                )\n        except Exception as e:\n            logging.error(f\"Error upserting {collection_name} vertex (ArangoDB): {e}\")\n\n    def _upsert_edge(\n        self, from_key: str, to_key: str, source_type: str, target_type: str\n    ) -> None:\n        source_string: str = f\"{source_type}/{from_key}\"\n        target_string: str = f\"{target_type}/{to_key}\"\n\n        edge_data: dict[str, str] = {\n            \"_from\": source_string,\n            \"_to\": target_string,\n            \"source_type\": source_type,\n            \"target_type\": target_type,\n        }\n\n        try:\n            self.db_connector.ensure_edge_collection(\"code_edges\")\n            query = f\"\"\"\n            UPSERT {{_from: @from, _to: @to}}\n            INSERT @doc\n            UPDATE @doc\n            IN code_edges\n            \"\"\"\n            bind_vars = {\n                \"from\": edge_data[\"_from\"],\n                \"to\": edge_data[\"_to\"],\n                \"doc\": edge_data,\n            }\n            self.db_connector.db.aql.execute(query, bind_vars=bind_vars)\n        except Exception as e:\n            logging.error(f\"Error upserting edge (ArangoDB): {e}\")\n\n    def _get_collection_from_id(self, block_id: str) -> str:\n        block_id_parts: list[str] = block_id.split(\"__*__\")\n        block_type_part: str = block_id_parts[-1]\n\n        block_type_functions: dict[str, Callable[..., str]] = {\n            \"MODULE\": lambda: \"modules\",\n            \"CLASS\": lambda: \"classes\",\n            \"FUNCTION\": lambda: \"functions\",\n            \"STANDALONE_BLOCK\": lambda: \"standalone_blocks\",\n        }\n\n        for key, func in block_type_functions.items():\n            if block_type_part.startswith(key):\n                return func()\n\n        return \"unknown\"\n\n    def process_imports_and_dependencies(self) -> \"ArangoDBManager\":\n        for vertex_collection in helper_functions.pluralized_and_lowered_block_types():\n            cursor: Result[Cursor] = self.db_connector.db.collection(\n                vertex_collection\n            ).all()\n            if isinstance(cursor, Cursor):\n                for vertex in cursor:\n                    vertex_key = vertex[\"_key\"]\n                    if vertex_collection == \"modules\":\n                        self._create_edges_for_imports(\n                            vertex_key, vertex.get(\"imports\", [])\n                        )\n                    else:\n                        self._create_edges_for_dependencies(\n                            vertex_key, vertex.get(\"dependencies\", [])\n                        )\n            else:\n                logging.error(\n                    f\"Error getting cursor for vertex collection: {vertex_collection}\"\n                )\n        return self\n\n    def _create_edges_for_imports(\n        self, module_key: str, imports: list[dict[str, Any]]\n    ) -> None:\n        if not imports:\n            # logging.debug(f\"No imports found for module {module_key}\")\n            return\n\n        # logging.info(f\"Processing imports for module {module_key}\")\n\n        for _import in imports:\n            import_names: list[dict[str, str]] = _import.get(\"import_names\", [])\n            if not import_names:\n                # logging.debug(f\"No import names found in import {_import}\")\n                continue\n\n            for import_name in import_names:\n                local_block_id: str | None = import_name.get(\"local_block_id\")\n\n                if local_block_id:\n                    target_type = self._get_collection_from_id(local_block_id)\n                    try:\n                        self._upsert_edge(\n                            local_block_id, module_key, target_type, \"modules\"\n                        )\n\n                        # logging.info(\n                        #     f\"Upserted edge for import {module_key} to {local_block_id}\"\n                        # )\n                    except Exception as e:\n                        logging.error(\n                            f\"Error creating edge for import {module_key} to {local_block_id}: {e}\"\n                        )\n                else:\n                    # logging.warning(\n                    #     f\"Skipped import {import_name} in module {module_key}\"\n                    # )\n                    ...\n\n    def _create_edges_for_dependencies(\n        self, block_key: str, dependencies: list[dict[str, Any]]\n    ) -> None:\n        if not dependencies:\n            return\n\n        for dependency in dependencies:\n            code_block_id: str | None = dependency.get(\"code_block_id\")\n            if code_block_id:\n                source_type: str = self._get_collection_from_id(code_block_id)\n                target_type: str = self._get_collection_from_id(block_key)\n                try:\n                    self._upsert_edge(\n                        code_block_id, block_key, source_type, target_type\n                    )\n                    # logging.info(\n                    #     f\"Upserted edge for dependency {block_key} to {code_block_id}\"\n                    # )\n                except Exception as e:\n                    logging.error(\n                        f\"Error creating edge for dependency {block_key} to {code_block_id}: {e}\"\n                    )\n\n    def delete_vertex_by_id(\n        self, vertex_key: str, graph_name: str | None = None\n    ) -> None:\n        collection_name: str = self._get_collection_from_id(vertex_key)\n        if collection_name == \"unknown\":\n            logging.error(f\"Unknown vertex type for key: {vertex_key}\")\n            return None\n\n        if not graph_name:\n            graph_name = self.default_graph_name\n\n        try:\n            vertex_coll = self.db_connector.db.graph(graph_name).vertex_collection(\n                collection_name\n            )\n\n            vertex_coll.delete(vertex_key)\n\n            # logging.info(\n            #     f\"Vertex '{vertex_key}' from collection '{collection_name}' was successfully deleted.\"\n            # )\n\n        except Exception as e:\n            logging.error(\n                f\"Error deleting vertex '{vertex_key}' from collection '{collection_name}': {e}\"\n            )\n\n    def get_graph(self, graph_name: str | None = None) -> Graph | None:\n        if not graph_name:\n            graph_name = self.default_graph_name\n        try:\n            return self.db_connector.db.graph(self.default_graph_name)\n        except Exception as e:\n            logging.error(f\"Error getting graph '{self.default_graph_name}': {e}\")\n            return None\n\n    def get_or_create_graph(self, graph_name: str | None = None) -> Result[Graph]:\n        if not graph_name:\n            graph_name = self.default_graph_name\n\n        try:\n            if not self.db_connector.db.has_graph(graph_name):\n                edge_definitions: list[dict[str, str | list[str]]] = [\n                    {\n                        \"edge_collection\": \"code_edges\",\n                        \"from_vertex_collections\": helper_functions.pluralized_and_lowered_block_types(),\n                        \"to_vertex_collections\": helper_functions.pluralized_and_lowered_block_types(),\n                    }\n                ]\n\n                # logging.info(f\"Graph '{graph_name}' created successfully.\")\n                return self.db_connector.db.create_graph(\n                    graph_name, edge_definitions=edge_definitions\n                )\n\n            else:\n                return self.get_graph()\n\n        except Exception as e:\n            logging.error(f\"Error creating graph '{graph_name}': {e}\")\n\n    def delete_graph(self, graph_name: str | None = None) -> None:\n        if not graph_name:\n            graph_name = self.default_graph_name\n        try:\n            self.db_connector.db.delete_graph(graph_name)\n            logging.info(f\"Graph '{graph_name}' deleted successfully.\")\n        except Exception as e:\n            logging.error(f\"Error deleting graph '{graph_name}': {e}\")\n\n    def get_outbound_models(self, start_key: str) -> list[ModelType] | None:\n        vertex_type: str = self._get_collection_from_id(start_key)\n\n        query: str = f\"\"\"\n        FOR v, e, p IN 1..100 OUTBOUND '{vertex_type}/{start_key}' GRAPH '{self.default_graph_name}'\n        RETURN DISTINCT v\n        \"\"\"\n        # query: str = f\"\"\"\n        # FOR v, e, p IN 1..100 OUTBOUND '{vertex_type}/{start_key}' GRAPH '{self.default_graph_name}'\n        # FILTER LENGTH(p.edges[* FILTER CURRENT != e]) == 0\n        # RETURN DISTINCT v\n        # \"\"\"\n        # query: str = f\"\"\"\n        # FOR v, e, p IN 1..100 OUTBOUND '{vertex_type}/{start_key}' GRAPH '{self.default_graph_name}'\n        # FILTER LENGTH(p.edges[* FILTER CURRENT != e]) == 0\n        #     AND p.edges[*].distance ALL == 1\n        # RETURN DISTINCT v\n        # \"\"\"\n\n        try:\n            cursor = self.db_connector.db.aql.execute(query)\n            if isinstance(cursor, Cursor):\n                return [\n                    helper_functions.create_model_from_vertex(doc) for doc in cursor\n                ]\n            else:\n                logging.error(f\"Error getting cursor for query: {query}\")\n                return None\n        except Exception as e:\n            logging.error(f\"Error in get_all_downstream_vertices: {e}\")\n            return None\n\n    def get_inbound_models(self, end_key: str) -> list[ModelType] | None:\n        vertex_type: str = self._get_collection_from_id(end_key)\n\n        query: str = f\"\"\"\n        FOR v, e, p IN 1..100 INBOUND '{vertex_type}/{end_key}' GRAPH '{self.default_graph_name}'\n        RETURN DISTINCT v\n        \"\"\"\n\n        # query: str = f\"\"\"\n        # FOR v, e, p IN 1..100 INBOUND '{vertex_type}/{end_key}' GRAPH '{self.default_graph_name}'\n        # FILTER LENGTH(p.edges[* FILTER CURRENT != e]) == 0\n        # RETURN DISTINCT v\n        # \"\"\"\n\n        try:\n            cursor: Result[Cursor] = self.db_connector.db.aql.execute(query)\n            if isinstance(cursor, Cursor):\n                return [\n                    helper_functions.create_model_from_vertex(doc) for doc in cursor\n                ]\n            else:\n                logging.error(f\"Error getting cursor for query: {query}\")\n                return None\n        except Exception as e:\n            logging.error(f\"Error in get_all_upstream_vertices: {e}\")\n            return None\n\n    def update_vertex_by_id(self, id: str, new_summary: str) -> None:\n        try:\n            collection_name: str = self._get_collection_from_id(id)\n            if collection_name == \"unknown\":\n                logging.error(f\"Unknown vertex type for id: {id}\")\n                return\n\n            vertex_collection: StandardCollection = self.db_connector.db.collection(\n                collection_name\n            )\n            vertex_result: Result[Json | None] = vertex_collection.get(id)\n\n            if not vertex_result:\n                logging.error(f\"Vertex with id {id} not found.\")\n                return\n\n            if isinstance(vertex_result, dict):\n                vertex = vertex_result\n            else:\n                logging.error(\"Retrieved vertex is not in a mutable format.\")\n                return None\n\n            vertex[\"summary\"] = new_summary\n\n            vertex_collection.update(vertex)\n            logging.info(f\"Vertex with id {id} updated successfully.\")\n\n        except Exception as e:\n            logging.error(f\"Error in `update_vertex_by_id`: {e}\")\n\n    def get_all_modules(self) -> list[ModuleModel] | None:\n        try:\n            # Define the collection name for modules.\n            collection_name = \"modules\"\n            module_collection: StandardCollection = self.db_connector.db.collection(\n                collection_name\n            )\n\n            # Retrieve all documents from the modules collection.\n            cursor: Result[Cursor] = module_collection.all()\n\n            # Convert each document to a ModuleModel instance.\n            modules: list[ModuleModel] = []\n            for doc in cursor:  # type: ignore # FIXME: Fix type error\n                # Ensure the document is a dictionary.\n                try:\n                    # Convert the document to a ModuleModel instance and add it to the list.\n                    module = ModuleModel(**doc)\n                    modules.append(module)\n                except Exception as e:\n                    logging.error(f\"Retrieved document is not in a valid format: {e}\")\n                    continue\n\n            return modules\n\n        except Exception as e:\n            logging.error(f\"Error in get_all_modules: {e}\")\n            return None\n\n\nImported code block (postcode:databases:chroma:setup_chroma.py__*__MODULE) code content:\nfrom dataclasses import dataclass\nfrom logging import Logger\n\nimport chromadb\nfrom postcode.databases.chroma.chromadb_client_manager import ChromaDBClientManager\n\nfrom postcode.databases.chroma.chromadb_collection_manager import (\n    ChromaDBCollectionManager,\n)\n\nfrom chromadb.config import DEFAULT_DATABASE, DEFAULT_TENANT, Settings\nfrom chromadb.api import ClientAPI\nfrom chromadb.api.types import (\n    DataLoader,\n    CollectionMetadata,\n    GetResult,\n    QueryResult,\n    Where,\n    WhereDocument,\n    Include,\n    URIs,\n    Loadable,\n    Metadata,\n    Embedding,\n)\nfrom chromadb import Collection\nfrom chromadb import EmbeddingFunction\n\nfrom postcode.models.models import ModuleModel\n\n\n@dataclass\nclass ChromaSetupReturnContext:\n    \"\"\"\n    Represents the return value of the ChromaDB setup method.\n\n    Attributes:\n        - chroma_collection_manager (ChromaDBCollectionManager): The ChromaDB collection manager.\n        - chroma_collection (Collection): The ChromaDB collection.\n    \"\"\"\n\n    chroma_collection_manager: ChromaDBCollectionManager\n    chroma_collection: Collection\n\n\ndef setup_chroma(\n    module_models: list[ModuleModel], logger: Logger\n) -> ChromaSetupReturnContext:\n    chroma_settings = Settings(allow_reset=True)\n    chroma_client: ClientAPI = chromadb.PersistentClient(settings=chroma_settings)\n    chroma_client_manager = ChromaDBClientManager(chroma_client)\n\n    logger.debug(f\"Resetting Chroma client\")\n    if chroma_client_manager.reset_client():\n        logger.debug(\"Client reset\")\n\n    chroma_collection: Collection = chroma_client_manager.get_or_create_collection(\n        \"postcode\"\n    )\n\n    chroma_collection_manager = ChromaDBCollectionManager(chroma_collection)\n    chroma_collection_manager.upsert_models(tuple(module_models))\n\n    return ChromaSetupReturnContext(chroma_collection_manager, chroma_collection)\n\n\nImported code block (postcode:json_management:json_handler.py__*__MODULE) code content:\nimport json\nfrom pathlib import Path\n\nfrom postcode.models.models import ModuleModel\nfrom postcode.utilities.logger.decorators import logging_decorator\n\n\nclass JSONHandler:\n    def __init__(\n        self,\n        directory: str,\n        directory_modules: dict[str, list[str]],\n        output_directory: str = \"../output\",\n    ) -> None:\n        self.directory: str = directory\n        self.output_directory: str = output_directory\n        self.directory_modules: dict[str, list[str]] = directory_modules\n\n        self._create_output_directory()\n\n    @logging_decorator(message=\"Saving model as JSON\")\n    def save_model_as_json(self, module_model: ModuleModel, file_path: str) -> None:\n        \"\"\"Saves a parsed ModuleModel as JSON.\"\"\"\n\n        json_output_directory: str = self._create_json_output_directory()\n        output_path: str = self._get_json_output_path(file_path, json_output_directory)\n        self._write_json_file(module_model, output_path)\n\n    @logging_decorator(message=\"Saving visited directories\")\n    def save_visited_directories(\n        self, directory_mape_name: str = \"directory_map.json\"\n    ) -> None:\n        \"\"\"\n        Saves a JSON file mapping each visited directory to its Python files.\n\n        The output is saved in a file named '00_directory_module_map.json' within the specified output directory.\n\n        Args:\n            directory_mape_name (str): The name of the output file for the directory map.\n\n        Example:\n            >>> visitor_manager.save_visited_directories(\"directory_map.json\")\n            # Saves a mapping of directories to Python files as JSON.\n        \"\"\"\n\n        output_path: str = self._get_directory_map_output_path(directory_mape_name)\n        self._write_json_directory_map(output_path)\n\n    def _create_output_directory(self) -> None:\n        \"\"\"Creates the output directory if it does not already exist.\"\"\"\n\n        Path(self.output_directory).mkdir(exist_ok=True)\n\n    def _create_json_output_directory(self) -> str:\n        \"\"\"Creates the JSON output directory if it does not already exist.\"\"\"\n\n        json_output_directory: Path = Path(self.output_directory) / \"json\"\n        json_output_directory.mkdir(exist_ok=True)\n        return str(json_output_directory)\n\n    def _get_json_output_path(self, file_path: str, json_output_directory: str) -> str:\n        \"\"\"Gets the output path for a JSON file.\"\"\"\n\n        relative_path: Path = Path(file_path).relative_to(Path(self.directory))\n        safe_relative_path: str = str(relative_path).replace(\"/\", \":\").rstrip(\".py\")\n        return str(Path(json_output_directory) / f\"{safe_relative_path}.json\")\n\n    def _write_json_file(self, module_model: ModuleModel, output_path: str) -> None:\n        \"\"\"Writes a JSON file containing the parsed data from a ModuleModel.\"\"\"\n\n        parsed_data_json: str = module_model.model_dump_json(indent=4)\n        with open(output_path, \"w\") as json_file:\n            json_file.write(parsed_data_json)\n\n    def _get_directory_map_output_path(self, directory_output_name: str) -> str:\n        \"\"\"Gets the output path for the directory map JSON file.\"\"\"\n\n        return str(Path(self.output_directory) / directory_output_name)\n\n    def _write_json_directory_map(self, output_path: str) -> None:\n        \"\"\"Writes the directory map JSON file.\"\"\"\n\n        with open(output_path, \"w\") as json_file:\n            json.dump(self.directory_modules, json_file, indent=4)\n\n\nImported code block (postcode:models:models.py__*__MODULE) code content:\nfrom typing import Union\nfrom pydantic import BaseModel, Field, validator\n\nfrom postcode.models.enums import (\n    BlockType,\n    ImportModuleType,\n    CommentType,\n)\n\n\nclass ImportNameModel(BaseModel):\n    \"\"\"Class representing the name of an import.\"\"\"\n\n    name: str\n    as_name: str | None = None\n    local_block_id: str | None = None\n\n    # def convert_import_names_to_metadata(self) -> str:\n    #     \"\"\"Converts the import name to a metadata string.\"\"\"\n\n    #     return self.model_dump_json()\n\n\nclass ImportModel(BaseModel):\n    \"\"\"Class representing an import statement.\"\"\"\n\n    import_names: list[ImportNameModel]\n    imported_from: str | None = None\n    import_module_type: ImportModuleType = ImportModuleType.STANDARD_LIBRARY\n    local_module_id: str | None = None\n\n    def convert_import_to_metadata(self) -> str:\n        \"\"\"Converts the import to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass DependencyModel(BaseModel):\n    \"\"\"Class representing a module dependency.\"\"\"\n\n    code_block_id: str\n\n    def convert_dependency_to_metadata(self) -> str:\n        \"\"\"Converts the dependency to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass CommentModel(BaseModel):\n    \"\"\"Class representing a comment.\"\"\"\n\n    content: str\n    comment_types: list[CommentType]\n\n    def convert_comment_to_metadata(self) -> str:\n        \"\"\"Converts the comment to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass DecoratorModel(BaseModel):\n    \"\"\"Class representing a decorator.\"\"\"\n\n    content: str\n    decorator_name: str\n    decorator_args: list[str] | None = None\n\n    def convert_decorator_to_metadata(self) -> str:\n        \"\"\"Converts the decorator to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass ClassKeywordModel(BaseModel):\n    \"\"\"Class representing a class keyword.\"\"\"\n\n    content: str\n    keyword_name: str\n    args: str | None = None\n\n    def convert_class_keyword_to_metadata(self) -> str:\n        \"\"\"Converts the class keyword to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass ParameterModel(BaseModel):\n    \"\"\"Class representing a function parameter.\"\"\"\n\n    content: str\n\n\nclass ParameterListModel(BaseModel):\n    \"\"\"Class representing a list of parameters.\"\"\"\n\n    params: list[ParameterModel] | None = None\n    star_arg: ParameterModel | None = None\n    kwonly_params: list[ParameterModel] | None = None\n    star_kwarg: ParameterModel | None = None\n    posonly_params: list[ParameterModel] | None = None\n\n    def convert_parameters_to_metadata(self) -> str:\n        \"\"\"Converts the parameter list to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass BaseCodeBlockModel(BaseModel):\n    \"\"\"Attributes common to all code block models.\"\"\"\n\n    id: str\n    parent_id: str | None = None\n    block_type: BlockType\n    start_line_num: int\n    end_line_num: int\n    code_content: str = \"\"\n    important_comments: list[CommentModel] | None = None\n    dependencies: list[ImportModel | DependencyModel] | None = None\n    summary: str | None = None\n    children: list[\n        Union[\n            \"ClassModel\",\n            \"FunctionModel\",\n            \"StandaloneCodeBlockModel\",\n        ]\n    ] | None = []\n\n    @validator(\"parent_id\", always=True)\n    def check_parent_id(cls, v, values, **kwargs) -> str | None:\n        \"\"\"Validates that parent_id is a non-empty string unless block_type is MODULE.\"\"\"\n\n        if \"block_type\" in values and values[\"block_type\"] != BlockType.MODULE:\n            if len(v) < 1:\n                raise ValueError(\"parent_id is required!\")\n        return v\n\n    def _convert_parent_id_to_metadata(self) -> str:\n        \"\"\"Converts the parent_id to a metadata string.\"\"\"\n        return f\"{self.parent_id}\" if self.parent_id else \"\"\n\n    def _convert_block_type_to_metadata(self) -> str:\n        \"\"\"Converts the block_type to a metadata string.\"\"\"\n        return f\"{self.block_type.name}\"\n\n    def _convert_important_comments_to_metadata(self) -> str:\n        \"\"\"Converts the important comments to a metadata string.\"\"\"\n\n        important_comments: str = (\n            self.model_dump_json() if self.important_comments else \"\"\n        )\n\n        return f\"{important_comments}\"\n\n    def _convert_dependencies_to_metadata(self) -> str:\n        \"\"\"Converts the dependencies to a metadata string.\"\"\"\n\n        dependencies_str: str = \"\"\n\n        if self.dependencies:\n            for dependency in self.dependencies:\n                if isinstance(dependency, ImportModel):\n                    dependencies_str += f\"{dependency.convert_import_to_metadata()}\\n\"\n                elif isinstance(dependency, DependencyModel):\n                    dependencies_str += (\n                        f\"{dependency.convert_dependency_to_metadata()}\\n\"\n                    )\n\n        return dependencies_str\n\n    def _convert_summary_to_metadata(self) -> str:\n        \"\"\"Converts the summary to a metadata string.\"\"\"\n        return f\"{self.summary}\" if self.summary else \"\"\n\n    def _convert_children_to_metadata(self) -> str:\n        \"\"\"Converts the children to a metadata string.\"\"\"\n\n        children_str: str = \"\"\n\n        if self.children:\n            for child in self.children:\n                children_str += f\"{child.id}\\n\"\n\n        return children_str\n\n    def _convert_base_attributes_to_metadata_dict(self) -> dict[str, str | int]:\n        \"\"\"Converts the base attributes to a metadata dictionary.\"\"\"\n\n        return {\n            \"id\": self.id,\n            \"parent_id\": self._convert_parent_id_to_metadata(),\n            \"block_type\": self._convert_block_type_to_metadata(),\n            \"start_line_num\": self.start_line_num,\n            \"end_line_num\": self.end_line_num,\n            \"code_content\": self.code_content,\n            \"important_comments\": self._convert_important_comments_to_metadata(),\n            \"dependencies\": self._convert_dependencies_to_metadata(),\n            \"summary\": self._convert_summary_to_metadata(),\n            \"children\": self._convert_children_to_metadata(),\n        }\n\n\nclass ModuleSpecificAttributes(BaseModel):\n    \"\"\"Module specific attributes.\"\"\"\n\n    file_path: str = Field(min_length=1)\n    docstring: str | None = None\n    header: list[str] | None = None\n    footer: list[str] | None = None\n    imports: list[ImportModel] | None = None\n\n    def _convert_docstring_to_metadata(self) -> str:\n        \"\"\"Converts the docstring to a metadata string.\"\"\"\n        return f\"{self.docstring}\"\n\n    def _convert_header_to_metadata(self) -> str:\n        \"\"\"Converts the header and footer to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n    def _convert_footer_to_metadata(self) -> str:\n        \"\"\"Converts the header and footer to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n    def _convert_imports_to_metadata(self) -> str:\n        \"\"\"Converts the imports to a metadata string.\"\"\"\n        imports_str: str = self.model_dump_json() if self.imports else \"\"\n        return f\"{imports_str}\"\n\n    def _convert_module_attributes_to_metadata_dict(self) -> dict[str, str | int]:\n        \"\"\"Converts the module attributes to a metadata dictionary.\"\"\"\n\n        return {\n            \"file_path\": self.file_path,\n            \"docstring\": self._convert_docstring_to_metadata(),\n            \"header\": self._convert_header_to_metadata(),\n            \"footer\": self._convert_footer_to_metadata(),\n            \"imports\": self._convert_imports_to_metadata(),\n        }\n\n\nclass ModuleModel(BaseCodeBlockModel, ModuleSpecificAttributes):\n    \"\"\"Model for a module.\"\"\"\n\n    def convert_to_metadata(self) -> dict[str, str | int]:\n        \"\"\"Converts the module model to a metadata dictionary.\"\"\"\n\n        return {\n            **self._convert_base_attributes_to_metadata_dict(),\n            **self._convert_module_attributes_to_metadata_dict(),\n        }\n\n\nclass ClassSpecificAttributes(BaseModel):\n    \"\"\"Class specific attributes.\"\"\"\n\n    class_name: str = Field(min_length=1)\n    decorators: list[DecoratorModel] | None = None\n    bases: list[str] | None = None\n    docstring: str | None = None\n    keywords: list[ClassKeywordModel] | None = None\n    # attributes: list[dict] | None = None\n\n    def _convert_decorators_to_metadata(self) -> str:\n        \"\"\"Converts the decorators to a metadata string.\"\"\"\n        decorators_str: str = self.model_dump_json() if self.decorators else \"\"\n        return f\"{decorators_str}\"\n\n    def _convert_bases_to_metadata(self) -> str:\n        \"\"\"Converts the bases to a metadata string.\"\"\"\n        return self.model_dump_json() if self.bases else \"\"\n\n    def _convert_docstring_to_metadata(self) -> str:\n        \"\"\"Converts the docstring to a metadata string.\"\"\"\n        return f\"{self.docstring}\" if self.docstring else \"\"\n\n    def _convert_keywords_to_metadata(self) -> str:\n        \"\"\"Converts the keywords to a metadata string.\"\"\"\n        keywords_str: str = self.model_dump_json() if self.keywords else \"\"\n        return f\"{keywords_str}\"\n\n    def _convert_class_attributes_to_metadata_dict(self) -> dict[str, str | int]:\n        \"\"\"Converts the class attributes to a metadata dictionary.\"\"\"\n\n        return {\n            \"class_name\": self.class_name,\n            \"decorators\": self._convert_decorators_to_metadata(),\n            \"bases\": self._convert_bases_to_metadata(),\n            \"docstring\": self._convert_docstring_to_metadata(),\n            \"keywords\": self._convert_keywords_to_metadata(),\n        }\n\n\nclass ClassModel(BaseCodeBlockModel, ClassSpecificAttributes):\n    \"\"\"Model for a class.\"\"\"\n\n    def convert_to_metadata(self) -> dict[str, str | int]:\n        \"\"\"Converts the class model to a metadata dictionary.\"\"\"\n        return {\n            **self._convert_base_attributes_to_metadata_dict(),\n            **self._convert_class_attributes_to_metadata_dict(),\n        }\n\n\nclass FunctionSpecificAttributes(BaseModel):\n    \"\"\"Function specific attributes.\"\"\"\n\n    function_name: str = Field(min_length=1)\n    docstring: str | None = None\n    decorators: list[DecoratorModel] | None = None\n    parameters: ParameterListModel | None = None\n    returns: str | None = None\n    is_method: bool = False\n    is_async: bool = False\n\n    def _convert_docstring_to_metadata(self) -> str:\n        \"\"\"Converts the docstring to a metadata string.\"\"\"\n        return f\"{self.docstring}\" if self.docstring else \"\"\n\n    def _convert_decorators_to_metadata(self) -> str:\n        \"\"\"Converts the decorators to a metadata string.\"\"\"\n        decorators_str: str = self.model_dump_json() if self.decorators else \"\"\n        return f\"{decorators_str}\"\n\n    def _convert_parameters_to_metadata(self) -> str:\n        \"\"\"Converts the parameters to a metadata string.\"\"\"\n        return (\n            self.parameters.convert_parameters_to_metadata() if self.parameters else \"\"\n        )\n\n    def _convert_returns_to_metadata(self) -> str:\n        \"\"\"Converts the returns to a metadata string.\"\"\"\n        return f\"{self.returns}\" if self.returns else \"\"\n\n    def _convert_function_attributes_to_metadata_dict(self) -> dict[str, str | bool]:\n        \"\"\"Converts the function attributes to a metadata dictionary.\"\"\"\n\n        return {\n            \"function_name\": self.function_name,\n            \"docstring\": self._convert_docstring_to_metadata(),\n            \"decorators\": self._convert_decorators_to_metadata(),\n            \"parameters\": self._convert_parameters_to_metadata(),\n            \"returns\": self._convert_returns_to_metadata(),\n            \"is_method\": self.is_method,\n            \"is_async\": self.is_async,\n        }\n\n\nclass FunctionModel(BaseCodeBlockModel, FunctionSpecificAttributes):\n    \"\"\"Model for a function.\"\"\"\n\n    def convert_to_metadata(self) -> dict[str, str | int]:\n        \"\"\"Converts the function model to a metadata dictionary.\"\"\"\n\n        return {\n            **self._convert_base_attributes_to_metadata_dict(),\n            **self._convert_function_attributes_to_metadata_dict(),\n        }\n\n\nclass StandaloneCodeBlockSpecificAttributes(BaseModel):\n    \"\"\"Standalone code block specific attributes.\"\"\"\n\n    variable_assignments: list[str] | None = None\n\n    def _convert_variable_assignments_to_metadata(self) -> str:\n        \"\"\"Converts the variable assignments to a metadata string.\"\"\"\n        return self.model_dump_json() if self.variable_assignments else \"\"\n\n    def _convert_standalone_block_attributes_to_metadata_dict(\n        self,\n    ) -> dict[str, str | int]:\n        \"\"\"Converts the standalone code block attributes to a metadata dictionary.\"\"\"\n        return {\n            \"variable_assignments\": self._convert_variable_assignments_to_metadata(),\n        }\n\n\nclass StandaloneCodeBlockModel(\n    BaseCodeBlockModel, StandaloneCodeBlockSpecificAttributes\n):\n    \"\"\"Model for a standalone code block.\"\"\"\n\n    def convert_to_metadata(self) -> dict[str, str | int]:\n        \"\"\"Converts the standalone code block model to a metadata dictionary.\"\"\"\n\n        return {\n            **self._convert_base_attributes_to_metadata_dict(),\n            **self._convert_standalone_block_attributes_to_metadata_dict(),\n        }\n\n\nImported code block (postcode:python_parser:visitor_manager:visitor_manager.py__*__MODULE) code content:\nfrom dataclasses import dataclass\nimport logging\nfrom pathlib import Path\n\nfrom postcode.python_parser.model_builders.module_model_builder import (\n    ModuleModelBuilder,\n)\nfrom postcode.utilities.logger.decorators import logging_decorator\n\nfrom postcode.python_parser.parsers.python_parser import PythonParser\nfrom postcode.python_parser.visitor_manager.import_and_dependency_updater import (\n    ImportAndDependencyUpdater,\n)\nfrom postcode.models.models import ModuleModel\n\nfrom postcode.ai_services.summarizer.summarization_context import Summarizer\n\nEXCLUDED_DIRECTORIES: set[str] = {\".venv\", \"node_modules\", \"__pycache__\", \".git\"}\n\n\n@dataclass\nclass VisitorManagerProcessFilesReturn:\n    \"\"\"\n    Represents the return value of the VisitorManager.process_files() method.\n\n    Attributes:\n        - models_tuple (tuple[ModuleModel, ...]): A tuple of ModuleModel objects representing the parsed modules.\n        - directory_modules (dict[str, list[str]]): A dictionary mapping directory paths to lists of module names.\n            This is used to keep track of the modules present in each directory.\n    \"\"\"\n\n    models_tuple: tuple[ModuleModel, ...]\n    directory_modules: dict[str, list[str]]\n\n\nclass VisitorManager:\n    \"\"\"\n    Manages the visiting and processing of Python files in a given directory.\n\n    This class scans a specified directory, filters for Python files, parses them, and saves the parsed data in a structured JSON format. It also maintains a mapping of directories to the Python files they contain.\n\n    Attributes:\n        directory (str): The root directory to scan for Python files.\n        output_directory (str): The directory where output JSON files will be saved.\n        directory_modules (dict): A mapping of directories to their contained Python files.\n\n    Example:\n        >>> visitor_manager = VisitorManager(\"/path/to/python/code\", \"output\")\n        >>> visitor_manager.process_files()\n        # This will process all Python files in /path/to/python/code and save their parsed data in the output directory.\n    \"\"\"\n\n    @logging_decorator(message=\"Initializing VisitorManager\")\n    def __init__(self, directory: str, output_directory: str = \"output_json\") -> None:\n        self.directory: str = directory\n        self.output_directory: str = output_directory\n        self.directory_modules: dict[str, list[str]] = {}\n\n    def process_files(self) -> VisitorManagerProcessFilesReturn:\n        \"\"\"\n        Process the files in the directory and return the module models.\n\n        This function iterates through all the Python files in the directory, processes each file,\n        updates the imports, and builds module models for each file. It returns a tuple of module models\n        and a dictionary of directory modules.\n\n        Returns:\n            A named tuple (VisitorManagerProcessFilesReturn) containing:\n            - models_tuple (tuple[ModuleModel, ...]): A tuple of module models.\n            - directory_modules (dict[str, ModuleModel]): A dictionary of directory modules.\n\n        Examples:\n            >>> visitor_manager = VisitorManager()\n            >>> result = visitor_manager.process_files()\n            >>> print(result.models_tuple)\n            (ModuleModel(file_path='/path/to/file1.py'), ModuleModel(file_path='/path/to/file2.py'))\n            >>> print(result.directory_modules)\n            {'/path/to/directory1': ModuleModel(file_path='/path/to/directory1/__init__.py')}\n        \"\"\"\n\n        logging.info(\"Processing files\")\n        python_files: list[str] = self._get_python_files()\n        model_builder_list: list[ModuleModelBuilder] = []\n        for file_path in python_files:\n            if model_builder := self._process_file(file_path):\n                model_builder_list.append((model_builder))\n\n        logging.info(\"File processing completed\")\n        logging.info(\"Updating imports\")\n\n        # TODO: Test making this a tuple of tuples, see if that solves the double update import issue\n        model_builder_tuple: tuple[ModuleModelBuilder, ...] = tuple(model_builder_list)\n\n        import_and_dependency_updater = ImportAndDependencyUpdater(model_builder_tuple)\n        import_and_dependency_updater.update_imports()\n        logging.info(\"Updated imports\")\n\n        module_models_list: list[ModuleModel] = []\n        for module_model_builder in model_builder_tuple:\n            module_model: ModuleModel = self._build_module_model(module_model_builder)\n            module_models_list.append(module_model)\n\n        module_models_tuple: tuple[ModuleModel, ...] = tuple(module_models_list)\n\n        return VisitorManagerProcessFilesReturn(\n            models_tuple=module_models_tuple, directory_modules=self.directory_modules\n        )\n\n    def _walk_directories(self) -> list[str]:\n        \"\"\"Walks the specified directory and returns a list of all files.\"\"\"\n\n        all_files: list[str] = []\n        for file_path in Path(self.directory).rglob(\"*\"):\n            if not any(\n                excluded in file_path.parts for excluded in EXCLUDED_DIRECTORIES\n            ):\n                all_files.append(str(file_path))\n        return all_files\n\n    def _filter_python_files(self, files: list[str]) -> list[str]:\n        \"\"\"Filters a list of files to only include Python files.\"\"\"\n\n        return [file for file in files if file.endswith(\".py\")]\n\n    @logging_decorator(message=\"Getting Python files\")\n    def _get_python_files(self) -> list[str]:\n        \"\"\"Gets all Python files in the specified directory.\"\"\"\n\n        all_files: list[str] = self._walk_directories()\n        return self._filter_python_files(all_files)\n\n    def _process_file(self, file_path: str) -> ModuleModelBuilder | None:\n        \"\"\"Processes a single Python file.\"\"\"\n\n        file_path_obj = Path(file_path)\n        root = str(file_path_obj.parent)\n        self.directory_modules.setdefault(root, []).append(file_path_obj.name)\n        return self._parse_file(file_path)\n\n    @logging_decorator(message=\"Processing file\")\n    def _parse_file(self, file_path: str) -> ModuleModelBuilder | None:\n        \"\"\"Parses a Python file and saves the parsed data as JSON.\"\"\"\n\n        parser = PythonParser(file_path)\n        code: str = parser.open_file()\n        module_model_builder: ModuleModelBuilder | None = parser.parse(code)\n\n        return module_model_builder\n\n    def _build_module_model(\n        self, visitor_stack: ModuleModelBuilder | None\n    ) -> ModuleModel:\n        \"\"\"\n        Builds a module model from the provided module builder.\n\n        Args:\n            visitor_stack (ModuleModelBuilder): The module builder to build the model from.\n\n        Returns:\n            ModuleModel: A structured module model.\n\n        Example:\n            >>> module_model = python_parser.build_module_model(visitor_stack)\n            # Builds a module model from the provided module builder.\n        \"\"\"\n\n        if not isinstance(visitor_stack, ModuleModelBuilder):\n            raise TypeError(\"Expected the first builder to be a ModuleModelBuilder\")\n\n        return visitor_stack.build()\n\n, \nfrom logging import Logger\nfrom openai import OpenAI\n        "}utes_to_metadata_dict(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the module attributes to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            \\\"file_path\\\": self.file_path,\\n            \\\"docstring\\\": self._convert_docstring_to_metadata(),\\n            \\\"header\\\": self._convert_header_to_metadata(),\\n            \\\"footer\\\": self._convert_footer_to_metadata(),\\n            \\\"imports\\\": self._convert_imports_to_metadata(),\\n        }\\n\\n\\nclass ModuleModel(BaseCodeBlockModel, ModuleSpecificAttributes):\\n    \\\"\\\"\\\"Model for a module.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the module model to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_module_attributes_to_metadata_dict(),\\n        }\\n\\n\\nclass ClassSpecificAttributes(BaseModel):\\n    \\\"\\\"\\\"Class specific attributes.\\\"\\\"\\\"\\n\\n    class_name: str = Field(min_length=1)\\n    decorators: list[DecoratorModel] | None = None\\n    bases: list[str] | None = None\\n    docstring: str | None = None\\n    keywords: list[ClassKeywordModel] | None = None\\n    # attributes: list[dict] | None = None\\n\\n    def _convert_decorators_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the decorators to a metadata string.\\\"\\\"\\\"\\n        decorators_str: str = self.model_dump_json() if self.decorators else \\\"\\\"\\n        return f\\\"{decorators_str}\\\"\\n\\n    def _convert_bases_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the bases to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json() if self.bases else \\\"\\\"\\n\\n    def _convert_docstring_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the docstring to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.docstring}\\\" if self.docstring else \\\"\\\"\\n\\n    def _convert_keywords_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the keywords to a metadata string.\\\"\\\"\\\"\\n        keywords_str: str = self.model_dump_json() if self.keywords else \\\"\\\"\\n        return f\\\"{keywords_str}\\\"\\n\\n    def _convert_class_attributes_to_metadata_dict(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the class attributes to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            \\\"class_name\\\": self.class_name,\\n            \\\"decorators\\\": self._convert_decorators_to_metadata(),\\n            \\\"bases\\\": self._convert_bases_to_metadata(),\\n            \\\"docstring\\\": self._convert_docstring_to_metadata(),\\n            \\\"keywords\\\": self._convert_keywords_to_metadata(),\\n        }\\n\\n\\nclass ClassModel(BaseCodeBlockModel, ClassSpecificAttributes):\\n    \\\"\\\"\\\"Model for a class.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the class model to a metadata dictionary.\\\"\\\"\\\"\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_class_attributes_to_metadata_dict(),\\n        }\\n\\n\\nclass FunctionSpecificAttributes(BaseModel):\\n    \\\"\\\"\\\"Function specific attributes.\\\"\\\"\\\"\\n\\n    function_name: str = Field(min_length=1)\\n    docstring: str | None = None\\n    decorators: list[DecoratorModel] | None = None\\n    parameters: ParameterListModel | None = None\\n    returns: str | None = None\\n    is_method: bool = False\\n    is_async: bool = False\\n\\n    def _convert_docstring_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the docstring to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.docstring}\\\" if self.docstring else \\\"\\\"\\n\\n    def _convert_decorators_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the decorators to a metadata string.\\\"\\\"\\\"\\n        decorators_str: str = self.model_dump_json() if self.decorators else \\\"\\\"\\n        return f\\\"{decorators_str}\\\"\\n\\n    def _convert_parameters_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the parameters to a metadata string.\\\"\\\"\\\"\\n        return (\\n            self.parameters.convert_parameters_to_metadata() if self.parameters else \\\"\\\"\\n        )\\n\\n    def _convert_returns_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the returns to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.returns}\\\" if self.returns else \\\"\\\"\\n\\n    def _convert_function_attributes_to_metadata_dict(self) -> dict[str, str | bool]:\\n        \\\"\\\"\\\"Converts the function attributes to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            \\\"function_name\\\": self.function_name,\\n            \\\"docstring\\\": self._convert_docstring_to_metadata(),\\n            \\\"decorators\\\": self._convert_decorators_to_metadata(),\\n            \\\"parameters\\\": self._convert_parameters_to_metadata(),\\n            \\\"returns\\\": self._convert_returns_to_metadata(),\\n            \\\"is_method\\\": self.is_method,\\n            \\\"is_async\\\": self.is_async,\\n        }\\n\\n\\nclass FunctionModel(BaseCodeBlockModel, FunctionSpecificAttributes):\\n    \\\"\\\"\\\"Model for a function.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the function model to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_function_attributes_to_metadata_dict(),\\n        }\\n\\n\\nclass StandaloneCodeBlockSpecificAttributes(BaseModel):\\n    \\\"\\\"\\\"Standalone code block specific attributes.\\\"\\\"\\\"\\n\\n    variable_assignments: list[str] | None = None\\n\\n    def _convert_variable_assignments_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the variable assignments to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json() if self.variable_assignments else \\\"\\\"\\n\\n    def _convert_standalone_block_attributes_to_metadata_dict(\\n        self,\\n    ) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the standalone code block attributes to a metadata dictionary.\\\"\\\"\\\"\\n        return {\\n            \\\"variable_assignments\\\": self._convert_variable_assignments_to_metadata(),\\n        }\\n\\n\\nclass StandaloneCodeBlockModel(\\n    BaseCodeBlockModel, StandaloneCodeBlockSpecificAttributes\\n):\\n    \\\"\\\"\\\"Model for a standalone code block.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the standalone code block model to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_standalone_block_attributes_to_metadata_dict(),\\n        }\\n\\n, \\nimport logging\\nfrom pprint import pprint\\nfrom typing import Union\\n        \",\"children\":[{\"variable_assignments\":[\"ModelType = Union[\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n]\"],\"id\":\"postcode:ai_services:summarizer:graph_db_summarization_manager.py__*__MODULE__*__STANDALONE_BLOCK-1\",\"parent_id\":\"postcode:ai_services:summarizer:graph_db_summarization_manager.py__*__MODULE\",\"block_type\":\"STANDALONE_BLOCK\",\"start_line_num\":24,\"end_line_num\":31,\"code_content\":\"ModelType = Union[\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n]\\n\",\"important_comments\":null,\"dependencies\":[{\"import_names\":[{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"DependencyModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"ImportModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"DependencyModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"ImportModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"DependencyModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"ImportModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"DependencyModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"ImportModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"Union\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"typing\",\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null}],\"summary\":null,\"children\":null},{\"class_name\":\"GraphDBSummarizationManager\",\"decorators\":null,\"bases\":null,\"docstring\":null,\"keywords\":null,\"id\":\"postcode:ai_services:summarizer:graph_db_summarization_manager.py__*__MODULE__*__CLASS-GraphDBSummarizationManager\",\"parent_id\":\"postcode:ai_services:summarizer:graph_db_summarization_manager.py__*__MODULE\",\"block_type\":\"CLASS\",\"start_line_num\":31,\"end_line_num\":297,\"code_content\":\"\\n\\nclass GraphDBSummarizationManager:\\n    def __init__(\\n        self,\\n        module_models_tuple: tuple[ModuleModel, ...],\\n        summarization_mapper: SummarizationMapper,\\n        summarizer: Summarizer,\\n        graph_manager: ArangoDBManager,\\n    ) -> None:\\n        self.module_models_tuple: tuple[ModuleModel, ...] = module_models_tuple\\n        self.summarization_mapper: SummarizationMapper = summarization_mapper\\n        self.summarizer: Summarizer = summarizer\\n        self.summarized_code_block_ids: set[str] = set()\\n        self.prompt_tokens: int = 0\\n        self.completion_tokens: int = 0\\n        self.graph_manager: ArangoDBManager = graph_manager\\n\\n    @property\\n    def total_cost(self) -> float:\\n        \\\"\\\"\\\"Provides the total cost of the summarization process.\\\"\\\"\\\"\\n        prompt_cost: int = self.prompt_tokens * 1  # Costs 1 cent per 1,000 tokens\\n        completion_cost: int = (\\n            self.completion_tokens * 3\\n        )  # Costs 3 cents per 1,000 tokens\\n        return (prompt_cost + completion_cost) / 100_000  # Convert to dollars\\n\\n    def create_summaries_and_return_updated_models(self) -> list[ModuleModel] | None:\\n        summarization_map: list[\\n            ModelType\\n        ] = self.summarization_mapper.create_summarization_map()\\n        models_to_summarize_count: int = len(summarization_map)\\n        models_summarized_count: int = 0\\n\\n        for model in summarization_map:\\n            children_summaries: str | None = None\\n            dependency_summaries: str | None = None\\n            import_details: str | None = None\\n\\n            if model.children:\\n                children_summaries: str | None = self._stringify_children_summaries(\\n                    self._get_child_summaries(model)\\n                )\\n            if isinstance(model, ModuleModel):\\n                if model.imports:\\n                    dependency_summaries = self._get_dependencies_summaries(model)\\n                    import_details = \\\"\\\"\\n                    for _import in model.imports:\\n                        if import_summary := self._get_import_details(_import):\\n                            import_details += f\\\"\\\\n{import_summary}\\\"\\n            else:\\n                if model.dependencies:\\n                    dependency_summaries = self._get_dependencies_summaries(model)\\n                    import_details = \\\"\\\"\\n                    for dependency in model.dependencies:\\n                        if isinstance(dependency, DependencyModel):\\n                            continue\\n                        if import_summary := self._get_import_details(dependency):\\n                            import_details += f\\\"\\\\n{import_summary}\\\"\\n\\n            models_summarized_count += 1\\n            logging.info(\\n                f\\\"Summarizing model {models_summarized_count} out of {models_to_summarize_count}; {model.id}.\\\"\\n            )\\n\\n            summary_return_context: OpenAIReturnContext | None = (\\n                self.summarizer.test_summarize_code(\\n                    model.code_content,\\n                    model_id=model.id,\\n                    children_summaries=children_summaries,\\n                    dependency_summaries=dependency_summaries,\\n                    import_details=import_details,\\n                )\\n            )\\n            if summary_return_context:\\n                if summary_return_context.summary:\\n                    self.graph_manager.update_vertex_by_id(\\n                        model.id, summary_return_context.summary\\n                    )\\n                self.prompt_tokens += summary_return_context.prompt_tokens\\n                self.completion_tokens += summary_return_context.completion_tokens\\n\\n                # for module_model in self.module_models_tuple:\\n                #     if isinstance(model, ModuleModel):\\n                #         if module_model.id == model.id:\\n                #             module_model.summary = model.summary\\n                #             break\\n                #         else:\\n                #             continue\\n                #     else:\\n                #         module_id_for_model: str = model.id.split(\\\"MODULE\\\")[0]\\n                #         if (\\n                #             module_model.children\\n                #             and module_id_for_model in module_model.id\\n                #         ):\\n                #             for child_model in module_model.children:\\n                #                 if child_model.id == model.id:\\n                #                     # child_model.summary = model.summary\\n                #                     break\\n                #         else:\\n                #             continue\\n\\n        pprint([model.id for model in summarization_map[::-1]])\\n        print(len(summarization_map))\\n\\n        return self.graph_manager.get_all_modules() if self.graph_manager else None\\n\\n    def _get_child_summaries(self, model: ModelType) -> list[str]:\\n        \\\"\\\"\\\"Gathers summaries of child models.\\\"\\\"\\\"\\n        child_summary_list: list[str] = []\\n        if model.children:\\n            for child in model.children:\\n                if child.summary:\\n                    child_summary: str = child.summary\\n                else:\\n                    child_summary = (\\n                        f\\\"Child ({child.id}) code content:\\\\n{child.code_content}\\\\n\\\"\\n                    )\\n                child_summary_list.append(child_summary)\\n        return child_summary_list\\n\\n    def _stringify_children_summaries(self, children_summary_list: list[str]) -> str:\\n        \\\"\\\"\\\"Converts all of the child summaries to a single string to be used in the prompt.\\\"\\\"\\\"\\n\\n        children_summaries: str = \\\"\\\"\\n        for child_summary in children_summary_list:\\n            children_summaries += f\\\"\\\\n{child_summary}\\\"\\n        return children_summaries\\n\\n    def _get_dependencies_summaries(self, model: ModelType) -> str | None:\\n        dependency_list: list[ImportModel | DependencyModel] | list[ImportModel] = []\\n        dependency_summary_list: list[str] = []\\n\\n        if isinstance(model, ModuleModel):\\n            if not model.imports:\\n                return None\\n\\n            dependency_list = model.imports\\n        else:\\n            if not model.dependencies:\\n                return None\\n\\n            dependency_list = model.dependencies\\n        for dependency in dependency_list:\\n            if isinstance(dependency, DependencyModel) and dependency.code_block_id:\\n                if module_local_dependency_summary := self._get_local_dependency_summary(\\n                    dependency, model\\n                ):\\n                    dependency_summary_list.append(module_local_dependency_summary)\\n\\n            elif isinstance(dependency, ImportModel):\\n                if dependency.import_module_type == \\\"LOCAL\\\":\\n                    if not dependency.import_names:\\n                        if module_import_dependency := self._get_local_import_summary(\\n                            dependency\\n                        ):\\n                            dependency_summary_list.append(module_import_dependency)\\n                    else:\\n                        if import_from_dependency := self._get_local_import_from_summary(\\n                            dependency\\n                        ):\\n                            dependency_summary_list.append(import_from_dependency)\\n\\n        dependency_summaries = self._stringify_dependencies_summaries(\\n            dependency_summary_list\\n        )\\n\\n        return dependency_summaries\\n\\n    # def _get_import_details_for_dependencies(\\n    #     self, dependencies: list[ImportModel | DependencyModel]\\n    # ) -> str | None:\\n    #     import_details: str | None = None\\n    #     for dependency in dependencies:\\n    #         if isinstance(dependency, ImportModel):\\n    #             if dependency.import_module_type == \\\"LOCAL\\\":\\n    #                 continue\\n    #             else:\\n    #                 import_detail: str | None = self._get_import_details(dependency)\\n    #                 if not import_detail:\\n    #                     continue\\n    #                 if not import_details:\\n    #                     import_details = \\\"\\\"\\n    #                 import_details += f\\\"\\\\n{import_detail}\\\"\\n    #     return import_details\\n\\n    def _get_local_dependency_summary(\\n        self,\\n        dependency: DependencyModel,\\n        model: ModelType,\\n    ) -> str | None:\\n        \\\"\\\"\\\"Gets a summary for a dependency local to the module.\\\"\\\"\\\"\\n        if not model.children:\\n            return None\\n\\n        for child_model in model.children:\\n            if child_model.id == dependency.code_block_id:\\n                child_summary: str | None = None\\n\\n                if child_model.summary:\\n                    child_summary = child_model.summary\\n                else:\\n                    child_summary = f\\\"Dependency ({dependency.code_block_id}) code content:\\\\n{child_model.code_content}\\\\n\\\"\\n\\n                return child_summary\\n        return None\\n\\n    def _stringify_dependencies_summaries(\\n        self, dependencies_summary_list: list[str] | None\\n    ) -> str | None:\\n        \\\"\\\"\\\"Converts all of the dependency summaries to a single string to be used in the prompt.\\\"\\\"\\\"\\n        if not dependencies_summary_list:\\n            return None\\n\\n        dependency_summaries: str = \\\"\\\"\\n        for dependency_summary in dependencies_summary_list:\\n            dependency_summaries += f\\\"\\\\n{dependency_summary}\\\"\\n        return dependency_summaries\\n\\n    def _get_local_import_summary(self, dependency: ImportModel) -> str | None:\\n        for module_model in self.module_models_tuple:\\n            if module_model.id == dependency.local_module_id:\\n                import_summary: str | None = None\\n                if module_model.summary:\\n                    import_summary = module_model.summary\\n                else:\\n                    import_summary = f\\\"Imported module ({dependency.local_module_id}) code content:\\\\n{module_model.code_content}\\\\n\\\"\\n                return import_summary\\n        return None\\n\\n    def _get_local_import_from_summary(self, dependency: ImportModel) -> str | None:\\n        for import_name in dependency.import_names:\\n            for module_model in self.module_models_tuple:\\n                if module_model.id == dependency.local_module_id:\\n                    if module_model.children:\\n                        for child_model in module_model.children:\\n                            if (\\n                                child_model.id == import_name.local_block_id\\n                                and child_model.id\\n                            ):\\n                                import_summary: str | None = None\\n                                if child_model.summary:\\n                                    import_summary = child_model.summary\\n                                else:\\n                                    import_summary = f\\\"Imported code block ({dependency.local_module_id}) code content:\\\\n{module_model.code_content}\\\\n\\\"\\n                                return import_summary\\n        return None\\n\\n    def _get_import_details(self, import_model: ImportModel) -> str | None:\\n        \\\"\\\"\\\"Retrieves details of import statements to be used in the prompt.\\\"\\\"\\\"\\n        if import_model.import_module_type == \\\"LOCAL\\\" or not import_model.import_names:\\n            return None\\n\\n        import_names_list: list[str] = []\\n        for import_name in import_model.import_names:\\n            if import_name.as_name:\\n                import_names_list.append(f\\\"{import_name.name} as {import_name.as_name}\\\")\\n            else:\\n                import_names_list.append(f\\\"{import_name.name}\\\")\\n\\n        if import_model.imported_from:\\n            import_details: str = f\\\"from {import_model.imported_from} import {', '.join(import_names_list)}\\\"\\n        else:\\n            import_details = f\\\"import {', '.join(import_names_list)}\\\"\\n\\n        return import_details\\n\",\"important_comments\":null,\"dependencies\":[{\"import_names\":[{\"name\":\"Summarizer\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"OpenAIReturnContext\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"postcode.ai_services.summarizer.summarization_context\",\"import_module_type\":\"LOCAL\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"Summarizer\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"OpenAIReturnContext\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"postcode.ai_services.summarizer.summarization_context\",\"import_module_type\":\"LOCAL\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"DependencyModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"ImportModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"DependencyModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"ImportModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"DependencyModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"ImportModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"logging\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":null,\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"pprint\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"pprint\",\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"SummarizationMapper\",\"as_name\":null,\"local_block_id\":\"postcode:ai_services:summarizer:summarization_mapper.py__*__MODULE__*__CLASS-SummarizationMapper\"}],\"imported_from\":\"postcode.ai_services.summarizer.summarization_mapper\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:ai_services:summarizer:summarization_mapper.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ArangoDBManager\",\"as_name\":null,\"local_block_id\":\"postcode:databases:arangodb:arangodb_manager.py__*__MODULE__*__CLASS-ArangoDBManager\"}],\"imported_from\":\"postcode.databases.arangodb.arangodb_manager\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:databases:arangodb:arangodb_manager.py__*__MODULE\"}],\"summary\":null,\"children\":[{\"function_name\":\"__init__\",\"docstring\":null,\"decorators\":null,\"parameters\":null,\"returns\":\"None\",\"is_method\":true,\"is_async\":false,\"id\":\"postcode:ai_services:summarizer:graph_db_summarization_manager.py__*__MODULE__*__CLASS-GraphDBSummarizationManager__*__FUNCTION-__init__\",\"parent_id\":\"postcode:ai_services:summarizer:graph_db_summarization_manager.py__*__MODULE__*__CLASS-GraphDBSummarizationManager\",\"block_type\":\"FUNCTION\",\"start_line_num\":34,\"end_line_num\":48,\"code_content\":\"def __init__(\\n    self,\\n    module_models_tuple: tuple[ModuleModel, ...],\\n    summarization_mapper: SummarizationMapper,\\n    summarizer: Summarizer,\\n    graph_manager: ArangoDBManager,\\n) -> None:\\n    self.module_models_tuple: tuple[ModuleModel, ...] = module_models_tuple\\n    self.summarization_mapper: SummarizationMapper = summarization_mapper\\n    self.summarizer: Summarizer = summarizer\\n    self.summarized_code_block_ids: set[str] = set()\\n    self.prompt_tokens: int = 0\\n    self.completion_tokens: int = 0\\n    self.graph_manager: ArangoDBManager = graph_manager\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":null,\"children\":null},{\"function_name\":\"total_cost\",\"docstring\":\"Provides the total cost of the summarization process.\",\"decorators\":[{\"content\":\"@property\",\"decorator_name\":\"property\",\"decorator_args\":null}],\"parameters\":null,\"returns\":\"float\",\"is_method\":true,\"is_async\":false,\"id\":\"postcode:ai_services:summarizer:graph_db_summarization_manager.py__*__MODULE__*__CLASS-GraphDBSummarizationManager__*__FUNCTION-total_cost\",\"parent_id\":\"postcode:ai_services:summarizer:graph_db_summarization_manager.py__*__MODULE__*__CLASS-GraphDBSummarizationManager\",\"block_type\":\"FUNCTION\",\"start_line_num\":48,\"end_line_num\":57,\"code_content\":\"\\n@property\\ndef total_cost(self) -> float:\\n    \\\"\\\"\\\"Provides the total cost of the summarization process.\\\"\\\"\\\"\\n    prompt_cost: int = self.prompt_tokens * 1  # Costs 1 cent per 1,000 tokens\\n    completion_cost: int = (\\n        self.completion_tokens * 3\\n    )  # Costs 3 cents per 1,000 tokens\\n    return (prompt_cost + completion_cost) / 100_000  # Convert to dollars\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":null,\"children\":null},{\"function_name\":\"create_summaries_and_return_updated_models\",\"docstring\":null,\"decorators\":null,\"parameters\":null,\"returns\":\"list[ModuleModel] | None\",\"is_method\":true,\"is_async\":false,\"id\":\"postcode:ai_services:summarizer:graph_db_summarization_manager.py__*__MODULE__*__CLASS-GraphDBSummarizationManager__*__FUNCTION-create_summaries_and_return_updated_models\",\"parent_id\":\"postcode:ai_services:summarizer:graph_db_summarization_manager.py__*__MODULE__*__CLASS-GraphDBSummarizationManager\",\"block_type\":\"FUNCTION\",\"start_line_num\":57,\"end_line_num\":137,\"code_content\":\"\\ndef create_summaries_and_return_updated_models(self) -> list[ModuleModel] | None:\\n    summarization_map: list[\\n        ModelType\\n    ] = self.summarization_mapper.create_summarization_map()\\n    models_to_summarize_count: int = len(summarization_map)\\n    models_summarized_count: int = 0\\n\\n    for model in summarization_map:\\n        children_summaries: str | None = None\\n        dependency_summaries: str | None = None\\n        import_details: str | None = None\\n\\n        if model.children:\\n            children_summaries: str | None = self._stringify_children_summaries(\\n                self._get_child_summaries(model)\\n            )\\n        if isinstance(model, ModuleModel):\\n            if model.imports:\\n                dependency_summaries = self._get_dependencies_summaries(model)\\n                import_details = \\\"\\\"\\n                for _import in model.imports:\\n                    if import_summary := self._get_import_details(_import):\\n                        import_details += f\\\"\\\\n{import_summary}\\\"\\n        else:\\n            if model.dependencies:\\n                dependency_summaries = self._get_dependencies_summaries(model)\\n                import_details = \\\"\\\"\\n                for dependency in model.dependencies:\\n                    if isinstance(dependency, DependencyModel):\\n                        continue\\n                    if import_summary := self._get_import_details(dependency):\\n                        import_details += f\\\"\\\\n{import_summary}\\\"\\n\\n        models_summarized_count += 1\\n        logging.info(\\n            f\\\"Summarizing model {models_summarized_count} out of {models_to_summarize_count}; {model.id}.\\\"\\n        )\\n\\n        summary_return_context: OpenAIReturnContext | None = (\\n            self.summarizer.test_summarize_code(\\n                model.code_content,\\n                model_id=model.id,\\n                children_summaries=children_summaries,\\n                dependency_summaries=dependency_summaries,\\n                import_details=import_details,\\n            )\\n        )\\n        if summary_return_context:\\n            if summary_return_context.summary:\\n                self.graph_manager.update_vertex_by_id(\\n                    model.id, summary_return_context.summary\\n                )\\n            self.prompt_tokens += summary_return_context.prompt_tokens\\n            self.completion_tokens += summary_return_context.completion_tokens\\n\\n            # for module_model in self.module_models_tuple:\\n            #     if isinstance(model, ModuleModel):\\n            #         if module_model.id == model.id:\\n            #             module_model.summary = model.summary\\n            #             break\\n            #         else:\\n            #             continue\\n            #     else:\\n            #         module_id_for_model: str = model.id.split(\\\"MODULE\\\")[0]\\n            #         if (\\n            #             module_model.children\\n            #             and module_id_for_model in module_model.id\\n            #         ):\\n            #             for child_model in module_model.children:\\n            #                 if child_model.id == model.id:\\n            #                     # child_model.summary = model.summary\\n            #                     break\\n            #         else:\\n            #             continue\\n\\n    pprint([model.id for model in summarization_map[::-1]])\\n    print(len(summarization_map))\\n\\n    return self.graph_manager.get_all_modules() if self.graph_manager else None\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":null,\"children\":null},{\"function_name\":\"_get_child_summaries\",\"docstring\":\"Gathers summaries of child models.\",\"decorators\":null,\"parameters\":null,\"returns\":\"list[str]\",\"is_method\":true,\"is_async\":false,\"id\":\"postcode:ai_services:summarizer:graph_db_summarization_manager.py__*__MODULE__*__CLASS-GraphDBSummarizationManager__*__FUNCTION-_get_child_summaries\",\"parent_id\":\"postcode:ai_services:summarizer:graph_db_summarization_manager.py__*__MODULE__*__CLASS-GraphDBSummarizationManager\",\"block_type\":\"FUNCTION\",\"start_line_num\":137,\"end_line_num\":151,\"code_content\":\"\\ndef _get_child_summaries(self, model: ModelType) -> list[str]:\\n    \\\"\\\"\\\"Gathers summaries of child models.\\\"\\\"\\\"\\n    child_summary_list: list[str] = []\\n    if model.children:\\n        for child in model.children:\\n            if child.summary:\\n                child_summary: str = child.summary\\n            else:\\n                child_summary = (\\n                    f\\\"Child ({child.id}) code content:\\\\n{child.code_content}\\\\n\\\"\\n                )\\n            child_summary_list.append(child_summary)\\n    return child_summary_list\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":null,\"children\":null},{\"function_name\":\"_stringify_children_summaries\",\"docstring\":\"Converts all of the child summaries to a single string to be used in the prompt.\",\"decorators\":null,\"parameters\":null,\"returns\":\"str\",\"is_method\":true,\"is_async\":false,\"id\":\"postcode:ai_services:summarizer:graph_db_summarization_manager.py__*__MODULE__*__CLASS-GraphDBSummarizationManager__*__FUNCTION-_stringify_children_summaries\",\"parent_id\":\"postcode:ai_services:summarizer:graph_db_summarization_manager.py__*__MODULE__*__CLASS-GraphDBSummarizationManager\",\"block_type\":\"FUNCTION\",\"start_line_num\":151,\"end_line_num\":159,\"code_content\":\"\\ndef _stringify_children_summaries(self, children_summary_list: list[str]) -> str:\\n    \\\"\\\"\\\"Converts all of the child summaries to a single string to be used in the prompt.\\\"\\\"\\\"\\n\\n    children_summaries: str = \\\"\\\"\\n    for child_summary in children_summary_list:\\n        children_summaries += f\\\"\\\\n{child_summary}\\\"\\n    return children_summaries\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":null,\"children\":null},{\"function_name\":\"_get_dependencies_summaries\",\"docstring\":null,\"decorators\":null,\"parameters\":null,\"returns\":\"str | None\",\"is_method\":true,\"is_async\":false,\"id\":\"postcode:ai_services:summarizer:graph_db_summarization_manager.py__*__MODULE__*__CLASS-GraphDBSummarizationManager__*__FUNCTION-_get_dependencies_summaries\",\"parent_id\":\"postcode:ai_services:summarizer:graph_db_summarization_manager.py__*__MODULE__*__CLASS-GraphDBSummarizationManager\",\"block_type\":\"FUNCTION\",\"start_line_num\":159,\"end_line_num\":199,\"code_content\":\"\\ndef _get_dependencies_summaries(self, model: ModelType) -> str | None:\\n    dependency_list: list[ImportModel | DependencyModel] | list[ImportModel] = []\\n    dependency_summary_list: list[str] = []\\n\\n    if isinstance(model, ModuleModel):\\n        if not model.imports:\\n            return None\\n\\n        dependency_list = model.imports\\n    else:\\n        if not model.dependencies:\\n            return None\\n\\n        dependency_list = model.dependencies\\n    for dependency in dependency_list:\\n        if isinstance(dependency, DependencyModel) and dependency.code_block_id:\\n            if module_local_dependency_summary := self._get_local_dependency_summary(\\n                dependency, model\\n            ):\\n                dependency_summary_list.append(module_local_dependency_summary)\\n\\n        elif isinstance(dependency, ImportModel):\\n            if dependency.import_module_type == \\\"LOCAL\\\":\\n                if not dependency.import_names:\\n                    if module_import_dependency := self._get_local_import_summary(\\n                        dependency\\n                    ):\\n                        dependency_summary_list.append(module_import_dependency)\\n                else:\\n                    if import_from_dependency := self._get_local_import_from_summary(\\n                        dependency\\n                    ):\\n                        dependency_summary_list.append(import_from_dependency)\\n\\n    dependency_summaries = self._stringify_dependencies_summaries(\\n        dependency_summary_list\\n    )\\n\\n    return dependency_summaries\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":null,\"children\":null},{\"function_name\":\"_get_local_dependency_summary\",\"docstring\":\"Gets a summary for a dependency local to the module.\",\"decorators\":null,\"parameters\":null,\"returns\":\"str | None\",\"is_method\":true,\"is_async\":false,\"id\":\"postcode:ai_services:summarizer:graph_db_summarization_manager.py__*__MODULE__*__CLASS-GraphDBSummarizationManager__*__FUNCTION-_get_local_dependency_summary\",\"parent_id\":\"postcode:ai_services:summarizer:graph_db_summarization_manager.py__*__MODULE__*__CLASS-GraphDBSummarizationManager\",\"block_type\":\"FUNCTION\",\"start_line_num\":199,\"end_line_num\":237,\"code_content\":\"\\n# def _get_import_details_for_dependencies(\\n#     self, dependencies: list[ImportModel | DependencyModel]\\n# ) -> str | None:\\n#     import_details: str | None = None\\n#     for dependency in dependencies:\\n#         if isinstance(dependency, ImportModel):\\n#             if dependency.import_module_type == \\\"LOCAL\\\":\\n#                 continue\\n#             else:\\n#                 import_detail: str | None = self._get_import_details(dependency)\\n#                 if not import_detail:\\n#                     continue\\n#                 if not import_details:\\n#                     import_details = \\\"\\\"\\n#                 import_details += f\\\"\\\\n{import_detail}\\\"\\n#     return import_details\\n\\ndef _get_local_dependency_summary(\\n    self,\\n    dependency: DependencyModel,\\n    model: ModelType,\\n) -> str | None:\\n    \\\"\\\"\\\"Gets a summary for a dependency local to the module.\\\"\\\"\\\"\\n    if not model.children:\\n        return None\\n\\n    for child_model in model.children:\\n        if child_model.id == dependency.code_block_id:\\n            child_summary: str | None = None\\n\\n            if child_model.summary:\\n                child_summary = child_model.summary\\n            else:\\n                child_summary = f\\\"Dependency ({dependency.code_block_id}) code content:\\\\n{child_model.code_content}\\\\n\\\"\\n\\n            return child_summary\\n    return None\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":null,\"children\":null},{\"function_name\":\"_stringify_dependencies_summaries\",\"docstring\":\"Converts all of the dependency summaries to a single string to be used in the prompt.\",\"decorators\":null,\"parameters\":null,\"returns\":\"str | None\",\"is_method\":true,\"is_async\":false,\"id\":\"postcode:ai_services:summarizer:graph_db_summarization_manager.py__*__MODULE__*__CLASS-GraphDBSummarizationManager__*__FUNCTION-_stringify_dependencies_summaries\",\"parent_id\":\"postcode:ai_services:summarizer:graph_db_summarization_manager.py__*__MODULE__*__CLASS-GraphDBSummarizationManager\",\"block_type\":\"FUNCTION\",\"start_line_num\":237,\"end_line_num\":249,\"code_content\":\"\\ndef _stringify_dependencies_summaries(\\n    self, dependencies_summary_list: list[str] | None\\n) -> str | None:\\n    \\\"\\\"\\\"Converts all of the dependency summaries to a single string to be used in the prompt.\\\"\\\"\\\"\\n    if not dependencies_summary_list:\\n        return None\\n\\n    dependency_summaries: str = \\\"\\\"\\n    for dependency_summary in dependencies_summary_list:\\n        dependency_summaries += f\\\"\\\\n{dependency_summary}\\\"\\n    return dependency_summaries\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":null,\"children\":null},{\"function_name\":\"_get_local_import_summary\",\"docstring\":null,\"decorators\":null,\"parameters\":null,\"returns\":\"str | None\",\"is_method\":true,\"is_async\":false,\"id\":\"postcode:ai_services:summarizer:graph_db_summarization_manager.py__*__MODULE__*__CLASS-GraphDBSummarizationManager__*__FUNCTION-_get_local_import_summary\",\"parent_id\":\"postcode:ai_services:summarizer:graph_db_summarization_manager.py__*__MODULE__*__CLASS-GraphDBSummarizationManager\",\"block_type\":\"FUNCTION\",\"start_line_num\":249,\"end_line_num\":260,\"code_content\":\"\\ndef _get_local_import_summary(self, dependency: ImportModel) -> str | None:\\n    for module_model in self.module_models_tuple:\\n        if module_model.id == dependency.local_module_id:\\n            import_summary: str | None = None\\n            if module_model.summary:\\n                import_summary = module_model.summary\\n            else:\\n                import_summary = f\\\"Imported module ({dependency.local_module_id}) code content:\\\\n{module_model.code_content}\\\\n\\\"\\n            return import_summary\\n    return None\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":null,\"children\":null},{\"function_name\":\"_get_local_import_from_summary\",\"docstring\":null,\"decorators\":null,\"parameters\":null,\"returns\":\"str | None\",\"is_method\":true,\"is_async\":false,\"id\":\"postcode:ai_services:summarizer:graph_db_summarization_manager.py__*__MODULE__*__CLASS-GraphDBSummarizationManager__*__FUNCTION-_get_local_import_from_summary\",\"parent_id\":\"postcode:ai_services:summarizer:graph_db_summarization_manager.py__*__MODULE__*__CLASS-GraphDBSummarizationManager\",\"block_type\":\"FUNCTION\",\"start_line_num\":260,\"end_line_num\":278,\"code_content\":\"\\ndef _get_local_import_from_summary(self, dependency: ImportModel) -> str | None:\\n    for import_name in dependency.import_names:\\n        for module_model in self.module_models_tuple:\\n            if module_model.id == dependency.local_module_id:\\n                if module_model.children:\\n                    for child_model in module_model.children:\\n                        if (\\n                            child_model.id == import_name.local_block_id\\n                            and child_model.id\\n                        ):\\n                            import_summary: str | None = None\\n                            if child_model.summary:\\n                                import_summary = child_model.summary\\n                            else:\\n                                import_summary = f\\\"Imported code block ({dependency.local_module_id}) code content:\\\\n{module_model.code_content}\\\\n\\\"\\n                            return import_summary\\n    return None\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":null,\"children\":null},{\"function_name\":\"_get_import_details\",\"docstring\":\"Retrieves details of import statements to be used in the prompt.\",\"decorators\":null,\"parameters\":null,\"returns\":\"str | None\",\"is_method\":true,\"is_async\":false,\"id\":\"postcode:ai_services:summarizer:graph_db_summarization_manager.py__*__MODULE__*__CLASS-GraphDBSummarizationManager__*__FUNCTION-_get_import_details\",\"parent_id\":\"postcode:ai_services:summarizer:graph_db_summarization_manager.py__*__MODULE__*__CLASS-GraphDBSummarizationManager\",\"block_type\":\"FUNCTION\",\"start_line_num\":278,\"end_line_num\":297,\"code_content\":\"\\ndef _get_import_details(self, import_model: ImportModel) -> str | None:\\n    \\\"\\\"\\\"Retrieves details of import statements to be used in the prompt.\\\"\\\"\\\"\\n    if import_model.import_module_type == \\\"LOCAL\\\" or not import_model.import_names:\\n        return None\\n\\n    import_names_list: list[str] = []\\n    for import_name in import_model.import_names:\\n        if import_name.as_name:\\n            import_names_list.append(f\\\"{import_name.name} as {import_name.as_name}\\\")\\n        else:\\n            import_names_list.append(f\\\"{import_name.name}\\\")\\n\\n    if import_model.imported_from:\\n        import_details: str = f\\\"from {import_model.imported_from} import {', '.join(import_names_list)}\\\"\\n    else:\\n        import_details = f\\\"import {', '.join(import_names_list)}\\\"\\n\\n    return import_details\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":null,\"children\":null}]}]}", "chroma:document": "\nSummary:\n\n        postcode:ai_services:summarizer:graph_db_summarization_manager.py__*__MODULE\n\n        \nChild (postcode:ai_services:summarizer:graph_db_summarization_manager.py__*__MODULE__*__STANDALONE_BLOCK-1) code content:\nModelType = Union[\n    ModuleModel,\n    ClassModel,\n    FunctionModel,\n    StandaloneCodeBlockModel,\n]\n\n\nChild (postcode:ai_services:summarizer:graph_db_summarization_manager.py__*__MODULE__*__CLASS-GraphDBSummarizationManager) code content:\n\n\nclass GraphDBSummarizationManager:\n    def __init__(\n        self,\n        module_models_tuple: tuple[ModuleModel, ...],\n        summarization_mapper: SummarizationMapper,\n        summarizer: Summarizer,\n        graph_manager: ArangoDBManager,\n    ) -> None:\n        self.module_models_tuple: tuple[ModuleModel, ...] = module_models_tuple\n        self.summarization_mapper: SummarizationMapper = summarization_mapper\n        self.summarizer: Summarizer = summarizer\n        self.summarized_code_block_ids: set[str] = set()\n        self.prompt_tokens: int = 0\n        self.completion_tokens: int = 0\n        self.graph_manager: ArangoDBManager = graph_manager\n\n    @property\n    def total_cost(self) -> float:\n        \"\"\"Provides the total cost of the summarization process.\"\"\"\n        prompt_cost: int = self.prompt_tokens * 1  # Costs 1 cent per 1,000 tokens\n        completion_cost: int = (\n            self.completion_tokens * 3\n        )  # Costs 3 cents per 1,000 tokens\n        return (prompt_cost + completion_cost) / 100_000  # Convert to dollars\n\n    def create_summaries_and_return_updated_models(self) -> list[ModuleModel] | None:\n        summarization_map: list[\n            ModelType\n        ] = self.summarization_mapper.create_summarization_map()\n        models_to_summarize_count: int = len(summarization_map)\n        models_summarized_count: int = 0\n\n        for model in summarization_map:\n            children_summaries: str | None = None\n            dependency_summaries: str | None = None\n            import_details: str | None = None\n\n            if model.children:\n                children_summaries: str | None = self._stringify_children_summaries(\n                    self._get_child_summaries(model)\n                )\n            if isinstance(model, ModuleModel):\n                if model.imports:\n                    dependency_summaries = self._get_dependencies_summaries(model)\n                    import_details = \"\"\n                    for _import in model.imports:\n                        if import_summary := self._get_import_details(_import):\n                            import_details += f\"\\n{import_summary}\"\n            else:\n                if model.dependencies:\n                    dependency_summaries = self._get_dependencies_summaries(model)\n                    import_details = \"\"\n                    for dependency in model.dependencies:\n                        if isinstance(dependency, DependencyModel):\n                            continue\n                        if import_summary := self._get_import_details(dependency):\n                            import_details += f\"\\n{import_summary}\"\n\n            models_summarized_count += 1\n            logging.info(\n                f\"Summarizing model {models_summarized_count} out of {models_to_summarize_count}; {model.id}.\"\n            )\n\n            summary_return_context: OpenAIReturnContext | None = (\n                self.summarizer.test_summarize_code(\n                    model.code_content,\n                    model_id=model.id,\n                    children_summaries=children_summaries,\n                    dependency_summaries=dependency_summaries,\n                    import_details=import_details,\n                )\n            )\n            if summary_return_context:\n                if summary_return_context.summary:\n                    self.graph_manager.update_vertex_by_id(\n                        model.id, summary_return_context.summary\n                    )\n                self.prompt_tokens += summary_return_context.prompt_tokens\n                self.completion_tokens += summary_return_context.completion_tokens\n\n                # for module_model in self.module_models_tuple:\n                #     if isinstance(model, ModuleModel):\n                #         if module_model.id == model.id:\n                #             module_model.summary = model.summary\n                #             break\n                #         else:\n                #             continue\n                #     else:\n                #         module_id_for_model: str = model.id.split(\"MODULE\")[0]\n                #         if (\n                #             module_model.children\n                #             and module_id_for_model in module_model.id\n                #         ):\n                #             for child_model in module_model.children:\n                #                 if child_model.id == model.id:\n                #                     # child_model.summary = model.summary\n                #                     break\n                #         else:\n                #             continue\n\n        pprint([model.id for model in summarization_map[::-1]])\n        print(len(summarization_map))\n\n        return self.graph_manager.get_all_modules() if self.graph_manager else None\n\n    def _get_child_summaries(self, model: ModelType) -> list[str]:\n        \"\"\"Gathers summaries of child models.\"\"\"\n        child_summary_list: list[str] = []\n        if model.children:\n            for child in model.children:\n                if child.summary:\n                    child_summary: str = child.summary\n                else:\n                    child_summary = (\n                        f\"Child ({child.id}) code content:\\n{child.code_content}\\n\"\n                    )\n                child_summary_list.append(child_summary)\n        return child_summary_list\n\n    def _stringify_children_summaries(self, children_summary_list: list[str]) -> str:\n        \"\"\"Converts all of the child summaries to a single string to be used in the prompt.\"\"\"\n\n        children_summaries: str = \"\"\n        for child_summary in children_summary_list:\n            children_summaries += f\"\\n{child_summary}\"\n        return children_summaries\n\n    def _get_dependencies_summaries(self, model: ModelType) -> str | None:\n        dependency_list: list[ImportModel | DependencyModel] | list[ImportModel] = []\n        dependency_summary_list: list[str] = []\n\n        if isinstance(model, ModuleModel):\n            if not model.imports:\n                return None\n\n            dependency_list = model.imports\n        else:\n            if not model.dependencies:\n                return None\n\n            dependency_list = model.dependencies\n        for dependency in dependency_list:\n            if isinstance(dependency, DependencyModel) and dependency.code_block_id:\n                if module_local_dependency_summary := self._get_local_dependency_summary(\n                    dependency, model\n                ):\n                    dependency_summary_list.append(module_local_dependency_summary)\n\n            elif isinstance(dependency, ImportModel):\n                if dependency.import_module_type == \"LOCAL\":\n                    if not dependency.import_names:\n                        if module_import_dependency := self._get_local_import_summary(\n                            dependency\n                        ):\n                            dependency_summary_list.append(module_import_dependency)\n                    else:\n                        if import_from_dependency := self._get_local_import_from_summary(\n                            dependency\n                        ):\n                            dependency_summary_list.append(import_from_dependency)\n\n        dependency_summaries = self._stringify_dependencies_summaries(\n            dependency_summary_list\n        )\n\n        return dependency_summaries\n\n    # def _get_import_details_for_dependencies(\n    #     self, dependencies: list[ImportModel | DependencyModel]\n    # ) -> str | None:\n    #     import_details: str | None = None\n    #     for dependency in dependencies:\n    #         if isinstance(dependency, ImportModel):\n    #             if dependency.import_module_type == \"LOCAL\":\n    #                 continue\n    #             else:\n    #                 import_detail: str | None = self._get_import_details(dependency)\n    #                 if not import_detail:\n    #                     continue\n    #                 if not import_details:\n    #                     import_details = \"\"\n    #                 import_details += f\"\\n{import_detail}\"\n    #     return import_details\n\n    def _get_local_dependency_summary(\n        self,\n        dependency: DependencyModel,\n        model: ModelType,\n    ) -> str | None:\n        \"\"\"Gets a summary for a dependency local to the module.\"\"\"\n        if not model.children:\n            return None\n\n        for child_model in model.children:\n            if child_model.id == dependency.code_block_id:\n                child_summary: str | None = None\n\n                if child_model.summary:\n                    child_summary = child_model.summary\n                else:\n                    child_summary = f\"Dependency ({dependency.code_block_id}) code content:\\n{child_model.code_content}\\n\"\n\n                return child_summary\n        return None\n\n    def _stringify_dependencies_summaries(\n        self, dependencies_summary_list: list[str] | None\n    ) -> str | None:\n        \"\"\"Converts all of the dependency summaries to a single string to be used in the prompt.\"\"\"\n        if not dependencies_summary_list:\n            return None\n\n        dependency_summaries: str = \"\"\n        for dependency_summary in dependencies_summary_list:\n            dependency_summaries += f\"\\n{dependency_summary}\"\n        return dependency_summaries\n\n    def _get_local_import_summary(self, dependency: ImportModel) -> str | None:\n        for module_model in self.module_models_tuple:\n            if module_model.id == dependency.local_module_id:\n                import_summary: str | None = None\n                if module_model.summary:\n                    import_summary = module_model.summary\n                else:\n                    import_summary = f\"Imported module ({dependency.local_module_id}) code content:\\n{module_model.code_content}\\n\"\n                return import_summary\n        return None\n\n    def _get_local_import_from_summary(self, dependency: ImportModel) -> str | None:\n        for import_name in dependency.import_names:\n            for module_model in self.module_models_tuple:\n                if module_model.id == dependency.local_module_id:\n                    if module_model.children:\n                        for child_model in module_model.children:\n                            if (\n                                child_model.id == import_name.local_block_id\n                                and child_model.id\n                            ):\n                                import_summary: str | None = None\n                                if child_model.summary:\n                                    import_summary = child_model.summary\n                                else:\n                                    import_summary = f\"Imported code block ({dependency.local_module_id}) code content:\\n{module_model.code_content}\\n\"\n                                return import_summary\n        return None\n\n    def _get_import_details(self, import_model: ImportModel) -> str | None:\n        \"\"\"Retrieves details of import statements to be used in the prompt.\"\"\"\n        if import_model.import_module_type == \"LOCAL\" or not import_model.import_names:\n            return None\n\n        import_names_list: list[str] = []\n        for import_name in import_model.import_names:\n            if import_name.as_name:\n                import_names_list.append(f\"{import_name.name} as {import_name.as_name}\")\n            else:\n                import_names_list.append(f\"{import_name.name}\")\n\n        if import_model.imported_from:\n            import_details: str = f\"from {import_model.imported_from} import {', '.join(import_names_list)}\"\n        else:\n            import_details = f\"import {', '.join(import_names_list)}\"\n\n        return import_details\n\n, \nImported code block (postcode:ai_services:summarizer:summarization_context.py__*__MODULE) code content:\nfrom typing import Literal, Protocol\nfrom dataclasses import dataclass\n\nfrom pydantic import BaseModel\n\nfrom postcode.ai_services.summarizer.prompts import summarization_prompts\n\n\nclass SummaryCompletionConfigs(BaseModel):\n    \"\"\"\n    Configs for the summarization completion.\n\n    Used to set the chat completion parameters for the OpenAI chat completions method call.\n\n    Args:\n        - system_message (str): The system message used for chat completion.\n        - model (str): The model to use for the completion. Default is \"gpt-4-1106-preview\".\n        - max_tokens (int | None): The maximum number of tokens to generate. 'None' implies no limit. Default is None.\n        - stream (bool): Whether to stream back partial progress. Default is False.\n        - temperature (float): Sampling temperature to use. Default is 0.0.\n\n    Notes:\n        - model must be a valid OpenAI model name.\n\n    Examples:\n        ```Python\n        system_message = \"Summarize the following code.\"\n        summary_completion_configs = SummaryCompletionConfigs(\n            system_message=system_message,\n            model=\"gpt-4-1106-preview\",\n            max_tokens=100,\n            presence_penalty=0.0,\n            stream=False,\n            temperature=0.0,\n        )\n        ```\n    \"\"\"\n\n    system_message: str = summarization_prompts.SUMMARIZER_DEFAULT_INSTRUCTIONS\n    model: Literal[\n        \"gpt-4-1106-preview\",\n        \"gpt-4-vision-preview\",\n        \"gpt-4\",\n        \"gpt-4-0314\",\n        \"gpt-4-0613\",\n        \"gpt-4-32k\",\n        \"gpt-4-32k-0314\",\n        \"gpt-4-32k-0613\",\n        \"gpt-3.5-turbo-1106\",\n        \"gpt-3.5-turbo\",\n        \"gpt-3.5-turbo-16k\",\n        \"gpt-3.5-turbo-0301\",\n        \"gpt-3.5-turbo-0613\",\n        \"gpt-3.5-turbo-16k-0613\",\n    ] = \"gpt-4-1106-preview\"\n    max_tokens: int | None = None\n    stream: bool = False\n    temperature: float = 0.0\n\n\n@dataclass\nclass OpenAIReturnContext:\n    \"\"\"\n    A dataclass for storing the return context of an OpenAI completion.\n\n    Attributes:\n        - prompt_tokens (int): The number of tokens in the prompt.\n        - completion_tokens (int): The number of tokens in the completion.\n        - summary (str | None): The summary of the code snippet.\n    \"\"\"\n\n    prompt_tokens: int\n    completion_tokens: int\n    summary: str | None\n\n\nclass Summarizer(Protocol):\n    def summarize_code(\n        self,\n        code: str,\n        *,\n        model_id: str,\n        children_summaries: str | None,\n        dependency_summaries: str | None,\n        import_details: str | None,\n        configs: SummaryCompletionConfigs = SummaryCompletionConfigs(),\n    ) -> OpenAIReturnContext | None:\n        \"\"\"\n        Summarizes the provided code snippet using the OpenAI API.\n\n        Args:\n            - code (str): The code snippet to summarize.\n            - configs (SummaryCompletionConfigs, optional): Configuration settings for the summarization.\n                Defaults to SummaryCompletionConfigs().\n\n        Returns:\n            str: The summary of the provided code snippet.\n\n        Examples:\n            ```Python\n            client = OpenAI()\n\n            # Create a summarizer instance with the OpenAI client\n            summarizer = Summarizer(client=client)\n            code_example = \"print('Hello, world')\"\n\n            # Summarize the code snippet\n            summary = summarizer.summarize_code(code_example)\n            print(summary)\n            ```\n        \"\"\"\n        ...\n\n    def test_summarize_code(\n        self,\n        code: str,\n        *,\n        model_id: str,\n        children_summaries: str | None,\n        dependency_summaries: str | None,\n        import_details: str | None,\n        configs: SummaryCompletionConfigs = SummaryCompletionConfigs(),\n    ) -> OpenAIReturnContext | None:\n        \"\"\"\n        A method for testing whether or not a summary path is working as expected.\n\n        Args:\n            - code (str): The code snippet to summarize (pass in dummy string).\n            - configs (SummaryCompletionConfigs, optional): Configuration settings for the summarization.\n                Defaults to SummaryCompletionConfigs().\n\n        Returns:\n            str: The summary of the provided code snippet.\n\n        Examples:\n            ```Python\n            client = OpenAI()\n            summarizer = Summarizer(client=client)\n            code_example = \"print('Hello, world')\"\n\n            # Run summary tester the code snippet\n            summary = summarizer.summarize_code(code_example)\n            print(summary)\n            ```\n        \"\"\"\n        ...\n\n\nImported code block (postcode:ai_services:summarizer:summarization_mapper.py__*__MODULE) code content:\nimport logging\nfrom pprint import pprint\nfrom typing import Union\nfrom postcode.databases.arangodb.arangodb_manager import ArangoDBManager\nfrom postcode.models.models import (\n    ClassModel,\n    FunctionModel,\n    ModuleModel,\n    StandaloneCodeBlockModel,\n)\n\n# from postcode.types.postcode import ModelType\n\nModelType = Union[\n    ModuleModel,\n    ClassModel,\n    FunctionModel,\n    StandaloneCodeBlockModel,\n]\n\n\nclass SummarizationMapper:\n    def __init__(\n        self,\n        module_ids_to_update: list[str],\n        module_models: tuple[ModuleModel, ...],\n        arangodb_manager: ArangoDBManager,\n    ) -> None:\n        self.module_ids_to_update: list[str] = module_ids_to_update\n        self.module_models: tuple[ModuleModel, ...] = module_models\n        self.arangodb_manager: ArangoDBManager = arangodb_manager\n        self.models_to_update: list[ModelType] = []\n        self.model_visited_in_db: set[str] = set()\n        self.summarization_map: list[ModelType] = []\n        self.temp_map: list[ModelType] = []\n\n    def _set_child_models_to_update(self, model: ModelType) -> None:\n        if model.children:\n            for child in model.children:\n                # logging.info(f\"Setting child model to update: {child.id}\")\n                self._set_child_models_to_update(child)\n                child.summary = None\n                self.models_to_update.append(child)\n            self.models_to_update.append(model)\n\n    def _set_models_to_update(self) -> None:\n        for model in self.module_models:\n            if model.id in self.module_ids_to_update:\n                if model.children:\n                    for child in model.children:\n                        self._set_child_models_to_update(child)\n\n                model.summary = None\n                self.models_to_update.append(model)\n\n    def _set_inbound_models_in_summarization_map(self, model_id: str) -> None:\n        if model_id in self.model_visited_in_db:\n            return\n        self.model_visited_in_db.add(model_id)\n        if inbound_models := self.arangodb_manager.get_inbound_models(model_id):\n            for model in inbound_models:\n                # logging.info(f\"Setting inbound models in summarization map: {model.id}\")\n                self.model_visited_in_db.add(model_id)\n                self._set_inbound_models_in_summarization_map(model.id)\n\n                self.temp_map.append(model)\n\n    def _set_outbound_models_in_summarization_map(self, model_id: str) -> None:\n        if model_id in self.model_visited_in_db:\n            return\n\n        if outbound_models := self.arangodb_manager.get_outbound_models(model_id):\n            for model in outbound_models[::-1]:\n                # logging.info(\n                #     f\"Setting outbound models in summarization map: {model.id}\"\n                # )\n                self.model_visited_in_db.add(model_id)\n                # self._set_outbound_models_in_summarization_map(model.id)``\n\n                if model.id in self.models_to_update:\n                    model.summary = None\n                self.temp_map.append(model)\n\n    def create_summarization_map(self) -> list[ModelType]:\n        self._set_models_to_update()\n        logging.info(\"Set models to update\")\n\n        # pprint([model.id for model in self.models_to_update])\n\n        for model in self.models_to_update:\n            # self.model_visited_in_db = set()\n            # logging.info(f\"Setting inbound models in summarization map: {model.id}\")\n            self._set_inbound_models_in_summarization_map(model.id)\n            self.temp_map.append(model)\n\n            self.model_visited_in_db.remove(model.id)\n            # logging.info(f\"Setting outbound models in summarization map: {model.id}\")\n            # self._set_outbound_models_in_summarization_map(model.id)\n            self.summarization_map.extend(self.temp_map)\n            self.temp_map = []\n\n        for model in self.models_to_update:\n            self.model_visited_in_db = set()\n            # logging.info(f\"Setting outbound models in summarization map: {model.id}\")\n            self._set_outbound_models_in_summarization_map(model.id)\n            self.summarization_map.extend(self.temp_map)\n            self.temp_map = []\n\n        logging.info(\"Created summarization map\")\n        summary_ids: set[str] = set()\n        summary_map: list[ModelType] = []\n        for model in self.summarization_map[::-1]:\n            if model.id not in summary_ids:\n                summary_map.append(model)\n                summary_ids.add(model.id)\n\n        # return summary_map[::-1]\n        pprint([model.id for model in summary_map[::-1]])\n        return summary_map[::-1]\n\n    # def old_create_summarization_map(self) -> list[list[ModelType]]:\n    #     for module_id in self.module_ids_to_update:\n    #         models_to_update: list[ModelType] = []\n\n    #         upstream_models: list[\n    #             ModelType\n    #         ] | None = self.arangodb_manager.get_all_upstream_vertices(module_id)\n    #         downstream_models: list[\n    #             ModelType\n    #         ] | None = self.arangodb_manager.get_all_downstream_vertices(module_id)\n\n    #         ids_from_db: list[str] = []\n    #         if upstream_models:\n    #             upstream_ids_to_update: list[str] = [\n    #                 model.id for model in upstream_models\n    #             ]\n    #             ids_from_db.extend(upstream_ids_to_update)\n\n    #         ids_from_db.append(module_id)\n\n    #         if downstream_models:\n    #             downstream_ids_to_update: list[str] = [\n    #                 model.id for model in downstream_models\n    #             ]\n    #             ids_from_db.extend(downstream_ids_to_update)\n\n    #         for id in ids_from_db:\n    #             for model in self.module_models:\n    #                 if model.id == id:\n    #                     models_to_update.append(model)\n    #                 elif model.children:\n    #                     for child in model.children:\n    #                         if child.id == id:\n    #                             models_to_update.append(child)\n\n    #         self.summarization_map.append(models_to_update)\n\n    #     return self.summarization_map\n\n\nImported code block (postcode:databases:arangodb:arangodb_manager.py__*__MODULE) code content:\nimport logging\nfrom typing import Any, Callable, Union\n\nfrom arango.result import Result\nfrom arango.cursor import Cursor\nfrom arango.graph import Graph\nfrom arango.collection import StandardCollection\nfrom arango.typings import Json\n\nfrom postcode.databases.arangodb.arangodb_connector import ArangoDBConnector\n\n# from postcode.types.postcode import ModelType\nfrom postcode.models.models import (\n    ClassModel,\n    FunctionModel,\n    ModuleModel,\n    StandaloneCodeBlockModel,\n)\nimport postcode.databases.arangodb.helper_functions as helper_functions\n\nModelType = Union[\n    ModuleModel,\n    ClassModel,\n    FunctionModel,\n    StandaloneCodeBlockModel,\n]\n\n# NOTE: Remember, when adding logic to connect dependencies, the `from` the external dependency `to` the internal definition using it\n\n\nclass ArangoDBManager:\n    def __init__(\n        self,\n        db_connector: ArangoDBConnector,\n        default_graph_name: str = \"codebase_graph\",\n    ) -> None:\n        self.db_connector: ArangoDBConnector = db_connector\n\n        self.processed_id_set = set()\n        self.default_graph_name: str = default_graph_name\n\n    def upsert_models(self, module_models: list[ModuleModel]) -> \"ArangoDBManager\":\n        for model in module_models:\n            self._upsert_model(model)\n        return self\n\n    def _upsert_model(self, module_model: ModuleModel) -> None:\n        self._upsert_vertex(module_model, \"modules\")\n        self._process_children(module_model)\n\n    def _process_children(self, parent_model: ModelType) -> None:\n        if not parent_model.children:\n            return None\n\n        for child in parent_model.children:\n            # if child.id in self.processed_id_set:\n            #     continue\n\n            self.processed_id_set.add(child.id)\n            self._upsert_vertex(\n                child, helper_functions.pluralize_block_type(child.block_type)\n            )\n\n            if child.children:\n                self._process_children(child)\n\n    def _upsert_vertex(self, model: ModelType, collection_name: str) -> None:\n        model_data: dict[str, Any] = model.model_dump()\n        model_data[\"_key\"] = model.id\n\n        try:\n            self.db_connector.ensure_collection(\n                collection_name, model.model_json_schema()\n            )\n            query: str = f\"\"\"\n            UPSERT {{_key: @key}}\n            INSERT @doc\n            UPDATE @doc\n            IN {collection_name}\n            \"\"\"\n            bind_vars: dict[str, Any] = {\"key\": model.id, \"doc\": model_data}\n            self.db_connector.db.aql.execute(query, bind_vars=bind_vars)\n\n            if not isinstance(model, ModuleModel) and model.parent_id:\n                parent_type: str = self._get_collection_from_id(model.parent_id)\n                self._upsert_edge(\n                    model.id, model.parent_id, collection_name, parent_type\n                )\n        except Exception as e:\n            logging.error(f\"Error upserting {collection_name} vertex (ArangoDB): {e}\")\n\n    def _upsert_edge(\n        self, from_key: str, to_key: str, source_type: str, target_type: str\n    ) -> None:\n        source_string: str = f\"{source_type}/{from_key}\"\n        target_string: str = f\"{target_type}/{to_key}\"\n\n        edge_data: dict[str, str] = {\n            \"_from\": source_string,\n            \"_to\": target_string,\n            \"source_type\": source_type,\n            \"target_type\": target_type,\n        }\n\n        try:\n            self.db_connector.ensure_edge_collection(\"code_edges\")\n            query = f\"\"\"\n            UPSERT {{_from: @from, _to: @to}}\n            INSERT @doc\n            UPDATE @doc\n            IN code_edges\n            \"\"\"\n            bind_vars = {\n                \"from\": edge_data[\"_from\"],\n                \"to\": edge_data[\"_to\"],\n                \"doc\": edge_data,\n            }\n            self.db_connector.db.aql.execute(query, bind_vars=bind_vars)\n        except Exception as e:\n            logging.error(f\"Error upserting edge (ArangoDB): {e}\")\n\n    def _get_collection_from_id(self, block_id: str) -> str:\n        block_id_parts: list[str] = block_id.split(\"__*__\")\n        block_type_part: str = block_id_parts[-1]\n\n        block_type_functions: dict[str, Callable[..., str]] = {\n            \"MODULE\": lambda: \"modules\",\n            \"CLASS\": lambda: \"classes\",\n            \"FUNCTION\": lambda: \"functions\",\n            \"STANDALONE_BLOCK\": lambda: \"standalone_blocks\",\n        }\n\n        for key, func in block_type_functions.items():\n            if block_type_part.startswith(key):\n                return func()\n\n        return \"unknown\"\n\n    def process_imports_and_dependencies(self) -> \"ArangoDBManager\":\n        for vertex_collection in helper_functions.pluralized_and_lowered_block_types():\n            cursor: Result[Cursor] = self.db_connector.db.collection(\n                vertex_collection\n            ).all()\n            if isinstance(cursor, Cursor):\n                for vertex in cursor:\n                    vertex_key = vertex[\"_key\"]\n                    if vertex_collection == \"modules\":\n                        self._create_edges_for_imports(\n                            vertex_key, vertex.get(\"imports\", [])\n                        )\n                    else:\n                        self._create_edges_for_dependencies(\n                            vertex_key, vertex.get(\"dependencies\", [])\n                        )\n            else:\n                logging.error(\n                    f\"Error getting cursor for vertex collection: {vertex_collection}\"\n                )\n        return self\n\n    def _create_edges_for_imports(\n        self, module_key: str, imports: list[dict[str, Any]]\n    ) -> None:\n        if not imports:\n            # logging.debug(f\"No imports found for module {module_key}\")\n            return\n\n        # logging.info(f\"Processing imports for module {module_key}\")\n\n        for _import in imports:\n            import_names: list[dict[str, str]] = _import.get(\"import_names\", [])\n            if not import_names:\n                # logging.debug(f\"No import names found in import {_import}\")\n                continue\n\n            for import_name in import_names:\n                local_block_id: str | None = import_name.get(\"local_block_id\")\n\n                if local_block_id:\n                    target_type = self._get_collection_from_id(local_block_id)\n                    try:\n                        self._upsert_edge(\n                            local_block_id, module_key, target_type, \"modules\"\n                        )\n\n                        # logging.info(\n                        #     f\"Upserted edge for import {module_key} to {local_block_id}\"\n                        # )\n                    except Exception as e:\n                        logging.error(\n                            f\"Error creating edge for import {module_key} to {local_block_id}: {e}\"\n                        )\n                else:\n                    # logging.warning(\n                    #     f\"Skipped import {import_name} in module {module_key}\"\n                    # )\n                    ...\n\n    def _create_edges_for_dependencies(\n        self, block_key: str, dependencies: list[dict[str, Any]]\n    ) -> None:\n        if not dependencies:\n            return\n\n        for dependency in dependencies:\n            code_block_id: str | None = dependency.get(\"code_block_id\")\n            if code_block_id:\n                source_type: str = self._get_collection_from_id(code_block_id)\n                target_type: str = self._get_collection_from_id(block_key)\n                try:\n                    self._upsert_edge(\n                        code_block_id, block_key, source_type, target_type\n                    )\n                    # logging.info(\n                    #     f\"Upserted edge for dependency {block_key} to {code_block_id}\"\n                    # )\n                except Exception as e:\n                    logging.error(\n                        f\"Error creating edge for dependency {block_key} to {code_block_id}: {e}\"\n                    )\n\n    def delete_vertex_by_id(\n        self, vertex_key: str, graph_name: str | None = None\n    ) -> None:\n        collection_name: str = self._get_collection_from_id(vertex_key)\n        if collection_name == \"unknown\":\n            logging.error(f\"Unknown vertex type for key: {vertex_key}\")\n            return None\n\n        if not graph_name:\n            graph_name = self.default_graph_name\n\n        try:\n            vertex_coll = self.db_connector.db.graph(graph_name).vertex_collection(\n                collection_name\n            )\n\n            vertex_coll.delete(vertex_key)\n\n            # logging.info(\n            #     f\"Vertex '{vertex_key}' from collection '{collection_name}' was successfully deleted.\"\n            # )\n\n        except Exception as e:\n            logging.error(\n                f\"Error deleting vertex '{vertex_key}' from collection '{collection_name}': {e}\"\n            )\n\n    def get_graph(self, graph_name: str | None = None) -> Graph | None:\n        if not graph_name:\n            graph_name = self.default_graph_name\n        try:\n            return self.db_connector.db.graph(self.default_graph_name)\n        except Exception as e:\n            logging.error(f\"Error getting graph '{self.default_graph_name}': {e}\")\n            return None\n\n    def get_or_create_graph(self, graph_name: str | None = None) -> Result[Graph]:\n        if not graph_name:\n            graph_name = self.default_graph_name\n\n        try:\n            if not self.db_connector.db.has_graph(graph_name):\n                edge_definitions: list[dict[str, str | list[str]]] = [\n                    {\n                        \"edge_collection\": \"code_edges\",\n                        \"from_vertex_collections\": helper_functions.pluralized_and_lowered_block_types(),\n                        \"to_vertex_collections\": helper_functions.pluralized_and_lowered_block_types(),\n                    }\n                ]\n\n                # logging.info(f\"Graph '{graph_name}' created successfully.\")\n                return self.db_connector.db.create_graph(\n                    graph_name, edge_definitions=edge_definitions\n                )\n\n            else:\n                return self.get_graph()\n\n        except Exception as e:\n            logging.error(f\"Error creating graph '{graph_name}': {e}\")\n\n    def delete_graph(self, graph_name: str | None = None) -> None:\n        if not graph_name:\n            graph_name = self.default_graph_name\n        try:\n            self.db_connector.db.delete_graph(graph_name)\n            logging.info(f\"Graph '{graph_name}' deleted successfully.\")\n        except Exception as e:\n            logging.error(f\"Error deleting graph '{graph_name}': {e}\")\n\n    def get_outbound_models(self, start_key: str) -> list[ModelType] | None:\n        vertex_type: str = self._get_collection_from_id(start_key)\n\n        query: str = f\"\"\"\n        FOR v, e, p IN 1..100 OUTBOUND '{vertex_type}/{start_key}' GRAPH '{self.default_graph_name}'\n        RETURN DISTINCT v\n        \"\"\"\n        # query: str = f\"\"\"\n        # FOR v, e, p IN 1..100 OUTBOUND '{vertex_type}/{start_key}' GRAPH '{self.default_graph_name}'\n        # FILTER LENGTH(p.edges[* FILTER CURRENT != e]) == 0\n        # RETURN DISTINCT v\n        # \"\"\"\n        # query: str = f\"\"\"\n        # FOR v, e, p IN 1..100 OUTBOUND '{vertex_type}/{start_key}' GRAPH '{self.default_graph_name}'\n        # FILTER LENGTH(p.edges[* FILTER CURRENT != e]) == 0\n        #     AND p.edges[*].distance ALL == 1\n        # RETURN DISTINCT v\n        # \"\"\"\n\n        try:\n            cursor = self.db_connector.db.aql.execute(query)\n            if isinstance(cursor, Cursor):\n                return [\n                    helper_functions.create_model_from_vertex(doc) for doc in cursor\n                ]\n            else:\n                logging.error(f\"Error getting cursor for query: {query}\")\n                return None\n        except Exception as e:\n            logging.error(f\"Error in get_all_downstream_vertices: {e}\")\n            return None\n\n    def get_inbound_models(self, end_key: str) -> list[ModelType] | None:\n        vertex_type: str = self._get_collection_from_id(end_key)\n\n        query: str = f\"\"\"\n        FOR v, e, p IN 1..100 INBOUND '{vertex_type}/{end_key}' GRAPH '{self.default_graph_name}'\n        RETURN DISTINCT v\n        \"\"\"\n\n        # query: str = f\"\"\"\n        # FOR v, e, p IN 1..100 INBOUND '{vertex_type}/{end_key}' GRAPH '{self.default_graph_name}'\n        # FILTER LENGTH(p.edges[* FILTER CURRENT != e]) == 0\n        # RETURN DISTINCT v\n        # \"\"\"\n\n        try:\n            cursor: Result[Cursor] = self.db_connector.db.aql.execute(query)\n            if isinstance(cursor, Cursor):\n                return [\n                    helper_functions.create_model_from_vertex(doc) for doc in cursor\n                ]\n            else:\n                logging.error(f\"Error getting cursor for query: {query}\")\n                return None\n        except Exception as e:\n            logging.error(f\"Error in get_all_upstream_vertices: {e}\")\n            return None\n\n    def update_vertex_by_id(self, id: str, new_summary: str) -> None:\n        try:\n            collection_name: str = self._get_collection_from_id(id)\n            if collection_name == \"unknown\":\n                logging.error(f\"Unknown vertex type for id: {id}\")\n                return\n\n            vertex_collection: StandardCollection = self.db_connector.db.collection(\n                collection_name\n            )\n            vertex_result: Result[Json | None] = vertex_collection.get(id)\n\n            if not vertex_result:\n                logging.error(f\"Vertex with id {id} not found.\")\n                return\n\n            if isinstance(vertex_result, dict):\n                vertex = vertex_result\n            else:\n                logging.error(\"Retrieved vertex is not in a mutable format.\")\n                return None\n\n            vertex[\"summary\"] = new_summary\n\n            vertex_collection.update(vertex)\n            logging.info(f\"Vertex with id {id} updated successfully.\")\n\n        except Exception as e:\n            logging.error(f\"Error in `update_vertex_by_id`: {e}\")\n\n    def get_all_modules(self) -> list[ModuleModel] | None:\n        try:\n            # Define the collection name for modules.\n            collection_name = \"modules\"\n            module_collection: StandardCollection = self.db_connector.db.collection(\n                collection_name\n            )\n\n            # Retrieve all documents from the modules collection.\n            cursor: Result[Cursor] = module_collection.all()\n\n            # Convert each document to a ModuleModel instance.\n            modules: list[ModuleModel] = []\n            for doc in cursor:  # type: ignore # FIXME: Fix type error\n                # Ensure the document is a dictionary.\n                try:\n                    # Convert the document to a ModuleModel instance and add it to the list.\n                    module = ModuleModel(**doc)\n                    modules.append(module)\n                except Exception as e:\n                    logging.error(f\"Retrieved document is not in a valid format: {e}\")\n                    continue\n\n            return modules\n\n        except Exception as e:\n            logging.error(f\"Error in get_all_modules: {e}\")\n            return None\n\n\nImported code block (postcode:models:models.py__*__MODULE) code content:\nfrom typing import Union\nfrom pydantic import BaseModel, Field, validator\n\nfrom postcode.models.enums import (\n    BlockType,\n    ImportModuleType,\n    CommentType,\n)\n\n\nclass ImportNameModel(BaseModel):\n    \"\"\"Class representing the name of an import.\"\"\"\n\n    name: str\n    as_name: str | None = None\n    local_block_id: str | None = None\n\n    # def convert_import_names_to_metadata(self) -> str:\n    #     \"\"\"Converts the import name to a metadata string.\"\"\"\n\n    #     return self.model_dump_json()\n\n\nclass ImportModel(BaseModel):\n    \"\"\"Class representing an import statement.\"\"\"\n\n    import_names: list[ImportNameModel]\n    imported_from: str | None = None\n    import_module_type: ImportModuleType = ImportModuleType.STANDARD_LIBRARY\n    local_module_id: str | None = None\n\n    def convert_import_to_metadata(self) -> str:\n        \"\"\"Converts the import to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass DependencyModel(BaseModel):\n    \"\"\"Class representing a module dependency.\"\"\"\n\n    code_block_id: str\n\n    def convert_dependency_to_metadata(self) -> str:\n        \"\"\"Converts the dependency to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass CommentModel(BaseModel):\n    \"\"\"Class representing a comment.\"\"\"\n\n    content: str\n    comment_types: list[CommentType]\n\n    def convert_comment_to_metadata(self) -> str:\n        \"\"\"Converts the comment to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass DecoratorModel(BaseModel):\n    \"\"\"Class representing a decorator.\"\"\"\n\n    content: str\n    decorator_name: str\n    decorator_args: list[str] | None = None\n\n    def convert_decorator_to_metadata(self) -> str:\n        \"\"\"Converts the decorator to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass ClassKeywordModel(BaseModel):\n    \"\"\"Class representing a class keyword.\"\"\"\n\n    content: str\n    keyword_name: str\n    args: str | None = None\n\n    def convert_class_keyword_to_metadata(self) -> str:\n        \"\"\"Converts the class keyword to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass ParameterModel(BaseModel):\n    \"\"\"Class representing a function parameter.\"\"\"\n\n    content: str\n\n\nclass ParameterListModel(BaseModel):\n    \"\"\"Class representing a list of parameters.\"\"\"\n\n    params: list[ParameterModel] | None = None\n    star_arg: ParameterModel | None = None\n    kwonly_params: list[ParameterModel] | None = None\n    star_kwarg: ParameterModel | None = None\n    posonly_params: list[ParameterModel] | None = None\n\n    def convert_parameters_to_metadata(self) -> str:\n        \"\"\"Converts the parameter list to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass BaseCodeBlockModel(BaseModel):\n    \"\"\"Attributes common to all code block models.\"\"\"\n\n    id: str\n    parent_id: str | None = None\n    block_type: BlockType\n    start_line_num: int\n    end_line_num: int\n    code_content: str = \"\"\n    important_comments: list[CommentModel] | None = None\n    dependencies: list[ImportModel | DependencyModel] | None = None\n    summary: str | None = None\n    children: list[\n        Union[\n            \"ClassModel\",\n            \"FunctionModel\",\n            \"StandaloneCodeBlockModel\",\n        ]\n    ] | None = []\n\n    @validator(\"parent_id\", always=True)\n    def check_parent_id(cls, v, values, **kwargs) -> str | None:\n        \"\"\"Validates that parent_id is a non-empty string unless block_type is MODULE.\"\"\"\n\n        if \"block_type\" in values and values[\"block_type\"] != BlockType.MODULE:\n            if len(v) < 1:\n                raise ValueError(\"parent_id is required!\")\n        return v\n\n    def _convert_parent_id_to_metadata(self) -> str:\n        \"\"\"Converts the parent_id to a metadata string.\"\"\"\n        return f\"{self.parent_id}\" if self.parent_id else \"\"\n\n    def _convert_block_type_to_metadata(self) -> str:\n        \"\"\"Converts the block_type to a metadata string.\"\"\"\n        return f\"{self.block_type.name}\"\n\n    def _convert_important_comments_to_metadata(self) -> str:\n        \"\"\"Converts the important comments to a metadata string.\"\"\"\n\n        important_comments: str = (\n            self.model_dump_json() if self.important_comments else \"\"\n        )\n\n        return f\"{important_comments}\"\n\n    def _convert_dependencies_to_metadata(self) -> str:\n        \"\"\"Converts the dependencies to a metadata string.\"\"\"\n\n        dependencies_str: str = \"\"\n\n        if self.dependencies:\n            for dependency in self.dependencies:\n                if isinstance(dependency, ImportModel):\n                    dependencies_str += f\"{dependency.convert_import_to_metadata()}\\n\"\n                elif isinstance(dependency, DependencyModel):\n                    dependencies_str += (\n                        f\"{dependency.convert_dependency_to_metadata()}\\n\"\n                    )\n\n        return dependencies_str\n\n    def _convert_summary_to_metadata(self) -> str:\n        \"\"\"Converts the summary to a metadata string.\"\"\"\n        return f\"{self.summary}\" if self.summary else \"\"\n\n    def _convert_children_to_metadata(self) -> str:\n        \"\"\"Converts the children to a metadata string.\"\"\"\n\n        children_str: str = \"\"\n\n        if self.children:\n            for child in self.children:\n                children_str += f\"{child.id}\\n\"\n\n        return children_str\n\n    def _convert_base_attributes_to_metadata_dict(self) -> dict[str, str | int]:\n        \"\"\"Converts the base attributes to a metadata dictionary.\"\"\"\n\n        return {\n            \"id\": self.id,\n            \"parent_id\": self._convert_parent_id_to_metadata(),\n            \"block_type\": self._convert_block_type_to_metadata(),\n            \"start_line_num\": self.start_line_num,\n            \"end_line_num\": self.end_line_num,\n            \"code_content\": self.code_content,\n            \"important_comments\": self._convert_important_comments_to_metadata(),\n            \"dependencies\": self._convert_dependencies_to_metadata(),\n            \"summary\": self._convert_summary_to_metadata(),\n            \"children\": self._convert_children_to_metadata(),\n        }\n\n\nclass ModuleSpecificAttributes(BaseModel):\n    \"\"\"Module specific attributes.\"\"\"\n\n    file_path: str = Field(min_length=1)\n    docstring: str | None = None\n    header: list[str] | None = None\n    footer: list[str] | None = None\n    imports: list[ImportModel] | None = None\n\n    def _convert_docstring_to_metadata(self) -> str:\n        \"\"\"Converts the docstring to a metadata string.\"\"\"\n        return f\"{self.docstring}\"\n\n    def _convert_header_to_metadata(self) -> str:\n        \"\"\"Converts the header and footer to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n    def _convert_footer_to_metadata(self) -> str:\n        \"\"\"Converts the header and footer to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n    def _convert_imports_to_metadata(self) -> str:\n        \"\"\"Converts the imports to a metadata string.\"\"\"\n        imports_str: str = self.model_dump_json() if self.imports else \"\"\n        return f\"{imports_str}\"\n\n    def _convert_module_attributes_to_metadata_dict(self) -> dict[str, str | int]:\n        \"\"\"Converts the module attributes to a metadata dictionary.\"\"\"\n\n        return {\n            \"file_path\": self.file_path,\n            \"docstring\": self._convert_docstring_to_metadata(),\n            \"header\": self._convert_header_to_metadata(),\n            \"footer\": self._convert_footer_to_metadata(),\n            \"imports\": self._convert_imports_to_metadata(),\n        }\n\n\nclass ModuleModel(BaseCodeBlockModel, ModuleSpecificAttributes):\n    \"\"\"Model for a module.\"\"\"\n\n    def convert_to_metadata(self) -> dict[str, str | int]:\n        \"\"\"Converts the module model to a metadata dictionary.\"\"\"\n\n        return {\n            **self._convert_base_attributes_to_metadata_dict(),\n            **self._convert_module_attributes_to_metadata_dict(),\n        }\n\n\nclass ClassSpecificAttributes(BaseModel):\n    \"\"\"Class specific attributes.\"\"\"\n\n    class_name: str = Field(min_length=1)\n    decorators: list[DecoratorModel] | None = None\n    bases: list[str] | None = None\n    docstring: str | None = None\n    keywords: list[ClassKeywordModel] | None = None\n    # attributes: list[dict] | None = None\n\n    def _convert_decorators_to_metadata(self) -> str:\n        \"\"\"Converts the decorators to a metadata string.\"\"\"\n        decorators_str: str = self.model_dump_json() if self.decorators else \"\"\n        return f\"{decorators_str}\"\n\n    def _convert_bases_to_metadata(self) -> str:\n        \"\"\"Converts the bases to a metadata string.\"\"\"\n        return self.model_dump_json() if self.bases else \"\"\n\n    def _convert_docstring_to_metadata(self) -> str:\n        \"\"\"Converts the docstring to a metadata string.\"\"\"\n        return f\"{self.docstring}\" if self.docstring else \"\"\n\n    def _convert_keywords_to_metadata(self) -> str:\n        \"\"\"Converts the keywords to a metadata string.\"\"\"\n        keywords_str: str = self.model_dump_json() if self.keywords else \"\"\n        return f\"{keywords_str}\"\n\n    def _convert_class_attributes_to_metadata_dict(self) -> dict[str, str | int]:\n        \"\"\"Converts the class attributes to a metadata dictionary.\"\"\"\n\n        return {\n            \"class_name\": self.class_name,\n            \"decorators\": self._convert_decorators_to_metadata(),\n            \"bases\": self._convert_bases_to_metadata(),\n            \"docstring\": self._convert_docstring_to_metadata(),\n            \"keywords\": self._convert_keywords_to_metadata(),\n        }\n\n\nclass ClassModel(BaseCodeBlockModel, ClassSpecificAttributes):\n    \"\"\"Model for a class.\"\"\"\n\n    def convert_to_metadata(self) -> dict[str, str | int]:\n        \"\"\"Converts the class model to a metadata dictionary.\"\"\"\n        return {\n            **self._convert_base_attributes_to_metadata_dict(),\n            **self._convert_class_attributes_to_metadata_dict(),\n        }\n\n\nclass FunctionSpecificAttributes(BaseModel):\n    \"\"\"Function specific attributes.\"\"\"\n\n    function_name: str = Field(min_length=1)\n    docstring: str | None = None\n    decorators: list[DecoratorModel] | None = None\n    parameters: ParameterListModel | None = None\n    returns: str | None = None\n    is_method: bool = False\n    is_async: bool = False\n\n    def _convert_docstring_to_metadata(self) -> str:\n        \"\"\"Converts the docstring to a metadata string.\"\"\"\n        return f\"{self.docstring}\" if self.docstring else \"\"\n\n    def _convert_decorators_to_metadata(self) -> str:\n        \"\"\"Converts the decorators to a metadata string.\"\"\"\n        decorators_str: str = self.model_dump_json() if self.decorators else \"\"\n        return f\"{decorators_str}\"\n\n    def _convert_parameters_to_metadata(self) -> str:\n        \"\"\"Converts the parameters to a metadata string.\"\"\"\n        return (\n            self.parameters.convert_parameters_to_metadata() if self.parameters else \"\"\n        )\n\n    def _convert_returns_to_metadata(self) -> str:\n        \"\"\"Converts the returns to a metadata string.\"\"\"\n        return f\"{self.returns}\" if self.returns else \"\"\n\n    def _convert_function_attributes_to_metadata_dict(self) -> dict[str, str | bool]:\n        \"\"\"Converts the function attributes to a metadata dictionary.\"\"\"\n\n        return {\n            \"function_name\": self.function_name,\n            \"docstring\": self._convert_docstring_to_metadata(),\n            \"decorators\": self._convert_decorators_to_metadata(),\n            \"parameters\": self._convert_parameters_to_metadata(),\n            \"returns\": self._convert_returns_to_metadata(),\n            \"is_method\": self.is_method,\n            \"is_async\": self.is_async,\n        }\n\n\nclass FunctionModel(BaseCodeBlockModel, FunctionSpecificAttributes):\n    \"\"\"Model for a function.\"\"\"\n\n    def convert_to_metadata(self) -> dict[str, str | int]:\n        \"\"\"Converts the function model to a metadata dictionary.\"\"\"\n\n        return {\n            **self._convert_base_attributes_to_metadata_dict(),\n            **self._convert_function_attributes_to_metadata_dict(),\n        }\n\n\nclass StandaloneCodeBlockSpecificAttributes(BaseModel):\n    \"\"\"Standalone code block specific attributes.\"\"\"\n\n    variable_assignments: list[str] | None = None\n\n    def _convert_variable_assignments_to_metadata(self) -> str:\n        \"\"\"Converts the variable assignments to a metadata string.\"\"\"\n        return self.model_dump_json() if self.variable_assignments else \"\"\n\n    def _convert_standalone_block_attributes_to_metadata_dict(\n        self,\n    ) -> dict[str, str | int]:\n        \"\"\"Converts the standalone code block attributes to a metadata dictionary.\"\"\"\n        return {\n            \"variable_assignments\": self._convert_variable_assignments_to_metadata(),\n        }\n\n\nclass StandaloneCodeBlockModel(\n    BaseCodeBlockModel, StandaloneCodeBlockSpecificAttributes\n):\n    \"\"\"Model for a standalone code block.\"\"\"\n\n    def convert_to_metadata(self) -> dict[str, str | int]:\n        \"\"\"Converts the standalone code block model to a metadata dictionary.\"\"\"\n\n        return {\n            **self._convert_base_attributes_to_metadata_dict(),\n            **self._convert_standalone_block_attributes_to_metadata_dict(),\n        }\n\n, \nimport logging\nfrom pprint import pprint\nfrom typing import Union\n        "} str = \"\"\n\n        if self.dependencies:\n            for dependency in self.dependencies:\n                if isinstance(dependency, ImportModel):\n                    dependencies_str += f\"{dependency.convert_import_to_metadata()}\\n\"\n                elif isinstance(dependency, DependencyModel):\n                    dependencies_str += (\n                        f\"{dependency.convert_dependency_to_metadata()}\\n\"\n                    )\n\n        return dependencies_str\n\n    def _convert_summary_to_metadata(self) -> str:\n        \"\"\"Converts the summary to a metadata string.\"\"\"\n        return f\"{self.summary}\" if self.summary else \"\"\n\n    def _convert_children_to_metadata(self) -> str:\n        \"\"\"Converts the children to a metadata string.\"\"\"\n\n        children_str: str = \"\"\n\n        if self.children:\n            for child in self.children:\n                children_str += f\"{child.id}\\n\"\n\n        return children_str\n\n    def _convert_base_attributes_to_metadata_dict(self) -> dict[str, str | int]:\n        \"\"\"Converts the base attributes to a metadata dictionary.\"\"\"\n\n        return {\n            \"id\": self.id,\n            \"parent_id\": self._convert_parent_id_to_metadata(),\n            \"block_type\": self._convert_block_type_to_metadata(),\n            \"start_line_num\": self.start_line_num,\n            \"end_line_num\": self.end_line_num,\n            \"code_content\": self.code_content,\n            \"important_comments\": self._convert_important_comments_to_metadata(),\n            \"dependencies\": self._convert_dependencies_to_metadata(),\n            \"summary\": self._convert_summary_to_metadata(),\n            \"children\": self._convert_children_to_metadata(),\n        }\n\n\nclass ModuleSpecificAttributes(BaseModel):\n    \"\"\"Module specific attributes.\"\"\"\n\n    file_path: str = Field(min_length=1)\n    docstring: str | None = None\n    header: list[str] | None = None\n    footer: list[str] | None = None\n    imports: list[ImportModel] | None = None\n\n    def _convert_docstring_to_metadata(self) -> str:\n        \"\"\"Converts the docstring to a metadata string.\"\"\"\n        return f\"{self.docstring}\"\n\n    def _convert_header_to_metadata(self) -> str:\n        \"\"\"Converts the header and footer to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n    def _convert_footer_to_metadata(self) -> str:\n        \"\"\"Converts the header and footer to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n    def _convert_imports_to_metadata(self) -> str:\n        \"\"\"Converts the imports to a metadata string.\"\"\"\n        imports_str: str = self.model_dump_json() if self.imports else \"\"\n        return f\"{imports_str}\"\n\n    def _convert_module_attributes_to_metadata_dict(self) -> dict[str, str | int]:\n        \"\"\"Converts the module attributes to a metadata dictionary.\"\"\"\n\n        return {\n            \"file_path\": self.file_path,\n            \"docstring\": self._convert_docstring_to_metadata(),\n            \"header\": self._convert_header_to_metadata(),\n            \"footer\": self._convert_footer_to_metadata(),\n            \"imports\": self._convert_imports_to_metadata(),\n        }\n\n\nclass ModuleModel(BaseCodeBlockModel, ModuleSpecificAttributes):\n    \"\"\"Model for a module.\"\"\"\n\n    def convert_to_metadata(self) -> dict[str, str | int]:\n        \"\"\"Converts the module model to a metadata dictionary.\"\"\"\n\n        return {\n            **self._convert_base_attributes_to_metadata_dict(),\n            **self._convert_module_attributes_to_metadata_dict(),\n        }\n\n\nclass ClassSpecificAttributes(BaseModel):\n    \"\"\"Class specific attributes.\"\"\"\n\n    class_name: str = Field(min_length=1)\n    decorators: list[DecoratorModel] | None = None\n    bases: list[str] | None = None\n    docstring: str | None = None\n    keywords: list[ClassKeywordModel] | None = None\n    # attributes: list[dict] | None = None\n\n    def _convert_decorators_to_metadata(self) -> str:\n        \"\"\"Converts the decorators to a metadata string.\"\"\"\n        decorators_str: str = self.model_dump_json() if self.decorators else \"\"\n        return f\"{decorators_str}\"\n\n    def _convert_bases_to_metadata(self) -> str:\n        \"\"\"Converts the bases to a metadata string.\"\"\"\n        return self.model_dump_json() if self.bases else \"\"\n\n    def _convert_docstring_to_metadata(self) -> str:\n        \"\"\"Converts the docstring to a metadata string.\"\"\"\n        return f\"{self.docstring}\" if self.docstring else \"\"\n\n    def _convert_keywords_to_metadata(self) -> str:\n        \"\"\"Converts the keywords to a metadata string.\"\"\"\n        keywords_str: str = self.model_dump_json() if self.keywords else \"\"\n        return f\"{keywords_str}\"\n\n    def _convert_class_attributes_to_metadata_dict(self) -> dict[str, str | int]:\n        \"\"\"Converts the class attributes to a metadata dictionary.\"\"\"\n\n        return {\n            \"class_name\": self.class_name,\n            \"decorators\": self._convert_decorators_to_metadata(),\n            \"bases\": self._convert_bases_to_metadata(),\n            \"docstring\": self._convert_docstring_to_metadata(),\n            \"keywords\": self._convert_keywords_to_metadata(),\n        }\n\n\nclass ClassModel(BaseCodeBlockModel, ClassSpecificAttributes):\n    \"\"\"Model for a class.\"\"\"\n\n    def convert_to_metadata(self) -> dict[str, str | int]:\n        \"\"\"Converts the class model to a metadata dictionary.\"\"\"\n        return {\n            **self._convert_base_attributes_to_metadata_dict(),\n            **self._convert_class_attributes_to_metadata_dict(),\n        }\n\n\nclass FunctionSpecificAttributes(BaseModel):\n    \"\"\"Function specific attributes.\"\"\"\n\n    function_name: str = Field(min_length=1)\n    docstring: str | None = None\n    decorators: list[DecoratorModel] | None = None\n    parameters: ParameterListModel | None = None\n    returns: str | None = None\n    is_method: bool = False\n    is_async: bool = False\n\n    def _convert_docstring_to_metadata(self) -> str:\n        \"\"\"Converts the docstring to a metadata string.\"\"\"\n        return f\"{self.docstring}\" if self.docstring else \"\"\n\n    def _convert_decorators_to_metadata(self) -> str:\n        \"\"\"Converts the decorators to a metadata string.\"\"\"\n        decorators_str: str = self.model_dump_json() if self.decorators else \"\"\n        return f\"{decorators_str}\"\n\n    def _convert_parameters_to_metadata(self) -> str:\n        \"\"\"Converts the parameters to a metadata string.\"\"\"\n        return (\n            self.parameters.convert_parameters_to_metadata() if self.parameters else \"\"\n        )\n\n    def _convert_returns_to_metadata(self) -> str:\n        \"\"\"Converts the returns to a metadata string.\"\"\"\n        return f\"{self.returns}\" if self.returns else \"\"\n\n    def _convert_function_attributes_to_metadata_dict(self) -> dict[str, str | bool]:\n        \"\"\"Converts the function attributes to a metadata dictionary.\"\"\"\n\n        return {\n            \"function_name\": self.function_name,\n            \"docstring\": self._convert_docstring_to_metadata(),\n            \"decorators\": self._convert_decorators_to_metadata(),\n            \"parameters\": self._convert_parameters_to_metadata(),\n            \"returns\": self._convert_returns_to_metadata(),\n            \"is_method\": self.is_method,\n            \"is_async\": self.is_async,\n        }\n\n\nclass FunctionModel(BaseCodeBlockModel, FunctionSpecificAttributes):\n    \"\"\"Model for a function.\"\"\"\n\n    def convert_to_metadata(self) -> dict[str, str | int]:\n        \"\"\"Converts the function model to a metadata dictionary.\"\"\"\n\n        return {\n            **self._convert_base_attributes_to_metadata_dict(),\n            **self._convert_function_attributes_to_metadata_dict(),\n        }\n\n\nclass StandaloneCodeBlockSpecificAttributes(BaseModel):\n    \"\"\"Standalone code block specific attributes.\"\"\"\n\n    variable_assignments: list[str] | None = None\n\n    def _convert_variable_assignments_to_metadata(self) -> str:\n        \"\"\"Converts the variable assignments to a metadata string.\"\"\"\n        return self.model_dump_json() if self.variable_assignments else \"\"\n\n    def _convert_standalone_block_attributes_to_metadata_dict(\n        self,\n    ) -> dict[str, str | int]:\n        \"\"\"Converts the standalone code block attributes to a metadata dictionary.\"\"\"\n        return {\n            \"variable_assignments\": self._convert_variable_assignments_to_metadata(),\n        }\n\n\nclass StandaloneCodeBlockModel(\n    BaseCodeBlockModel, StandaloneCodeBlockSpecificAttributes\n):\n    \"\"\"Model for a standalone code block.\"\"\"\n\n    def convert_to_metadata(self) -> dict[str, str | int]:\n        \"\"\"Converts the standalone code block model to a metadata dictionary.\"\"\"\n\n        return {\n            **self._convert_base_attributes_to_metadata_dict(),\n            **self._convert_standalone_block_attributes_to_metadata_dict(),\n        }\n\n, \nimport logging\nfrom typing import Any, Mapping, Union\nfrom chromadb.config import DEFAULT_DATABASE, DEFAULT_TENANT, Settings\nfrom chromadb.api import ClientAPI\nfrom chromadb.api.types import DataLoader, CollectionMetadata, GetResult, QueryResult, Where, WhereDocument, Include, URIs, Loadable, Metadata, Embedding\nfrom chromadb import Collection\nfrom chromadb import EmbeddingFunction\n        "}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     {"id": "postcode:databases:arangodb:helper_functions.py__*__MODULE", "parent_id": "", "block_type": "MODULE", "start_line_num": 1, "end_line_num": 45, "code_content": "from typing import Any, Union\n\nfrom postcode.models.enums import BlockType\nfrom postcode.models.models import (\n    ModuleModel,\n    ClassModel,\n    FunctionModel,\n    StandaloneCodeBlockModel,\n)\n\n# from postcode.types.postcode import ModelType\n\nModelType = Union[\n    ModuleModel,\n    ClassModel,\n    FunctionModel,\n    StandaloneCodeBlockModel,\n]\n\n\ndef pluralized_and_lowered_block_types() -> list[str]:\n    return [pluralize_block_type(block_type).lower() for block_type in BlockType]\n\n\ndef pluralize_block_type(block_type: str) -> str:\n    if block_type == BlockType.CLASS:\n        return \"classes\"\n    else:\n        return f\"{block_type.lower()}s\"\n\n\ndef create_model_from_vertex(vertex_data: dict) -> ModelType:\n    block_type = vertex_data.get(\"block_type\")\n\n    if block_type == BlockType.MODULE:\n        return ModuleModel(**vertex_data)\n    elif block_type == BlockType.CLASS:\n        return ClassModel(**vertex_data)\n    elif block_type == BlockType.FUNCTION:\n        return FunctionModel(**vertex_data)\n    elif block_type == BlockType.STANDALONE_CODE_BLOCK:\n        return StandaloneCodeBlockModel(**vertex_data)\n    else:\n        raise ValueError(f\"Unknown block type: {block_type}\")\n", "important_comments": "", "dependencies": "", "summary": "\nSummary:\n\n        postcode:databases:arangodb:helper_functions.py__*__MODULE\n\n        \nChild (postcode:databases:arangodb:helper_functions.py__*__MODULE__*__STANDALONE_BLOCK-1) code content:\n# from postcode.types.postcode import ModelType\n\nModelType = Union[\n    ModuleModel,\n    ClassModel,\n    FunctionModel,\n    StandaloneCodeBlockModel,\n]\n\n\nChild (postcode:databases:arangodb:helper_functions.py__*__MODULE__*__FUNCTION-pluralized_and_lowered_block_types) code content:\n\n\ndef pluralized_and_lowered_block_types() -> list[str]:\n    return [pluralize_block_type(block_type).lower() for block_type in BlockType]\n\n\nChild (postcode:databases:arangodb:helper_functions.py__*__MODULE__*__FUNCTION-pluralize_block_type) code content:\n\n\ndef pluralize_block_type(block_type: str) -> str:\n    if block_type == BlockType.CLASS:\n        return \"classes\"\n    else:\n        return f\"{block_type.lower()}s\"\n\n\nChild (postcode:databases:arangodb:helper_functions.py__*__MODULE__*__FUNCTION-create_model_from_vertex) code content:\n\n\ndef create_model_from_vertex(vertex_data: dict) -> ModelType:\n    block_type = vertex_data.get(\"block_type\")\n\n    if block_type == BlockType.MODULE:\n        return ModuleModel(**vertex_data)\n    elif block_type == BlockType.CLASS:\n        return ClassModel(**vertex_data)\n    elif block_type == BlockType.FUNCTION:\n        return FunctionModel(**vertex_data)\n    elif block_type == BlockType.STANDALONE_CODE_BLOCK:\n        return StandaloneCodeBlockModel(**vertex_data)\n    else:\n        raise ValueError(f\"Unknown block type: {block_type}\")\n\n, \nImported code block (postcode:models:enums.py__*__MODULE) code content:\nfrom enum import Enum\n\n\nclass ImportModuleType(str, Enum):\n    \"\"\"Enum of import module types.\"\"\"\n\n    STANDARD_LIBRARY = \"STANDARD_LIBRARY\"\n    LOCAL = \"LOCAL\"\n    THIRD_PARTY = \"THIRD_PARTY\"\n\n    def __str__(self) -> str:\n        return self.value\n\n\nclass CommentType(str, Enum):\n    \"\"\"Class representing the different types of important comments.\"\"\"\n\n    TODO = \"TODO\"\n    FIXME = \"FIXME\"\n    NOTE = \"NOTE\"\n    HACK = \"HACK\"\n    XXX = \"XXX\"\n    REVIEW = \"REVIEW\"\n    OPTIMIZE = \"OPTIMIZE\"\n    CHANGED = \"CHANGED\"\n    QUESTION = \"QUESTION\"\n    Q = \"Q\"\n    DEPRECATED = \"@deprecated\"\n    NOSONAR = \"NOSONAR\"\n    TODO_FIXME = \"TODO-FIXME\"\n\n    def __str__(self) -> str:\n        return self.value\n\n\nclass BlockType(str, Enum):\n    \"\"\"Enum of code block types.\"\"\"\n\n    STANDALONE_CODE_BLOCK = \"STANDALONE_BLOCK\"\n    CLASS = \"CLASS\"\n    FUNCTION = \"FUNCTION\"\n    MODULE = \"MODULE\"\n\n    def __str__(self) -> str:\n        return self.value\n\n\nImported code block (postcode:models:models.py__*__MODULE) code content:\nfrom typing import Union\nfrom pydantic import BaseModel, Field, validator\n\nfrom postcode.models.enums import (\n    BlockType,\n    ImportModuleType,\n    CommentType,\n)\n\n\nclass ImportNameModel(BaseModel):\n    \"\"\"Class representing the name of an import.\"\"\"\n\n    name: str\n    as_name: str | None = None\n    local_block_id: str | None = None\n\n    # def convert_import_names_to_metadata(self) -> str:\n    #     \"\"\"Converts the import name to a metadata string.\"\"\"\n\n    #     return self.model_dump_json()\n\n\nclass ImportModel(BaseModel):\n    \"\"\"Class representing an import statement.\"\"\"\n\n    import_names: list[ImportNameModel]\n    imported_from: str | None = None\n    import_module_type: ImportModuleType = ImportModuleType.STANDARD_LIBRARY\n    local_module_id: str | None = None\n\n    def convert_import_to_metadata(self) -> str:\n        \"\"\"Converts the import to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass DependencyModel(BaseModel):\n    \"\"\"Class representing a module dependency.\"\"\"\n\n    code_block_id: str\n\n    def convert_dependency_to_metadata(self) -> str:\n        \"\"\"Converts the dependency to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass CommentModel(BaseModel):\n    \"\"\"Class representing a comment.\"\"\"\n\n    content: str\n    comment_types: list[CommentType]\n\n    def convert_comment_to_metadata(self) -> str:\n        \"\"\"Converts the comment to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass DecoratorModel(BaseModel):\n    \"\"\"Class representing a decorator.\"\"\"\n\n    content: str\n    decorator_name: str\n    decorator_args: list[str] | None = None\n\n    def convert_decorator_to_metadata(self) -> str:\n        \"\"\"Converts the decorator to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass ClassKeywordModel(BaseModel):\n    \"\"\"Class representing a class keyword.\"\"\"\n\n    content: str\n    keyword_name: str\n    args: str | None = None\n\n    def convert_class_keyword_to_metadata(self) -> str:\n        \"\"\"Converts the class keyword to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass ParameterModel(BaseModel):\n    \"\"\"Class representing a function parameter.\"\"\"\n\n    content: str\n\n\nclass ParameterListModel(BaseModel):\n    \"\"\"Class representing a list of parameters.\"\"\"\n\n    params: list[ParameterModel] | None = None\n    star_arg: ParameterModel | None = None\n    kwonly_params: list[ParameterModel] | None = None\n    star_kwarg: ParameterModel | None = None\n    posonly_params: list[ParameterModel] | None = None\n\n    def convert_parameters_to_metadata(self) -> str:\n        \"\"\"Converts the parameter list to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass BaseCodeBlockModel(BaseModel):\n    \"\"\"Attributes common to all code block models.\"\"\"\n\n    id: str\n    parent_id: str | None = None\n    block_type: BlockType\n    start_line_num: int\n    end_line_num: int\n    code_content: str = \"\"\n    important_comments: list[CommentModel] | None = None\n    dependencies: list[ImportModel | DependencyModel] | None = None\n    summary: str | None = None\n    children: list[\n        Union[\n            \"ClassModel\",\n            \"FunctionModel\",\n            \"StandaloneCodeBlockModel\",\n        ]\n    ] | None = []\n\n    @validator(\"parent_id\", always=True)\n    def check_parent_id(cls, v, values, **kwargs) -> str | None:\n        \"\"\"Validates that parent_id is a non-empty string unless block_type is MODULE.\"\"\"\n\n        if \"block_type\" in values and values[\"block_type\"] != BlockType.MODULE:\n            if len(v) < 1:\n                raise ValueError(\"parent_id is required!\")\n        return v\n\n    def _convert_parent_id_to_metadata(self) -> str:\n        \"\"\"Converts the parent_id to a metadata string.\"\"\"\n        return f\"{self.parent_id}\" if self.parent_id else \"\"\n\n    def _convert_block_type_to_metadata(self) -> str:\n        \"\"\"Converts the block_type to a metadata string.\"\"\"\n        return f\"{self.block_type.name}\"\n\n    def _convert_important_comments_to_metadata(self) -> str:\n        \"\"\"Converts the important comments to a metadata string.\"\"\"\n\n        important_comments: str = (\n            self.model_dump_json() if self.important_comments else \"\"\n        )\n\n        return f\"{important_comments}\"\n\n    def _convert_dependencies_to_metadata(self) -> str:\n        \"\"\"Converts the dependencies to a metadata string.\"\"\"\n\n        dependencies_str: str = \"\"\n\n        if self.dependencies:\n            for dependency in self.dependencies:\n                if isinstance(dependency, ImportModel):\n                    dependencies_str += f\"{dependency.convert_import_to_metadata()}\\n\"\n                elif isinstance(dependency, DependencyModel):\n                    dependencies_str += (\n                        f\"{dependency.convert_dependency_to_metadata()}\\n\"\n                    )\n\n        return dependencies_str\n\n    def _convert_summary_to_metadata(self) -> str:\n        \"\"\"Converts the summary to a metadata string.\"\"\"\n        return f\"{self.summary}\" if self.summary else \"\"\n\n    def _convert_children_to_metadata(self) -> str:\n        \"\"\"Converts the children to a metadata string.\"\"\"\n\n        children_str: str = \"\"\n\n        if self.children:\n            for child in self.children:\n                children_str += f\"{child.id}\\n\"\n\n        return children_str\n\n    def _convert_base_attributes_to_metadata_dict(self) -> dict[str, str | int]:\n        \"\"\"Converts the base attributes to a metadata dictionary.\"\"\"\n\n        return {\n            \"id\": self.id,\n            \"parent_id\": self._convert_parent_id_to_metadata(),\n            \"block_type\": self._convert_block_type_to_metadata(),\n            \"start_line_num\": self.start_line_num,\n            \"end_line_num\": self.end_line_num,\n            \"code_content\": self.code_content,\n            \"important_comments\": self._convert_important_comments_to_metadata(),\n            \"dependencies\": self._convert_dependencies_to_metadata(),\n            \"summary\": self._convert_summary_to_metadata(),\n            \"children\": self._convert_children_to_metadata(),\n        }\n\n\nclass ModuleSpecificAttributes(BaseModel):\n    \"\"\"Module specific attributes.\"\"\"\n\n    file_path: str = Field(min_length=1)\n    docstring: str | None = None\n    header: list[str] | None = None\n    footer: list[str] | None = None\n    imports: list[ImportModel] | None = None\n\n    def _convert_docstring_to_metadata(self) -> str:\n        \"\"\"Converts the docstring to a metadata string.\"\"\"\n        return f\"{self.docstring}\"\n\n    def _convert_header_to_metadata(self) -> str:\n        \"\"\"Converts the header and footer to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n    def _convert_footer_to_metadata(self) -> str:\n        \"\"\"Converts the header and footer to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n    def _convert_imports_to_metadata(self) -> str:\n        \"\"\"Converts the imports to a metadata string.\"\"\"\n        imports_str: str = self.model_dump_json() if self.imports else \"\"\n        return f\"{imports_str}\"\n\n    def _convert_module_attributes_to_metadata_dict(self) -> dict[str, str | int]:\n        \"\"\"Converts the module attributes to a metadata dictionary.\"\"\"\n\n        return {\n            \"file_path\": self.file_path,\n            \"docstring\": self._convert_docstring_to_metadata(),\n            \"header\": self._convert_header_to_metadata(),\n            \"footer\": self._convert_footer_to_metadata(),\n            \"imports\": self._convert_imports_to_metadata(),\n        }\n\n\nclass ModuleModel(BaseCodeBlockModel, ModuleSpecificAttributes):\n    \"\"\"Model for a module.\"\"\"\n\n    def convert_to_metadata(self) -> dict[str, str | int]:\n        \"\"\"Converts the module model to a metadata dictionary.\"\"\"\n\n        return {\n            **self._convert_base_attributes_to_metadata_dict(),\n            **self._convert_module_attributes_to_metadata_dict(),\n        }\n\n\nclass ClassSpecificAttributes(BaseModel):\n    \"\"\"Class specific attributes.\"\"\"\n\n    class_name: str = Field(min_length=1)\n    decorators: list[DecoratorModel] | None = None\n    bases: list[str] | None = None\n    docstring: str | None = None\n    keywords: list[ClassKeywordModel] | None = None\n    # attributes: list[dict] | None = None\n\n    def _convert_decorators_to_metadata(self) -> str:\n        \"\"\"Converts the decorators to a metadata string.\"\"\"\n        decorators_str: str = self.model_dump_json() if self.decorators else \"\"\n        return f\"{decorators_str}\"\n\n    def _convert_bases_to_metadata(self) -> str:\n        \"\"\"Converts the bases to a metadata string.\"\"\"\n        return self.model_dump_json() if self.bases else \"\"\n\n    def _convert_docstring_to_metadata(self) -> str:\n        \"\"\"Converts the docstring to a metadata string.\"\"\"\n        return f\"{self.docstring}\" if self.docstring else \"\"\n\n    def _convert_keywords_to_metadata(self) -> str:\n        \"\"\"Converts the keywords to a metadata string.\"\"\"\n        keywords_str: str = self.model_dump_json() if self.keywords else \"\"\n        return f\"{keywords_str}\"\n\n    def _convert_class_attributes_to_metadata_dict(self) -> dict[str, str | int]:\n        \"\"\"Converts the class attributes to a metadata dictionary.\"\"\"\n\n        return {\n            \"class_name\": self.class_name,\n            \"decorators\": self._convert_decorators_to_metadata(),\n            \"bases\": self._convert_bases_to_metadata(),\n            \"docstring\": self._convert_docstring_to_metadata(),\n            \"keywords\": self._convert_keywords_to_metadata(),\n        }\n\n\nclass ClassModel(BaseCodeBlockModel, ClassSpecificAttributes):\n    \"\"\"Model for a class.\"\"\"\n\n    def convert_to_metadata(self) -> dict[str, str | int]:\n        \"\"\"Converts the class model to a metadata dictionary.\"\"\"\n        return {\n            **self._convert_base_attributes_to_metadata_dict(),\n            **self._convert_class_attributes_to_metadata_dict(),\n        }\n\n\nclass FunctionSpecificAttributes(BaseModel):\n    \"\"\"Function specific attributes.\"\"\"\n\n    function_name: str = Field(min_length=1)\n    docstring: str | None = None\n    decorators: list[DecoratorModel] | None = None\n    parameters: ParameterListModel | None = None\n    returns: str | None = None\n    is_method: bool = False\n    is_async: bool = False\n\n    def _convert_docstring_to_metadata(self) -> str:\n        \"\"\"Converts the docstring to a metadata string.\"\"\"\n        return f\"{self.docstring}\" if self.docstring else \"\"\n\n    def _convert_decorators_to_metadata(self) -> str:\n        \"\"\"Converts the decorators to a metadata string.\"\"\"\n        decorators_str: str = self.model_dump_json() if self.decorators else \"\"\n        return f\"{decorators_str}\"\n\n    def _convert_parameters_to_metadata(self) -> str:\n        \"\"\"Converts the parameters to a metadata string.\"\"\"\n        return (\n            self.parameters.convert_parameters_to_metadata() if self.parameters else \"\"\n        )\n\n    def _convert_returns_to_metadata(self) -> str:\n        \"\"\"Converts the returns to a metadata string.\"\"\"\n        return f\"{self.returns}\" if self.returns else \"\"\n\n    def _convert_function_attributes_to_metadata_dict(self) -> dict[str, str | bool]:\n        \"\"\"Converts the function attributes to a metadata dictionary.\"\"\"\n\n        return {\n            \"function_name\": self.function_name,\n            \"docstring\": self._convert_docstring_to_metadata(),\n            \"decorators\": self._convert_decorators_to_metadata(),\n            \"parameters\": self._convert_parameters_to_metadata(),\n            \"returns\": self._convert_returns_to_metadata(),\n            \"is_method\": self.is_method,\n            \"is_async\": self.is_async,\n        }\n\n\nclass FunctionModel(BaseCodeBlockModel, FunctionSpecificAttributes):\n    \"\"\"Model for a function.\"\"\"\n\n    def convert_to_metadata(self) -> dict[str, str | int]:\n        \"\"\"Converts the function model to a metadata dictionary.\"\"\"\n\n        return {\n            **self._convert_base_attributes_to_metadata_dict(),\n            **self._convert_function_attributes_to_metadata_dict(),\n        }\n\n\nclass StandaloneCodeBlockSpecificAttributes(BaseModel):\n    \"\"\"Standalone code block specific attributes.\"\"\"\n\n    variable_assignments: list[str] | None = None\n\n    def _convert_variable_assignments_to_metadata(self) -> str:\n        \"\"\"Converts the variable assignments to a metadata string.\"\"\"\n        return self.model_dump_json() if self.variable_assignments else \"\"\n\n    def _convert_standalone_block_attributes_to_metadata_dict(\n        self,\n    ) -> dict[str, str | int]:\n        \"\"\"Converts the standalone code block attributes to a metadata dictionary.\"\"\"\n        return {\n            \"variable_assignments\": self._convert_variable_assignments_to_metadata(),\n        }\n\n\nclass StandaloneCodeBlockModel(\n    BaseCodeBlockModel, StandaloneCodeBlockSpecificAttributes\n):\n    \"\"\"Model for a standalone code block.\"\"\"\n\n    def convert_to_metadata(self) -> dict[str, str | int]:\n        \"\"\"Converts the standalone code block model to a metadata dictionary.\"\"\"\n\n        return {\n            **self._convert_base_attributes_to_metadata_dict(),\n            **self._convert_standalone_block_attributes_to_metadata_dict(),\n        }\n\n, \nfrom typing import Any, Union\n        ", "children": "postcode:databases:arangodb:helper_functions.py__*__MODULE__*__STANDALONE_BLOCK-1\npostcode:databases:arangodb:helper_functions.py__*__MODULE__*__FUNCTION-pluralized_and_lowered_block_types\npostcode:databases:arangodb:helper_functions.py__*__MODULE__*__FUNCTION-pluralize_block_type\npostcode:databases:arangodb:helper_functions.py__*__MODULE__*__FUNCTION-create_model_from_vertex\n", "file_path": "postcode/databases/arangodb/helper_functions.py", "docstring": "None", "header": "{\"file_path\":\"postcode/databases/arangodb/helper_functions.py\",\"docstring\":null,\"header\":[],\"footer\":[],\"imports\":[{\"import_names\":[{\"name\":\"Any\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"Union\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"typing\",\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"BlockType\",\"as_name\":null,\"local_block_id\":\"postcode:models:enums.py__*__MODULE__*__CLASS-BlockType\"}],\"imported_from\":\"postcode.models.enums\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:enums.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"},{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ClassModel\"},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-FunctionModel\"},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-StandaloneCodeBlockModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"}],\"id\":\"postcode:databases:arangodb:helper_functions.py__*__MODULE\",\"parent_id\":null,\"block_type\":\"MODULE\",\"start_line_num\":1,\"end_line_num\":45,\"code_content\":\"from typing import Any, Union\\n\\nfrom postcode.models.enums import BlockType\\nfrom postcode.models.models import (\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n)\\n\\n# from postcode.types.postcode import ModelType\\n\\nModelType = Union[\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n]\\n\\n\\ndef pluralized_and_lowered_block_types() -> list[str]:\\n    return [pluralize_block_type(block_type).lower() for block_type in BlockType]\\n\\n\\ndef pluralize_block_type(block_type: str) -> str:\\n    if block_type == BlockType.CLASS:\\n        return \\\"classes\\\"\\n    else:\\n        return f\\\"{block_type.lower()}s\\\"\\n\\n\\ndef create_model_from_vertex(vertex_data: dict) -> ModelType:\\n    block_type = vertex_data.get(\\\"block_type\\\")\\n\\n    if block_type == BlockType.MODULE:\\n        return ModuleModel(**vertex_data)\\n    elif block_type == BlockType.CLASS:\\n        return ClassModel(**vertex_data)\\n    elif block_type == BlockType.FUNCTION:\\n        return FunctionModel(**vertex_data)\\n    elif block_type == BlockType.STANDALONE_CODE_BLOCK:\\n        return StandaloneCodeBlockModel(**vertex_data)\\n    else:\\n        raise ValueError(f\\\"Unknown block type: {block_type}\\\")\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":\"\\nSummary:\\n\\n        postcode:databases:arangodb:helper_functions.py__*__MODULE\\n\\n        \\nChild (postcode:databases:arangodb:helper_functions.py__*__MODULE__*__STANDALONE_BLOCK-1) code content:\\n# from postcode.types.postcode import ModelType\\n\\nModelType = Union[\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n]\\n\\n\\nChild (postcode:databases:arangodb:helper_functions.py__*__MODULE__*__FUNCTION-pluralized_and_lowered_block_types) code content:\\n\\n\\ndef pluralized_and_lowered_block_types() -> list[str]:\\n    return [pluralize_block_type(block_type).lower() for block_type in BlockType]\\n\\n\\nChild (postcode:databases:arangodb:helper_functions.py__*__MODULE__*__FUNCTION-pluralize_block_type) code content:\\n\\n\\ndef pluralize_block_type(block_type: str) -> str:\\n    if block_type == BlockType.CLASS:\\n        return \\\"classes\\\"\\n    else:\\n        return f\\\"{block_type.lower()}s\\\"\\n\\n\\nChild (postcode:databases:arangodb:helper_functions.py__*__MODULE__*__FUNCTION-create_model_from_vertex) code content:\\n\\n\\ndef create_model_from_vertex(vertex_data: dict) -> ModelType:\\n    block_type = vertex_data.get(\\\"block_type\\\")\\n\\n    if block_type == BlockType.MODULE:\\n        return ModuleModel(**vertex_data)\\n    elif block_type == BlockType.CLASS:\\n        return ClassModel(**vertex_data)\\n    elif block_type == BlockType.FUNCTION:\\n        return FunctionModel(**vertex_data)\\n    elif block_type == BlockType.STANDALONE_CODE_BLOCK:\\n        return StandaloneCodeBlockModel(**vertex_data)\\n    else:\\n        raise ValueError(f\\\"Unknown block type: {block_type}\\\")\\n\\n, \\nImported code block (postcode:models:enums.py__*__MODULE) code content:\\nfrom enum import Enum\\n\\n\\nclass ImportModuleType(str, Enum):\\n    \\\"\\\"\\\"Enum of import module types.\\\"\\\"\\\"\\n\\n    STANDARD_LIBRARY = \\\"STANDARD_LIBRARY\\\"\\n    LOCAL = \\\"LOCAL\\\"\\n    THIRD_PARTY = \\\"THIRD_PARTY\\\"\\n\\n    def __str__(self) -> str:\\n        return self.value\\n\\n\\nclass CommentType(str, Enum):\\n    \\\"\\\"\\\"Class representing the different types of important comments.\\\"\\\"\\\"\\n\\n    TODO = \\\"TODO\\\"\\n    FIXME = \\\"FIXME\\\"\\n    NOTE = \\\"NOTE\\\"\\n    HACK = \\\"HACK\\\"\\n    XXX = \\\"XXX\\\"\\n    REVIEW = \\\"REVIEW\\\"\\n    OPTIMIZE = \\\"OPTIMIZE\\\"\\n    CHANGED = \\\"CHANGED\\\"\\n    QUESTION = \\\"QUESTION\\\"\\n    Q = \\\"Q\\\"\\n    DEPRECATED = \\\"@deprecated\\\"\\n    NOSONAR = \\\"NOSONAR\\\"\\n    TODO_FIXME = \\\"TODO-FIXME\\\"\\n\\n    def __str__(self) -> str:\\n        return self.value\\n\\n\\nclass BlockType(str, Enum):\\n    \\\"\\\"\\\"Enum of code block types.\\\"\\\"\\\"\\n\\n    STANDALONE_CODE_BLOCK = \\\"STANDALONE_BLOCK\\\"\\n    CLASS = \\\"CLASS\\\"\\n    FUNCTION = \\\"FUNCTION\\\"\\n    MODULE = \\\"MODULE\\\"\\n\\n    def __str__(self) -> str:\\n        return self.value\\n\\n\\nImported code block (postcode:models:models.py__*__MODULE) code content:\\nfrom typing import Union\\nfrom pydantic import BaseModel, Field, validator\\n\\nfrom postcode.models.enums import (\\n    BlockType,\\n    ImportModuleType,\\n    CommentType,\\n)\\n\\n\\nclass ImportNameModel(BaseModel):\\n    \\\"\\\"\\\"Class representing the name of an import.\\\"\\\"\\\"\\n\\n    name: str\\n    as_name: str | None = None\\n    local_block_id: str | None = None\\n\\n    # def convert_import_names_to_metadata(self) -> str:\\n    #     \\\"\\\"\\\"Converts the import name to a metadata string.\\\"\\\"\\\"\\n\\n    #     return self.model_dump_json()\\n\\n\\nclass ImportModel(BaseModel):\\n    \\\"\\\"\\\"Class representing an import statement.\\\"\\\"\\\"\\n\\n    import_names: list[ImportNameModel]\\n    imported_from: str | None = None\\n    import_module_type: ImportModuleType = ImportModuleType.STANDARD_LIBRARY\\n    local_module_id: str | None = None\\n\\n    def convert_import_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the import to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass DependencyModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a module dependency.\\\"\\\"\\\"\\n\\n    code_block_id: str\\n\\n    def convert_dependency_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the dependency to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass CommentModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a comment.\\\"\\\"\\\"\\n\\n    content: str\\n    comment_types: list[CommentType]\\n\\n    def convert_comment_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the comment to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass DecoratorModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a decorator.\\\"\\\"\\\"\\n\\n    content: str\\n    decorator_name: str\\n    decorator_args: list[str] | None = None\\n\\n    def convert_decorator_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the decorator to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass ClassKeywordModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a class keyword.\\\"\\\"\\\"\\n\\n    content: str\\n    keyword_name: str\\n    args: str | None = None\\n\\n    def convert_class_keyword_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the class keyword to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass ParameterModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a function parameter.\\\"\\\"\\\"\\n\\n    content: str\\n\\n\\nclass ParameterListModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a list of parameters.\\\"\\\"\\\"\\n\\n    params: list[ParameterModel] | None = None\\n    star_arg: ParameterModel | None = None\\n    kwonly_params: list[ParameterModel] | None = None\\n    star_kwarg: ParameterModel | None = None\\n    posonly_params: list[ParameterModel] | None = None\\n\\n    def convert_parameters_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the parameter list to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass BaseCodeBlockModel(BaseModel):\\n    \\\"\\\"\\\"Attributes common to all code block models.\\\"\\\"\\\"\\n\\n    id: str\\n    parent_id: str | None = None\\n    block_type: BlockType\\n    start_line_num: int\\n    end_line_num: int\\n    code_content: str = \\\"\\\"\\n    important_comments: list[CommentModel] | None = None\\n    dependencies: list[ImportModel | DependencyModel] | None = None\\n    summary: str | None = None\\n    children: list[\\n        Union[\\n            \\\"ClassModel\\\",\\n            \\\"FunctionModel\\\",\\n            \\\"StandaloneCodeBlockModel\\\",\\n        ]\\n    ] | None = []\\n\\n    @validator(\\\"parent_id\\\", always=True)\\n    def check_parent_id(cls, v, values, **kwargs) -> str | None:\\n        \\\"\\\"\\\"Validates that parent_id is a non-empty string unless block_type is MODULE.\\\"\\\"\\\"\\n\\n        if \\\"block_type\\\" in values and values[\\\"block_type\\\"] != BlockType.MODULE:\\n            if len(v) < 1:\\n                raise ValueError(\\\"parent_id is required!\\\")\\n        return v\\n\\n    def _convert_parent_id_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the parent_id to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.parent_id}\\\" if self.parent_id else \\\"\\\"\\n\\n    def _convert_block_type_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the block_type to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.block_type.name}\\\"\\n\\n    def _convert_important_comments_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the important comments to a metadata string.\\\"\\\"\\\"\\n\\n        important_comments: str = (\\n            self.model_dump_json() if self.important_comments else \\\"\\\"\\n        )\\n\\n        return f\\\"{important_comments}\\\"\\n\\n    def _convert_dependencies_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the dependencies to a metadata string.\\\"\\\"\\\"\\n\\n        dependencies_str: str = \\\"\\\"\\n\\n        if self.dependencies:\\n            for dependency in self.dependencies:\\n                if isinstance(dependency, ImportModel):\\n                    dependencies_str += f\\\"{dependency.convert_import_to_metadata()}\\\\n\\\"\\n                elif isinstance(dependency, DependencyModel):\\n                    dependencies_str += (\\n                        f\\\"{dependency.convert_dependency_to_metadata()}\\\\n\\\"\\n                    )\\n\\n        return dependencies_str\\n\\n    def _convert_summary_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the summary to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.summary}\\\" if self.summary else \\\"\\\"\\n\\n    def _convert_children_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the children to a metadata string.\\\"\\\"\\\"\\n\\n        children_str: str = \\\"\\\"\\n\\n        if self.children:\\n            for child in self.children:\\n                children_str += f\\\"{child.id}\\\\n\\\"\\n\\n        return children_str\\n\\n    def _convert_base_attributes_to_metadata_dict(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the base attributes to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            \\\"id\\\": self.id,\\n            \\\"parent_id\\\": self._convert_parent_id_to_metadata(),\\n            \\\"block_type\\\": self._convert_block_type_to_metadata(),\\n            \\\"start_line_num\\\": self.start_line_num,\\n            \\\"end_line_num\\\": self.end_line_num,\\n            \\\"code_content\\\": self.code_content,\\n            \\\"important_comments\\\": self._convert_important_comments_to_metadata(),\\n            \\\"dependencies\\\": self._convert_dependencies_to_metadata(),\\n            \\\"summary\\\": self._convert_summary_to_metadata(),\\n            \\\"children\\\": self._convert_children_to_metadata(),\\n        }\\n\\n\\nclass ModuleSpecificAttributes(BaseModel):\\n    \\\"\\\"\\\"Module specific attributes.\\\"\\\"\\\"\\n\\n    file_path: str = Field(min_length=1)\\n    docstring: str | None = None\\n    header: list[str] | None = None\\n    footer: list[str] | None = None\\n    imports: list[ImportModel] | None = None\\n\\n    def _convert_docstring_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the docstring to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.docstring}\\\"\\n\\n    def _convert_header_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the header and footer to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n    def _convert_footer_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the header and footer to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n    def _convert_imports_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the imports to a metadata string.\\\"\\\"\\\"\\n        imports_str: str = self.model_dump_json() if self.imports else \\\"\\\"\\n        return f\\\"{imports_str}\\\"\\n\\n    def _convert_module_attributes_to_metadata_dict(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the module attributes to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            \\\"file_path\\\": self.file_path,\\n            \\\"docstring\\\": self._convert_docstring_to_metadata(),\\n            \\\"header\\\": self._convert_header_to_metadata(),\\n            \\\"footer\\\": self._convert_footer_to_metadata(),\\n            \\\"imports\\\": self._convert_imports_to_metadata(),\\n        }\\n\\n\\nclass ModuleModel(BaseCodeBlockModel, ModuleSpecificAttributes):\\n    \\\"\\\"\\\"Model for a module.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the module model to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_module_attributes_to_metadata_dict(),\\n        }\\n\\n\\nclass ClassSpecificAttributes(BaseModel):\\n    \\\"\\\"\\\"Class specific attributes.\\\"\\\"\\\"\\n\\n    class_name: str = Field(min_length=1)\\n    decorators: list[DecoratorModel] | None = None\\n    bases: list[str] | None = None\\n    docstring: str | None = None\\n    keywords: list[ClassKeywordModel] | None = None\\n    # attributes: list[dict] | None = None\\n\\n    def _convert_decorators_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the decorators to a metadata string.\\\"\\\"\\\"\\n        decorators_str: str = self.model_dump_json() if self.decorators else \\\"\\\"\\n        return f\\\"{decorators_str}\\\"\\n\\n    def _convert_bases_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the bases to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json() if self.bases else \\\"\\\"\\n\\n    def _convert_docstring_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the docstring to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.docstring}\\\" if self.docstring else \\\"\\\"\\n\\n    def _convert_keywords_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the keywords to a metadata string.\\\"\\\"\\\"\\n        keywords_str: str = self.model_dump_json() if self.keywords else \\\"\\\"\\n        return f\\\"{keywords_str}\\\"\\n\\n    def _convert_class_attributes_to_metadata_dict(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the class attributes to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            \\\"class_name\\\": self.class_name,\\n            \\\"decorators\\\": self._convert_decorators_to_metadata(),\\n            \\\"bases\\\": self._convert_bases_to_metadata(),\\n            \\\"docstring\\\": self._convert_docstring_to_metadata(),\\n            \\\"keywords\\\": self._convert_keywords_to_metadata(),\\n        }\\n\\n\\nclass ClassModel(BaseCodeBlockModel, ClassSpecificAttributes):\\n    \\\"\\\"\\\"Model for a class.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the class model to a metadata dictionary.\\\"\\\"\\\"\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_class_attributes_to_metadata_dict(),\\n        }\\n\\n\\nclass FunctionSpecificAttributes(BaseModel):\\n    \\\"\\\"\\\"Function specific attributes.\\\"\\\"\\\"\\n\\n    function_name: str = Field(min_length=1)\\n    docstring: str | None = None\\n    decorators: list[DecoratorModel] | None = None\\n    parameters: ParameterListModel | None = None\\n    returns: str | None = None\\n    is_method: bool = False\\n    is_async: bool = False\\n\\n    def _convert_docstring_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the docstring to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.docstring}\\\" if self.docstring else \\\"\\\"\\n\\n    def _convert_decorators_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the decorators to a metadata string.\\\"\\\"\\\"\\n        decorators_str: str = self.model_dump_json() if self.decorators else \\\"\\\"\\n        return f\\\"{decorators_str}\\\"\\n\\n    def _convert_parameters_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the parameters to a metadata string.\\\"\\\"\\\"\\n        return (\\n            self.parameters.convert_parameters_to_metadata() if self.parameters else \\\"\\\"\\n        )\\n\\n    def _convert_returns_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the returns to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.returns}\\\" if self.returns else \\\"\\\"\\n\\n    def _convert_function_attributes_to_metadata_dict(self) -> dict[str, str | bool]:\\n        \\\"\\\"\\\"Converts the function attributes to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            \\\"function_name\\\": self.function_name,\\n            \\\"docstring\\\": self._convert_docstring_to_metadata(),\\n            \\\"decorators\\\": self._convert_decorators_to_metadata(),\\n            \\\"parameters\\\": self._convert_parameters_to_metadata(),\\n            \\\"returns\\\": self._convert_returns_to_metadata(),\\n            \\\"is_method\\\": self.is_method,\\n            \\\"is_async\\\": self.is_async,\\n        }\\n\\n\\nclass FunctionModel(BaseCodeBlockModel, FunctionSpecificAttributes):\\n    \\\"\\\"\\\"Model for a function.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the function model to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_function_attributes_to_metadata_dict(),\\n        }\\n\\n\\nclass StandaloneCodeBlockSpecificAttributes(BaseModel):\\n    \\\"\\\"\\\"Standalone code block specific attributes.\\\"\\\"\\\"\\n\\n    variable_assignments: list[str] | None = None\\n\\n    def _convert_variable_assignments_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the variable assignments to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json() if self.variable_assignments else \\\"\\\"\\n\\n    def _convert_standalone_block_attributes_to_metadata_dict(\\n        self,\\n    ) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the standalone code block attributes to a metadata dictionary.\\\"\\\"\\\"\\n        return {\\n            \\\"variable_assignments\\\": self._convert_variable_assignments_to_metadata(),\\n        }\\n\\n\\nclass StandaloneCodeBlockModel(\\n    BaseCodeBlockModel, StandaloneCodeBlockSpecificAttributes\\n):\\n    \\\"\\\"\\\"Model for a standalone code block.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the standalone code block model to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_standalone_block_attributes_to_metadata_dict(),\\n        }\\n\\n, \\nfrom typing import Any, Union\\n        \",\"children\":[{\"variable_assignments\":[\"ModelType = Union[\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n]\"],\"id\":\"postcode:databases:arangodb:helper_functions.py__*__MODULE__*__STANDALONE_BLOCK-1\",\"parent_id\":\"postcode:databases:arangodb:helper_functions.py__*__MODULE\",\"block_type\":\"STANDALONE_BLOCK\",\"start_line_num\":10,\"end_line_num\":19,\"code_content\":\"# from postcode.types.postcode import ModelType\\n\\nModelType = Union[\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n]\\n\",\"important_comments\":null,\"dependencies\":[{\"import_names\":[{\"name\":\"Any\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"Union\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"typing\",\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"},{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ClassModel\"},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-FunctionModel\"},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-StandaloneCodeBlockModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"},{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ClassModel\"},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-FunctionModel\"},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-StandaloneCodeBlockModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"},{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ClassModel\"},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-FunctionModel\"},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-StandaloneCodeBlockModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"},{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ClassModel\"},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-FunctionModel\"},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-StandaloneCodeBlockModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"}],\"summary\":null,\"children\":null},{\"function_name\":\"pluralized_and_lowered_block_types\",\"docstring\":null,\"decorators\":null,\"parameters\":null,\"returns\":\"list[str]\",\"is_method\":false,\"is_async\":false,\"id\":\"postcode:databases:arangodb:helper_functions.py__*__MODULE__*__FUNCTION-pluralized_and_lowered_block_types\",\"parent_id\":\"postcode:databases:arangodb:helper_functions.py__*__MODULE\",\"block_type\":\"FUNCTION\",\"start_line_num\":19,\"end_line_num\":23,\"code_content\":\"\\n\\ndef pluralized_and_lowered_block_types() -> list[str]:\\n    return [pluralize_block_type(block_type).lower() for block_type in BlockType]\\n\",\"important_comments\":null,\"dependencies\":[{\"code_block_id\":\"postcode:databases:arangodb:helper_functions.py__*__MODULE__*__FUNCTION-pluralize_block_type\"},{\"import_names\":[{\"name\":\"BlockType\",\"as_name\":null,\"local_block_id\":\"postcode:models:enums.py__*__MODULE__*__CLASS-BlockType\"}],\"imported_from\":\"postcode.models.enums\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:enums.py__*__MODULE\"}],\"summary\":null,\"children\":null},{\"function_name\":\"pluralize_block_type\",\"docstring\":null,\"decorators\":null,\"parameters\":null,\"returns\":\"str\",\"is_method\":false,\"is_async\":false,\"id\":\"postcode:databases:arangodb:helper_functions.py__*__MODULE__*__FUNCTION-pluralize_block_type\",\"parent_id\":\"postcode:databases:arangodb:helper_functions.py__*__MODULE\",\"block_type\":\"FUNCTION\",\"start_line_num\":23,\"end_line_num\":30,\"code_content\":\"\\n\\ndef pluralize_block_type(block_type: str) -> str:\\n    if block_type == BlockType.CLASS:\\n        return \\\"classes\\\"\\n    else:\\n        return f\\\"{block_type.lower()}s\\\"\\n\",\"important_comments\":null,\"dependencies\":[{\"import_names\":[{\"name\":\"BlockType\",\"as_name\":null,\"local_block_id\":\"postcode:models:enums.py__*__MODULE__*__CLASS-BlockType\"}],\"imported_from\":\"postcode.models.enums\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:enums.py__*__MODULE\"}],\"summary\":null,\"children\":null},{\"function_name\":\"create_model_from_vertex\",\"docstring\":null,\"decorators\":null,\"parameters\":null,\"returns\":\"ModelType\",\"is_method\":false,\"is_async\":false,\"id\":\"postcode:databases:arangodb:helper_functions.py__*__MODULE__*__FUNCTION-create_model_from_vertex\",\"parent_id\":\"postcode:databases:arangodb:helper_functions.py__*__MODULE\",\"block_type\":\"FUNCTION\",\"start_line_num\":30,\"end_line_num\":45,\"code_content\":\"\\n\\ndef create_model_from_vertex(vertex_data: dict) -> ModelType:\\n    block_type = vertex_data.get(\\\"block_type\\\")\\n\\n    if block_type == BlockType.MODULE:\\n        return ModuleModel(**vertex_data)\\n    elif block_type == BlockType.CLASS:\\n        return ClassModel(**vertex_data)\\n    elif block_type == BlockType.FUNCTION:\\n        return FunctionModel(**vertex_data)\\n    elif block_type == BlockType.STANDALONE_CODE_BLOCK:\\n        return StandaloneCodeBlockModel(**vertex_data)\\n    else:\\n        raise ValueError(f\\\"Unknown block type: {block_type}\\\")\\n\",\"important_comments\":null,\"dependencies\":[{\"import_names\":[{\"name\":\"BlockType\",\"as_name\":null,\"local_block_id\":\"postcode:models:enums.py__*__MODULE__*__CLASS-BlockType\"}],\"imported_from\":\"postcode.models.enums\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:enums.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"},{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ClassModel\"},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-FunctionModel\"},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-StandaloneCodeBlockModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"},{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ClassModel\"},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-FunctionModel\"},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-StandaloneCodeBlockModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"},{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ClassModel\"},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-FunctionModel\"},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-StandaloneCodeBlockModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"},{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ClassModel\"},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-FunctionModel\"},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-StandaloneCodeBlockModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"}],\"summary\":null,\"children\":null}]}", "footer": "{\"file_path\":\"postcode/databases/arangodb/helper_functions.py\",\"docstring\":null,\"header\":[],\"footer\":[],\"imports\":[{\"import_names\":[{\"name\":\"Any\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"Union\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"typing\",\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"BlockType\",\"as_name\":null,\"local_block_id\":\"postcode:models:enums.py__*__MODULE__*__CLASS-BlockType\"}],\"imported_from\":\"postcode.models.enums\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:enums.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"},{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ClassModel\"},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-FunctionModel\"},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-StandaloneCodeBlockModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"}],\"id\":\"postcode:databases:arangodb:helper_functions.py__*__MODULE\",\"parent_id\":null,\"block_type\":\"MODULE\",\"start_line_num\":1,\"end_line_num\":45,\"code_content\":\"from typing import Any, Union\\n\\nfrom postcode.models.enums import BlockType\\nfrom postcode.models.models import (\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n)\\n\\n# from postcode.types.postcode import ModelType\\n\\nModelType = Union[\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n]\\n\\n\\ndef pluralized_and_lowered_block_types() -> list[str]:\\n    return [pluralize_block_type(block_type).lower() for block_type in BlockType]\\n\\n\\ndef pluralize_block_type(block_type: str) -> str:\\n    if block_type == BlockType.CLASS:\\n        return \\\"classes\\\"\\n    else:\\n        return f\\\"{block_type.lower()}s\\\"\\n\\n\\ndef create_model_from_vertex(vertex_data: dict) -> ModelType:\\n    block_type = vertex_data.get(\\\"block_type\\\")\\n\\n    if block_type == BlockType.MODULE:\\n        return ModuleModel(**vertex_data)\\n    elif block_type == BlockType.CLASS:\\n        return ClassModel(**vertex_data)\\n    elif block_type == BlockType.FUNCTION:\\n        return FunctionModel(**vertex_data)\\n    elif block_type == BlockType.STANDALONE_CODE_BLOCK:\\n        return StandaloneCodeBlockModel(**vertex_data)\\n    else:\\n        raise ValueError(f\\\"Unknown block type: {block_type}\\\")\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":\"\\nSummary:\\n\\n        postcode:databases:arangodb:helper_functions.py__*__MODULE\\n\\n        \\nChild (postcode:databases:arangodb:helper_functions.py__*__MODULE__*__STANDALONE_BLOCK-1) code content:\\n# from postcode.types.postcode import ModelType\\n\\nModelType = Union[\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n]\\n\\n\\nChild (postcode:databases:arangodb:helper_functions.py__*__MODULE__*__FUNCTION-pluralized_and_lowered_block_types) code content:\\n\\n\\ndef pluralized_and_lowered_block_types() -> list[str]:\\n    return [pluralize_block_type(block_type).lower() for block_type in BlockType]\\n\\n\\nChild (postcode:databases:arangodb:helper_functions.py__*__MODULE__*__FUNCTION-pluralize_block_type) code content:\\n\\n\\ndef pluralize_block_type(block_type: str) -> str:\\n    if block_type == BlockType.CLASS:\\n        return \\\"classes\\\"\\n    else:\\n        return f\\\"{block_type.lower()}s\\\"\\n\\n\\nChild (postcode:databases:arangodb:helper_functions.py__*__MODULE__*__FUNCTION-create_model_from_vertex) code content:\\n\\n\\ndef create_model_from_vertex(vertex_data: dict) -> ModelType:\\n    block_type = vertex_data.get(\\\"block_type\\\")\\n\\n    if block_type == BlockType.MODULE:\\n        return ModuleModel(**vertex_data)\\n    elif block_type == BlockType.CLASS:\\n        return ClassModel(**vertex_data)\\n    elif block_type == BlockType.FUNCTION:\\n        return FunctionModel(**vertex_data)\\n    elif block_type == BlockType.STANDALONE_CODE_BLOCK:\\n        return StandaloneCodeBlockModel(**vertex_data)\\n    else:\\n        raise ValueError(f\\\"Unknown block type: {block_type}\\\")\\n\\n, \\nImported code block (postcode:models:enums.py__*__MODULE) code content:\\nfrom enum import Enum\\n\\n\\nclass ImportModuleType(str, Enum):\\n    \\\"\\\"\\\"Enum of import module types.\\\"\\\"\\\"\\n\\n    STANDARD_LIBRARY = \\\"STANDARD_LIBRARY\\\"\\n    LOCAL = \\\"LOCAL\\\"\\n    THIRD_PARTY = \\\"THIRD_PARTY\\\"\\n\\n    def __str__(self) -> str:\\n        return self.value\\n\\n\\nclass CommentType(str, Enum):\\n    \\\"\\\"\\\"Class representing the different types of important comments.\\\"\\\"\\\"\\n\\n    TODO = \\\"TODO\\\"\\n    FIXME = \\\"FIXME\\\"\\n    NOTE = \\\"NOTE\\\"\\n    HACK = \\\"HACK\\\"\\n    XXX = \\\"XXX\\\"\\n    REVIEW = \\\"REVIEW\\\"\\n    OPTIMIZE = \\\"OPTIMIZE\\\"\\n    CHANGED = \\\"CHANGED\\\"\\n    QUESTION = \\\"QUESTION\\\"\\n    Q = \\\"Q\\\"\\n    DEPRECATED = \\\"@deprecated\\\"\\n    NOSONAR = \\\"NOSONAR\\\"\\n    TODO_FIXME = \\\"TODO-FIXME\\\"\\n\\n    def __str__(self) -> str:\\n        return self.value\\n\\n\\nclass BlockType(str, Enum):\\n    \\\"\\\"\\\"Enum of code block types.\\\"\\\"\\\"\\n\\n    STANDALONE_CODE_BLOCK = \\\"STANDALONE_BLOCK\\\"\\n    CLASS = \\\"CLASS\\\"\\n    FUNCTION = \\\"FUNCTION\\\"\\n    MODULE = \\\"MODULE\\\"\\n\\n    def __str__(self) -> str:\\n        return self.value\\n\\n\\nImported code block (postcode:models:models.py__*__MODULE) code content:\\nfrom typing import Union\\nfrom pydantic import BaseModel, Field, validator\\n\\nfrom postcode.models.enums import (\\n    BlockType,\\n    ImportModuleType,\\n    CommentType,\\n)\\n\\n\\nclass ImportNameModel(BaseModel):\\n    \\\"\\\"\\\"Class representing the name of an import.\\\"\\\"\\\"\\n\\n    name: str\\n    as_name: str | None = None\\n    local_block_id: str | None = None\\n\\n    # def convert_import_names_to_metadata(self) -> str:\\n    #     \\\"\\\"\\\"Converts the import name to a metadata string.\\\"\\\"\\\"\\n\\n    #     return self.model_dump_json()\\n\\n\\nclass ImportModel(BaseModel):\\n    \\\"\\\"\\\"Class representing an import statement.\\\"\\\"\\\"\\n\\n    import_names: list[ImportNameModel]\\n    imported_from: str | None = None\\n    import_module_type: ImportModuleType = ImportModuleType.STANDARD_LIBRARY\\n    local_module_id: str | None = None\\n\\n    def convert_import_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the import to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass DependencyModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a module dependency.\\\"\\\"\\\"\\n\\n    code_block_id: str\\n\\n    def convert_dependency_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the dependency to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass CommentModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a comment.\\\"\\\"\\\"\\n\\n    content: str\\n    comment_types: list[CommentType]\\n\\n    def convert_comment_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the comment to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass DecoratorModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a decorator.\\\"\\\"\\\"\\n\\n    content: str\\n    decorator_name: str\\n    decorator_args: list[str] | None = None\\n\\n    def convert_decorator_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the decorator to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass ClassKeywordModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a class keyword.\\\"\\\"\\\"\\n\\n    content: str\\n    keyword_name: str\\n    args: str | None = None\\n\\n    def convert_class_keyword_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the class keyword to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass ParameterModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a function parameter.\\\"\\\"\\\"\\n\\n    content: str\\n\\n\\nclass ParameterListModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a list of parameters.\\\"\\\"\\\"\\n\\n    params: list[ParameterModel] | None = None\\n    star_arg: ParameterModel | None = None\\n    kwonly_params: list[ParameterModel] | None = None\\n    star_kwarg: ParameterModel | None = None\\n    posonly_params: list[ParameterModel] | None = None\\n\\n    def convert_parameters_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the parameter list to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass BaseCodeBlockModel(BaseModel):\\n    \\\"\\\"\\\"Attributes common to all code block models.\\\"\\\"\\\"\\n\\n    id: str\\n    parent_id: str | None = None\\n    block_type: BlockType\\n    start_line_num: int\\n    end_line_num: int\\n    code_content: str = \\\"\\\"\\n    important_comments: list[CommentModel] | None = None\\n    dependencies: list[ImportModel | DependencyModel] | None = None\\n    summary: str | None = None\\n    children: list[\\n        Union[\\n            \\\"ClassModel\\\",\\n            \\\"FunctionModel\\\",\\n            \\\"StandaloneCodeBlockModel\\\",\\n        ]\\n    ] | None = []\\n\\n    @validator(\\\"parent_id\\\", always=True)\\n    def check_parent_id(cls, v, values, **kwargs) -> str | None:\\n        \\\"\\\"\\\"Validates that parent_id is a non-empty string unless block_type is MODULE.\\\"\\\"\\\"\\n\\n        if \\\"block_type\\\" in values and values[\\\"block_type\\\"] != BlockType.MODULE:\\n            if len(v) < 1:\\n                raise ValueError(\\\"parent_id is required!\\\")\\n        return v\\n\\n    def _convert_parent_id_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the parent_id to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.parent_id}\\\" if self.parent_id else \\\"\\\"\\n\\n    def _convert_block_type_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the block_type to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.block_type.name}\\\"\\n\\n    def _convert_important_comments_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the important comments to a metadata string.\\\"\\\"\\\"\\n\\n        important_comments: str = (\\n            self.model_dump_json() if self.important_comments else \\\"\\\"\\n        )\\n\\n        return f\\\"{important_comments}\\\"\\n\\n    def _convert_dependencies_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the dependencies to a metadata string.\\\"\\\"\\\"\\n\\n        dependencies_str: str = \\\"\\\"\\n\\n        if self.dependencies:\\n            for dependency in self.dependencies:\\n                if isinstance(dependency, ImportModel):\\n                    dependencies_str += f\\\"{dependency.convert_import_to_metadata()}\\\\n\\\"\\n                elif isinstance(dependency, DependencyModel):\\n                    dependencies_str += (\\n                        f\\\"{dependency.convert_dependency_to_metadata()}\\\\n\\\"\\n                    )\\n\\n        return dependencies_str\\n\\n    def _convert_summary_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the summary to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.summary}\\\" if self.summary else \\\"\\\"\\n\\n    def _convert_children_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the children to a metadata string.\\\"\\\"\\\"\\n\\n        children_str: str = \\\"\\\"\\n\\n        if self.children:\\n            for child in self.children:\\n                children_str += f\\\"{child.id}\\\\n\\\"\\n\\n        return children_str\\n\\n    def _convert_base_attributes_to_metadata_dict(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the base attributes to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            \\\"id\\\": self.id,\\n            \\\"parent_id\\\": self._convert_parent_id_to_metadata(),\\n            \\\"block_type\\\": self._convert_block_type_to_metadata(),\\n            \\\"start_line_num\\\": self.start_line_num,\\n            \\\"end_line_num\\\": self.end_line_num,\\n            \\\"code_content\\\": self.code_content,\\n            \\\"important_comments\\\": self._convert_important_comments_to_metadata(),\\n            \\\"dependencies\\\": self._convert_dependencies_to_metadata(),\\n            \\\"summary\\\": self._convert_summary_to_metadata(),\\n            \\\"children\\\": self._convert_children_to_metadata(),\\n        }\\n\\n\\nclass ModuleSpecificAttributes(BaseModel):\\n    \\\"\\\"\\\"Module specific attributes.\\\"\\\"\\\"\\n\\n    file_path: str = Field(min_length=1)\\n    docstring: str | None = None\\n    header: list[str] | None = None\\n    footer: list[str] | None = None\\n    imports: list[ImportModel] | None = None\\n\\n    def _convert_docstring_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the docstring to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.docstring}\\\"\\n\\n    def _convert_header_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the header and footer to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n    def _convert_footer_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the header and footer to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n    def _convert_imports_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the imports to a metadata string.\\\"\\\"\\\"\\n        imports_str: str = self.model_dump_json() if self.imports else \\\"\\\"\\n        return f\\\"{imports_str}\\\"\\n\\n    def _convert_module_attributes_to_metadata_dict(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the module attributes to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            \\\"file_path\\\": self.file_path,\\n            \\\"docstring\\\": self._convert_docstring_to_metadata(),\\n            \\\"header\\\": self._convert_header_to_metadata(),\\n            \\\"footer\\\": self._convert_footer_to_metadata(),\\n            \\\"imports\\\": self._convert_imports_to_metadata(),\\n        }\\n\\n\\nclass ModuleModel(BaseCodeBlockModel, ModuleSpecificAttributes):\\n    \\\"\\\"\\\"Model for a module.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the module model to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_module_attributes_to_metadata_dict(),\\n        }\\n\\n\\nclass ClassSpecificAttributes(BaseModel):\\n    \\\"\\\"\\\"Class specific attributes.\\\"\\\"\\\"\\n\\n    class_name: str = Field(min_length=1)\\n    decorators: list[DecoratorModel] | None = None\\n    bases: list[str] | None = None\\n    docstring: str | None = None\\n    keywords: list[ClassKeywordModel] | None = None\\n    # attributes: list[dict] | None = None\\n\\n    def _convert_decorators_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the decorators to a metadata string.\\\"\\\"\\\"\\n        decorators_str: str = self.model_dump_json() if self.decorators else \\\"\\\"\\n        return f\\\"{decorators_str}\\\"\\n\\n    def _convert_bases_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the bases to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json() if self.bases else \\\"\\\"\\n\\n    def _convert_docstring_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the docstring to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.docstring}\\\" if self.docstring else \\\"\\\"\\n\\n    def _convert_keywords_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the keywords to a metadata string.\\\"\\\"\\\"\\n        keywords_str: str = self.model_dump_json() if self.keywords else \\\"\\\"\\n        return f\\\"{keywords_str}\\\"\\n\\n    def _convert_class_attributes_to_metadata_dict(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the class attributes to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            \\\"class_name\\\": self.class_name,\\n            \\\"decorators\\\": self._convert_decorators_to_metadata(),\\n            \\\"bases\\\": self._convert_bases_to_metadata(),\\n            \\\"docstring\\\": self._convert_docstring_to_metadata(),\\n            \\\"keywords\\\": self._convert_keywords_to_metadata(),\\n        }\\n\\n\\nclass ClassModel(BaseCodeBlockModel, ClassSpecificAttributes):\\n    \\\"\\\"\\\"Model for a class.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the class model to a metadata dictionary.\\\"\\\"\\\"\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_class_attributes_to_metadata_dict(),\\n        }\\n\\n\\nclass FunctionSpecificAttributes(BaseModel):\\n    \\\"\\\"\\\"Function specific attributes.\\\"\\\"\\\"\\n\\n    function_name: str = Field(min_length=1)\\n    docstring: str | None = None\\n    decorators: list[DecoratorModel] | None = None\\n    parameters: ParameterListModel | None = None\\n    returns: str | None = None\\n    is_method: bool = False\\n    is_async: bool = False\\n\\n    def _convert_docstring_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the docstring to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.docstring}\\\" if self.docstring else \\\"\\\"\\n\\n    def _convert_decorators_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the decorators to a metadata string.\\\"\\\"\\\"\\n        decorators_str: str = self.model_dump_json() if self.decorators else \\\"\\\"\\n        return f\\\"{decorators_str}\\\"\\n\\n    def _convert_parameters_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the parameters to a metadata string.\\\"\\\"\\\"\\n        return (\\n            self.parameters.convert_parameters_to_metadata() if self.parameters else \\\"\\\"\\n        )\\n\\n    def _convert_returns_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the returns to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.returns}\\\" if self.returns else \\\"\\\"\\n\\n    def _convert_function_attributes_to_metadata_dict(self) -> dict[str, str | bool]:\\n        \\\"\\\"\\\"Converts the function attributes to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            \\\"function_name\\\": self.function_name,\\n            \\\"docstring\\\": self._convert_docstring_to_metadata(),\\n            \\\"decorators\\\": self._convert_decorators_to_metadata(),\\n            \\\"parameters\\\": self._convert_parameters_to_metadata(),\\n            \\\"returns\\\": self._convert_returns_to_metadata(),\\n            \\\"is_method\\\": self.is_method,\\n            \\\"is_async\\\": self.is_async,\\n        }\\n\\n\\nclass FunctionModel(BaseCodeBlockModel, FunctionSpecificAttributes):\\n    \\\"\\\"\\\"Model for a function.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the function model to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_function_attributes_to_metadata_dict(),\\n        }\\n\\n\\nclass StandaloneCodeBlockSpecificAttributes(BaseModel):\\n    \\\"\\\"\\\"Standalone code block specific attributes.\\\"\\\"\\\"\\n\\n    variable_assignments: list[str] | None = None\\n\\n    def _convert_variable_assignments_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the variable assignments to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json() if self.variable_assignments else \\\"\\\"\\n\\n    def _convert_standalone_block_attributes_to_metadata_dict(\\n        self,\\n    ) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the standalone code block attributes to a metadata dictionary.\\\"\\\"\\\"\\n        return {\\n            \\\"variable_assignments\\\": self._convert_variable_assignments_to_metadata(),\\n        }\\n\\n\\nclass StandaloneCodeBlockModel(\\n    BaseCodeBlockModel, StandaloneCodeBlockSpecificAttributes\\n):\\n    \\\"\\\"\\\"Model for a standalone code block.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the standalone code block model to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_standalone_block_attributes_to_metadata_dict(),\\n        }\\n\\n, \\nfrom typing import Any, Union\\n        \",\"children\":[{\"variable_assignments\":[\"ModelType = Union[\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n]\"],\"id\":\"postcode:databases:arangodb:helper_functions.py__*__MODULE__*__STANDALONE_BLOCK-1\",\"parent_id\":\"postcode:databases:arangodb:helper_functions.py__*__MODULE\",\"block_type\":\"STANDALONE_BLOCK\",\"start_line_num\":10,\"end_line_num\":19,\"code_content\":\"# from postcode.types.postcode import ModelType\\n\\nModelType = Union[\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n]\\n\",\"important_comments\":null,\"dependencies\":[{\"import_names\":[{\"name\":\"Any\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"Union\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"typing\",\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"},{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ClassModel\"},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-FunctionModel\"},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-StandaloneCodeBlockModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"},{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ClassModel\"},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-FunctionModel\"},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-StandaloneCodeBlockModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"},{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ClassModel\"},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-FunctionModel\"},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-StandaloneCodeBlockModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"},{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ClassModel\"},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-FunctionModel\"},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-StandaloneCodeBlockModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"}],\"summary\":null,\"children\":null},{\"function_name\":\"pluralized_and_lowered_block_types\",\"docstring\":null,\"decorators\":null,\"parameters\":null,\"returns\":\"list[str]\",\"is_method\":false,\"is_async\":false,\"id\":\"postcode:databases:arangodb:helper_functions.py__*__MODULE__*__FUNCTION-pluralized_and_lowered_block_types\",\"parent_id\":\"postcode:databases:arangodb:helper_functions.py__*__MODULE\",\"block_type\":\"FUNCTION\",\"start_line_num\":19,\"end_line_num\":23,\"code_content\":\"\\n\\ndef pluralized_and_lowered_block_types() -> list[str]:\\n    return [pluralize_block_type(block_type).lower() for block_type in BlockType]\\n\",\"important_comments\":null,\"dependencies\":[{\"code_block_id\":\"postcode:databases:arangodb:helper_functions.py__*__MODULE__*__FUNCTION-pluralize_block_type\"},{\"import_names\":[{\"name\":\"BlockType\",\"as_name\":null,\"local_block_id\":\"postcode:models:enums.py__*__MODULE__*__CLASS-BlockType\"}],\"imported_from\":\"postcode.models.enums\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:enums.py__*__MODULE\"}],\"summary\":null,\"children\":null},{\"function_name\":\"pluralize_block_type\",\"docstring\":null,\"decorators\":null,\"parameters\":null,\"returns\":\"str\",\"is_method\":false,\"is_async\":false,\"id\":\"postcode:databases:arangodb:helper_functions.py__*__MODULE__*__FUNCTION-pluralize_block_type\",\"parent_id\":\"postcode:databases:arangodb:helper_functions.py__*__MODULE\",\"block_type\":\"FUNCTION\",\"start_line_num\":23,\"end_line_num\":30,\"code_content\":\"\\n\\ndef pluralize_block_type(block_type: str) -> str:\\n    if block_type == BlockType.CLASS:\\n        return \\\"classes\\\"\\n    else:\\n        return f\\\"{block_type.lower()}s\\\"\\n\",\"important_comments\":null,\"dependencies\":[{\"import_names\":[{\"name\":\"BlockType\",\"as_name\":null,\"local_block_id\":\"postcode:models:enums.py__*__MODULE__*__CLASS-BlockType\"}],\"imported_from\":\"postcode.models.enums\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:enums.py__*__MODULE\"}],\"summary\":null,\"children\":null},{\"function_name\":\"create_model_from_vertex\",\"docstring\":null,\"decorators\":null,\"parameters\":null,\"returns\":\"ModelType\",\"is_method\":false,\"is_async\":false,\"id\":\"postcode:databases:arangodb:helper_functions.py__*__MODULE__*__FUNCTION-create_model_from_vertex\",\"parent_id\":\"postcode:databases:arangodb:helper_functions.py__*__MODULE\",\"block_type\":\"FUNCTION\",\"start_line_num\":30,\"end_line_num\":45,\"code_content\":\"\\n\\ndef create_model_from_vertex(vertex_data: dict) -> ModelType:\\n    block_type = vertex_data.get(\\\"block_type\\\")\\n\\n    if block_type == BlockType.MODULE:\\n        return ModuleModel(**vertex_data)\\n    elif block_type == BlockType.CLASS:\\n        return ClassModel(**vertex_data)\\n    elif block_type == BlockType.FUNCTION:\\n        return FunctionModel(**vertex_data)\\n    elif block_type == BlockType.STANDALONE_CODE_BLOCK:\\n        return StandaloneCodeBlockModel(**vertex_data)\\n    else:\\n        raise ValueError(f\\\"Unknown block type: {block_type}\\\")\\n\",\"important_comments\":null,\"dependencies\":[{\"import_names\":[{\"name\":\"BlockType\",\"as_name\":null,\"local_block_id\":\"postcode:models:enums.py__*__MODULE__*__CLASS-BlockType\"}],\"imported_from\":\"postcode.models.enums\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:enums.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"},{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ClassModel\"},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-FunctionModel\"},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-StandaloneCodeBlockModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"},{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ClassModel\"},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-FunctionModel\"},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-StandaloneCodeBlockModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"},{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ClassModel\"},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-FunctionModel\"},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-StandaloneCodeBlockModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"},{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ClassModel\"},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-FunctionModel\"},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-StandaloneCodeBlockModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"}],\"summary\":null,\"children\":null}]}", "imports": "{\"file_path\":\"postcode/databases/arangodb/helper_functions.py\",\"docstring\":null,\"header\":[],\"footer\":[],\"imports\":[{\"import_names\":[{\"name\":\"Any\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"Union\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"typing\",\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"BlockType\",\"as_name\":null,\"local_block_id\":\"postcode:models:enums.py__*__MODULE__*__CLASS-BlockType\"}],\"imported_from\":\"postcode.models.enums\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:enums.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"},{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ClassModel\"},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-FunctionModel\"},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-StandaloneCodeBlockModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"}],\"id\":\"postcode:databases:arangodb:helper_functions.py__*__MODULE\",\"parent_id\":null,\"block_type\":\"MODULE\",\"start_line_num\":1,\"end_line_num\":45,\"code_content\":\"from typing import Any, Union\\n\\nfrom postcode.models.enums import BlockType\\nfrom postcode.models.models import (\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n)\\n\\n# from postcode.types.postcode import ModelType\\n\\nModelType = Union[\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n]\\n\\n\\ndef pluralized_and_lowered_block_types() -> list[str]:\\n    return [pluralize_block_type(block_type).lower() for block_type in BlockType]\\n\\n\\ndef pluralize_block_type(block_type: str) -> str:\\n    if block_type == BlockType.CLASS:\\n        return \\\"classes\\\"\\n    else:\\n        return f\\\"{block_type.lower()}s\\\"\\n\\n\\ndef create_model_from_vertex(vertex_data: dict) -> ModelType:\\n    block_type = vertex_data.get(\\\"block_type\\\")\\n\\n    if block_type == BlockType.MODULE:\\n        return ModuleModel(**vertex_data)\\n    elif block_type == BlockType.CLASS:\\n        return ClassModel(**vertex_data)\\n    elif block_type == BlockType.FUNCTION:\\n        return FunctionModel(**vertex_data)\\n    elif block_type == BlockType.STANDALONE_CODE_BLOCK:\\n        return StandaloneCodeBlockModel(**vertex_data)\\n    else:\\n        raise ValueError(f\\\"Unknown block type: {block_type}\\\")\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":\"\\nSummary:\\n\\n        postcode:databases:arangodb:helper_functions.py__*__MODULE\\n\\n        \\nChild (postcode:databases:arangodb:helper_functions.py__*__MODULE__*__STANDALONE_BLOCK-1) code content:\\n# from postcode.types.postcode import ModelType\\n\\nModelType = Union[\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n]\\n\\n\\nChild (postcode:databases:arangodb:helper_functions.py__*__MODULE__*__FUNCTION-pluralized_and_lowered_block_types) code content:\\n\\n\\ndef pluralized_and_lowered_block_types() -> list[str]:\\n    return [pluralize_block_type(block_type).lower() for block_type in BlockType]\\n\\n\\nChild (postcode:databases:arangodb:helper_functions.py__*__MODULE__*__FUNCTION-pluralize_block_type) code content:\\n\\n\\ndef pluralize_block_type(block_type: str) -> str:\\n    if block_type == BlockType.CLASS:\\n        return \\\"classes\\\"\\n    else:\\n        return f\\\"{block_type.lower()}s\\\"\\n\\n\\nChild (postcode:databases:arangodb:helper_functions.py__*__MODULE__*__FUNCTION-create_model_from_vertex) code content:\\n\\n\\ndef create_model_from_vertex(vertex_data: dict) -> ModelType:\\n    block_type = vertex_data.get(\\\"block_type\\\")\\n\\n    if block_type == BlockType.MODULE:\\n        return ModuleModel(**vertex_data)\\n    elif block_type == BlockType.CLASS:\\n        return ClassModel(**vertex_data)\\n    elif block_type == BlockType.FUNCTION:\\n        return FunctionModel(**vertex_data)\\n    elif block_type == BlockType.STANDALONE_CODE_BLOCK:\\n        return StandaloneCodeBlockModel(**vertex_data)\\n    else:\\n        raise ValueError(f\\\"Unknown block type: {block_type}\\\")\\n\\n, \\nImported code block (postcode:models:enums.py__*__MODULE) code content:\\nfrom enum import Enum\\n\\n\\nclass ImportModuleType(str, Enum):\\n    \\\"\\\"\\\"Enum of import module types.\\\"\\\"\\\"\\n\\n    STANDARD_LIBRARY = \\\"STANDARD_LIBRARY\\\"\\n    LOCAL = \\\"LOCAL\\\"\\n    THIRD_PARTY = \\\"THIRD_PARTY\\\"\\n\\n    def __str__(self) -> str:\\n        return self.value\\n\\n\\nclass CommentType(str, Enum):\\n    \\\"\\\"\\\"Class representing the different types of important comments.\\\"\\\"\\\"\\n\\n    TODO = \\\"TODO\\\"\\n    FIXME = \\\"FIXME\\\"\\n    NOTE = \\\"NOTE\\\"\\n    HACK = \\\"HACK\\\"\\n    XXX = \\\"XXX\\\"\\n    REVIEW = \\\"REVIEW\\\"\\n    OPTIMIZE = \\\"OPTIMIZE\\\"\\n    CHANGED = \\\"CHANGED\\\"\\n    QUESTION = \\\"QUESTION\\\"\\n    Q = \\\"Q\\\"\\n    DEPRECATED = \\\"@deprecated\\\"\\n    NOSONAR = \\\"NOSONAR\\\"\\n    TODO_FIXME = \\\"TODO-FIXME\\\"\\n\\n    def __str__(self) -> str:\\n        return self.value\\n\\n\\nclass BlockType(str, Enum):\\n    \\\"\\\"\\\"Enum of code block types.\\\"\\\"\\\"\\n\\n    STANDALONE_CODE_BLOCK = \\\"STANDALONE_BLOCK\\\"\\n    CLASS = \\\"CLASS\\\"\\n    FUNCTION = \\\"FUNCTION\\\"\\n    MODULE = \\\"MODULE\\\"\\n\\n    def __str__(self) -> str:\\n        return self.value\\n\\n\\nImported code block (postcode:models:models.py__*__MODULE) code content:\\nfrom typing import Union\\nfrom pydantic import BaseModel, Field, validator\\n\\nfrom postcode.models.enums import (\\n    BlockType,\\n    ImportModuleType,\\n    CommentType,\\n)\\n\\n\\nclass ImportNameModel(BaseModel):\\n    \\\"\\\"\\\"Class representing the name of an import.\\\"\\\"\\\"\\n\\n    name: str\\n    as_name: str | None = None\\n    local_block_id: str | None = None\\n\\n    # def convert_import_names_to_metadata(self) -> str:\\n    #     \\\"\\\"\\\"Converts the import name to a metadata string.\\\"\\\"\\\"\\n\\n    #     return self.model_dump_json()\\n\\n\\nclass ImportModel(BaseModel):\\n    \\\"\\\"\\\"Class representing an import statement.\\\"\\\"\\\"\\n\\n    import_names: list[ImportNameModel]\\n    imported_from: str | None = None\\n    import_module_type: ImportModuleType = ImportModuleType.STANDARD_LIBRARY\\n    local_module_id: str | None = None\\n\\n    def convert_import_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the import to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass DependencyModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a module dependency.\\\"\\\"\\\"\\n\\n    code_block_id: str\\n\\n    def convert_dependency_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the dependency to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass CommentModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a comment.\\\"\\\"\\\"\\n\\n    content: str\\n    comment_types: list[CommentType]\\n\\n    def convert_comment_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the comment to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass DecoratorModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a decorator.\\\"\\\"\\\"\\n\\n    content: str\\n    decorator_name: str\\n    decorator_args: list[str] | None = None\\n\\n    def convert_decorator_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the decorator to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass ClassKeywordModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a class keyword.\\\"\\\"\\\"\\n\\n    content: str\\n    keyword_name: str\\n    args: str | None = None\\n\\n    def convert_class_keyword_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the class keyword to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass ParameterModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a function parameter.\\\"\\\"\\\"\\n\\n    content: str\\n\\n\\nclass ParameterListModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a list of parameters.\\\"\\\"\\\"\\n\\n    params: list[ParameterModel] | None = None\\n    star_arg: ParameterModel | None = None\\n    kwonly_params: list[ParameterModel] | None = None\\n    star_kwarg: ParameterModel | None = None\\n    posonly_params: list[ParameterModel] | None = None\\n\\n    def convert_parameters_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the parameter list to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass BaseCodeBlockModel(BaseModel):\\n    \\\"\\\"\\\"Attributes common to all code block models.\\\"\\\"\\\"\\n\\n    id: str\\n    parent_id: str | None = None\\n    block_type: BlockType\\n    start_line_num: int\\n    end_line_num: int\\n    code_content: str = \\\"\\\"\\n    important_comments: list[CommentModel] | None = None\\n    dependencies: list[ImportModel | DependencyModel] | None = None\\n    summary: str | None = None\\n    children: list[\\n        Union[\\n            \\\"ClassModel\\\",\\n            \\\"FunctionModel\\\",\\n            \\\"StandaloneCodeBlockModel\\\",\\n        ]\\n    ] | None = []\\n\\n    @validator(\\\"parent_id\\\", always=True)\\n    def check_parent_id(cls, v, values, **kwargs) -> str | None:\\n        \\\"\\\"\\\"Validates that parent_id is a non-empty string unless block_type is MODULE.\\\"\\\"\\\"\\n\\n        if \\\"block_type\\\" in values and values[\\\"block_type\\\"] != BlockType.MODULE:\\n            if len(v) < 1:\\n                raise ValueError(\\\"parent_id is required!\\\")\\n        return v\\n\\n    def _convert_parent_id_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the parent_id to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.parent_id}\\\" if self.parent_id else \\\"\\\"\\n\\n    def _convert_block_type_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the block_type to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.block_type.name}\\\"\\n\\n    def _convert_important_comments_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the important comments to a metadata string.\\\"\\\"\\\"\\n\\n        important_comments: str = (\\n            self.model_dump_json() if self.important_comments else \\\"\\\"\\n        )\\n\\n        return f\\\"{important_comments}\\\"\\n\\n    def _convert_dependencies_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the dependencies to a metadata string.\\\"\\\"\\\"\\n\\n        dependencies_str: str = \\\"\\\"\\n\\n        if self.dependencies:\\n            for dependency in self.dependencies:\\n                if isinstance(dependency, ImportModel):\\n                    dependencies_str += f\\\"{dependency.convert_import_to_metadata()}\\\\n\\\"\\n                elif isinstance(dependency, DependencyModel):\\n                    dependencies_str += (\\n                        f\\\"{dependency.convert_dependency_to_metadata()}\\\\n\\\"\\n                    )\\n\\n        return dependencies_str\\n\\n    def _convert_summary_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the summary to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.summary}\\\" if self.summary else \\\"\\\"\\n\\n    def _convert_children_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the children to a metadata string.\\\"\\\"\\\"\\n\\n        children_str: str = \\\"\\\"\\n\\n        if self.children:\\n            for child in self.children:\\n                children_str += f\\\"{child.id}\\\\n\\\"\\n\\n        return children_str\\n\\n    def _convert_base_attributes_to_metadata_dict(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the base attributes to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            \\\"id\\\": self.id,\\n            \\\"parent_id\\\": self._convert_parent_id_to_metadata(),\\n            \\\"block_type\\\": self._convert_block_type_to_metadata(),\\n            \\\"start_line_num\\\": self.start_line_num,\\n            \\\"end_line_num\\\": self.end_line_num,\\n            \\\"code_content\\\": self.code_content,\\n            \\\"important_comments\\\": self._convert_important_comments_to_metadata(),\\n            \\\"dependencies\\\": self._convert_dependencies_to_metadata(),\\n            \\\"summary\\\": self._convert_summary_to_metadata(),\\n            \\\"children\\\": self._convert_children_to_metadata(),\\n        }\\n\\n\\nclass ModuleSpecificAttributes(BaseModel):\\n    \\\"\\\"\\\"Module specific attributes.\\\"\\\"\\\"\\n\\n    file_path: str = Field(min_length=1)\\n    docstring: str | None = None\\n    header: list[str] | None = None\\n    footer: list[str] | None = None\\n    imports: list[ImportModel] | None = None\\n\\n    def _convert_docstring_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the docstring to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.docstring}\\\"\\n\\n    def _convert_header_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the header and footer to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n    def _convert_footer_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the header and footer to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n    def _convert_imports_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the imports to a metadata string.\\\"\\\"\\\"\\n        imports_str: str = self.model_dump_json() if self.imports else \\\"\\\"\\n        return f\\\"{imports_str}\\\"\\n\\n    def _convert_module_attributes_to_metadata_dict(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the module attributes to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            \\\"file_path\\\": self.file_path,\\n            \\\"docstring\\\": self._convert_docstring_to_metadata(),\\n            \\\"header\\\": self._convert_header_to_metadata(),\\n            \\\"footer\\\": self._convert_footer_to_metadata(),\\n            \\\"imports\\\": self._convert_imports_to_metadata(),\\n        }\\n\\n\\nclass ModuleModel(BaseCodeBlockModel, ModuleSpecificAttributes):\\n    \\\"\\\"\\\"Model for a module.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the module model to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_module_attributes_to_metadata_dict(),\\n        }\\n\\n\\nclass ClassSpecificAttributes(BaseModel):\\n    \\\"\\\"\\\"Class specific attributes.\\\"\\\"\\\"\\n\\n    class_name: str = Field(min_length=1)\\n    decorators: list[DecoratorModel] | None = None\\n    bases: list[str] | None = None\\n    docstring: str | None = None\\n    keywords: list[ClassKeywordModel] | None = None\\n    # attributes: list[dict] | None = None\\n\\n    def _convert_decorators_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the decorators to a metadata string.\\\"\\\"\\\"\\n        decorators_str: str = self.model_dump_json() if self.decorators else \\\"\\\"\\n        return f\\\"{decorators_str}\\\"\\n\\n    def _convert_bases_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the bases to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json() if self.bases else \\\"\\\"\\n\\n    def _convert_docstring_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the docstring to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.docstring}\\\" if self.docstring else \\\"\\\"\\n\\n    def _convert_keywords_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the keywords to a metadata string.\\\"\\\"\\\"\\n        keywords_str: str = self.model_dump_json() if self.keywords else \\\"\\\"\\n        return f\\\"{keywords_str}\\\"\\n\\n    def _convert_class_attributes_to_metadata_dict(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the class attributes to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            \\\"class_name\\\": self.class_name,\\n            \\\"decorators\\\": self._convert_decorators_to_metadata(),\\n            \\\"bases\\\": self._convert_bases_to_metadata(),\\n            \\\"docstring\\\": self._convert_docstring_to_metadata(),\\n            \\\"keywords\\\": self._convert_keywords_to_metadata(),\\n        }\\n\\n\\nclass ClassModel(BaseCodeBlockModel, ClassSpecificAttributes):\\n    \\\"\\\"\\\"Model for a class.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the class model to a metadata dictionary.\\\"\\\"\\\"\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_class_attributes_to_metadata_dict(),\\n        }\\n\\n\\nclass FunctionSpecificAttributes(BaseModel):\\n    \\\"\\\"\\\"Function specific attributes.\\\"\\\"\\\"\\n\\n    function_name: str = Field(min_length=1)\\n    docstring: str | None = None\\n    decorators: list[DecoratorModel] | None = None\\n    parameters: ParameterListModel | None = None\\n    returns: str | None = None\\n    is_method: bool = False\\n    is_async: bool = False\\n\\n    def _convert_docstring_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the docstring to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.docstring}\\\" if self.docstring else \\\"\\\"\\n\\n    def _convert_decorators_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the decorators to a metadata string.\\\"\\\"\\\"\\n        decorators_str: str = self.model_dump_json() if self.decorators else \\\"\\\"\\n        return f\\\"{decorators_str}\\\"\\n\\n    def _convert_parameters_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the parameters to a metadata string.\\\"\\\"\\\"\\n        return (\\n            self.parameters.convert_parameters_to_metadata() if self.parameters else \\\"\\\"\\n        )\\n\\n    def _convert_returns_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the returns to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.returns}\\\" if self.returns else \\\"\\\"\\n\\n    def _convert_function_attributes_to_metadata_dict(self) -> dict[str, str | bool]:\\n        \\\"\\\"\\\"Converts the function attributes to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            \\\"function_name\\\": self.function_name,\\n            \\\"docstring\\\": self._convert_docstring_to_metadata(),\\n            \\\"decorators\\\": self._convert_decorators_to_metadata(),\\n            \\\"parameters\\\": self._convert_parameters_to_metadata(),\\n            \\\"returns\\\": self._convert_returns_to_metadata(),\\n            \\\"is_method\\\": self.is_method,\\n            \\\"is_async\\\": self.is_async,\\n        }\\n\\n\\nclass FunctionModel(BaseCodeBlockModel, FunctionSpecificAttributes):\\n    \\\"\\\"\\\"Model for a function.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the function model to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_function_attributes_to_metadata_dict(),\\n        }\\n\\n\\nclass StandaloneCodeBlockSpecificAttributes(BaseModel):\\n    \\\"\\\"\\\"Standalone code block specific attributes.\\\"\\\"\\\"\\n\\n    variable_assignments: list[str] | None = None\\n\\n    def _convert_variable_assignments_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the variable assignments to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json() if self.variable_assignments else \\\"\\\"\\n\\n    def _convert_standalone_block_attributes_to_metadata_dict(\\n        self,\\n    ) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the standalone code block attributes to a metadata dictionary.\\\"\\\"\\\"\\n        return {\\n            \\\"variable_assignments\\\": self._convert_variable_assignments_to_metadata(),\\n        }\\n\\n\\nclass StandaloneCodeBlockModel(\\n    BaseCodeBlockModel, StandaloneCodeBlockSpecificAttributes\\n):\\n    \\\"\\\"\\\"Model for a standalone code block.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the standalone code block model to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_standalone_block_attributes_to_metadata_dict(),\\n        }\\n\\n, \\nfrom typing import Any, Union\\n        \",\"children\":[{\"variable_assignments\":[\"ModelType = Union[\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n]\"],\"id\":\"postcode:databases:arangodb:helper_functions.py__*__MODULE__*__STANDALONE_BLOCK-1\",\"parent_id\":\"postcode:databases:arangodb:helper_functions.py__*__MODULE\",\"block_type\":\"STANDALONE_BLOCK\",\"start_line_num\":10,\"end_line_num\":19,\"code_content\":\"# from postcode.types.postcode import ModelType\\n\\nModelType = Union[\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n]\\n\",\"important_comments\":null,\"dependencies\":[{\"import_names\":[{\"name\":\"Any\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"Union\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"typing\",\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"},{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ClassModel\"},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-FunctionModel\"},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-StandaloneCodeBlockModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"},{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ClassModel\"},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-FunctionModel\"},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-StandaloneCodeBlockModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"},{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ClassModel\"},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-FunctionModel\"},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-StandaloneCodeBlockModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"},{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ClassModel\"},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-FunctionModel\"},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-StandaloneCodeBlockModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"}],\"summary\":null,\"children\":null},{\"function_name\":\"pluralized_and_lowered_block_types\",\"docstring\":null,\"decorators\":null,\"parameters\":null,\"returns\":\"list[str]\",\"is_method\":false,\"is_async\":false,\"id\":\"postcode:databases:arangodb:helper_functions.py__*__MODULE__*__FUNCTION-pluralized_and_lowered_block_types\",\"parent_id\":\"postcode:databases:arangodb:helper_functions.py__*__MODULE\",\"block_type\":\"FUNCTION\",\"start_line_num\":19,\"end_line_num\":23,\"code_content\":\"\\n\\ndef pluralized_and_lowered_block_types() -> list[str]:\\n    return [pluralize_block_type(block_type).lower() for block_type in BlockType]\\n\",\"important_comments\":null,\"dependencies\":[{\"code_block_id\":\"postcode:databases:arangodb:helper_functions.py__*__MODULE__*__FUNCTION-pluralize_block_type\"},{\"import_names\":[{\"name\":\"BlockType\",\"as_name\":null,\"local_block_id\":\"postcode:models:enums.py__*__MODULE__*__CLASS-BlockType\"}],\"imported_from\":\"postcode.models.enums\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:enums.py__*__MODULE\"}],\"summary\":null,\"children\":null},{\"function_name\":\"pluralize_block_type\",\"docstring\":null,\"decorators\":null,\"parameters\":null,\"returns\":\"str\",\"is_method\":false,\"is_async\":false,\"id\":\"postcode:databases:arangodb:helper_functions.py__*__MODULE__*__FUNCTION-pluralize_block_type\",\"parent_id\":\"postcode:databases:arangodb:helper_functions.py__*__MODULE\",\"block_type\":\"FUNCTION\",\"start_line_num\":23,\"end_line_num\":30,\"code_content\":\"\\n\\ndef pluralize_block_type(block_type: str) -> str:\\n    if block_type == BlockType.CLASS:\\n        return \\\"classes\\\"\\n    else:\\n        return f\\\"{block_type.lower()}s\\\"\\n\",\"important_comments\":null,\"dependencies\":[{\"import_names\":[{\"name\":\"BlockType\",\"as_name\":null,\"local_block_id\":\"postcode:models:enums.py__*__MODULE__*__CLASS-BlockType\"}],\"imported_from\":\"postcode.models.enums\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:enums.py__*__MODULE\"}],\"summary\":null,\"children\":null},{\"function_name\":\"create_model_from_vertex\",\"docstring\":null,\"decorators\":null,\"parameters\":null,\"returns\":\"ModelType\",\"is_method\":false,\"is_async\":false,\"id\":\"postcode:databases:arangodb:helper_functions.py__*__MODULE__*__FUNCTION-create_model_from_vertex\",\"parent_id\":\"postcode:databases:arangodb:helper_functions.py__*__MODULE\",\"block_type\":\"FUNCTION\",\"start_line_num\":30,\"end_line_num\":45,\"code_content\":\"\\n\\ndef create_model_from_vertex(vertex_data: dict) -> ModelType:\\n    block_type = vertex_data.get(\\\"block_type\\\")\\n\\n    if block_type == BlockType.MODULE:\\n        return ModuleModel(**vertex_data)\\n    elif block_type == BlockType.CLASS:\\n        return ClassModel(**vertex_data)\\n    elif block_type == BlockType.FUNCTION:\\n        return FunctionModel(**vertex_data)\\n    elif block_type == BlockType.STANDALONE_CODE_BLOCK:\\n        return StandaloneCodeBlockModel(**vertex_data)\\n    else:\\n        raise ValueError(f\\\"Unknown block type: {block_type}\\\")\\n\",\"important_comments\":null,\"dependencies\":[{\"import_names\":[{\"name\":\"BlockType\",\"as_name\":null,\"local_block_id\":\"postcode:models:enums.py__*__MODULE__*__CLASS-BlockType\"}],\"imported_from\":\"postcode.models.enums\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:enums.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"},{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ClassModel\"},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-FunctionModel\"},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-StandaloneCodeBlockModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"},{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ClassModel\"},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-FunctionModel\"},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-StandaloneCodeBlockModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"},{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ClassModel\"},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-FunctionModel\"},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-StandaloneCodeBlockModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"},{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ClassModel\"},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-FunctionModel\"},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-StandaloneCodeBlockModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"}],\"summary\":null,\"children\":null}]}", "chroma:document": "\nSummary:\n\n        postcode:databases:arangodb:helper_functions.py__*__MODULE\n\n        \nChild (postcode:databases:arangodb:helper_functions.py__*__MODULE__*__STANDALONE_BLOCK-1) code content:\n# from postcode.types.postcode import ModelType\n\nModelType = Union[\n    ModuleModel,\n    ClassModel,\n    FunctionModel,\n    StandaloneCodeBlockModel,\n]\n\n\nChild (postcode:databases:arangodb:helper_functions.py__*__MODULE__*__FUNCTION-pluralized_and_lowered_block_types) code content:\n\n\ndef pluralized_and_lowered_block_types() -> list[str]:\n    return [pluralize_block_type(block_type).lower() for block_type in BlockType]\n\n\nChild (postcode:databases:arangodb:helper_functions.py__*__MODULE__*__FUNCTION-pluralize_block_type) code content:\n\n\ndef pluralize_block_type(block_type: str) -> str:\n    if block_type == BlockType.CLASS:\n        return \"classes\"\n    else:\n        return f\"{block_type.lower()}s\"\n\n\nChild (postcode:databases:arangodb:helper_functions.py__*__MODULE__*__FUNCTION-create_model_from_vertex) code content:\n\n\ndef create_model_from_vertex(vertex_data: dict) -> ModelType:\n    block_type = vertex_data.get(\"block_type\")\n\n    if block_type == BlockType.MODULE:\n        return ModuleModel(**vertex_data)\n    elif block_type == BlockType.CLASS:\n        return ClassModel(**vertex_data)\n    elif block_type == BlockType.FUNCTION:\n        return FunctionModel(**vertex_data)\n    elif block_type == BlockType.STANDALONE_CODE_BLOCK:\n        return StandaloneCodeBlockModel(**vertex_data)\n    else:\n        raise ValueError(f\"Unknown block type: {block_type}\")\n\n, \nImported code block (postcode:models:enums.py__*__MODULE) code content:\nfrom enum import Enum\n\n\nclass ImportModuleType(str, Enum):\n    \"\"\"Enum of import module types.\"\"\"\n\n    STANDARD_LIBRARY = \"STANDARD_LIBRARY\"\n    LOCAL = \"LOCAL\"\n    THIRD_PARTY = \"THIRD_PARTY\"\n\n    def __str__(self) -> str:\n        return self.value\n\n\nclass CommentType(str, Enum):\n    \"\"\"Class representing the different types of important comments.\"\"\"\n\n    TODO = \"TODO\"\n    FIXME = \"FIXME\"\n    NOTE = \"NOTE\"\n    HACK = \"HACK\"\n    XXX = \"XXX\"\n    REVIEW = \"REVIEW\"\n    OPTIMIZE = \"OPTIMIZE\"\n    CHANGED = \"CHANGED\"\n    QUESTION = \"QUESTION\"\n    Q = \"Q\"\n    DEPRECATED = \"@deprecated\"\n    NOSONAR = \"NOSONAR\"\n    TODO_FIXME = \"TODO-FIXME\"\n\n    def __str__(self) -> str:\n        return self.value\n\n\nclass BlockType(str, Enum):\n    \"\"\"Enum of code block types.\"\"\"\n\n    STANDALONE_CODE_BLOCK = \"STANDALONE_BLOCK\"\n    CLASS = \"CLASS\"\n    FUNCTION = \"FUNCTION\"\n    MODULE = \"MODULE\"\n\n    def __str__(self) -> str:\n        return self.value\n\n\nImported code block (postcode:models:models.py__*__MODULE) code content:\nfrom typing import Union\nfrom pydantic import BaseModel, Field, validator\n\nfrom postcode.models.enums import (\n    BlockType,\n    ImportModuleType,\n    CommentType,\n)\n\n\nclass ImportNameModel(BaseModel):\n    \"\"\"Class representing the name of an import.\"\"\"\n\n    name: str\n    as_name: str | None = None\n    local_block_id: str | None = None\n\n    # def convert_import_names_to_metadata(self) -> str:\n    #     \"\"\"Converts the import name to a metadata string.\"\"\"\n\n    #     return self.model_dump_json()\n\n\nclass ImportModel(BaseModel):\n    \"\"\"Class representing an import statement.\"\"\"\n\n    import_names: list[ImportNameModel]\n    imported_from: str | None = None\n    import_module_type: ImportModuleType = ImportModuleType.STANDARD_LIBRARY\n    local_module_id: str | None = None\n\n    def convert_import_to_metadata(self) -> str:\n        \"\"\"Converts the import to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass DependencyModel(BaseModel):\n    \"\"\"Class representing a module dependency.\"\"\"\n\n    code_block_id: str\n\n    def convert_dependency_to_metadata(self) -> str:\n        \"\"\"Converts the dependency to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass CommentModel(BaseModel):\n    \"\"\"Class representing a comment.\"\"\"\n\n    content: str\n    comment_types: list[CommentType]\n\n    def convert_comment_to_metadata(self) -> str:\n        \"\"\"Converts the comment to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass DecoratorModel(BaseModel):\n    \"\"\"Class representing a decorator.\"\"\"\n\n    content: str\n    decorator_name: str\n    decorator_args: list[str] | None = None\n\n    def convert_decorator_to_metadata(self) -> str:\n        \"\"\"Converts the decorator to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass ClassKeywordModel(BaseModel):\n    \"\"\"Class representing a class keyword.\"\"\"\n\n    content: str\n    keyword_name: str\n    args: str | None = None\n\n    def convert_class_keyword_to_metadata(self) -> str:\n        \"\"\"Converts the class keyword to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass ParameterModel(BaseModel):\n    \"\"\"Class representing a function parameter.\"\"\"\n\n    content: str\n\n\nclass ParameterListModel(BaseModel):\n    \"\"\"Class representing a list of parameters.\"\"\"\n\n    params: list[ParameterModel] | None = None\n    star_arg: ParameterModel | None = None\n    kwonly_params: list[ParameterModel] | None = None\n    star_kwarg: ParameterModel | None = None\n    posonly_params: list[ParameterModel] | None = None\n\n    def convert_parameters_to_metadata(self) -> str:\n        \"\"\"Converts the parameter list to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass BaseCodeBlockModel(BaseModel):\n    \"\"\"Attributes common to all code block models.\"\"\"\n\n    id: str\n    parent_id: str | None = None\n    block_type: BlockType\n    start_line_num: int\n    end_line_num: int\n    code_content: str = \"\"\n    important_comments: list[CommentModel] | None = None\n    dependencies: list[ImportModel | DependencyModel] | None = None\n    summary: str | None = None\n    children: list[\n        Union[\n            \"ClassModel\",\n            \"FunctionModel\",\n            \"StandaloneCodeBlockModel\",\n        ]\n    ] | None = []\n\n    @validator(\"parent_id\", always=True)\n    def check_parent_id(cls, v, values, **kwargs) -> str | None:\n        \"\"\"Validates that parent_id is a non-empty string unless block_type is MODULE.\"\"\"\n\n        if \"block_type\" in values and values[\"block_type\"] != BlockType.MODULE:\n            if len(v) < 1:\n                raise ValueError(\"parent_id is required!\")\n        return v\n\n    def _convert_parent_id_to_metadata(self) -> str:\n        \"\"\"Converts the parent_id to a metadata string.\"\"\"\n        return f\"{self.parent_id}\" if self.parent_id else \"\"\n\n    def _convert_block_type_to_metadata(self) -> str:\n        \"\"\"Converts the block_type to a metadata string.\"\"\"\n        return f\"{self.block_type.name}\"\n\n    def _convert_important_comments_to_metadata(self) -> str:\n        \"\"\"Converts the important comments to a metadata string.\"\"\"\n\n        important_comments: str = (\n            self.model_dump_json() if self.important_comments else \"\"\n        )\n\n        return f\"{important_comments}\"\n\n    def _convert_dependencies_to_metadata(self) -> str:\n        \"\"\"Converts the dependencies to a metadata string.\"\"\"\n\n        dependencies_str: str = \"\"\n\n        if self.dependencies:\n            for dependency in self.dependencies:\n                if isinstance(dependency, ImportModel):\n                    dependencies_str += f\"{dependency.convert_import_to_metadata()}\\n\"\n                elif isinstance(dependency, DependencyModel):\n                    dependencies_str += (\n                        f\"{dependency.convert_dependency_to_metadata()}\\n\"\n                    )\n\n        return dependencies_str\n\n    def _convert_summary_to_metadata(self) -> str:\n        \"\"\"Converts the summary to a metadata string.\"\"\"\n        return f\"{self.summary}\" if self.summary else \"\"\n\n    def _convert_children_to_metadata(self) -> str:\n        \"\"\"Converts the children to a metadata string.\"\"\"\n\n        children_str: str = \"\"\n\n        if self.children:\n            for child in self.children:\n                children_str += f\"{child.id}\\n\"\n\n        return children_str\n\n    def _convert_base_attributes_to_metadata_dict(self) -> dict[str, str | int]:\n        \"\"\"Converts the base attributes to a metadata dictionary.\"\"\"\n\n        return {\n            \"id\": self.id,\n            \"parent_id\": self._convert_parent_id_to_metadata(),\n            \"block_type\": self._convert_block_type_to_metadata(),\n            \"start_line_num\": self.start_line_num,\n            \"end_line_num\": self.end_line_num,\n            \"code_content\": self.code_content,\n            \"important_comments\": self._convert_important_comments_to_metadata(),\n            \"dependencies\": self._convert_dependencies_to_metadata(),\n            \"summary\": self._convert_summary_to_metadata(),\n            \"children\": self._convert_children_to_metadata(),\n        }\n\n\nclass ModuleSpecificAttributes(BaseModel):\n    \"\"\"Module specific attributes.\"\"\"\n\n    file_path: str = Field(min_length=1)\n    docstring: str | None = None\n    header: list[str] | None = None\n    footer: list[str] | None = None\n    imports: list[ImportModel] | None = None\n\n    def _convert_docstring_to_metadata(self) -> str:\n        \"\"\"Converts the docstring to a metadata string.\"\"\"\n        return f\"{self.docstring}\"\n\n    def _convert_header_to_metadata(self) -> str:\n        \"\"\"Converts the header and footer to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n    def _convert_footer_to_metadata(self) -> str:\n        \"\"\"Converts the header and footer to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n    def _convert_imports_to_metadata(self) -> str:\n        \"\"\"Converts the imports to a metadata string.\"\"\"\n        imports_str: str = self.model_dump_json() if self.imports else \"\"\n        return f\"{imports_str}\"\n\n    def _convert_module_attributes_to_metadata_dict(self) -> dict[str, str | int]:\n        \"\"\"Converts the module attributes to a metadata dictionary.\"\"\"\n\n        return {\n            \"file_path\": self.file_path,\n            \"docstring\": self._convert_docstring_to_metadata(),\n            \"header\": self._convert_header_to_metadata(),\n            \"footer\": self._convert_footer_to_metadata(),\n            \"imports\": self._convert_imports_to_metadata(),\n        }\n\n\nclass ModuleModel(BaseCodeBlockModel, ModuleSpecificAttributes):\n    \"\"\"Model for a module.\"\"\"\n\n    def convert_to_metadata(self) -> dict[str, str | int]:\n        \"\"\"Converts the module model to a metadata dictionary.\"\"\"\n\n        return {\n            **self._convert_base_attributes_to_metadata_dict(),\n            **self._convert_module_attributes_to_metadata_dict(),\n        }\n\n\nclass ClassSpecificAttributes(BaseModel):\n    \"\"\"Class specific attributes.\"\"\"\n\n    class_name: str = Field(min_length=1)\n    decorators: list[DecoratorModel] | None = None\n    bases: list[str] | None = None\n    docstring: str | None = None\n    keywords: list[ClassKeywordModel] | None = None\n    # attributes: list[dict] | None = None\n\n    def _convert_decorators_to_metadata(self) -> str:\n        \"\"\"Converts the decorators to a metadata string.\"\"\"\n        decorators_str: str = self.model_dump_json() if self.decorators else \"\"\n        return f\"{decorators_str}\"\n\n    def _convert_bases_to_metadata(self) -> str:\n        \"\"\"Converts the bases to a metadata string.\"\"\"\n        return self.model_dump_json() if self.bases else \"\"\n\n    def _convert_docstring_to_metadata(self) -> str:\n        \"\"\"Converts the docstring to a metadata string.\"\"\"\n        return f\"{self.docstring}\" if self.docstring else \"\"\n\n    def _convert_keywords_to_metadata(self) -> str:\n        \"\"\"Converts the keywords to a metadata string.\"\"\"\n        keywords_str: str = self.model_dump_json() if self.keywords else \"\"\n        return f\"{keywords_str}\"\n\n    def _convert_class_attributes_to_metadata_dict(self) -> dict[str, str | int]:\n        \"\"\"Converts the class attributes to a metadata dictionary.\"\"\"\n\n        return {\n            \"class_name\": self.class_name,\n            \"decorators\": self._convert_decorators_to_metadata(),\n            \"bases\": self._convert_bases_to_metadata(),\n            \"docstring\": self._convert_docstring_to_metadata(),\n            \"keywords\": self._convert_keywords_to_metadata(),\n        }\n\n\nclass ClassModel(BaseCodeBlockModel, ClassSpecificAttributes):\n    \"\"\"Model for a class.\"\"\"\n\n    def convert_to_metadata(self) -> dict[str, str | int]:\n        \"\"\"Converts the class model to a metadata dictionary.\"\"\"\n        return {\n            **self._convert_base_attributes_to_metadata_dict(),\n            **self._convert_class_attributes_to_metadata_dict(),\n        }\n\n\nclass FunctionSpecificAttributes(BaseModel):\n    \"\"\"Function specific attributes.\"\"\"\n\n    function_name: str = Field(min_length=1)\n    docstring: str | None = None\n    decorators: list[DecoratorModel] | None = None\n    parameters: ParameterListModel | None = None\n    returns: str | None = None\n    is_method: bool = False\n    is_async: bool = False\n\n    def _convert_docstring_to_metadata(self) -> str:\n        \"\"\"Converts the docstring to a metadata string.\"\"\"\n        return f\"{self.docstring}\" if self.docstring else \"\"\n\n    def _convert_decorators_to_metadata(self) -> str:\n        \"\"\"Converts the decorators to a metadata string.\"\"\"\n        decorators_str: str = self.model_dump_json() if self.decorators else \"\"\n        return f\"{decorators_str}\"\n\n    def _convert_parameters_to_metadata(self) -> str:\n        \"\"\"Converts the parameters to a metadata string.\"\"\"\n        return (\n            self.parameters.convert_parameters_to_metadata() if self.parameters else \"\"\n        )\n\n    def _convert_returns_to_metadata(self) -> str:\n        \"\"\"Converts the returns to a metadata string.\"\"\"\n        return f\"{self.returns}\" if self.returns else \"\"\n\n    def _convert_function_attributes_to_metadata_dict(self) -> dict[str, str | bool]:\n        \"\"\"Converts the function attributes to a metadata dictionary.\"\"\"\n\n        return {\n            \"function_name\": self.function_name,\n            \"docstring\": self._convert_docstring_to_metadata(),\n            \"decorators\": self._convert_decorators_to_metadata(),\n            \"parameters\": self._convert_parameters_to_metadata(),\n            \"returns\": self._convert_returns_to_metadata(),\n            \"is_method\": self.is_method,\n            \"is_async\": self.is_async,\n        }\n\n\nclass FunctionModel(BaseCodeBlockModel, FunctionSpecificAttributes):\n    \"\"\"Model for a function.\"\"\"\n\n    def convert_to_metadata(self) -> dict[str, str | int]:\n        \"\"\"Converts the function model to a metadata dictionary.\"\"\"\n\n        return {\n            **self._convert_base_attributes_to_metadata_dict(),\n            **self._convert_function_attributes_to_metadata_dict(),\n        }\n\n\nclass StandaloneCodeBlockSpecificAttributes(BaseModel):\n    \"\"\"Standalone code block specific attributes.\"\"\"\n\n    variable_assignments: list[str] | None = None\n\n    def _convert_variable_assignments_to_metadata(self) -> str:\n        \"\"\"Converts the variable assignments to a metadata string.\"\"\"\n        return self.model_dump_json() if self.variable_assignments else \"\"\n\n    def _convert_standalone_block_attributes_to_metadata_dict(\n        self,\n    ) -> dict[str, str | int]:\n        \"\"\"Converts the standalone code block attributes to a metadata dictionary.\"\"\"\n        return {\n            \"variable_assignments\": self._convert_variable_assignments_to_metadata(),\n        }\n\n\nclass StandaloneCodeBlockModel(\n    BaseCodeBlockModel, StandaloneCodeBlockSpecificAttributes\n):\n    \"\"\"Model for a standalone code block.\"\"\"\n\n    def convert_to_metadata(self) -> dict[str, str | int]:\n        \"\"\"Converts the standalone code block model to a metadata dictionary.\"\"\"\n\n        return {\n            **self._convert_base_attributes_to_metadata_dict(),\n            **self._convert_standalone_block_attributes_to_metadata_dict(),\n        }\n\n, \nfrom typing import Any, Union\n        "}               ):\\n                import_model_to_remove = existing_import_model\\n                break\\n\\n        if not import_model_to_remove:\\n            raise Exception(f\\\"Could not find import to remove: {old_import_model}\\\")\\n\\n        self.common_attributes.dependencies.remove(import_model_to_remove)\\n        self.common_attributes.dependencies.append(new_import_model)\\n    else:\\n        raise Exception(\\n            f\\\"No imports in the builders imports list: {self.common_attributes.dependencies}\\\"\\n        )\\n    return self\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":null,\"children\":null},{\"function_name\":\"build_and_set_children\",\"docstring\":null,\"decorators\":null,\"parameters\":null,\"returns\":\"None\",\"is_method\":true,\"is_async\":false,\"id\":\"postcode:python_parser:model_builders:base_model_builder.py__*__MODULE__*__CLASS-BaseModelBuilder__*__FUNCTION-build_and_set_children\",\"parent_id\":\"postcode:python_parser:model_builders:base_model_builder.py__*__MODULE__*__CLASS-BaseModelBuilder\",\"block_type\":\"FUNCTION\",\"start_line_num\":211,\"end_line_num\":217,\"code_content\":\"\\ndef build_and_set_children(self) -> None:\\n    if self.children_builders:\\n        self.common_attributes.children = [\\n            child.build() for child in self.children_builders\\n        ]\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":null,\"children\":null},{\"function_name\":\"_get_common_attributes\",\"docstring\":\"Returns a dictionary containing the attributes common to all code block models.\",\"decorators\":null,\"parameters\":null,\"returns\":\"dict[str, Any]\",\"is_method\":true,\"is_async\":false,\"id\":\"postcode:python_parser:model_builders:base_model_builder.py__*__MODULE__*__CLASS-BaseModelBuilder__*__FUNCTION-_get_common_attributes\",\"parent_id\":\"postcode:python_parser:model_builders:base_model_builder.py__*__MODULE__*__CLASS-BaseModelBuilder\",\"block_type\":\"FUNCTION\",\"start_line_num\":217,\"end_line_num\":223,\"code_content\":\"\\ndef _get_common_attributes(self) -> dict[str, Any]:\\n    \\\"\\\"\\\"\\n        Returns a dictionar       {"id": "postcode:databases:arangodb:arangodb_manager.py__*__MODULE", "parent_id": "", "block_type": "MODULE", "start_line_num": 1, "end_line_num": 409, "code_content": "import logging\nfrom typing import Any, Callable, Union\n\nfrom arango.result import Result\nfrom arango.cursor import Cursor\nfrom arango.graph import Graph\nfrom arango.collection import StandardCollection\nfrom arango.typings import Json\n\nfrom postcode.databases.arangodb.arangodb_connector import ArangoDBConnector\n\n# from postcode.types.postcode import ModelType\nfrom postcode.models.models import (\n    ClassModel,\n    FunctionModel,\n    ModuleModel,\n    StandaloneCodeBlockModel,\n)\nimport postcode.databases.arangodb.helper_functions as helper_functions\n\nModelType = Union[\n    ModuleModel,\n    ClassModel,\n    FunctionModel,\n    StandaloneCodeBlockModel,\n]\n\n# NOTE: Remember, when adding logic to connect dependencies, the `from` the external dependency `to` the internal definition using it\n\n\nclass ArangoDBManager:\n    def __init__(\n        self,\n        db_connector: ArangoDBConnector,\n        default_graph_name: str = \"codebase_graph\",\n    ) -> None:\n        self.db_connector: ArangoDBConnector = db_connector\n\n        self.processed_id_set = set()\n        self.default_graph_name: str = default_graph_name\n\n    def upsert_models(self, module_models: list[ModuleModel]) -> \"ArangoDBManager\":\n        for model in module_models:\n            self._upsert_model(model)\n        return self\n\n    def _upsert_model(self, module_model: ModuleModel) -> None:\n        self._upsert_vertex(module_model, \"modules\")\n        self._process_children(module_model)\n\n    def _process_children(self, parent_model: ModelType) -> None:\n        if not parent_model.children:\n            return None\n\n        for child in parent_model.children:\n            # if child.id in self.processed_id_set:\n            #     continue\n\n            self.processed_id_set.add(child.id)\n            self._upsert_vertex(\n                child, helper_functions.pluralize_block_type(child.block_type)\n            )\n\n            if child.children:\n                self._process_children(child)\n\n    def _upsert_vertex(self, model: ModelType, collection_name: str) -> None:\n        model_data: dict[str, Any] = model.model_dump()\n        model_data[\"_key\"] = model.id\n\n        try:\n            self.db_connector.ensure_collection(\n                collection_name, model.model_json_schema()\n            )\n            query: str = f\"\"\"\n            UPSERT {{_key: @key}}\n            INSERT @doc\n            UPDATE @doc\n            IN {collection_name}\n            \"\"\"\n            bind_vars: dict[str, Any] = {\"key\": model.id, \"doc\": model_data}\n            self.db_connector.db.aql.execute(query, bind_vars=bind_vars)\n\n            if not isinstance(model, ModuleModel) and model.parent_id:\n                parent_type: str = self._get_collection_from_id(model.parent_id)\n                self._upsert_edge(\n                    model.id, model.parent_id, collection_name, parent_type\n                )\n        except Exception as e:\n            logging.error(f\"Error upserting {collection_name} vertex (ArangoDB): {e}\")\n\n    def _upsert_edge(\n        self, from_key: str, to_key: str, source_type: str, target_type: str\n    ) -> None:\n        source_string: str = f\"{source_type}/{from_key}\"\n        target_string: str = f\"{target_type}/{to_key}\"\n\n        edge_data: dict[str, str] = {\n            \"_from\": source_string,\n            \"_to\": target_string,\n            \"source_type\": source_type,\n            \"target_type\": target_type,\n        }\n\n        try:\n            self.db_connector.ensure_edge_collection(\"code_edges\")\n            query = f\"\"\"\n            UPSERT {{_from: @from, _to: @to}}\n            INSERT @doc\n            UPDATE @doc\n            IN code_edges\n            \"\"\"\n            bind_vars = {\n                \"from\": edge_data[\"_from\"],\n                \"to\": edge_data[\"_to\"],\n                \"doc\": edge_data,\n            }\n            self.db_connector.db.aql.execute(query, bind_vars=bind_vars)\n        except Exception as e:\n            logging.error(f\"Error upserting edge (ArangoDB): {e}\")\n\n    def _get_collection_from_id(self, block_id: str) -> str:\n        block_id_parts: list[str] = block_id.split(\"__*__\")\n        block_type_part: str = block_id_parts[-1]\n\n        block_type_functions: dict[str, Callable[..., str]] = {\n            \"MODULE\": lambda: \"modules\",\n            \"CLASS\": lambda: \"classes\",\n            \"FUNCTION\": lambda: \"functions\",\n            \"STANDALONE_BLOCK\": lambda: \"standalone_blocks\",\n        }\n\n        for key, func in block_type_functions.items():\n            if block_type_part.startswith(key):\n                return func()\n\n        return \"unknown\"\n\n    def process_imports_and_dependencies(self) -> \"ArangoDBManager\":\n        for vertex_collection in helper_functions.pluralized_and_lowered_block_types():\n            cursor: Result[Cursor] = self.db_connector.db.collection(\n                vertex_collection\n            ).all()\n            if isinstance(cursor, Cursor):\n                for vertex in cursor:\n                    vertex_key = vertex[\"_key\"]\n                    if vertex_collection == \"modules\":\n                        self._create_edges_for_imports(\n                            vertex_key, vertex.get(\"imports\", [])\n                        )\n                    else:\n                        self._create_edges_for_dependencies(\n                            vertex_key, vertex.get(\"dependencies\", [])\n                        )\n            else:\n                logging.error(\n                    f\"Error getting cursor for vertex collection: {vertex_collection}\"\n                )\n        return self\n\n    def _create_edges_for_imports(\n        self, module_key: str, imports: list[dict[str, Any]]\n    ) -> None:\n        if not imports:\n            # logging.debug(f\"No imports found for module {module_key}\")\n            return\n\n        # logging.info(f\"Processing imports for module {module_key}\")\n\n        for _import in imports:\n            import_names: list[dict[str, str]] = _import.get(\"import_names\", [])\n            if not import_names:\n                # logging.debug(f\"No import names found in import {_import}\")\n                continue\n\n            for import_name in import_names:\n                local_block_id: str | None = import_name.get(\"local_block_id\")\n\n                if local_block_id:\n                    target_type = self._get_collection_from_id(local_block_id)\n                    try:\n                        self._upsert_edge(\n                            local_block_id, module_key, target_type, \"modules\"\n                        )\n\n                        # logging.info(\n                        #     f\"Upserted edge for import {module_key} to {local_block_id}\"\n                        # )\n                    except Exception as e:\n                        logging.error(\n                            f\"Error creating edge for import {module_key} to {local_block_id}: {e}\"\n                        )\n                else:\n                    # logging.warning(\n                    #     f\"Skipped import {import_name} in module {module_key}\"\n                    # )\n                    ...\n\n    def _create_edges_for_dependencies(\n        self, block_key: str, dependencies: list[dict[str, Any]]\n    ) -> None:\n        if not dependencies:\n            return\n\n        for dependency in dependencies:\n            code_block_id: str | None = dependency.get(\"code_block_id\")\n            if code_block_id:\n                source_type: str = self._get_collection_from_id(code_block_id)\n                target_type: str = self._get_collection_from_id(block_key)\n                try:\n                    self._upsert_edge(\n                        code_block_id, block_key, source_type, target_type\n                    )\n                    # logging.info(\n                    #     f\"Upserted edge for dependency {block_key} to {code_block_id}\"\n                    # )\n                except Exception as e:\n                    logging.error(\n                        f\"Error creating edge for dependency {block_key} to {code_block_id}: {e}\"\n                    )\n\n    def delete_vertex_by_id(\n        self, vertex_key: str, graph_name: str | None = None\n    ) -> None:\n        collection_name: str = self._get_collection_from_id(vertex_key)\n        if collection_name == \"unknown\":\n            logging.error(f\"Unknown vertex type for key: {vertex_key}\")\n            return None\n\n        if not graph_name:\n            graph_name = self.default_graph_name\n\n        try:\n            vertex_coll = self.db_connector.db.graph(graph_name).vertex_collection(\n                collection_name\n            )\n\n            vertex_coll.delete(vertex_key)\n\n            # logging.info(\n            #     f\"Vertex '{vertex_key}' from collection '{collection_name}' was successfully deleted.\"\n            # )\n\n        except Exception as e:\n            logging.error(\n                f\"Error deleting vertex '{vertex_key}' from collection '{collection_name}': {e}\"\n            )\n\n    def get_graph(self, graph_name: str | None = None) -> Graph | None:\n        if not graph_name:\n            graph_name = self.default_graph_name\n        try:\n            return self.db_connector.db.graph(self.default_graph_name)\n        except Exception as e:\n            logging.error(f\"Error getting graph '{self.default_graph_name}': {e}\")\n            return None\n\n    def get_or_create_graph(self, graph_name: str | None = None) -> Result[Graph]:\n        if not graph_name:\n            graph_name = self.default_graph_name\n\n        try:\n            if not self.db_connector.db.has_graph(graph_name):\n                edge_definitions: list[dict[str, str | list[str]]] = [\n                    {\n                        \"edge_collection\": \"code_edges\",\n                        \"from_vertex_collections\": helper_functions.pluralized_and_lowered_block_types(),\n                        \"to_vertex_collections\": helper_functions.pluralized_and_lowered_block_types(),\n                    }\n                ]\n\n                # logging.info(f\"Graph '{graph_name}' created successfully.\")\n                return self.db_connector.db.create_graph(\n                    graph_name, edge_definitions=edge_definitions\n                )\n\n            else:\n                return self.get_graph()\n\n        except Exception as e:\n            logging.error(f\"Error creating graph '{graph_name}': {e}\")\n\n    def delete_graph(self, graph_name: str | None = None) -> None:\n        if not graph_name:\n            graph_name = self.default_graph_name\n        try:\n            self.db_connector.db.delete_graph(graph_name)\n            logging.info(f\"Graph '{graph_name}' deleted successfully.\")\n        except Exception as e:\n            logging.error(f\"Error deleting graph '{graph_name}': {e}\")\n\n    def get_outbound_models(self, start_key: str) -> list[ModelType] | None:\n        vertex_type: str = self._get_collection_from_id(start_key)\n\n        query: str = f\"\"\"\n        FOR v, e, p IN 1..100 OUTBOUND '{vertex_type}/{start_key}' GRAPH '{self.default_graph_name}'\n        RETURN DISTINCT v\n        \"\"\"\n        # query: str = f\"\"\"\n        # FOR v, e, p IN 1..100 OUTBOUND '{vertex_type}/{start_key}' GRAPH '{self.default_graph_name}'\n        # FILTER LENGTH(p.edges[* FILTER CURRENT != e]) == 0\n        # RETURN DISTINCT v\n        # \"\"\"\n        # query: str = f\"\"\"\n        # FOR v, e, p IN 1..100 OUTBOUND '{vertex_type}/{start_key}' GRAPH '{self.default_graph_name}'\n        # FILTER LENGTH(p.edges[* FILTER CURRENT != e]) == 0\n        #     AND p.edges[*].distance ALL == 1\n        # RETURN DISTINCT v\n        # \"\"\"\n\n        try:\n            cursor = self.db_connector.db.aql.execute(query)\n            if isinstance(cursor, Cursor):\n                return [\n                    helper_functions.create_model_from_vertex(doc) for doc in cursor\n                ]\n            else:\n                logging.error(f\"Error getting cursor for query: {query}\")\n                return None\n        except Exception as e:\n            logging.error(f\"Error in get_all_downstream_vertices: {e}\")\n            return None\n\n    def get_inbound_models(self, end_key: str) -> list[ModelType] | None:\n        vertex_type: str = self._get_collection_from_id(end_key)\n\n        query: str = f\"\"\"\n        FOR v, e, p IN 1..100 INBOUND '{vertex_type}/{end_key}' GRAPH '{self.default_graph_name}'\n        RETURN DISTINCT v\n        \"\"\"\n\n        # query: str = f\"\"\"\n        # FOR v, e, p IN 1..100 INBOUND '{vertex_type}/{end_key}' GRAPH '{self.default_graph_name}'\n        # FILTER LENGTH(p.edges[* FILTER CURRENT != e]) == 0\n        # RETURN DISTINCT v\n        # \"\"\"\n\n        try:\n            cursor: Result[Cursor] = self.db_connector.db.aql.execute(query)\n            if isinstance(cursor, Cursor):\n                return [\n                    helper_functions.create_model_from_vertex(doc) for doc in cursor\n                ]\n            else:\n                logging.error(f\"Error getting cursor for query: {query}\")\n                return None\n        except Exception as e:\n            logging.error(f\"Error in get_all_upstream_vertices: {e}\")\n            return None\n\n    def update_vertex_by_id(self, id: str, new_summary: str) -> None:\n        try:\n            collection_name: str = self._get_collection_from_id(id)\n            if collection_name == \"unknown\":\n                logging.error(f\"Unknown vertex type for id: {id}\")\n                return\n\n            vertex_collection: StandardCollection = self.db_connector.db.collection(\n                collection_name\n            )\n            vertex_result: Result[Json | None] = vertex_collection.get(id)\n\n            if not vertex_result:\n                logging.error(f\"Vertex with id {id} not found.\")\n                return\n\n            if isinstance(vertex_result, dict):\n                vertex = vertex_result\n            else:\n                logging.error(\"Retrieved vertex is not in a mutable format.\")\n                return None\n\n            vertex[\"summary\"] = new_summary\n\n            vertex_collection.update(vertex)\n            logging.info(f\"Vertex with id {id} updated successfully.\")\n\n        except Exception as e:\n            logging.error(f\"Error in `update_vertex_by_id`: {e}\")\n\n    def get_all_modules(self) -> list[ModuleModel] | None:\n        try:\n            # Define the collection name for modules.\n            collection_name = \"modules\"\n            module_collection: StandardCollection = self.db_connector.db.collection(\n                collection_name\n            )\n\n            # Retrieve all documents from the modules collection.\n            cursor: Result[Cursor] = module_collection.all()\n\n            # Convert each document to a ModuleModel instance.\n            modules: list[ModuleModel] = []\n            for doc in cursor:  # type: ignore # FIXME: Fix type error\n                # Ensure the document is a dictionary.\n                try:\n                    # Convert the document to a ModuleModel instance and add it to the list.\n                    module = ModuleModel(**doc)\n                    modules.append(module)\n                except Exception as e:\n                    logging.error(f\"Retrieved document is not in a valid format: {e}\")\n                    continue\n\n            return modules\n\n        except Exception as e:\n            logging.error(f\"Error in get_all_modules: {e}\")\n            return None\n", "important_comments": "", "dependencies": "", "summary": "\nSummary:\n\n        postcode:databases:arangodb:arangodb_manager.py__*__MODULE\n\n        \nChild (postcode:databases:arangodb:arangodb_manager.py__*__MODULE__*__STANDALONE_BLOCK-1) code content:\nModelType = Union[\n    ModuleModel,\n    ClassModel,\n    FunctionModel,\n    StandaloneCodeBlockModel,\n]\n\n\nChild (postcode:databases:arangodb:arangodb_manager.py__*__MODULE__*__CLASS-ArangoDBManager) code content:\n\n# NOTE: Remember, when adding logic to connect dependencies, the `from` the external dependency `to` the internal definition using it\n\n\nclass ArangoDBManager:\n    def __init__(\n        self,\n        db_connector: ArangoDBConnector,\n        default_graph_name: str = \"codebase_graph\",\n    ) -> None:\n        self.db_connector: ArangoDBConnector = db_connector\n\n        self.processed_id_set = set()\n        self.default_graph_name: str = default_graph_name\n\n    def upsert_models(self, module_models: list[ModuleModel]) -> \"ArangoDBManager\":\n        for model in module_models:\n            self._upsert_model(model)\n        return self\n\n    def _upsert_model(self, module_model: ModuleModel) -> None:\n        self._upsert_vertex(module_model, \"modules\")\n        self._process_children(module_model)\n\n    def _process_children(self, parent_model: ModelType) -> None:\n        if not parent_model.children:\n            return None\n\n        for child in parent_model.children:\n            # if child.id in self.processed_id_set:\n            #     continue\n\n            self.processed_id_set.add(child.id)\n            self._upsert_vertex(\n                child, helper_functions.pluralize_block_type(child.block_type)\n            )\n\n            if child.children:\n                self._process_children(child)\n\n    def _upsert_vertex(self, model: ModelType, collection_name: str) -> None:\n        model_data: dict[str, Any] = model.model_dump()\n        model_data[\"_key\"] = model.id\n\n        try:\n            self.db_connector.ensure_collection(\n                collection_name, model.model_json_schema()\n            )\n            query: str = f\"\"\"\n            UPSERT {{_key: @key}}\n            INSERT @doc\n            UPDATE @doc\n            IN {collection_name}\n            \"\"\"\n            bind_vars: dict[str, Any] = {\"key\": model.id, \"doc\": model_data}\n            self.db_connector.db.aql.execute(query, bind_vars=bind_vars)\n\n            if not isinstance(model, ModuleModel) and model.parent_id:\n                parent_type: str = self._get_collection_from_id(model.parent_id)\n                self._upsert_edge(\n                    model.id, model.parent_id, collection_name, parent_type\n                )\n        except Exception as e:\n            logging.error(f\"Error upserting {collection_name} vertex (ArangoDB): {e}\")\n\n    def _upsert_edge(\n        self, from_key: str, to_key: str, source_type: str, target_type: str\n    ) -> None:\n        source_string: str = f\"{source_type}/{from_key}\"\n        target_string: str = f\"{target_type}/{to_key}\"\n\n        edge_data: dict[str, str] = {\n            \"_from\": source_string,\n            \"_to\": target_string,\n            \"source_type\": source_type,\n            \"target_type\": target_type,\n        }\n\n        try:\n            self.db_connector.ensure_edge_collection(\"code_edges\")\n            query = f\"\"\"\n            UPSERT {{_from: @from, _to: @to}}\n            INSERT @doc\n            UPDATE @doc\n            IN code_edges\n            \"\"\"\n            bind_vars = {\n                \"from\": edge_data[\"_from\"],\n                \"to\": edge_data[\"_to\"],\n                \"doc\": edge_data,\n            }\n            self.db_connector.db.aql.execute(query, bind_vars=bind_vars)\n        except Exception as e:\n            logging.error(f\"Error upserting edge (ArangoDB): {e}\")\n\n    def _get_collection_from_id(self, block_id: str) -> str:\n        block_id_parts: list[str] = block_id.split(\"__*__\")\n        block_type_part: str = block_id_parts[-1]\n\n        block_type_functions: dict[str, Callable[..., str]] = {\n            \"MODULE\": lambda: \"modules\",\n            \"CLASS\": lambda: \"classes\",\n            \"FUNCTION\": lambda: \"functions\",\n            \"STANDALONE_BLOCK\": lambda: \"standalone_blocks\",\n        }\n\n        for key, func in block_type_functions.items():\n            if block_type_part.startswith(key):\n                return func()\n\n        return \"unknown\"\n\n    def process_imports_and_dependencies(self) -> \"ArangoDBManager\":\n        for vertex_collection in helper_functions.pluralized_and_lowered_block_types():\n            cursor: Result[Cursor] = self.db_connector.db.collection(\n                vertex_collection\n            ).all()\n            if isinstance(cursor, Cursor):\n                for vertex in cursor:\n                    vertex_key = vertex[\"_key\"]\n                    if vertex_collection == \"modules\":\n                        self._create_edges_for_imports(\n                            vertex_key, vertex.get(\"imports\", [])\n                        )\n                    else:\n                        self._create_edges_for_dependencies(\n                            vertex_key, vertex.get(\"dependencies\", [])\n                        )\n            else:\n                logging.error(\n                    f\"Error getting cursor for vertex collection: {vertex_collection}\"\n                )\n        return self\n\n    def _create_edges_for_imports(\n        self, module_key: str, imports: list[dict[str, Any]]\n    ) -> None:\n        if not imports:\n            # logging.debug(f\"No imports found for module {module_key}\")\n            return\n\n        # logging.info(f\"Processing imports for module {module_key}\")\n\n        for _import in imports:\n            import_names: list[dict[str, str]] = _import.get(\"import_names\", [])\n            if not import_names:\n                # logging.debug(f\"No import names found in import {_import}\")\n                continue\n\n            for import_name in import_names:\n                local_block_id: str | None = import_name.get(\"local_block_id\")\n\n                if local_block_id:\n                    target_type = self._get_collection_from_id(local_block_id)\n                    try:\n                        self._upsert_edge(\n                            local_block_id, module_key, target_type, \"modules\"\n                        )\n\n                        # logging.info(\n                        #     f\"Upserted edge for import {module_key} to {local_block_id}\"\n                        # )\n                    except Exception as e:\n                        logging.error(\n                            f\"Error creating edge for import {module_key} to {local_block_id}: {e}\"\n                        )\n                else:\n                    # logging.warning(\n                    #     f\"Skipped import {import_name} in module {module_key}\"\n                    # )\n                    ...\n\n    def _create_edges_for_dependencies(\n        self, block_key: str, dependencies: list[dict[str, Any]]\n    ) -> None:\n        if not dependencies:\n            return\n\n        for dependency in dependencies:\n            code_block_id: str | None = dependency.get(\"code_block_id\")\n            if code_block_id:\n                source_type: str = self._get_collection_from_id(code_block_id)\n                target_type: str = self._get_collection_from_id(block_key)\n                try:\n                    self._upsert_edge(\n                        code_block_id, block_key, source_type, target_type\n                    )\n                    # logging.info(\n                    #     f\"Upserted edge for dependency {block_key} to {code_block_id}\"\n                    # )\n                except Exception as e:\n                    logging.error(\n                        f\"Error creating edge for dependency {block_key} to {code_block_id}: {e}\"\n                    )\n\n    def delete_vertex_by_id(\n        self, vertex_key: str, graph_name: str | None = None\n    ) -> None:\n        collection_name: str = self._get_collection_from_id(vertex_key)\n        if collection_name == \"unknown\":\n            logging.error(f\"Unknown vertex type for key: {vertex_key}\")\n            return None\n\n        if not graph_name:\n            graph_name = self.default_graph_name\n\n        try:\n            vertex_coll = self.db_connector.db.graph(graph_name).vertex_collection(\n                collection_name\n            )\n\n            vertex_coll.delete(vertex_key)\n\n            # logging.info(\n            #     f\"Vertex '{vertex_key}' from collection '{collection_name}' was successfully deleted.\"\n            # )\n\n        except Exception as e:\n            logging.error(\n                f\"Error deleting vertex '{vertex_key}' from collection '{collection_name}': {e}\"\n            )\n\n    def get_graph(self, graph_name: str | None = None) -> Graph | None:\n        if not graph_name:\n            graph_name = self.default_graph_name\n        try:\n            return self.db_connector.db.graph(self.default_graph_name)\n        except Exception as e:\n            logging.error(f\"Error getting graph '{self.default_graph_name}': {e}\")\n            return None\n\n    def get_or_create_graph(self, graph_name: str | None = None) -> Result[Graph]:\n        if not graph_name:\n            graph_name = self.default_graph_name\n\n        try:\n            if not self.db_connector.db.has_graph(graph_name):\n                edge_definitions: list[dict[str, str | list[str]]] = [\n                    {\n                        \"edge_collection\": \"code_edges\",\n                        \"from_vertex_collections\": helper_functions.pluralized_and_lowered_block_types(),\n                        \"to_vertex_collections\": helper_functions.pluralized_and_lowered_block_types(),\n                    }\n                ]\n\n                # logging.info(f\"Graph '{graph_name}' created successfully.\")\n                return self.db_connector.db.create_graph(\n                    graph_name, edge_definitions=edge_definitions\n                )\n\n            else:\n                return self.get_graph()\n\n        except Exception as e:\n            logging.error(f\"Error creating graph '{graph_name}': {e}\")\n\n    def delete_graph(self, graph_name: str | None = None) -> None:\n        if not graph_name:\n            graph_name = self.default_graph_name\n        try:\n            self.db_connector.db.delete_graph(graph_name)\n            logging.info(f\"Graph '{graph_name}' deleted successfully.\")\n        except Exception as e:\n            logging.error(f\"Error deleting graph '{graph_name}': {e}\")\n\n    def get_outbound_models(self, start_key: str) -> list[ModelType] | None:\n        vertex_type: str = self._get_collection_from_id(start_key)\n\n        query: str = f\"\"\"\n        FOR v, e, p IN 1..100 OUTBOUND '{vertex_type}/{start_key}' GRAPH '{self.default_graph_name}'\n        RETURN DISTINCT v\n        \"\"\"\n        # query: str = f\"\"\"\n        # FOR v, e, p IN 1..100 OUTBOUND '{vertex_type}/{start_key}' GRAPH '{self.default_graph_name}'\n        # FILTER LENGTH(p.edges[* FILTER CURRENT != e]) == 0\n        # RETURN DISTINCT v\n        # \"\"\"\n        # query: str = f\"\"\"\n        # FOR v, e, p IN 1..100 OUTBOUND '{vertex_type}/{start_key}' GRAPH '{self.default_graph_name}'\n        # FILTER LENGTH(p.edges[* FILTER CURRENT != e]) == 0\n        #     AND p.edges[*].distance ALL == 1\n        # RETURN DISTINCT v\n        # \"\"\"\n\n        try:\n            cursor = self.db_connector.db.aql.execute(query)\n            if isinstance(cursor, Cursor):\n                return [\n                    helper_functions.create_model_from_vertex(doc) for doc in cursor\n                ]\n            else:\n                logging.error(f\"Error getting cursor for query: {query}\")\n                return None\n        except Exception as e:\n            logging.error(f\"Error in get_all_downstream_vertices: {e}\")\n            return None\n\n    def get_inbound_models(self, end_key: str) -> list[ModelType] | None:\n        vertex_type: str = self._get_collection_from_id(end_key)\n\n        query: str = f\"\"\"\n        FOR v, e, p IN 1..100 INBOUND '{vertex_type}/{end_key}' GRAPH '{self.default_graph_name}'\n        RETURN DISTINCT v\n        \"\"\"\n\n        # query: str = f\"\"\"\n        # FOR v, e, p IN 1..100 INBOUND '{vertex_type}/{end_key}' GRAPH '{self.default_graph_name}'\n        # FILTER LENGTH(p.edges[* FILTER CURRENT != e]) == 0\n        # RETURN DISTINCT v\n        # \"\"\"\n\n        try:\n            cursor: Result[Cursor] = self.db_connector.db.aql.execute(query)\n            if isinstance(cursor, Cursor):\n                return [\n                    helper_functions.create_model_from_vertex(doc) for doc in cursor\n                ]\n            else:\n                logging.error(f\"Error getting cursor for query: {query}\")\n                return None\n        except Exception as e:\n            logging.error(f\"Error in get_all_upstream_vertices: {e}\")\n            return None\n\n    def update_vertex_by_id(self, id: str, new_summary: str) -> None:\n        try:\n            collection_name: str = self._get_collection_from_id(id)\n            if collection_name == \"unknown\":\n                logging.error(f\"Unknown vertex type for id: {id}\")\n                return\n\n            vertex_collection: StandardCollection = self.db_connector.db.collection(\n                collection_name\n            )\n            vertex_result: Result[Json | None] = vertex_collection.get(id)\n\n            if not vertex_result:\n                logging.error(f\"Vertex with id {id} not found.\")\n                return\n\n            if isinstance(vertex_result, dict):\n                vertex = vertex_result\n            else:\n                logging.error(\"Retrieved vertex is not in a mutable format.\")\n                return None\n\n            vertex[\"summary\"] = new_summary\n\n            vertex_collection.update(vertex)\n            logging.info(f\"Vertex with id {id} updated successfully.\")\n\n        except Exception as e:\n            logging.error(f\"Error in `update_vertex_by_id`: {e}\")\n\n    def get_all_modules(self) -> list[ModuleModel] | None:\n        try:\n            # Define the collection name for modules.\n            collection_name = \"modules\"\n            module_collection: StandardCollection = self.db_connector.db.collection(\n                collection_name\n            )\n\n            # Retrieve all documents from the modules collection.\n            cursor: Result[Cursor] = module_collection.all()\n\n            # Convert each document to a ModuleModel instance.\n            modules: list[ModuleModel] = []\n            for doc in cursor:  # type: ignore # FIXME: Fix type error\n                # Ensure the document is a dictionary.\n                try:\n                    # Convert the document to a ModuleModel instance and add it to the list.\n                    module = ModuleModel(**doc)\n                    modules.append(module)\n                except Exception as e:\n                    logging.error(f\"Retrieved document is not in a valid format: {e}\")\n                    continue\n\n            return modules\n\n        except Exception as e:\n            logging.error(f\"Error in get_all_modules: {e}\")\n            return None\n\n, \nImported code block (postcode:databases:arangodb:arangodb_connector.py__*__MODULE) code content:\nimport logging\nfrom typing import Any\nfrom arango.client import ArangoClient\nfrom arango.database import StandardDatabase\nfrom arango.result import Result\nfrom arango.typings import Jsons, Json\n\nimport postcode.databases.arangodb.helper_functions as helper_functions\n\n# from postcode.models import (\n#     ModuleModel,\n#     ClassModel,\n#     FunctionModel,\n#     StandaloneCodeBlockModel,\n# )\n\n\n# test = ArangoClient(hosts=\"http://localhost:8529\")\nclass ArangoDBConnector:\n    def __init__(\n        self,\n        url: str = \"http://localhost:8529\",\n        username: str = \"root\",\n        password: str = \"openSesame\",\n        db_name: str = \"postcode\",\n    ) -> None:\n        self.client = ArangoClient(hosts=url)\n        self.username: str = username\n        self.password: str = password\n        self.db_name: str = db_name\n        self.db: StandardDatabase = self._ensure_database()\n\n    def _ensure_database(self) -> StandardDatabase:\n        sys_db: StandardDatabase = self.client.db(\n            \"_system\", username=self.username, password=self.password\n        )\n        if not sys_db.has_database(self.db_name):\n            sys_db.create_database(self.db_name)\n        return self.client.db(\n            self.db_name, username=self.username, password=self.password\n        )\n\n    # def _ensure_vertex_collections(self, vertex_collections: list[str]) -> None:\n    #     for collection in vertex_collections:\n    #         if not self.db.has_collection(collection):\n    #             self.db.create_collection(collection)\n\n    def _get_current_schema(self, collection_name: str) -> dict:\n        collection = self.db.collection(collection_name)\n        try:\n            properties: Result[Json] = collection.properties()\n            return properties.get(\"schema\", {})  # type: ignore # FIXME: Fix type error\n        except Exception as e:\n            logging.error(f\"Error retrieving current schema for {collection_name}: {e}\")\n            return {}\n\n    def ensure_collection(\n        self, collection_name: str, schema: dict[str, Any] | None = None\n    ) -> None:\n        if not self.db.has_collection(collection_name) and not schema:\n            self.db.create_collection(collection_name)\n            logging.info(f\"Created collection: {collection_name}\")\n        # else:\n        #     current_schema = self._get_current_schema(collection_name)\n        #     self.db.collection(collection_name)\n        # if current_schema != schema:\n        #     collection = self.db.collection(collection_name)\n        #     try:\n        #         collection.configure(schema=schema)\n        #         logging.info(f\"Updated schema for collection: {collection_name}\")\n        #     except Exception as e:\n        #         logging.error(f\"Error updating schema for {collection_name}: {e}\")\n\n    def ensure_edge_collection(self, collection_name: str) -> None:\n        if not self.db.has_collection(collection_name):\n            self.db.create_collection(collection_name, edge=True)\n            logging.info(f\"Created edge collection: {collection_name}\")\n\n    def delete_all_collections(self) -> None:\n        collections: Result[Jsons] = self.db.collections()\n\n        for collection in collections:  # type: ignore # FIXME: Fix type error\n            if not collection[\"name\"].startswith(\"_\"):  # Skip system collections\n                self.db.delete_collection(collection[\"name\"])\n                logging.info(f\"Deleted collection: {collection['name']}\")\n\n    def ensure_collections(self) -> None:\n        # model_schemas: dict[str, dict[str, Any]] = self._get_model_schemas()\n        required_collections: list[\n            str\n        ] = helper_functions.pluralized_and_lowered_block_types()\n\n        for collection_name in required_collections:\n            # schema: dict[str, Any] = model_schemas[collection_name]\n            # self.ensure_collection(collection_name, schema)\n            self.ensure_collection(collection_name)\n\n        self.ensure_edge_collection(\"code_edges\")\n\n    # def _get_model_schemas(self) -> dict[str, dict[str, Any]]:\n    #     return {\n    #         \"modules\": ModuleModel.model_json_schema(),\n    #         \"classes\": ClassModel.model_json_schema(),\n    #         \"functions\": FunctionModel.model_json_schema(),\n    #         \"standalone_blocks\": StandaloneCodeBlockModel.model_json_schema(),\n    #     }\n\n\nImported code block (postcode:models:models.py__*__MODULE) code content:\nfrom typing import Union\nfrom pydantic import BaseModel, Field, validator\n\nfrom postcode.models.enums import (\n    BlockType,\n    ImportModuleType,\n    CommentType,\n)\n\n\nclass ImportNameModel(BaseModel):\n    \"\"\"Class representing the name of an import.\"\"\"\n\n    name: str\n    as_name: str | None = None\n    local_block_id: str | None = None\n\n    # def convert_import_names_to_metadata(self) -> str:\n    #     \"\"\"Converts the import name to a metadata string.\"\"\"\n\n    #     return self.model_dump_json()\n\n\nclass ImportModel(BaseModel):\n    \"\"\"Class representing an import statement.\"\"\"\n\n    import_names: list[ImportNameModel]\n    imported_from: str | None = None\n    import_module_type: ImportModuleType = ImportModuleType.STANDARD_LIBRARY\n    local_module_id: str | None = None\n\n    def convert_import_to_metadata(self) -> str:\n        \"\"\"Converts the import to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass DependencyModel(BaseModel):\n    \"\"\"Class representing a module dependency.\"\"\"\n\n    code_block_id: str\n\n    def convert_dependency_to_metadata(self) -> str:\n        \"\"\"Converts the dependency to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass CommentModel(BaseModel):\n    \"\"\"Class representing a comment.\"\"\"\n\n    content: str\n    comment_types: list[CommentType]\n\n    def convert_comment_to_metadata(self) -> str:\n        \"\"\"Converts the comment to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass DecoratorModel(BaseModel):\n    \"\"\"Class representing a decorator.\"\"\"\n\n    content: str\n    decorator_name: str\n    decorator_args: list[str] | None = None\n\n    def convert_decorator_to_metadata(self) -> str:\n        \"\"\"Converts the decorator to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass ClassKeywordModel(BaseModel):\n    \"\"\"Class representing a class keyword.\"\"\"\n\n    content: str\n    keyword_name: str\n    args: str | None = None\n\n    def convert_class_keyword_to_metadata(self) -> str:\n        \"\"\"Converts the class keyword to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass ParameterModel(BaseModel):\n    \"\"\"Class representing a function parameter.\"\"\"\n\n    content: str\n\n\nclass ParameterListModel(BaseModel):\n    \"\"\"Class representing a list of parameters.\"\"\"\n\n    params: list[ParameterModel] | None = None\n    star_arg: ParameterModel | None = None\n    kwonly_params: list[ParameterModel] | None = None\n    star_kwarg: ParameterModel | None = None\n    posonly_params: list[ParameterModel] | None = None\n\n    def convert_parameters_to_metadata(self) -> str:\n        \"\"\"Converts the parameter list to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n\nclass BaseCodeBlockModel(BaseModel):\n    \"\"\"Attributes common to all code block models.\"\"\"\n\n    id: str\n    parent_id: str | None = None\n    block_type: BlockType\n    start_line_num: int\n    end_line_num: int\n    code_content: str = \"\"\n    important_comments: list[CommentModel] | None = None\n    dependencies: list[ImportModel | DependencyModel] | None = None\n    summary: str | None = None\n    children: list[\n        Union[\n            \"ClassModel\",\n            \"FunctionModel\",\n            \"StandaloneCodeBlockModel\",\n        ]\n    ] | None = []\n\n    @validator(\"parent_id\", always=True)\n    def check_parent_id(cls, v, values, **kwargs) -> str | None:\n        \"\"\"Validates that parent_id is a non-empty string unless block_type is MODULE.\"\"\"\n\n        if \"block_type\" in values and values[\"block_type\"] != BlockType.MODULE:\n            if len(v) < 1:\n                raise ValueError(\"parent_id is required!\")\n        return v\n\n    def _convert_parent_id_to_metadata(self) -> str:\n        \"\"\"Converts the parent_id to a metadata string.\"\"\"\n        return f\"{self.parent_id}\" if self.parent_id else \"\"\n\n    def _convert_block_type_to_metadata(self) -> str:\n        \"\"\"Converts the block_type to a metadata string.\"\"\"\n        return f\"{self.block_type.name}\"\n\n    def _convert_important_comments_to_metadata(self) -> str:\n        \"\"\"Converts the important comments to a metadata string.\"\"\"\n\n        important_comments: str = (\n            self.model_dump_json() if self.important_comments else \"\"\n        )\n\n        return f\"{important_comments}\"\n\n    def _convert_dependencies_to_metadata(self) -> str:\n        \"\"\"Converts the dependencies to a metadata string.\"\"\"\n\n        dependencies_str: str = \"\"\n\n        if self.dependencies:\n            for dependency in self.dependencies:\n                if isinstance(dependency, ImportModel):\n                    dependencies_str += f\"{dependency.convert_import_to_metadata()}\\n\"\n                elif isinstance(dependency, DependencyModel):\n                    dependencies_str += (\n                        f\"{dependency.convert_dependency_to_metadata()}\\n\"\n                    )\n\n        return dependencies_str\n\n    def _convert_summary_to_metadata(self) -> str:\n        \"\"\"Converts the summary to a metadata string.\"\"\"\n        return f\"{self.summary}\" if self.summary else \"\"\n\n    def _convert_children_to_metadata(self) -> str:\n        \"\"\"Converts the children to a metadata string.\"\"\"\n\n        children_str: str = \"\"\n\n        if self.children:\n            for child in self.children:\n                children_str += f\"{child.id}\\n\"\n\n        return children_str\n\n    def _convert_base_attributes_to_metadata_dict(self) -> dict[str, str | int]:\n        \"\"\"Converts the base attributes to a metadata dictionary.\"\"\"\n\n        return {\n            \"id\": self.id,\n            \"parent_id\": self._convert_parent_id_to_metadata(),\n            \"block_type\": self._convert_block_type_to_metadata(),\n            \"start_line_num\": self.start_line_num,\n            \"end_line_num\": self.end_line_num,\n            \"code_content\": self.code_content,\n            \"important_comments\": self._convert_important_comments_to_metadata(),\n            \"dependencies\": self._convert_dependencies_to_metadata(),\n            \"summary\": self._convert_summary_to_metadata(),\n            \"children\": self._convert_children_to_metadata(),\n        }\n\n\nclass ModuleSpecificAttributes(BaseModel):\n    \"\"\"Module specific attributes.\"\"\"\n\n    file_path: str = Field(min_length=1)\n    docstring: str | None = None\n    header: list[str] | None = None\n    footer: list[str] | None = None\n    imports: list[ImportModel] | None = None\n\n    def _convert_docstring_to_metadata(self) -> str:\n        \"\"\"Converts the docstring to a metadata string.\"\"\"\n        return f\"{self.docstring}\"\n\n    def _convert_header_to_metadata(self) -> str:\n        \"\"\"Converts the header and footer to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n    def _convert_footer_to_metadata(self) -> str:\n        \"\"\"Converts the header and footer to a metadata string.\"\"\"\n        return self.model_dump_json()\n\n    def _convert_imports_to_metadata(self) -> str:\n        \"\"\"Converts the imports to a metadata string.\"\"\"\n        imports_str: str = self.model_dump_json() if self.imports else \"\"\n        return f\"{imports_str}\"\n\n    def _convert_module_attributes_to_metadata_dict(self) -> dict[str, str | int]:\n        \"\"\"Converts the module attributes to a metadata dictionary.\"\"\"\n\n        return {\n            \"file_path\": self.file_path,\n            \"docstring\": self._convert_docstring_to_metadata(),\n            \"header\": self._convert_header_to_metadata(),\n            \"footer\": self._convert_footer_to_metadata(),\n            \"imports\": self._convert_imports_to_metadata(),\n        }\n\n\nclass ModuleModel(BaseCodeBlockModel, ModuleSpecificAttributes):\n    \"\"\"Model for a module.\"\"\"\n\n    def convert_to_metadata(self) -> dict[str, str | int]:\n        \"\"\"Converts the module model to a metadata dictionary.\"\"\"\n\n        return {\n            **self._convert_base_attributes_to_metadata_dict(),\n            **self._convert_module_attributes_to_metadata_dict(),\n        }\n\n\nclass ClassSpecificAttributes(BaseModel):\n    \"\"\"Class specific attributes.\"\"\"\n\n    class_name: str = Field(min_length=1)\n    decorators: list[DecoratorModel] | None = None\n    bases: list[str] | None = None\n    docstring: str | None = None\n    keywords: list[ClassKeywordModel] | None = None\n    # attributes: list[dict] | None = None\n\n    def _convert_decorators_to_metadata(self) -> str:\n        \"\"\"Converts the decorators to a metadata string.\"\"\"\n        decorators_str: str = self.model_dump_json() if self.decorators else \"\"\n        return f\"{decorators_str}\"\n\n    def _convert_bases_to_metadata(self) -> str:\n        \"\"\"Converts the bases to a metadata string.\"\"\"\n        return self.model_dump_json() if self.bases else \"\"\n\n    def _convert_docstring_to_metadata(self) -> str:\n        \"\"\"Converts the docstring to a metadata string.\"\"\"\n        return f\"{self.docstring}\" if self.docstring else \"\"\n\n    def _convert_keywords_to_metadata(self) -> str:\n        \"\"\"Converts the keywords to a metadata string.\"\"\"\n        keywords_str: str = self.model_dump_json() if self.keywords else \"\"\n        return f\"{keywords_str}\"\n\n    def _convert_class_attributes_to_metadata_dict(self) -> dict[str, str | int]:\n        \"\"\"Converts the class attributes to a metadata dictionary.\"\"\"\n\n        return {\n            \"class_name\": self.class_name,\n            \"decorators\": self._convert_decorators_to_metadata(),\n            \"bases\": self._convert_bases_to_metadata(),\n            \"docstring\": self._convert_docstring_to_metadata(),\n            \"keywords\": self._convert_keywords_to_metadata(),\n        }\n\n\nclass ClassModel(BaseCodeBlockModel, ClassSpecificAttributes):\n    \"\"\"Model for a class.\"\"\"\n\n    def convert_to_metadata(self) -> dict[str, str | int]:\n        \"\"\"Converts the class model to a metadata dictionary.\"\"\"\n        return {\n            **self._convert_base_attributes_to_metadata_dict(),\n            **self._convert_class_attributes_to_metadata_dict(),\n        }\n\n\nclass FunctionSpecificAttributes(BaseModel):\n    \"\"\"Function specific attributes.\"\"\"\n\n    function_name: str = Field(min_length=1)\n    docstring: str | None = None\n    decorators: list[DecoratorModel] | None = None\n    parameters: ParameterListModel | None = None\n    returns: str | None = None\n    is_method: bool = False\n    is_async: bool = False\n\n    def _convert_docstring_to_metadata(self) -> str:\n        \"\"\"Converts the docstring to a metadata string.\"\"\"\n        return f\"{self.docstring}\" if self.docstring else \"\"\n\n    def _convert_decorators_to_metadata(self) -> str:\n        \"\"\"Converts the decorators to a metadata string.\"\"\"\n        decorators_str: str = self.model_dump_json() if self.decorators else \"\"\n        return f\"{decorators_str}\"\n\n    def _convert_parameters_to_metadata(self) -> str:\n        \"\"\"Converts the parameters to a metadata string.\"\"\"\n        return (\n            self.parameters.convert_parameters_to_metadata() if self.parameters else \"\"\n        )\n\n    def _convert_returns_to_metadata(self) -> str:\n        \"\"\"Converts the returns to a metadata string.\"\"\"\n        return f\"{self.returns}\" if self.returns else \"\"\n\n    def _convert_function_attributes_to_metadata_dict(self) -> dict[str, str | bool]:\n        \"\"\"Converts the function attributes to a metadata dictionary.\"\"\"\n\n        return {\n            \"function_name\": self.function_name,\n            \"docstring\": self._convert_docstring_to_metadata(),\n            \"decorators\": self._convert_decorators_to_metadata(),\n            \"parameters\": self._convert_parameters_to_metadata(),\n            \"returns\": self._convert_returns_to_metadata(),\n            \"is_method\": self.is_method,\n            \"is_async\": self.is_async,\n        }\n\n\nclass FunctionModel(BaseCodeBlockModel, FunctionSpecificAttributes):\n    \"\"\"Model for a function.\"\"\"\n\n    def convert_to_metadata(self) -> dict[str, str | int]:\n        \"\"\"Converts the function model to a metadata dictionary.\"\"\"\n\n        return {\n            **self._convert_base_attributes_to_metadata_dict(),\n            **self._convert_function_attributes_to_metadata_dict(),\n        }\n\n\nclass StandaloneCodeBlockSpecificAttributes(BaseModel):\n    \"\"\"Standalone code block specific attributes.\"\"\"\n\n    variable_assignments: list[str] | None = None\n\n    def _convert_variable_assignments_to_metadata(self) -> str:\n        \"\"\"Converts the variable assignments to a metadata string.\"\"\"\n        return self.model_dump_json() if self.variable_assignments else \"\"\n\n    def _convert_standalone_block_attributes_to_metadata_dict(\n        self,\n    ) -> dict[str, str | int]:\n        \"\"\"Converts the standalone code block attributes to a metadata dictionary.\"\"\"\n        return {\n            \"variable_assignments\": self._convert_variable_assignments_to_metadata(),\n        }\n\n\nclass StandaloneCodeBlockModel(\n    BaseCodeBlockModel, StandaloneCodeBlockSpecificAttributes\n):\n    \"\"\"Model for a standalone code block.\"\"\"\n\n    def convert_to_metadata(self) -> dict[str, str | int]:\n        \"\"\"Converts the standalone code block model to a metadata dictionary.\"\"\"\n\n        return {\n            **self._convert_base_attributes_to_metadata_dict(),\n            **self._convert_standalone_block_attributes_to_metadata_dict(),\n        }\n\n, \nimport logging\nfrom typing import Any, Callable, Union\nfrom arango.result import Result\nfrom arango.cursor import Cursor\nfrom arango.graph import Graph\nfrom arango.collection import StandardCollection\nfrom arango.typings import Json\n        ", "children": "postcode:databases:arangodb:arangodb_manager.py__*__MODULE__*__STANDALONE_BLOCK-1\npostcode:databases:arangodb:arangodb_manager.py__*__MODULE__*__CLASS-ArangoDBManager\n", "file_path": "postcode/databases/arangodb/arangodb_manager.py", "docstring": "None", "header": "{\"file_path\":\"postcode/databases/arangodb/arangodb_manager.py\",\"docstring\":null,\"header\":[],\"footer\":[],\"imports\":[{\"import_names\":[{\"name\":\"logging\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":null,\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"Any\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"Callable\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"Union\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"typing\",\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"Result\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"arango.result\",\"import_module_type\":\"THIRD_PARTY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"Cursor\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"arango.cursor\",\"import_module_type\":\"THIRD_PARTY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"Graph\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"arango.graph\",\"import_module_type\":\"THIRD_PARTY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"StandardCollection\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"arango.collection\",\"import_module_type\":\"THIRD_PARTY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"Json\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"arango.typings\",\"import_module_type\":\"THIRD_PARTY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"ArangoDBConnector\",\"as_name\":null,\"local_block_id\":\"postcode:databases:arangodb:arangodb_connector.py__*__MODULE__*__CLASS-ArangoDBConnector\"}],\"imported_from\":\"postcode.databases.arangodb.arangodb_connector\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:databases:arangodb:arangodb_connector.py__*__MODULE\"},{\"import_names\":[{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ModuleModel\"},{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-ClassModel\"},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-FunctionModel\"},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":\"postcode:models:models.py__*__MODULE__*__CLASS-StandaloneCodeBlockModel\"}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:models:models.py__*__MODULE\"},{\"import_names\":[{\"name\":\"postcode.databases.arangodb.helper_functions\",\"as_name\":\"helper_functions\",\"local_block_id\":null}],\"imported_from\":null,\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:databases:arangodb:helper_functions.py__*__MODULE\"}],\"id\":\"postcode:databases:arangodb:arangodb_manager.py__*__MODULE\",\"parent_id\":null,\"block_type\":\"MODULE\",\"start_line_num\":1,\"end_line_num\":409,\"code_content\":\"import logging\\nfrom typing import Any, Callable, Union\\n\\nfrom arango.result import Result\\nfrom arango.cursor import Cursor\\nfrom arango.graph import Graph\\nfrom arango.collection import StandardCollection\\nfrom arango.typings import Json\\n\\nfrom postcode.databases.arangodb.arangodb_connector import ArangoDBConnector\\n\\n# from postcode.types.postcode import ModelType\\nfrom postcode.models.models import (\\n    ClassModel,\\n    FunctionModel,\\n    ModuleModel,\\n    StandaloneCodeBlockModel,\\n)\\nimport postcode.databases.arangodb.helper_functions as helper_functions\\n\\nModelType = Union[\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n]\\n\\n# NOTE: Remember, when adding logic to connect dependencies, the `from` the external dependency `to` the internal definition using it\\n\\n\\nclass ArangoDBManager:\\n    def __init__(\\n        self,\\n        db_connector: ArangoDBConnector,\\n        default_graph_name: str = \\\"codebase_graph\\\",\\n    ) -> None:\\n        self.db_connector: ArangoDBConnector = db_connector\\n\\n        self.processed_id_set = set()\\n        self.default_graph_name: str = default_graph_name\\n\\n    def upsert_models(self, module_models: list[ModuleModel]) -> \\\"ArangoDBManager\\\":\\n        for model in module_models:\\n            self._upsert_model(model)\\n        return self\\n\\n    def _upsert_model(self, module_model: ModuleModel) -> None:\\n        self._upsert_vertex(module_model, \\\"modules\\\")\\n        self._process_children(module_model)\\n\\n    def _process_children(self, parent_model: ModelType) -> None:\\n        if not parent_model.children:\\n            return None\\n\\n        for child in parent_model.children:\\n            # if child.id in self.processed_id_set:\\n            #     continue\\n\\n            self.processed_id_set.add(child.id)\\n            self._upsert_vertex(\\n                child, helper_functions.pluralize_block_type(child.block_type)\\n            )\\n\\n            if child.children:\\n                self._process_children(child)\\n\\n    def _upsert_vertex(self, model: ModelType, collection_name: str) -> None:\\n        model_data: dict[str, Any] = model.model_dump()\\n        model_data[\\\"_key\\\"] = model.id\\n\\n        try:\\n            self.db_connector.ensure_collection(\\n                collection_name, model.model_json_schema()\\n            )\\n            query: str = f\\\"\\\"\\\"\\n            UPSERT {{_key: @key}}\\n            INSERT @doc\\n            UPDATE @doc\\n            IN {collection_name}\\n            \\\"\\\"\\\"\\n            bind_vars: dict[str, Any] = {\\\"key\\\": model.id, \\\"doc\\\": model_data}\\n            self.db_connector.db.aql.execute(query, bind_vars=bind_vars)\\n\\n            if not isinstance(model, ModuleModel) and model.parent_id:\\n                parent_type: str = self._get_collection_from_id(model.parent_id)\\n                self._upsert_edge(\\n                    model.id, model.parent_id, collection_name, parent_type\\n                )\\n        except Exception as e:\\n            logging.error(f\\\"Error upserting {collection_name} vertex (ArangoDB): {e}\\\")\\n\\n    def _upsert_edge(\\n        self, from_key: str, to_key: str, source_type: str, target_type: str\\n    ) -> None:\\n        source_string: str = f\\\"{source_type}/{from_key}\\\"\\n        target_string: str = f\\\"{target_type}/{to_key}\\\"\\n\\n        edge_data: dict[str, str] = {\\n            \\\"_from\\\": source_string,\\n            \\\"_to\\\": target_string,\\n            \\\"source_type\\\": source_type,\\n            \\\"target_type\\\": target_type,\\n        }\\n\\n        try:\\n            self.db_connector.ensure_edge_collection(\\\"code_edges\\\")\\n            query = f\\\"\\\"\\\"\\n            UPSERT {{_from: @from, _to: @to}}\\n            INSERT @doc\\n            UPDATE @doc\\n            IN code_edges\\n            \\\"\\\"\\\"\\n            bind_vars = {\\n                \\\"from\\\": edge_data[\\\"_from\\\"],\\n                \\\"to\\\": edge_data[\\\"_to\\\"],\\n                \\\"doc\\\": edge_data,\\n            }\\n            self.db_connector.db.aql.execute(query, bind_vars=bind_vars)\\n        except Exception as e:\\n            logging.error(f\\\"Error upserting edge (ArangoDB): {e}\\\")\\n\\n    def _get_collection_from_id(self, block_id: str) -> str:\\n        block_id_parts: list[str] = block_id.split(\\\"__*__\\\")\\n        block_type_part: str = block_id_parts[-1]\\n\\n        block_type_functions: dict[str, Callable[..., str]] = {\\n            \\\"MODULE\\\": lambda: \\\"modules\\\",\\n            \\\"CLASS\\\": lambda: \\\"classes\\\",\\n            \\\"FUNCTION\\\": lambda: \\\"functions\\\",\\n            \\\"STANDALONE_BLOCK\\\": lambda: \\\"standalone_blocks\\\",\\n        }\\n\\n        for key, func in block_type_functions.items():\\n            if block_type_part.startswith(key):\\n                return func()\\n\\n        return \\\"unknown\\\"\\n\\n    def process_imports_and_dependencies(self) -> \\\"ArangoDBManager\\\":\\n        for vertex_collection in helper_functions.pluralized_and_lowered_block_types():\\n            cursor: Result[Cursor] = self.db_connector.db.collection(\\n                vertex_collection\\n            ).all()\\n            if isinstance(cursor, Cursor):\\n                for vertex in cursor:\\n                    vertex_key = vertex[\\\"_key\\\"]\\n                    if vertex_collection == \\\"modules\\\":\\n                        self._create_edges_for_imports(\\n                            vertex_key, vertex.get(\\\"imports\\\", [])\\n                        )\\n                    else:\\n                        self._create_edges_for_dependencies(\\n                            vertex_key, vertex.get(\\\"dependencies\\\", [])\\n                        )\\n            else:\\n                logging.error(\\n                    f\\\"Error getting cursor for vertex collection: {vertex_collection}\\\"\\n                )\\n        return self\\n\\n    def _create_edges_for_imports(\\n        self, module_key: str, imports: list[dict[str, Any]]\\n    ) -> None:\\n        if not imports:\\n            # logging.debug(f\\\"No imports found for module {module_key}\\\")\\n            return\\n\\n        # logging.info(f\\\"Processing imports for module {module_key}\\\")\\n\\n        for _import in imports:\\n            import_names: list[dict[str, str]] = _import.get(\\\"import_names\\\", [])\\n            if not import_names:\\n                # logging.debug(f\\\"No import names found in import {_import}\\\")\\n                continue\\n\\n            for import_name in import_names:\\n                local_block_id: str | None = import_name.get(\\\"local_block_id\\\")\\n\\n                if local_block_id:\\n                    target_type = self._get_collection_from_id(local_block_id)\\n                    try:\\n                        self._upsert_edge(\\n                            local_block_id, module_key, target_type, \\\"modules\\\"\\n                        )\\n\\n                        # logging.info(\\n                        #     f\\\"Upserted edge for import {module_key} to {local_block_id}\\\"\\n                        # )\\n                    except Exception as e:\\n                        logging.error(\\n                            f\\\"Error creating edge for import {module_key} to {local_block_id}: {e}\\\"\\n                        )\\n                else:\\n                    # logging.warning(\\n                    #     f\\\"Skipped import {import_name} in module {module_key}\\\"\\n                    # )\\n                    ...\\n\\n    def _create_edges_for_dependencies(\\n        self, block_key: str, dependencies: list[dict[str, Any]]\\n    ) -> None:\\n        if not dependencies:\\n            return\\n\\n        for dependency in dependencies:\\n            code_block_id: str | None = dependency.get(\\\"code_block_id\\\")\\n            if code_block_id:\\n                source_type: str = self._get_collection_from_id(code_block_id)\\n                target_type: str = self._get_collection_from_id(block_key)\\n                try:\\n                    self._upsert_edge(\\n                        code_block_id, block_key, source_type, target_type\\n                    )\\n                    # logging.info(\\n                    #     f\\\"Upserted edge for dependency {block_key} to {code_block_id}\\\"\\n                    # )\\n                except Exception as e:\\n                    logging.error(\\n                        f\\\"Error creating edge for dependency {block_key} to {code_block_id}: {e}\\\"\\n                    )\\n\\n    def delete_vertex_by_id(\\n        self, vertex_key: str, graph_name: str | None = None\\n    ) -> None:\\n        collection_name: str = self._get_collection_from_id(vertex_key)\\n        if collection_name == \\\"unknown\\\":\\n            logging.error(f\\\"Unknown vertex type for key: {vertex_key}\\\")\\n            return None\\n\\n        if not graph_name:\\n            graph_name = self.default_graph_name\\n\\n        try:\\n            vertex_coll = self.db_connector.db.graph(graph_name).vertex_collection(\\n                collection_name\\n            )\\n\\n            vertex_coll.delete(vertex_key)\\n\\n            # logging.info(\\n            #     f\\\"Vertex '{vertex_key}' from collection '{collection_name}' was successfully deleted.\\\"\\n            # )\\n\\n        except Exception as e:\\n            logging.error(\\n                f\\\"Error deleting vertex '{vertex_key}' from collection '{collection_name}': {e}\\\"\\n            )\\n\\n    def get_graph(self, graph_name: str | None = None) -> Graph | None:\\n        if not graph_name:\\n            graph_name = self.default_graph_name\\n        try:\\n            return self.db_connector.db.graph(self.default_graph_name)\\n        except Exception as e:\\n            logging.error(f\\\"Error getting graph '{self.default_graph_name}': {e}\\\")\\n            return None\\n\\n    def get_or_create_graph(self, graph_name: str | None = None) -> Result[Graph]:\\n        if not graph_name:\\n            graph_name = self.default_graph_name\\n\\n        try:\\n            if not self.db_connector.db.has_graph(graph_name):\\n                edge_definitions: list[dict[str, str | list[str]]] = [\\n                    {\\n                        \\\"edge_collection\\\": \\\"code_edges\\\",\\n                        \\\"from_vertex_collections\\\": helper_functions.pluralized_and_lowered_block_types(),\\n                        \\\"to_vertex_collections\\\": helper_functions.pluralized_and_lowered_block_types(),\\n                    }\\n                ]\\n\\n                # logging.info(f\\\"Graph '{graph_name}' created successfully.\\\")\\n                return self.db_connector.db.create_graph(\\n                    graph_name, edge_definitions=edge_definitions\\n                )\\n\\n            else:\\n                return self.get_graph()\\n\\n        except Exception as e:\\n            logging.error(f\\\"Error creating graph '{graph_name}': {e}\\\")\\n\\n    def delete_graph(self, graph_name: str | None = None) -> None:\\n        if not graph_name:\\n            graph_name = self.default_graph_name\\n        try:\\n            self.db_connector.db.delete_graph(graph_name)\\n            logging.info(f\\\"Graph '{graph_name}' deleted successfully.\\\")\\n        except Exception as e:\\n            logging.error(f\\\"Error deleting graph '{graph_name}': {e}\\\")\\n\\n    def get_outbound_models(self, start_key: str) -> list[ModelType] | None:\\n        vertex_type: str = self._get_collection_from_id(start_key)\\n\\n        query: str = f\\\"\\\"\\\"\\n        FOR v, e, p IN 1..100 OUTBOUND '{vertex_type}/{start_key}' GRAPH '{self.default_graph_name}'\\n        RETURN DISTINCT v\\n        \\\"\\\"\\\"\\n        # query: str = f\\\"\\\"\\\"\\n        # FOR v, e, p IN 1..100 OUTBOUND '{vertex_type}/{start_key}' GRAPH '{self.default_graph_name}'\\n        # FILTER LENGTH(p.edges[* FILTER CURRENT != e]) == 0\\n        # RETURN DISTINCT v\\n        # \\\"\\\"\\\"\\n        # query: str = f\\\"\\\"\\\"\\n        # FOR v, e, p IN 1..100 OUTBOUND '{vertex_type}/{start_key}' GRAPH '{self.default_graph_name}'\\n        # FILTER LENGTH(p.edges[* FILTER CURRENT != e]) == 0\\n        #     AND p.edges[*].distance ALL == 1\\n        # RETURN DISTINCT v\\n        # \\\"\\\"\\\"\\n\\n        try:\\n            cursor = self.db_connector.db.aql.execute(query)\\n            if isinstance(cursor, Cursor):\\n                return [\\n                    helper_functions.create_model_from_vertex(doc) for doc in cursor\\n                ]\\n            else:\\n                logging.error(f\\\"Error getting cursor for query: {query}\\\")\\n                return None\\n        except Exception as e:\\n            logging.error(f\\\"Error in get_all_downstream_vertices: {e}\\\")\\n            return None\\n\\n    def get_inbound_models(self, end_key: str) -> list[ModelType] | None:\\n        vertex_type: str = self._get_collection_from_id(end_key)\\n\\n        query: str = f\\\"\\\"\\\"\\n        FOR v, e, p IN 1..100 INBOUND '{vertex_type}/{end_key}' GRAPH '{self.default_graph_name}'\\n        RETURN DISTINCT v\\n        \\\"\\\"\\\"\\n\\n        # query: str = f\\\"\\\"\\\"\\n        # FOR v, e, p IN 1..100 INBOUND '{vertex_type}/{end_key}' GRAPH '{self.default_graph_name}'\\n        # FILTER LENGTH(p.edges[* FILTER CURRENT != e]) == 0\\n        # RETURN DISTINCT v\\n        # \\\"\\\"\\\"\\n\\n        try:\\n            cursor: Result[Cursor] = self.db_connector.db.aql.execute(query)\\n            if isinstance(cursor, Cursor):\\n                return [\\n                    helper_functions.create_model_from_vertex(doc) for doc in cursor\\n                ]\\n            else:\\n                logging.error(f\\\"Error getting cursor for query: {query}\\\")\\n                return None\\n        except Exception as e:\\n            logging.error(f\\\"Error in get_all_upstream_vertices: {e}\\\")\\n            return None\\n\\n    def update_vertex_by_id(self, id: str, new_summary: str) -> None:\\n        try:\\n            collection_name: str = self._get_collection_from_id(id)\\n            if collection_name == \\\"unknown\\\":\\n                logging.error(f\\\"Unknown vertex type for id: {id}\\\")\\n                return\\n\\n            vertex_collection: StandardCollection = self.db_connector.db.collection(\\n                collection_name\\n            )\\n            vertex_result: Result[Json | None] = vertex_collection.get(id)\\n\\n            if not vertex_result:\\n                logging.error(f\\\"Vertex with id {id} not found.\\\")\\n                return\\n\\n            if isinstance(vertex_result, dict):\\n                vertex = vertex_result\\n            else:\\n                logging.error(\\\"Retrieved vertex is not in a mutable format.\\\")\\n                return None\\n\\n            vertex[\\\"summary\\\"] = new_summary\\n\\n            vertex_collection.update(vertex)\\n            logging.info(f\\\"Vertex with id {id} updated successfully.\\\")\\n\\n        except Exception as e:\\n            logging.error(f\\\"Error in `update_vertex_by_id`: {e}\\\")\\n\\n    def get_all_modules(self) -> list[ModuleModel] | None:\\n        try:\\n            # Define the collection name for modules.\\n            collection_name = \\\"modules\\\"\\n            module_collection: StandardCollection = self.db_connector.db.collection(\\n                collection_name\\n            )\\n\\n            # Retrieve all documents from the modules collection.\\n            cursor: Result[Cursor] = module_collection.all()\\n\\n            # Convert each document to a ModuleModel instance.\\n            modules: list[ModuleModel] = []\\n            for doc in cursor:  # type: ignore # FIXME: Fix type error\\n                # Ensure the document is a dictionary.\\n                try:\\n                    # Convert the document to a ModuleModel instance and add it to the list.\\n                    module = ModuleModel(**doc)\\n                    modules.append(module)\\n                except Exception as e:\\n                    logging.error(f\\\"Retrieved document is not in a valid format: {e}\\\")\\n                    continue\\n\\n            return modules\\n\\n        except Exception as e:\\n            logging.error(f\\\"Error in get_all_modules: {e}\\\")\\n            return None\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":\"\\nSummary:\\n\\n        postcode:databases:arangodb:arangodb_manager.py__*__MODULE\\n\\n        \\nChild (postcode:databases:arangodb:arangodb_manager.py__*__MODULE__*__STANDALONE_BLOCK-1) code content:\\nModelType = Union[\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n]\\n\\n\\nChild (postcode:databases:arangodb:arangodb_manager.py__*__MODULE__*__CLASS-ArangoDBManager) code content:\\n\\n# NOTE: Remember, when adding logic to connect dependencies, the `from` the external dependency `to` the internal definition using it\\n\\n\\nclass ArangoDBManager:\\n    def __init__(\\n        self,\\n        db_connector: ArangoDBConnector,\\n        default_graph_name: str = \\\"codebase_graph\\\",\\n    ) -> None:\\n        self.db_connector: ArangoDBConnector = db_connector\\n\\n        self.processed_id_set = set()\\n        self.default_graph_name: str = default_graph_name\\n\\n    def upsert_models(self, module_models: list[ModuleModel]) -> \\\"ArangoDBManager\\\":\\n        for model in module_models:\\n            self._upsert_model(model)\\n        return self\\n\\n    def _upsert_model(self, module_model: ModuleModel) -> None:\\n        self._upsert_vertex(module_model, \\\"modules\\\")\\n        self._process_children(module_model)\\n\\n    def _process_children(self, parent_model: ModelType) -> None:\\n        if not parent_model.children:\\n            return None\\n\\n        for child in parent_model.children:\\n            # if child.id in self.processed_id_set:\\n            #     continue\\n\\n            self.processed_id_set.add(child.id)\\n            self._upsert_vertex(\\n                child, helper_functions.pluralize_block_type(child.block_type)\\n            )\\n\\n            if child.children:\\n                self._process_children(child)\\n\\n    def _upsert_vertex(self, model: ModelType, collection_name: str) -> None:\\n        model_data: dict[str, Any] = model.model_dump()\\n        model_data[\\\"_key\\\"] = model.id\\n\\n        try:\\n            self.db_connector.ensure_collection(\\n                collection_name, model.model_json_schema()\\n            )\\n            query: str = f\\\"\\\"\\\"\\n            UPSERT {{_key: @key}}\\n            INSERT @doc\\n            UPDATE @doc\\n            IN {collection_name}\\n            \\\"\\\"\\\"\\n            bind_vars: dict[str, Any] = {\\\"key\\\": model.id, \\\"doc\\\": model_data}\\n            self.db_connector.db.aql.execute(query, bind_vars=bind_vars)\\n\\n            if not isinstance(model, ModuleModel) and model.parent_id:\\n                parent_type: str = self._get_collection_from_id(model.parent_id)\\n                self._upsert_edge(\\n                    model.id, model.parent_id, collection_name, parent_type\\n                )\\n        except Exception as e:\\n            logging.error(f\\\"Error upserting {collection_name} vertex (ArangoDB): {e}\\\")\\n\\n    def _upsert_edge(\\n        self, from_key: str, to_key: str, source_type: str, target_type: str\\n    ) -> None:\\n        source_string: str = f\\\"{source_type}/{from_key}\\\"\\n        target_string: str = f\\\"{target_type}/{to_key}\\\"\\n\\n        edge_data: dict[str, str] = {\\n            \\\"_from\\\": source_string,\\n            \\\"_to\\\": target_string,\\n            \\\"source_type\\\": source_type,\\n            \\\"target_type\\\": target_type,\\n        }\\n\\n        try:\\n            self.db_connector.ensure_edge_collection(\\\"code_edges\\\")\\n            query = f\\\"\\\"\\\"\\n            UPSERT {{_from: @from, _to: @to}}\\n            INSERT @doc\\n            UPDATE @doc\\n            IN code_edges\\n            \\\"\\\"\\\"\\n            bind_vars = {\\n                \\\"from\\\": edge_data[\\\"_from\\\"],\\n                \\\"to\\\": edge_data[\\\"_to\\\"],\\n                \\\"doc\\\": edge_data,\\n            }\\n            self.db_connector.db.aql.execute(query, bind_vars=bind_vars)\\n        except Exception as e:\\n            logging.error(f\\\"Error upserting edge (ArangoDB): {e}\\\")\\n\\n    def _get_collection_from_id(self, block_id: str) -> str:\\n        block_id_parts: list[str] = block_id.split(\\\"__*__\\\")\\n        block_type_part: str = block_id_parts[-1]\\n\\n        block_type_functions: dict[str, Callable[..., str]] = {\\n            \\\"MODULE\\\": lambda: \\\"modules\\\",\\n            \\\"CLASS\\\": lambda: \\\"classes\\\",\\n            \\\"FUNCTION\\\": lambda: \\\"functions\\\",\\n            \\\"STANDALONE_BLOCK\\\": lambda: \\\"standalone_blocks\\\",\\n        }\\n\\n        for key, func in block_type_functions.items():\\n            if block_type_part.startswith(key):\\n                return func()\\n\\n        return \\\"unknown\\\"\\n\\n    def process_imports_and_dependencies(self) -> \\\"ArangoDBManager\\\":\\n        for vertex_collection in helper_functions.pluralized_and_lowered_block_types():\\n            cursor: Result[Cursor] = self.db_connector.db.collection(\\n                vertex_collection\\n            ).all()\\n            if isinstance(cursor, Cursor):\\n                for vertex in cursor:\\n                    vertex_key = vertex[\\\"_key\\\"]\\n                    if vertex_collection == \\\"modules\\\":\\n                        self._create_edges_for_imports(\\n                            vertex_key, vertex.get(\\\"imports\\\", [])\\n                        )\\n                    else:\\n                        self._create_edges_for_dependencies(\\n                            vertex_key, vertex.get(\\\"dependencies\\\", [])\\n                        )\\n            else:\\n                logging.error(\\n                    f\\\"Error getting cursor for vertex collection: {vertex_collection}\\\"\\n                )\\n        return self\\n\\n    def _create_edges_for_imports(\\n        self, module_key: str, imports: list[dict[str, Any]]\\n    ) -> None:\\n        if not imports:\\n            # logging.debug(f\\\"No imports found for module {module_key}\\\")\\n            return\\n\\n        # logging.info(f\\\"Processing imports for module {module_key}\\\")\\n\\n        for _import in imports:\\n            import_names: list[dict[str, str]] = _import.get(\\\"import_names\\\", [])\\n            if not import_names:\\n                # logging.debug(f\\\"No import names found in import {_import}\\\")\\n                continue\\n\\n            for import_name in import_names:\\n                local_block_id: str | None = import_name.get(\\\"local_block_id\\\")\\n\\n                if local_block_id:\\n                    target_type = self._get_collection_from_id(local_block_id)\\n                    try:\\n                        self._upsert_edge(\\n                            local_block_id, module_key, target_type, \\\"modules\\\"\\n                        )\\n\\n                        # logging.info(\\n                        #     f\\\"Upserted edge for import {module_key} to {local_block_id}\\\"\\n                        # )\\n                    except Exception as e:\\n                        logging.error(\\n                            f\\\"Error creating edge for import {module_key} to {local_block_id}: {e}\\\"\\n                        )\\n                else:\\n                    # logging.warning(\\n                    #     f\\\"Skipped import {import_name} in module {module_key}\\\"\\n                    # )\\n                    ...\\n\\n    def _create_edges_for_dependencies(\\n        self, block_key: str, dependencies: list[dict[str, Any]]\\n    ) -> None:\\n        if not dependencies:\\n            return\\n\\n        for dependency in dependencies:\\n            code_block_id: str | None = dependency.get(\\\"code_block_id\\\")\\n            if code_block_id:\\n                source_type: str = self._get_collection_from_id(code_block_id)\\n                target_type: str = self._get_collection_from_id(block_key)\\n                try:\\n                    self._upsert_edge(\\n                        code_block_id, block_key, source_type, target_type\\n                    )\\n                    # logging.info(\\n                    #     f\\\"Upserted edge for dependency {block_key} to {code_block_id}\\\"\\n                    # )\\n                except Exception as e:\\n                    logging.error(\\n                        f\\\"Error creating edge for dependency {block_key} to {code_block_id}: {e}\\\"\\n                    )\\n\\n    def delete_vertex_by_id(\\n        self, vertex_key: str, graph_name: str | None = None\\n    ) -> None:\\n        collection_name: str = self._get_collection_from_id(vertex_key)\\n        if collection_name == \\\"unknown\\\":\\n            logging.error(f\\\"Unknown vertex type for key: {vertex_key}\\\")\\n            return None\\n\\n        if not graph_name:\\n            graph_name = self.default_graph_name\\n\\n        try:\\n            vertex_coll = self.db_connector.db.graph(graph_name).vertex_collection(\\n                collection_name\\n            )\\n\\n            vertex_coll.delete(vertex_key)\\n\\n            # logging.info(\\n            #     f\\\"Vertex '{vertex_key}' from collection '{collection_name}' was successfully deleted.\\\"\\n            # )\\n\\n        except Exception as e:\\n            logging.error(\\n                f\\\"Error deleting vertex '{vertex_key}' from collection '{collection_name}': {e}\\\"\\n            )\\n\\n    def get_graph(self, graph_name: str | None = None) -> Graph | None:\\n        if not graph_name:\\n            graph_name = self.default_graph_name\\n        try:\\n            return self.db_connector.db.graph(self.default_graph_name)\\n        except Exception as e:\\n            logging.error(f\\\"Error getting graph '{self.default_graph_name}': {e}\\\")\\n            return None\\n\\n    def get_or_create_graph(self, graph_name: str | None = None) -> Result[Graph]:\\n        if not graph_name:\\n            graph_name = self.default_graph_name\\n\\n        try:\\n            if not self.db_connector.db.has_graph(graph_name):\\n                edge_definitions: list[dict[str, str | list[str]]] = [\\n                    {\\n                        \\\"edge_collection\\\": \\\"code_edges\\\",\\n                        \\\"from_vertex_collections\\\": helper_functions.pluralized_and_lowered_block_types(),\\n                        \\\"to_vertex_collections\\\": helper_functions.pluralized_and_lowered_block_types(),\\n                    }\\n                ]\\n\\n                # logging.info(f\\\"Graph '{graph_name}' created successfully.\\\")\\n                return self.db_connector.db.create_graph(\\n                    graph_name, edge_definitions=edge_definitions\\n                )\\n\\n            else:\\n                return self.get_graph()\\n\\n        except Exception as e:\\n            logging.error(f\\\"Error creating graph '{graph_name}': {e}\\\")\\n\\n    def delete_graph(self, graph_name: str | None = None) -> None:\\n        if not graph_name:\\n            graph_name = self.default_graph_name\\n        try:\\n            self.db_connector.db.delete_graph(graph_name)\\n            logging.info(f\\\"Graph '{graph_name}' deleted successfully.\\\")\\n        except Exception as e:\\n            logging.error(f\\\"Error deleting graph '{graph_name}': {e}\\\")\\n\\n    def get_outbound_models(self, start_key: str) -> list[ModelType] | None:\\n        vertex_type: str = self._get_collection_from_id(start_key)\\n\\n        query: str = f\\\"\\\"\\\"\\n        FOR v, e, p IN 1..100 OUTBOUND '{vertex_type}/{start_key}' GRAPH '{self.default_graph_name}'\\n        RETURN DISTINCT v\\n        \\\"\\\"\\\"\\n        # query: str = f\\\"\\\"\\\"\\n        # FOR v, e, p IN 1..100 OUTBOUND '{vertex_type}/{start_key}' GRAPH '{self.default_graph_name}'\\n        # FILTER LENGTH(p.edges[* FILTER CURRENT != e]) == 0\\n        # RETURN DISTINCT v\\n        # \\\"\\\"\\\"\\n        # query: str = f\\\"\\\"\\\"\\n        # FOR v, e, p IN 1..100 OUTBOUND '{vertex_type}/{start_key}' GRAPH '{self.default_graph_name}'\\n        # FILTER LENGTH(p.edges[* FILTER CURRENT != e]) == 0\\n        #     AND p.edges[*].distance ALL == 1\\n        # RETURN DISTINCT v\\n        # \\\"\\\"\\\"\\n\\n        try:\\n            cursor = self.db_connector.db.aql.execute(query)\\n            if isinstance(cursor, Cursor):\\n                return [\\n                    helper_functions.create_model_from_vertex(doc) for doc in cursor\\n                ]\\n            else:\\n                logging.error(f\\\"Error getting cursor for query: {query}\\\")\\n                return None\\n        except Exception as e:\\n            logging.error(f\\\"Error in get_all_downstream_vertices: {e}\\\")\\n            return None\\n\\n    def get_inbound_models(self, end_key: str) -> list[ModelType] | None:\\n        vertex_type: str = self._get_collection_from_id(end_key)\\n\\n        query: str = f\\\"\\\"\\\"\\n        FOR v, e, p IN 1..100 INBOUND '{vertex_type}/{end_key}' GRAPH '{self.default_graph_name}'\\n        RETURN DISTINCT v\\n        \\\"\\\"\\\"\\n\\n        # query: str = f\\\"\\\"\\\"\\n        # FOR v, e, p IN 1..100 INBOUND '{vertex_type}/{end_key}' GRAPH '{self.default_graph_name}'\\n        # FILTER LENGTH(p.edges[* FILTER CURRENT != e]) == 0\\n        # RETURN DISTINCT v\\n        # \\\"\\\"\\\"\\n\\n        try:\\n            cursor: Result[Cursor] = self.db_connector.db.aql.execute(query)\\n            if isinstance(cursor, Cursor):\\n                return [\\n                    helper_functions.create_model_from_vertex(doc) for doc in cursor\\n                ]\\n            else:\\n                logging.error(f\\\"Error getting cursor for query: {query}\\\")\\n                return None\\n        except Exception as e:\\n            logging.error(f\\\"Error in get_all_upstream_vertices: {e}\\\")\\n            return None\\n\\n    def update_vertex_by_id(self, id: str, new_summary: str) -> None:\\n        try:\\n            collection_name: str = self._get_collection_from_id(id)\\n            if collection_name == \\\"unknown\\\":\\n                logging.error(f\\\"Unknown vertex type for id: {id}\\\")\\n                return\\n\\n            vertex_collection: StandardCollection = self.db_connector.db.collection(\\n                collection_name\\n            )\\n            vertex_result: Result[Json | None] = vertex_collection.get(id)\\n\\n            if not vertex_result:\\n                logging.error(f\\\"Vertex with id {id} not found.\\\")\\n                return\\n\\n            if isinstance(vertex_result, dict):\\n                vertex = vertex_result\\n            else:\\n                logging.error(\\\"Retrieved vertex is not in a mutable format.\\\")\\n                return None\\n\\n            vertex[\\\"summary\\\"] = new_summary\\n\\n            vertex_collection.update(vertex)\\n            logging.info(f\\\"Vertex with id {id} updated successfully.\\\")\\n\\n        except Exception as e:\\n            logging.error(f\\\"Error in `update_vertex_by_id`: {e}\\\")\\n\\n    def get_all_modules(self) -> list[ModuleModel] | None:\\n        try:\\n            # Define the collection name for modules.\\n            collection_name = \\\"modules\\\"\\n            module_collection: StandardCollection = self.db_connector.db.collection(\\n                collection_name\\n            )\\n\\n            # Retrieve all documents from the modules collection.\\n            cursor: Result[Cursor] = module_collection.all()\\n\\n            # Convert each document to a ModuleModel instance.\\n            modules: list[ModuleModel] = []\\n            for doc in cursor:  # type: ignore # FIXME: Fix type error\\n                # Ensure the document is a dictionary.\\n                try:\\n                    # Convert the document to a ModuleModel instance and add it to the list.\\n                    module = ModuleModel(**doc)\\n                    modules.append(module)\\n                except Exception as e:\\n                    logging.error(f\\\"Retrieved document is not in a valid format: {e}\\\")\\n                    continue\\n\\n            return modules\\n\\n        except Exception as e:\\n            logging.error(f\\\"Error in get_all_modules: {e}\\\")\\n            return None\\n\\n, \\nImported code block (postcode:databases:arangodb:arangodb_connector.py__*__MODULE) code content:\\nimport logging\\nfrom typing import Any\\nfrom arango.client import ArangoClient\\nfrom arango.database import StandardDatabase\\nfrom arango.result import Result\\nfrom arango.typings import Jsons, Json\\n\\nimport postcode.databases.arangodb.helper_functions as helper_functions\\n\\n# from postcode.models import (\\n#     ModuleModel,\\n#     ClassModel,\\n#     FunctionModel,\\n#     StandaloneCodeBlockModel,\\n# )\\n\\n\\n# test = ArangoClient(hosts=\\\"http://localhost:8529\\\")\\nclass ArangoDBConnector:\\n    def __init__(\\n        self,\\n        url: str = \\\"http://localhost:8529\\\",\\n        username: str = \\\"root\\\",\\n        password: str = \\\"openSesame\\\",\\n        db_name: str = \\\"postcode\\\",\\n    ) -> None:\\n        self.client = ArangoClient(hosts=url)\\n        self.username: str = username\\n        self.password: str = password\\n        self.db_name: str = db_name\\n        self.db: StandardDatabase = self._ensure_database()\\n\\n    def _ensure_database(self) -> StandardDatabase:\\n        sys_db: StandardDatabase = self.client.db(\\n            \\\"_system\\\", username=self.username, password=self.password\\n        )\\n        if not sys_db.has_database(self.db_name):\\n            sys_db.create_database(self.db_name)\\n        return self.client.db(\\n            self.db_name, username=self.username, password=self.password\\n        )\\n\\n    # def _ensure_vertex_collections(self, vertex_collections: list[str]) -> None:\\n    #     for collection in vertex_collections:\\n    #         if not self.db.has_collection(collection):\\n    #             self.db.create_collection(collection)\\n\\n    def _get_current_schema(self, collection_name: str) -> dict:\\n        collection = self.db.collection(collection_name)\\n        try:\\n            properties: Result[Json] = collection.properties()\\n            return properties.get(\\\"schema\\\", {})  # type: ignore # FIXME: Fix type error\\n        except Exception as e:\\n            logging.error(f\\\"Error retrieving current schema for {collection_name}: {e}\\\")\\n            return {}\\n\\n    def ensure_collection(\\n        self, collection_name: str, schema: dict[str, Any] | None = None\\n    ) -> None:\\n        if not self.db.has_collection(collection_name) and not schema:\\n            self.db.create_collection(collection_name)\\n            logging.info(f\\\"Created collection: {collection_name}\\\")\\n        # else:\\n        #     current_schema = self._get_current_schema(collection_name)\\n        #     self.db.collection(collection_name)\\n        # if current_schema != schema:\\n        #     collection = self.db.collection(collection_name)\\n        #     try:\\n        #         collection.configure(schema=schema)\\n        #         logging.info(f\\\"Updated schema for collection: {collection_name}\\\")\\n        #     except Exception as e:\\n        #         logging.error(f\\\"Error updating schema for {collection_name}: {e}\\\")\\n\\n    def ensure_edge_collection(self, collection_name: str) -> None:\\n        if not self.db.has_collection(collection_name):\\n            self.db.create_collection(collection_name, edge=True)\\n            logging.info(f\\\"Created edge collection: {collection_name}\\\")\\n\\n    def delete_all_collections(self) -> None:\\n        collections: Result[Jsons] = self.db.collections()\\n\\n        for collection in collections:  # type: ignore # FIXME: Fix type error\\n            if not collection[\\\"name\\\"].startswith(\\\"_\\\"):  # Skip system collections\\n                self.db.delete_collection(collection[\\\"name\\\"])\\n                logging.info(f\\\"Deleted collection: {collection['name']}\\\")\\n\\n    def ensure_collections(self) -> None:\\n        # model_schemas: dict[str, dict[str, Any]] = self._get_model_schemas()\\n        required_collections: list[\\n            str\\n        ] = helper_functions.pluralized_and_lowered_block_types()\\n\\n        for collection_name in required_collections:\\n            # schema: dict[str, Any] = model_schemas[collection_name]\\n            # self.ensure_collection(collection_name, schema)\\n            self.ensure_collection(collection_name)\\n\\n        self.ensure_edge_collection(\\\"code_edges\\\")\\n\\n    # def _get_model_schemas(self) -> dict[str, dict[str, Any]]:\\n    #     return {\\n    #         \\\"modules\\\": ModuleModel.model_json_schema(),\\n    #         \\\"classes\\\": ClassModel.model_json_schema(),\\n    #         \\\"functions\\\": FunctionModel.model_json_schema(),\\n    #         \\\"standalone_blocks\\\": StandaloneCodeBlockModel.model_json_schema(),\\n    #     }\\n\\n\\nImported code block (postcode:models:models.py__*__MODULE) code content:\\nfrom typing import Union\\nfrom pydantic import BaseModel, Field, validator\\n\\nfrom postcode.models.enums import (\\n    BlockType,\\n    ImportModuleType,\\n    CommentType,\\n)\\n\\n\\nclass ImportNameModel(BaseModel):\\n    \\\"\\\"\\\"Class representing the name of an import.\\\"\\\"\\\"\\n\\n    name: str\\n    as_name: str | None = None\\n    local_block_id: str | None = None\\n\\n    # def convert_import_names_to_metadata(self) -> str:\\n    #     \\\"\\\"\\\"Converts the import name to a metadata string.\\\"\\\"\\\"\\n\\n    #     return self.model_dump_json()\\n\\n\\nclass ImportModel(BaseModel):\\n    \\\"\\\"\\\"Class representing an import statement.\\\"\\\"\\\"\\n\\n    import_names: list[ImportNameModel]\\n    imported_from: str | None = None\\n    import_module_type: ImportModuleType = ImportModuleType.STANDARD_LIBRARY\\n    local_module_id: str | None = None\\n\\n    def convert_import_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the import to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass DependencyModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a module dependency.\\\"\\\"\\\"\\n\\n    code_block_id: str\\n\\n    def convert_dependency_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the dependency to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass CommentModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a comment.\\\"\\\"\\\"\\n\\n    content: str\\n    comment_types: list[CommentType]\\n\\n    def convert_comment_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the comment to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass DecoratorModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a decorator.\\\"\\\"\\\"\\n\\n    content: str\\n    decorator_name: str\\n    decorator_args: list[str] | None = None\\n\\n    def convert_decorator_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the decorator to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass ClassKeywordModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a class keyword.\\\"\\\"\\\"\\n\\n    content: str\\n    keyword_name: str\\n    args: str | None = None\\n\\n    def convert_class_keyword_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the class keyword to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass ParameterModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a function parameter.\\\"\\\"\\\"\\n\\n    content: str\\n\\n\\nclass ParameterListModel(BaseModel):\\n    \\\"\\\"\\\"Class representing a list of parameters.\\\"\\\"\\\"\\n\\n    params: list[ParameterModel] | None = None\\n    star_arg: ParameterModel | None = None\\n    kwonly_params: list[ParameterModel] | None = None\\n    star_kwarg: ParameterModel | None = None\\n    posonly_params: list[ParameterModel] | None = None\\n\\n    def convert_parameters_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the parameter list to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n\\nclass BaseCodeBlockModel(BaseModel):\\n    \\\"\\\"\\\"Attributes common to all code block models.\\\"\\\"\\\"\\n\\n    id: str\\n    parent_id: str | None = None\\n    block_type: BlockType\\n    start_line_num: int\\n    end_line_num: int\\n    code_content: str = \\\"\\\"\\n    important_comments: list[CommentModel] | None = None\\n    dependencies: list[ImportModel | DependencyModel] | None = None\\n    summary: str | None = None\\n    children: list[\\n        Union[\\n            \\\"ClassModel\\\",\\n            \\\"FunctionModel\\\",\\n            \\\"StandaloneCodeBlockModel\\\",\\n        ]\\n    ] | None = []\\n\\n    @validator(\\\"parent_id\\\", always=True)\\n    def check_parent_id(cls, v, values, **kwargs) -> str | None:\\n        \\\"\\\"\\\"Validates that parent_id is a non-empty string unless block_type is MODULE.\\\"\\\"\\\"\\n\\n        if \\\"block_type\\\" in values and values[\\\"block_type\\\"] != BlockType.MODULE:\\n            if len(v) < 1:\\n                raise ValueError(\\\"parent_id is required!\\\")\\n        return v\\n\\n    def _convert_parent_id_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the parent_id to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.parent_id}\\\" if self.parent_id else \\\"\\\"\\n\\n    def _convert_block_type_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the block_type to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.block_type.name}\\\"\\n\\n    def _convert_important_comments_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the important comments to a metadata string.\\\"\\\"\\\"\\n\\n        important_comments: str = (\\n            self.model_dump_json() if self.important_comments else \\\"\\\"\\n        )\\n\\n        return f\\\"{important_comments}\\\"\\n\\n    def _convert_dependencies_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the dependencies to a metadata string.\\\"\\\"\\\"\\n\\n        dependencies_str: str = \\\"\\\"\\n\\n        if self.dependencies:\\n            for dependency in self.dependencies:\\n                if isinstance(dependency, ImportModel):\\n                    dependencies_str += f\\\"{dependency.convert_import_to_metadata()}\\\\n\\\"\\n                elif isinstance(dependency, DependencyModel):\\n                    dependencies_str += (\\n                        f\\\"{dependency.convert_dependency_to_metadata()}\\\\n\\\"\\n                    )\\n\\n        return dependencies_str\\n\\n    def _convert_summary_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the summary to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.summary}\\\" if self.summary else \\\"\\\"\\n\\n    def _convert_children_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the children to a metadata string.\\\"\\\"\\\"\\n\\n        children_str: str = \\\"\\\"\\n\\n        if self.children:\\n            for child in self.children:\\n                children_str += f\\\"{child.id}\\\\n\\\"\\n\\n        return children_str\\n\\n    def _convert_base_attributes_to_metadata_dict(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the base attributes to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            \\\"id\\\": self.id,\\n            \\\"parent_id\\\": self._convert_parent_id_to_metadata(),\\n            \\\"block_type\\\": self._convert_block_type_to_metadata(),\\n            \\\"start_line_num\\\": self.start_line_num,\\n            \\\"end_line_num\\\": self.end_line_num,\\n            \\\"code_content\\\": self.code_content,\\n            \\\"important_comments\\\": self._convert_important_comments_to_metadata(),\\n            \\\"dependencies\\\": self._convert_dependencies_to_metadata(),\\n            \\\"summary\\\": self._convert_summary_to_metadata(),\\n            \\\"children\\\": self._convert_children_to_metadata(),\\n        }\\n\\n\\nclass ModuleSpecificAttributes(BaseModel):\\n    \\\"\\\"\\\"Module specific attributes.\\\"\\\"\\\"\\n\\n    file_path: str = Field(min_length=1)\\n    docstring: str | None = None\\n    header: list[str] | None = None\\n    footer: list[str] | None = None\\n    imports: list[ImportModel] | None = None\\n\\n    def _convert_docstring_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the docstring to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.docstring}\\\"\\n\\n    def _convert_header_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the header and footer to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n    def _convert_footer_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the header and footer to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json()\\n\\n    def _convert_imports_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the imports to a metadata string.\\\"\\\"\\\"\\n        imports_str: str = self.model_dump_json() if self.imports else \\\"\\\"\\n        return f\\\"{imports_str}\\\"\\n\\n    def _convert_module_attributes_to_metadata_dict(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the module attributes to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            \\\"file_path\\\": self.file_path,\\n            \\\"docstring\\\": self._convert_docstring_to_metadata(),\\n            \\\"header\\\": self._convert_header_to_metadata(),\\n            \\\"footer\\\": self._convert_footer_to_metadata(),\\n            \\\"imports\\\": self._convert_imports_to_metadata(),\\n        }\\n\\n\\nclass ModuleModel(BaseCodeBlockModel, ModuleSpecificAttributes):\\n    \\\"\\\"\\\"Model for a module.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the module model to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_module_attributes_to_metadata_dict(),\\n        }\\n\\n\\nclass ClassSpecificAttributes(BaseModel):\\n    \\\"\\\"\\\"Class specific attributes.\\\"\\\"\\\"\\n\\n    class_name: str = Field(min_length=1)\\n    decorators: list[DecoratorModel] | None = None\\n    bases: list[str] | None = None\\n    docstring: str | None = None\\n    keywords: list[ClassKeywordModel] | None = None\\n    # attributes: list[dict] | None = None\\n\\n    def _convert_decorators_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the decorators to a metadata string.\\\"\\\"\\\"\\n        decorators_str: str = self.model_dump_json() if self.decorators else \\\"\\\"\\n        return f\\\"{decorators_str}\\\"\\n\\n    def _convert_bases_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the bases to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json() if self.bases else \\\"\\\"\\n\\n    def _convert_docstring_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the docstring to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.docstring}\\\" if self.docstring else \\\"\\\"\\n\\n    def _convert_keywords_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the keywords to a metadata string.\\\"\\\"\\\"\\n        keywords_str: str = self.model_dump_json() if self.keywords else \\\"\\\"\\n        return f\\\"{keywords_str}\\\"\\n\\n    def _convert_class_attributes_to_metadata_dict(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the class attributes to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            \\\"class_name\\\": self.class_name,\\n            \\\"decorators\\\": self._convert_decorators_to_metadata(),\\n            \\\"bases\\\": self._convert_bases_to_metadata(),\\n            \\\"docstring\\\": self._convert_docstring_to_metadata(),\\n            \\\"keywords\\\": self._convert_keywords_to_metadata(),\\n        }\\n\\n\\nclass ClassModel(BaseCodeBlockModel, ClassSpecificAttributes):\\n    \\\"\\\"\\\"Model for a class.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the class model to a metadata dictionary.\\\"\\\"\\\"\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_class_attributes_to_metadata_dict(),\\n        }\\n\\n\\nclass FunctionSpecificAttributes(BaseModel):\\n    \\\"\\\"\\\"Function specific attributes.\\\"\\\"\\\"\\n\\n    function_name: str = Field(min_length=1)\\n    docstring: str | None = None\\n    decorators: list[DecoratorModel] | None = None\\n    parameters: ParameterListModel | None = None\\n    returns: str | None = None\\n    is_method: bool = False\\n    is_async: bool = False\\n\\n    def _convert_docstring_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the docstring to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.docstring}\\\" if self.docstring else \\\"\\\"\\n\\n    def _convert_decorators_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the decorators to a metadata string.\\\"\\\"\\\"\\n        decorators_str: str = self.model_dump_json() if self.decorators else \\\"\\\"\\n        return f\\\"{decorators_str}\\\"\\n\\n    def _convert_parameters_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the parameters to a metadata string.\\\"\\\"\\\"\\n        return (\\n            self.parameters.convert_parameters_to_metadata() if self.parameters else \\\"\\\"\\n        )\\n\\n    def _convert_returns_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the returns to a metadata string.\\\"\\\"\\\"\\n        return f\\\"{self.returns}\\\" if self.returns else \\\"\\\"\\n\\n    def _convert_function_attributes_to_metadata_dict(self) -> dict[str, str | bool]:\\n        \\\"\\\"\\\"Converts the function attributes to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            \\\"function_name\\\": self.function_name,\\n            \\\"docstring\\\": self._convert_docstring_to_metadata(),\\n            \\\"decorators\\\": self._convert_decorators_to_metadata(),\\n            \\\"parameters\\\": self._convert_parameters_to_metadata(),\\n            \\\"returns\\\": self._convert_returns_to_metadata(),\\n            \\\"is_method\\\": self.is_method,\\n            \\\"is_async\\\": self.is_async,\\n        }\\n\\n\\nclass FunctionModel(BaseCodeBlockModel, FunctionSpecificAttributes):\\n    \\\"\\\"\\\"Model for a function.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the function model to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_function_attributes_to_metadata_dict(),\\n        }\\n\\n\\nclass StandaloneCodeBlockSpecificAttributes(BaseModel):\\n    \\\"\\\"\\\"Standalone code block specific attributes.\\\"\\\"\\\"\\n\\n    variable_assignments: list[str] | None = None\\n\\n    def _convert_variable_assignments_to_metadata(self) -> str:\\n        \\\"\\\"\\\"Converts the variable assignments to a metadata string.\\\"\\\"\\\"\\n        return self.model_dump_json() if self.variable_assignments else \\\"\\\"\\n\\n    def _convert_standalone_block_attributes_to_metadata_dict(\\n        self,\\n    ) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the standalone code block attributes to a metadata dictionary.\\\"\\\"\\\"\\n        return {\\n            \\\"variable_assignments\\\": self._convert_variable_assignments_to_metadata(),\\n        }\\n\\n\\nclass StandaloneCodeBlockModel(\\n    BaseCodeBlockModel, StandaloneCodeBlockSpecificAttributes\\n):\\n    \\\"\\\"\\\"Model for a standalone code block.\\\"\\\"\\\"\\n\\n    def convert_to_metadata(self) -> dict[str, str | int]:\\n        \\\"\\\"\\\"Converts the standalone code block model to a metadata dictionary.\\\"\\\"\\\"\\n\\n        return {\\n            **self._convert_base_attributes_to_metadata_dict(),\\n            **self._convert_standalone_block_attributes_to_metadata_dict(),\\n        }\\n\\n, \\nimport logging\\nfrom typing import Any, Callable, Union\\nfrom arango.result import Result\\nfrom arango.cursor import Cursor\\nfrom arango.graph import Graph\\nfrom arango.collection import StandardCollection\\nfrom arango.typings import Json\\n        \",\"children\":[{\"variable_assignments\":[\"ModelType = Union[\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n]\"],\"id\":\"postcode:databases:arangodb:arangodb_manager.py__*__MODULE__*__STANDALONE_BLOCK-1\",\"parent_id\":\"postcode:databases:arangodb:arangodb_manager.py__*__MODULE\",\"block_type\":\"STANDALONE_BLOCK\",\"start_line_num\":20,\"end_line_num\":27,\"code_content\":\"ModelType = Union[\\n    ModuleModel,\\n    ClassModel,\\n    FunctionModel,\\n    StandaloneCodeBlockModel,\\n]\\n\",\"important_comments\":null,\"dependencies\":[{\"import_names\":[{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"Any\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"Callable\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"Union\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"typing\",\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null}],\"summary\":null,\"children\":null},{\"class_name\":\"ArangoDBManager\",\"decorators\":null,\"bases\":null,\"docstring\":null,\"keywords\":null,\"id\":\"postcode:databases:arangodb:arangodb_manager.py__*__MODULE__*__CLASS-ArangoDBManager\",\"parent_id\":\"postcode:databases:arangodb:arangodb_manager.py__*__MODULE\",\"block_type\":\"CLASS\",\"start_line_num\":27,\"end_line_num\":409,\"code_content\":\"\\n# NOTE: Remember, when adding logic to connect dependencies, the `from` the external dependency `to` the internal definition using it\\n\\n\\nclass ArangoDBManager:\\n    def __init__(\\n        self,\\n        db_connector: ArangoDBConnector,\\n        default_graph_name: str = \\\"codebase_graph\\\",\\n    ) -> None:\\n        self.db_connector: ArangoDBConnector = db_connector\\n\\n        self.processed_id_set = set()\\n        self.default_graph_name: str = default_graph_name\\n\\n    def upsert_models(self, module_models: list[ModuleModel]) -> \\\"ArangoDBManager\\\":\\n        for model in module_models:\\n            self._upsert_model(model)\\n        return self\\n\\n    def _upsert_model(self, module_model: ModuleModel) -> None:\\n        self._upsert_vertex(module_model, \\\"modules\\\")\\n        self._process_children(module_model)\\n\\n    def _process_children(self, parent_model: ModelType) -> None:\\n        if not parent_model.children:\\n            return None\\n\\n        for child in parent_model.children:\\n            # if child.id in self.processed_id_set:\\n            #     continue\\n\\n            self.processed_id_set.add(child.id)\\n            self._upsert_vertex(\\n                child, helper_functions.pluralize_block_type(child.block_type)\\n            )\\n\\n            if child.children:\\n                self._process_children(child)\\n\\n    def _upsert_vertex(self, model: ModelType, collection_name: str) -> None:\\n        model_data: dict[str, Any] = model.model_dump()\\n        model_data[\\\"_key\\\"] = model.id\\n\\n        try:\\n            self.db_connector.ensure_collection(\\n                collection_name, model.model_json_schema()\\n            )\\n            query: str = f\\\"\\\"\\\"\\n            UPSERT {{_key: @key}}\\n            INSERT @doc\\n            UPDATE @doc\\n            IN {collection_name}\\n            \\\"\\\"\\\"\\n            bind_vars: dict[str, Any] = {\\\"key\\\": model.id, \\\"doc\\\": model_data}\\n            self.db_connector.db.aql.execute(query, bind_vars=bind_vars)\\n\\n            if not isinstance(model, ModuleModel) and model.parent_id:\\n                parent_type: str = self._get_collection_from_id(model.parent_id)\\n                self._upsert_edge(\\n                    model.id, model.parent_id, collection_name, parent_type\\n                )\\n        except Exception as e:\\n            logging.error(f\\\"Error upserting {collection_name} vertex (ArangoDB): {e}\\\")\\n\\n    def _upsert_edge(\\n        self, from_key: str, to_key: str, source_type: str, target_type: str\\n    ) -> None:\\n        source_string: str = f\\\"{source_type}/{from_key}\\\"\\n        target_string: str = f\\\"{target_type}/{to_key}\\\"\\n\\n        edge_data: dict[str, str] = {\\n            \\\"_from\\\": source_string,\\n            \\\"_to\\\": target_string,\\n            \\\"source_type\\\": source_type,\\n            \\\"target_type\\\": target_type,\\n        }\\n\\n        try:\\n            self.db_connector.ensure_edge_collection(\\\"code_edges\\\")\\n            query = f\\\"\\\"\\\"\\n            UPSERT {{_from: @from, _to: @to}}\\n            INSERT @doc\\n            UPDATE @doc\\n            IN code_edges\\n            \\\"\\\"\\\"\\n            bind_vars = {\\n                \\\"from\\\": edge_data[\\\"_from\\\"],\\n                \\\"to\\\": edge_data[\\\"_to\\\"],\\n                \\\"doc\\\": edge_data,\\n            }\\n            self.db_connector.db.aql.execute(query, bind_vars=bind_vars)\\n        except Exception as e:\\n            logging.error(f\\\"Error upserting edge (ArangoDB): {e}\\\")\\n\\n    def _get_collection_from_id(self, block_id: str) -> str:\\n        block_id_parts: list[str] = block_id.split(\\\"__*__\\\")\\n        block_type_part: str = block_id_parts[-1]\\n\\n        block_type_functions: dict[str, Callable[..., str]] = {\\n            \\\"MODULE\\\": lambda: \\\"modules\\\",\\n            \\\"CLASS\\\": lambda: \\\"classes\\\",\\n            \\\"FUNCTION\\\": lambda: \\\"functions\\\",\\n            \\\"STANDALONE_BLOCK\\\": lambda: \\\"standalone_blocks\\\",\\n        }\\n\\n        for key, func in block_type_functions.items():\\n            if block_type_part.startswith(key):\\n                return func()\\n\\n        return \\\"unknown\\\"\\n\\n    def process_imports_and_dependencies(self) -> \\\"ArangoDBManager\\\":\\n        for vertex_collection in helper_functions.pluralized_and_lowered_block_types():\\n            cursor: Result[Cursor] = self.db_connector.db.collection(\\n                vertex_collection\\n            ).all()\\n            if isinstance(cursor, Cursor):\\n                for vertex in cursor:\\n                    vertex_key = vertex[\\\"_key\\\"]\\n                    if vertex_collection == \\\"modules\\\":\\n                        self._create_edges_for_imports(\\n                            vertex_key, vertex.get(\\\"imports\\\", [])\\n                        )\\n                    else:\\n                        self._create_edges_for_dependencies(\\n                            vertex_key, vertex.get(\\\"dependencies\\\", [])\\n                        )\\n            else:\\n                logging.error(\\n                    f\\\"Error getting cursor for vertex collection: {vertex_collection}\\\"\\n                )\\n        return self\\n\\n    def _create_edges_for_imports(\\n        self, module_key: str, imports: list[dict[str, Any]]\\n    ) -> None:\\n        if not imports:\\n            # logging.debug(f\\\"No imports found for module {module_key}\\\")\\n            return\\n\\n        # logging.info(f\\\"Processing imports for module {module_key}\\\")\\n\\n        for _import in imports:\\n            import_names: list[dict[str, str]] = _import.get(\\\"import_names\\\", [])\\n            if not import_names:\\n                # logging.debug(f\\\"No import names found in import {_import}\\\")\\n                continue\\n\\n            for import_name in import_names:\\n                local_block_id: str | None = import_name.get(\\\"local_block_id\\\")\\n\\n                if local_block_id:\\n                    target_type = self._get_collection_from_id(local_block_id)\\n                    try:\\n                        self._upsert_edge(\\n                            local_block_id, module_key, target_type, \\\"modules\\\"\\n                        )\\n\\n                        # logging.info(\\n                        #     f\\\"Upserted edge for import {module_key} to {local_block_id}\\\"\\n                        # )\\n                    except Exception as e:\\n                        logging.error(\\n                            f\\\"Error creating edge for import {module_key} to {local_block_id}: {e}\\\"\\n                        )\\n                else:\\n                    # logging.warning(\\n                    #     f\\\"Skipped import {import_name} in module {module_key}\\\"\\n                    # )\\n                    ...\\n\\n    def _create_edges_for_dependencies(\\n        self, block_key: str, dependencies: list[dict[str, Any]]\\n    ) -> None:\\n        if not dependencies:\\n            return\\n\\n        for dependency in dependencies:\\n            code_block_id: str | None = dependency.get(\\\"code_block_id\\\")\\n            if code_block_id:\\n                source_type: str = self._get_collection_from_id(code_block_id)\\n                target_type: str = self._get_collection_from_id(block_key)\\n                try:\\n                    self._upsert_edge(\\n                        code_block_id, block_key, source_type, target_type\\n                    )\\n                    # logging.info(\\n                    #     f\\\"Upserted edge for dependency {block_key} to {code_block_id}\\\"\\n                    # )\\n                except Exception as e:\\n                    logging.error(\\n                        f\\\"Error creating edge for dependency {block_key} to {code_block_id}: {e}\\\"\\n                    )\\n\\n    def delete_vertex_by_id(\\n        self, vertex_key: str, graph_name: str | None = None\\n    ) -> None:\\n        collection_name: str = self._get_collection_from_id(vertex_key)\\n        if collection_name == \\\"unknown\\\":\\n            logging.error(f\\\"Unknown vertex type for key: {vertex_key}\\\")\\n            return None\\n\\n        if not graph_name:\\n            graph_name = self.default_graph_name\\n\\n        try:\\n            vertex_coll = self.db_connector.db.graph(graph_name).vertex_collection(\\n                collection_name\\n            )\\n\\n            vertex_coll.delete(vertex_key)\\n\\n            # logging.info(\\n            #     f\\\"Vertex '{vertex_key}' from collection '{collection_name}' was successfully deleted.\\\"\\n            # )\\n\\n        except Exception as e:\\n            logging.error(\\n                f\\\"Error deleting vertex '{vertex_key}' from collection '{collection_name}': {e}\\\"\\n            )\\n\\n    def get_graph(self, graph_name: str | None = None) -> Graph | None:\\n        if not graph_name:\\n            graph_name = self.default_graph_name\\n        try:\\n            return self.db_connector.db.graph(self.default_graph_name)\\n        except Exception as e:\\n            logging.error(f\\\"Error getting graph '{self.default_graph_name}': {e}\\\")\\n            return None\\n\\n    def get_or_create_graph(self, graph_name: str | None = None) -> Result[Graph]:\\n        if not graph_name:\\n            graph_name = self.default_graph_name\\n\\n        try:\\n            if not self.db_connector.db.has_graph(graph_name):\\n                edge_definitions: list[dict[str, str | list[str]]] = [\\n                    {\\n                        \\\"edge_collection\\\": \\\"code_edges\\\",\\n                        \\\"from_vertex_collections\\\": helper_functions.pluralized_and_lowered_block_types(),\\n                        \\\"to_vertex_collections\\\": helper_functions.pluralized_and_lowered_block_types(),\\n                    }\\n                ]\\n\\n                # logging.info(f\\\"Graph '{graph_name}' created successfully.\\\")\\n                return self.db_connector.db.create_graph(\\n                    graph_name, edge_definitions=edge_definitions\\n                )\\n\\n            else:\\n                return self.get_graph()\\n\\n        except Exception as e:\\n            logging.error(f\\\"Error creating graph '{graph_name}': {e}\\\")\\n\\n    def delete_graph(self, graph_name: str | None = None) -> None:\\n        if not graph_name:\\n            graph_name = self.default_graph_name\\n        try:\\n            self.db_connector.db.delete_graph(graph_name)\\n            logging.info(f\\\"Graph '{graph_name}' deleted successfully.\\\")\\n        except Exception as e:\\n            logging.error(f\\\"Error deleting graph '{graph_name}': {e}\\\")\\n\\n    def get_outbound_models(self, start_key: str) -> list[ModelType] | None:\\n        vertex_type: str = self._get_collection_from_id(start_key)\\n\\n        query: str = f\\\"\\\"\\\"\\n        FOR v, e, p IN 1..100 OUTBOUND '{vertex_type}/{start_key}' GRAPH '{self.default_graph_name}'\\n        RETURN DISTINCT v\\n        \\\"\\\"\\\"\\n        # query: str = f\\\"\\\"\\\"\\n        # FOR v, e, p IN 1..100 OUTBOUND '{vertex_type}/{start_key}' GRAPH '{self.default_graph_name}'\\n        # FILTER LENGTH(p.edges[* FILTER CURRENT != e]) == 0\\n        # RETURN DISTINCT v\\n        # \\\"\\\"\\\"\\n        # query: str = f\\\"\\\"\\\"\\n        # FOR v, e, p IN 1..100 OUTBOUND '{vertex_type}/{start_key}' GRAPH '{self.default_graph_name}'\\n        # FILTER LENGTH(p.edges[* FILTER CURRENT != e]) == 0\\n        #     AND p.edges[*].distance ALL == 1\\n        # RETURN DISTINCT v\\n        # \\\"\\\"\\\"\\n\\n        try:\\n            cursor = self.db_connector.db.aql.execute(query)\\n            if isinstance(cursor, Cursor):\\n                return [\\n                    helper_functions.create_model_from_vertex(doc) for doc in cursor\\n                ]\\n            else:\\n                logging.error(f\\\"Error getting cursor for query: {query}\\\")\\n                return None\\n        except Exception as e:\\n            logging.error(f\\\"Error in get_all_downstream_vertices: {e}\\\")\\n            return None\\n\\n    def get_inbound_models(self, end_key: str) -> list[ModelType] | None:\\n        vertex_type: str = self._get_collection_from_id(end_key)\\n\\n        query: str = f\\\"\\\"\\\"\\n        FOR v, e, p IN 1..100 INBOUND '{vertex_type}/{end_key}' GRAPH '{self.default_graph_name}'\\n        RETURN DISTINCT v\\n        \\\"\\\"\\\"\\n\\n        # query: str = f\\\"\\\"\\\"\\n        # FOR v, e, p IN 1..100 INBOUND '{vertex_type}/{end_key}' GRAPH '{self.default_graph_name}'\\n        # FILTER LENGTH(p.edges[* FILTER CURRENT != e]) == 0\\n        # RETURN DISTINCT v\\n        # \\\"\\\"\\\"\\n\\n        try:\\n            cursor: Result[Cursor] = self.db_connector.db.aql.execute(query)\\n            if isinstance(cursor, Cursor):\\n                return [\\n                    helper_functions.create_model_from_vertex(doc) for doc in cursor\\n                ]\\n            else:\\n                logging.error(f\\\"Error getting cursor for query: {query}\\\")\\n                return None\\n        except Exception as e:\\n            logging.error(f\\\"Error in get_all_upstream_vertices: {e}\\\")\\n            return None\\n\\n    def update_vertex_by_id(self, id: str, new_summary: str) -> None:\\n        try:\\n            collection_name: str = self._get_collection_from_id(id)\\n            if collection_name == \\\"unknown\\\":\\n                logging.error(f\\\"Unknown vertex type for id: {id}\\\")\\n                return\\n\\n            vertex_collection: StandardCollection = self.db_connector.db.collection(\\n                collection_name\\n            )\\n            vertex_result: Result[Json | None] = vertex_collection.get(id)\\n\\n            if not vertex_result:\\n                logging.error(f\\\"Vertex with id {id} not found.\\\")\\n                return\\n\\n            if isinstance(vertex_result, dict):\\n                vertex = vertex_result\\n            else:\\n                logging.error(\\\"Retrieved vertex is not in a mutable format.\\\")\\n                return None\\n\\n            vertex[\\\"summary\\\"] = new_summary\\n\\n            vertex_collection.update(vertex)\\n            logging.info(f\\\"Vertex with id {id} updated successfully.\\\")\\n\\n        except Exception as e:\\n            logging.error(f\\\"Error in `update_vertex_by_id`: {e}\\\")\\n\\n    def get_all_modules(self) -> list[ModuleModel] | None:\\n        try:\\n            # Define the collection name for modules.\\n            collection_name = \\\"modules\\\"\\n            module_collection: StandardCollection = self.db_connector.db.collection(\\n                collection_name\\n            )\\n\\n            # Retrieve all documents from the modules collection.\\n            cursor: Result[Cursor] = module_collection.all()\\n\\n            # Convert each document to a ModuleModel instance.\\n            modules: list[ModuleModel] = []\\n            for doc in cursor:  # type: ignore # FIXME: Fix type error\\n                # Ensure the document is a dictionary.\\n                try:\\n                    # Convert the document to a ModuleModel instance and add it to the list.\\n                    module = ModuleModel(**doc)\\n                    modules.append(module)\\n                except Exception as e:\\n                    logging.error(f\\\"Retrieved document is not in a valid format: {e}\\\")\\n                    continue\\n\\n            return modules\\n\\n        except Exception as e:\\n            logging.error(f\\\"Error in get_all_modules: {e}\\\")\\n            return None\\n\",\"important_comments\":[{\"content\":\"# NOTE: Remember, when adding logic to connect dependencies, the `from` the external dependency `to` the internal definition using it\",\"comment_types\":[\"NOTE\"]}],\"dependencies\":[{\"import_names\":[{\"name\":\"ClassModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"FunctionModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"ModuleModel\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"StandaloneCodeBlockModel\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"postcode.models.models\",\"import_module_type\":\"LOCAL\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"logging\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":null,\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"Any\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"Callable\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"Union\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"typing\",\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"Any\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"Callable\",\"as_name\":null,\"local_block_id\":null},{\"name\":\"Union\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"typing\",\"import_module_type\":\"STANDARD_LIBRARY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"Result\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"arango.result\",\"import_module_type\":\"THIRD_PARTY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"Cursor\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"arango.cursor\",\"import_module_type\":\"THIRD_PARTY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"Graph\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"arango.graph\",\"import_module_type\":\"THIRD_PARTY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"StandardCollection\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"arango.collection\",\"import_module_type\":\"THIRD_PARTY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"Json\",\"as_name\":null,\"local_block_id\":null}],\"imported_from\":\"arango.typings\",\"import_module_type\":\"THIRD_PARTY\",\"local_module_id\":null},{\"import_names\":[{\"name\":\"ArangoDBConnector\",\"as_name\":null,\"local_block_id\":\"postcode:databases:arangodb:arangodb_connector.py__*__MODULE__*__CLASS-ArangoDBConnector\"}],\"imported_from\":\"postcode.databases.arangodb.arangodb_connector\",\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:databases:arangodb:arangodb_connector.py__*__MODULE\"},{\"import_names\":[{\"name\":\"postcode.databases.arangodb.helper_functions\",\"as_name\":\"helper_functions\",\"local_block_id\":null}],\"imported_from\":null,\"import_module_type\":\"LOCAL\",\"local_module_id\":\"postcode:databases:arangodb:helper_functions.py__*__MODULE\"}],\"summary\":null,\"children\":[{\"function_name\":\"__init__\",\"docstring\":null,\"decorators\":null,\"parameters\":null,\"returns\":\"None\",\"is_method\":true,\"is_async\":false,\"id\":\"postcode:databases:arangodb:arangodb_manager.py__*__MODULE__*__CLASS-ArangoDBManager__*__FUNCTION-__init__\",\"parent_id\":\"postcode:databases:arangodb:arangodb_manager.py__*__MODULE__*__CLASS-ArangoDBManager\",\"block_type\":\"FUNCTION\",\"start_line_num\":32,\"end_line_num\":41,\"code_content\":\"def __init__(\\n    self,\\n    db_connector: ArangoDBConnector,\\n    default_graph_name: str = \\\"codebase_graph\\\",\\n) -> None:\\n    self.db_connector: ArangoDBConnector = db_connector\\n\\n    self.processed_id_set = set()\\n    self.default_graph_name: str = default_graph_name\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":null,\"children\":null},{\"function_name\":\"upsert_models\",\"docstring\":null,\"decorators\":null,\"parameters\":null,\"returns\":\"No return annotation\",\"is_method\":true,\"is_async\":false,\"id\":\"postcode:databases:arangodb:arangodb_manager.py__*__MODULE__*__CLASS-ArangoDBManager__*__FUNCTION-upsert_models\",\"parent_id\":\"postcode:databases:arangodb:arangodb_manager.py__*__MODULE__*__CLASS-ArangoDBManager\",\"block_type\":\"FUNCTION\",\"start_line_num\":41,\"end_line_num\":46,\"code_content\":\"\\ndef upsert_models(self, module_models: list[ModuleModel]) -> \\\"ArangoDBManager\\\":\\n    for model in module_models:\\n        self._upsert_model(model)\\n    return self\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":null,\"children\":null},{\"function_name\":\"_upsert_model\",\"docstring\":null,\"decorators\":null,\"parameters\":null,\"returns\":\"None\",\"is_method\":true,\"is_async\":false,\"id\":\"postcode:databases:arangodb:arangodb_manager.py__*__MODULE__*__CLASS-ArangoDBManager__*__FUNCTION-_upsert_model\",\"parent_id\":\"postcode:databases:arangodb:arangodb_manager.py__*__MODULE__*__CLASS-ArangoDBManager\",\"block_type\":\"FUNCTION\",\"start_line_num\":46,\"end_line_num\":50,\"code_content\":\"\\ndef _upsert_model(self, module_model: ModuleModel) -> None:\\n    self._upsert_vertex(module_model, \\\"modules\\\")\\n    self._process_children(module_model)\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":null,\"children\":null},{\"function_name\":\"_process_children\",\"docstring\":null,\"decorators\":null,\"parameters\":null,\"returns\":\"None\",\"is_method\":true,\"is_async\":false,\"id\":\"postcode:databases:arangodb:arangodb_manager.py__*__MODULE__*__CLASS-ArangoDBManager__*__FUNCTION-_process_children\",\"parent_id\":\"postcode:databases:arangodb:arangodb_manager.py__*__MODULE__*__CLASS-ArangoDBManager\",\"block_type\":\"FUNCTION\",\"start_line_num\":50,\"end_line_num\":66,\"code_content\":\"\\ndef _process_children(self, parent_model: ModelType) -> None:\\n    if not parent_model.children:\\n        return None\\n\\n    for child in parent_model.children:\\n        # if child.id in self.processed_id_set:\\n        #     continue\\n\\n        self.processed_id_set.add(child.id)\\n        self._upsert_vertex(\\n            child, helper_functions.pluralize_block_type(child.block_type)\\n        )\\n\\n        if child.children:\\n            self._process_children(child)\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":null,\"children\":null},{\"function_name\":\"_upsert_vertex\",\"docstring\":null,\"decorators\":null,\"parameters\":null,\"returns\":\"None\",\"is_method\":true,\"is_async\":false,\"id\":\"postcode:databases:arangodb:arangodb_manager.py__*__MODULE__*__CLASS-ArangoDBManager__*__FUNCTION-_upsert_vertex\",\"parent_id\":\"postcode:databases:arangodb:arangodb_manager.py__*__MODULE__*__CLASS-ArangoDBManager\",\"block_type\":\"FUNCTION\",\"start_line_num\":66,\"end_line_num\":91,\"code_content\":\"\\ndef _upsert_vertex(self, model: ModelType, collection_name: str) -> None:\\n    model_data: dict[str, Any] = model.model_dump()\\n    model_data[\\\"_key\\\"] = model.id\\n\\n    try:\\n        self.db_connector.ensure_collection(\\n            collection_name, model.model_json_schema()\\n        )\\n        query: str = f\\\"\\\"\\\"\\n            UPSERT {{_key: @key}}\\n            INSERT @doc\\n            UPDATE @doc\\n            IN {collection_name}\\n            \\\"\\\"\\\"\\n        bind_vars: dict[str, Any] = {\\\"key\\\": model.id, \\\"doc\\\": model_data}\\n        self.db_connector.db.aql.execute(query, bind_vars=bind_vars)\\n\\n        if not isinstance(model, ModuleModel) and model.parent_id:\\n            parent_type: str = self._get_collection_from_id(model.parent_id)\\n            self._upsert_edge(\\n                model.id, model.parent_id, collection_name, parent_type\\n            )\\n    except Exception as e:\\n        logging.error(f\\\"Error upserting {collection_name} vertex (ArangoDB): {e}\\\")\\n\",\"important_comments\":null,\"dependencies\":null,\"summary\":null,\"children\":null},{\"function_name\":\"_upsert_edge\",\"docstring\":null,\"decorators\":null,\"parameters\":null,\"returns\":\"None\",\"is_method\":true,\"is_async\":false,\"id\":\"postcode:databases:arangodb:arangodb_manager.py__*__MODULE__*__CLASS-ArangoDBManager__*__FUNCTION-_upsert_edge\",\"parent_id\":\"postcode:databases:arangodb:arangodb_manager.py__*__MODULE__*__CLASS-ArangoDBManager\",\"block_type\":\"FUNCTION\",\"start_line_num\":91,\"end_line_num\":121,\"code_content\":\"\\ndef _upsert_edge(\\n    self, from_key: str, to_key: str, source_type: str, target_type: str\\n) -> None:\\n    source_string: str = f\\\"{source_type}/{from_key}\\\"\\n    target_string: str = f\\\"{target_type}/{to_key}\\\"\\n\\n    edge_data: dict[str, str] = {\\n        \\\"_from\\\": source_string,\\n        \\\"_to\\\": target_string,\\n        \\\"source_type\\\": source_type,\\n        \\\"target_type\\\": target_type,\\n    }\\n\\n    try:\\n        self.db_connector.ensure_edge_collection(\\\"code_edges\\\")\\n        query = f\\\"\\\"\\\"\\n            UPSERT {{_from: @from, _to: @to}}\\n            INSERT @doc\\n            UPDATE @doc\\n            IN code_edges\\n            \\\"\\\"\\\"\\n        bind_vars = {\\n            \\\"from\\\": edge_data[\\\"_from\\\"],\\n            \\\"to\\\": edge_data[\\\"_to\\\"],\\n            \\\"doc\\\": edge_data,\\n        }\\n        self.db_connector.db.aql.execu