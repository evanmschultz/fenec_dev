{
    "class_name": "ChromaLibrarian",
    "decorators": null,
    "bases": null,
    "docstring": null,
    "keywords": null,
    "id": "fenec:ai_services:librarians:chroma_librarians.py__*__MODULE__*__CLASS-ChromaLibrarian",
    "file_path": "fenec/ai_services/librarians/chroma_librarians.py",
    "parent_id": "fenec:ai_services:librarians:chroma_librarians.py__*__MODULE",
    "block_type": "CLASS",
    "start_line_num": 55,
    "end_line_num": 195,
    "code_content": "\n\nclass ChromaLibrarian:\n    def __init__(\n        self,\n        collection_manager: ChromaCollectionManager,\n        model: str = \"gpt-3.5-turbo-1106\",\n    ) -> None:\n        \"\"\"\n        Represents a librarian for interacting with the Chroma database using OpenAI.\n\n        Args:\n            - collection_manager (ChromaCollectionManager): The manager for Chroma collections.\n            - model (str, optional): The OpenAI model to use. Defaults to \"gpt-3.5-turbo-1106\".\n\n        Methods:\n            - query_chroma(user_question):\n                Queries the Chroma database using the provided user question.\n\n            - _query_collection(queries, n_results=3):\n                Queries the Chroma collection manager with a list of queries.\n\n            - _get_chroma_queries(user_question, queries_count=3, retries=3):\n                Generates Chroma queries based on the user question.\n\n        Attributes:\n            - collection_manager (ChromaCollectionManager): The Chroma collection manager.\n            - model (str): The OpenAI model being used.\n            - client: The OpenAI API client.\n\n        Examples:\n            ```python\n            chroma_librarian = ChromaLibrarian(chroma_collection_manager)\n            chroma_librarian.query_chroma(\"Which models are inherited by others?\")\n            ```\n        \"\"\"\n\n        self.collection_manager: ChromaCollectionManager = collection_manager\n        self.model: str = model\n        self.client = OpenAI()\n\n    def query_chroma(self, user_question: str) -> chroma_types.QueryResult | None:\n        \"\"\"\n        Queries the Chroma database using the provided user question.\n\n        Args:\n            - user_question (str): The user's question.\n\n        Returns:\n            - chroma_types.QueryResult | None: The result of the Chroma query, or None if unsuccessful.\n        \"\"\"\n\n        queries: list[str] | None = self._get_chroma_queries(user_question)\n        if not queries:\n            return None\n\n        print(queries)\n\n        return self._query_collection(queries)\n\n    def _query_collection(\n        self,\n        queries: list[str],\n        n_results: int = 3,\n    ) -> chroma_types.QueryResult | None:\n        \"\"\"\n        Queries the Chroma collection manager with a list of queries.\n\n        Args:\n            - queries (list[str]): List of queries to use in the Chroma collection manager.\n            - n_results (int, optional): Number of results to return. Defaults to 3.\n\n        Returns:\n            - chroma_types.QueryResult | None: The result of the Chroma query, or None if unsuccessful.\n        \"\"\"\n\n        return self.collection_manager.query_collection(\n            queries,\n            n_results=n_results,\n            include_in_result=[\"metadatas\", \"documents\"],\n        )\n\n    def _get_chroma_queries(\n        self, user_question: str, queries_count: int = 3, retries: int = 3\n    ) -> list[str] | None:\n        \"\"\"\n        Generates Chroma queries based on the user question.\n\n        Args:\n            - user_question (str): The user's question.\n            - queries_count (int, optional): Number of queries to generate. Defaults to 3.\n            - retries (int, optional): Number of retries in case of failure. Defaults to 3.\n\n        Returns:\n            - list[str] | None: The generated list of Chroma queries, or None if unsuccessful.\n        \"\"\"\n\n        while retries > 0:\n            retries -= 1\n\n            prompt: str = ChromaLibrarianPromptCreator.create_prompt(\n                user_question,\n                prompt_template=DEFAULT_CHROMA_LIBRARIAN_PROMPT,\n                queries_count=queries_count,\n            )\n\n            try:\n                completion: openai_types.ChatCompletion = (\n                    self.client.chat.completions.create(\n                        model=self.model,\n                        response_format={\"type\": \"json_object\"},\n                        messages=[\n                            {\n                                \"role\": \"system\",\n                                \"content\": DEFAULT_CHROMA_LIBRARIAN_SYSTEM_PROMPT,\n                            },\n                            {\"role\": \"user\", \"content\": prompt},\n                        ],\n                    )\n                )\n                content: str | None = completion.choices[0].message.content\n                if not content:\n                    continue\n\n                content_json = json.loads(content)\n                content_model = OpenAIResponseContent(\n                    query_list=content_json[\"query_list\"]\n                )\n                content_model.query_list.append(user_question)\n                queries_count += 1\n\n                if content:\n                    queries: list[str] = content_model.query_list\n                    if queries and len(queries) == queries_count:\n                        return queries\n\n            except Exception as e:\n                logging.error(f\"An error occurred: {e}\")\n\n        return None\n",
    "important_comments": null,
    "dependencies": [
        {
            "code_block_id": "fenec:ai_services:librarians:chroma_librarians.py__*__MODULE__*__CLASS-OpenAIResponseContent"
        },
        {
            "import_names": [
                {
                    "name": "logging",
                    "as_name": null,
                    "local_block_id": null
                }
            ],
            "imported_from": null,
            "import_module_type": "STANDARD_LIBRARY",
            "local_module_id": null
        },
        {
            "import_names": [
                {
                    "name": "json",
                    "as_name": null,
                    "local_block_id": null
                }
            ],
            "imported_from": null,
            "import_module_type": "STANDARD_LIBRARY",
            "local_module_id": null
        },
        {
            "import_names": [
                {
                    "name": "OpenAI",
                    "as_name": null,
                    "local_block_id": null
                }
            ],
            "imported_from": "openai",
            "import_module_type": "THIRD_PARTY",
            "local_module_id": null
        },
        {
            "import_names": [
                {
                    "name": "fenec.types.openai",
                    "as_name": "openai_types",
                    "local_block_id": null
                }
            ],
            "imported_from": null,
            "import_module_type": "LOCAL",
            "local_module_id": "fenec:types:openai.py__*__MODULE"
        },
        {
            "import_names": [
                {
                    "name": "ChromaCollectionManager",
                    "as_name": null,
                    "local_block_id": "fenec:databases:chroma:chromadb_collection_manager.py__*__MODULE__*__CLASS-ChromaCollectionManager"
                }
            ],
            "imported_from": "fenec.databases.chroma.chromadb_collection_manager",
            "import_module_type": "LOCAL",
            "local_module_id": "fenec:databases:chroma:chromadb_collection_manager.py__*__MODULE"
        },
        {
            "import_names": [
                {
                    "name": "ChromaLibrarianPromptCreator",
                    "as_name": null,
                    "local_block_id": "fenec:ai_services:librarians:prompts:prompt_creator.py__*__MODULE__*__CLASS-ChromaLibrarianPromptCreator"
                }
            ],
            "imported_from": "fenec.ai_services.librarians.prompts.prompt_creator",
            "import_module_type": "LOCAL",
            "local_module_id": "fenec:ai_services:librarians:prompts:prompt_creator.py__*__MODULE"
        },
        {
            "import_names": [
                {
                    "name": "DEFAULT_CHROMA_LIBRARIAN_PROMPT",
                    "as_name": null,
                    "local_block_id": null
                },
                {
                    "name": "DEFAULT_CHROMA_LIBRARIAN_SYSTEM_PROMPT",
                    "as_name": null,
                    "local_block_id": null
                }
            ],
            "imported_from": "fenec.ai_services.librarians.prompts.chroma_librarian_prompts",
            "import_module_type": "LOCAL",
            "local_module_id": "fenec:ai_services:librarians:prompts:chroma_librarian_prompts.py__*__MODULE"
        },
        {
            "import_names": [
                {
                    "name": "DEFAULT_CHROMA_LIBRARIAN_PROMPT",
                    "as_name": null,
                    "local_block_id": null
                },
                {
                    "name": "DEFAULT_CHROMA_LIBRARIAN_SYSTEM_PROMPT",
                    "as_name": null,
                    "local_block_id": null
                }
            ],
            "imported_from": "fenec.ai_services.librarians.prompts.chroma_librarian_prompts",
            "import_module_type": "LOCAL",
            "local_module_id": "fenec:ai_services:librarians:prompts:chroma_librarian_prompts.py__*__MODULE"
        },
        {
            "import_names": [
                {
                    "name": "fenec.types.chroma",
                    "as_name": "chroma_types",
                    "local_block_id": null
                }
            ],
            "imported_from": null,
            "import_module_type": "LOCAL",
            "local_module_id": "fenec:types:chroma.py__*__MODULE"
        }
    ],
    "summary": "The `ChromaLibrarian` class is a sophisticated component designed to enhance the interaction with a Chroma database by leveraging OpenAI's language models, specifically tailored for processing user queries and generating relevant database queries. Its primary purpose is to act as an intermediary that translates natural language user questions into effective queries for the Chroma database, utilizing the capabilities of a specified OpenAI model to improve the relevance and accuracy of the retrieved information. Key components of the class include: the `__init__` method, which initializes the librarian with a `ChromaCollectionManager` and an OpenAI model identifier, setting up the necessary infrastructure for database interaction; the `query_chroma` method, which serves as the main interface for users to submit questions and receive results from the Chroma database; the `_query_collection` method, which directly interfaces with the Chroma collection manager to execute queries and retrieve results, allowing for configurable parameters such as the number of results; and the `_get_chroma_queries` method, which is responsible for generating a list of queries from the user input, incorporating mechanisms for retries to ensure robustness.\n\nThe implementation involves setting up an OpenAI API client, instantiated within the `__init__` method, to facilitate communication with the language model. This client is used to generate and execute queries against the Chroma database, employing a structured approach that allows for flexibility in query formulation and execution. The design pattern employed here is a form of the adapter pattern, where the `ChromaLibrarian` class adapts user input into a format suitable for querying the Chroma database, thus abstracting the complexity of direct database interactions from the end-user. The `_get_chroma_queries` method uses OpenAI's API to create chat completions, which are then parsed using JSON to extract and construct a list of queries. This method dynamically adjusts the number of queries based on user input and retry attempts, ensuring that the system can handle failures gracefully. The `_query_collection` method interacts with the `ChromaCollectionManager` to retrieve results, specifying the inclusion of metadata and documents in the results, which enhances the richness of the data returned.\n\nThe technical stack includes OpenAI's API, which provides the language model capabilities necessary for natural language processing and understanding, and the `ChromaCollectionManager`, which manages the collections within the Chroma database, ensuring efficient data retrieval and management. The OpenAI API is crucial for interpreting user questions and generating relevant queries, while the `ChromaCollectionManager` handles the backend operations related to data storage and retrieval. The code also utilizes a custom prompt creation mechanism, `ChromaLibrarianPromptCreator`, to generate prompts for the language model, and a response content model, `OpenAIResponseContent`, to structure the query list.\n\nIn the context of a larger system, this code serves as a critical middleware component that bridges the gap between user input and the Chroma database, enhancing the data retrieval process through AI-driven query formulation. It integrates seamlessly with the Chroma database infrastructure and the OpenAI platform, providing a user-friendly interface for querying and information extraction. This integration allows for scalable and efficient data management, making it a valuable asset in systems that require dynamic and intelligent data retrieval capabilities. The `ChromaLibrarian` class thus plays a pivotal role in enabling sophisticated interactions with the Chroma database, supporting a wide range of applications that benefit from AI-enhanced data querying, such as knowledge management systems, customer support platforms, and data analytics tools. Its design supports scalability and adaptability, making it a valuable asset in systems that demand high-level AI-driven interactions with complex databases.",
    "children_ids": [
        "fenec:ai_services:librarians:chroma_librarians.py__*__MODULE__*__CLASS-ChromaLibrarian__*__FUNCTION-__init__",
        "fenec:ai_services:librarians:chroma_librarians.py__*__MODULE__*__CLASS-ChromaLibrarian__*__FUNCTION-query_chroma",
        "fenec:ai_services:librarians:chroma_librarians.py__*__MODULE__*__CLASS-ChromaLibrarian__*__FUNCTION-_query_collection",
        "fenec:ai_services:librarians:chroma_librarians.py__*__MODULE__*__CLASS-ChromaLibrarian__*__FUNCTION-_get_chroma_queries"
    ]
}