{
    "docstring": null,
    "header": [],
    "footer": [],
    "imports": [
        {
            "import_names": [
                {
                    "name": "Path",
                    "as_name": null,
                    "local_block_id": null
                }
            ],
            "imported_from": "pathlib",
            "import_module_type": "STANDARD_LIBRARY",
            "local_module_id": null
        },
        {
            "import_names": [
                {
                    "name": "Summarizer",
                    "as_name": null,
                    "local_block_id": "fenec:ai_services:summarizer:summarizer_protocol.py__*__MODULE__*__CLASS-Summarizer"
                }
            ],
            "imported_from": "fenec.ai_services.summarizer.summarizer_protocol",
            "import_module_type": "LOCAL",
            "local_module_id": "fenec:ai_services:summarizer:summarizer_protocol.py__*__MODULE"
        },
        {
            "import_names": [
                {
                    "name": "GraphDBUpdater",
                    "as_name": null,
                    "local_block_id": "fenec:updaters:graph_db_updater.py__*__MODULE__*__CLASS-GraphDBUpdater"
                }
            ],
            "imported_from": "fenec.updaters.graph_db_updater",
            "import_module_type": "LOCAL",
            "local_module_id": "fenec:updaters:graph_db_updater.py__*__MODULE"
        },
        {
            "import_names": [
                {
                    "name": "ChromaCollectionManager",
                    "as_name": null,
                    "local_block_id": "fenec:databases:chroma:chromadb_collection_manager.py__*__MODULE__*__CLASS-ChromaCollectionManager"
                }
            ],
            "imported_from": "fenec.databases.chroma.chromadb_collection_manager",
            "import_module_type": "LOCAL",
            "local_module_id": "fenec:databases:chroma:chromadb_collection_manager.py__*__MODULE"
        },
        {
            "import_names": [
                {
                    "name": "ChatConfigs",
                    "as_name": null,
                    "local_block_id": "fenec:utilities:configs:configs.py__*__MODULE__*__CLASS-ChatConfigs"
                },
                {
                    "name": "OpenAISummarizationConfigs",
                    "as_name": null,
                    "local_block_id": "fenec:utilities:configs:configs.py__*__MODULE__*__CLASS-OpenAISummarizationConfigs"
                },
                {
                    "name": "OpenAIChatConfigs",
                    "as_name": null,
                    "local_block_id": "fenec:utilities:configs:configs.py__*__MODULE__*__CLASS-OpenAIChatConfigs"
                },
                {
                    "name": "OllamaSummarizationConfigs",
                    "as_name": null,
                    "local_block_id": "fenec:utilities:configs:configs.py__*__MODULE__*__CLASS-OllamaSummarizationConfigs"
                },
                {
                    "name": "OllamaChatConfigs",
                    "as_name": null,
                    "local_block_id": "fenec:utilities:configs:configs.py__*__MODULE__*__CLASS-OllamaChatConfigs"
                }
            ],
            "imported_from": "fenec.utilities.configs.configs",
            "import_module_type": "LOCAL",
            "local_module_id": "fenec:utilities:configs:configs.py__*__MODULE"
        },
        {
            "import_names": [
                {
                    "name": "create_summarizer",
                    "as_name": null,
                    "local_block_id": "fenec:ai_services:summarizer:summarizer_factory.py__*__MODULE__*__FUNCTION-create_summarizer"
                }
            ],
            "imported_from": "fenec.ai_services.summarizer.summarizer_factory",
            "import_module_type": "LOCAL",
            "local_module_id": "fenec:ai_services:summarizer:summarizer_factory.py__*__MODULE"
        },
        {
            "import_names": [
                {
                    "name": "OpenAIChatAgent",
                    "as_name": null,
                    "local_block_id": "fenec:ai_services:chat:openai_agents.py__*__MODULE__*__CLASS-OpenAIChatAgent"
                }
            ],
            "imported_from": "fenec.ai_services.chat.openai_agents",
            "import_module_type": "LOCAL",
            "local_module_id": "fenec:ai_services:chat:openai_agents.py__*__MODULE"
        },
        {
            "import_names": [
                {
                    "name": "ChromaLibrarian",
                    "as_name": null,
                    "local_block_id": "fenec:ai_services:librarians:chroma_librarians.py__*__MODULE__*__CLASS-ChromaLibrarian"
                }
            ],
            "imported_from": "fenec.ai_services.librarians.chroma_librarians",
            "import_module_type": "LOCAL",
            "local_module_id": "fenec:ai_services:librarians:chroma_librarians.py__*__MODULE"
        },
        {
            "import_names": [
                {
                    "name": "setup_chroma",
                    "as_name": null,
                    "local_block_id": "fenec:databases:chroma:chroma_setup.py__*__MODULE__*__FUNCTION-setup_chroma"
                }
            ],
            "imported_from": "fenec.databases.chroma.chroma_setup",
            "import_module_type": "LOCAL",
            "local_module_id": "fenec:databases:chroma:chroma_setup.py__*__MODULE"
        },
        {
            "import_names": [
                {
                    "name": "setup_logging",
                    "as_name": null,
                    "local_block_id": "fenec:utilities:logger:logging_config.py__*__MODULE__*__FUNCTION-setup_logging"
                }
            ],
            "imported_from": "fenec.utilities.logger.logging_config",
            "import_module_type": "LOCAL",
            "local_module_id": "fenec:utilities:logger:logging_config.py__*__MODULE"
        }
    ],
    "id": "fenec:api.py__*__MODULE",
    "file_path": "fenec/api.py",
    "parent_id": "fenec__*__DIRECTORY",
    "block_type": "MODULE",
    "start_line_num": 1,
    "end_line_num": 148,
    "code_content": "from pathlib import Path\nfrom fenec.ai_services.summarizer.summarizer_protocol import Summarizer\nfrom fenec.updaters.graph_db_updater import GraphDBUpdater\nfrom fenec.databases.chroma.chromadb_collection_manager import (\n    ChromaCollectionManager,\n)\nfrom fenec.utilities.configs.configs import (\n    OpenAIChatConfigs,\n    ChatConfigs,\n    OllamaChatConfigs,\n    OpenAISummarizationConfigs,\n    OllamaSummarizationConfigs,\n)\nfrom fenec.ai_services.summarizer.summarizer_factory import create_summarizer\nfrom fenec.ai_services.chat.openai_agents import OpenAIChatAgent\nfrom fenec.ai_services.librarians.chroma_librarians import ChromaLibrarian\nfrom fenec.databases.chroma.chroma_setup import setup_chroma\nfrom fenec.utilities.logger.logging_config import setup_logging\n\n\nclass Fenec:\n    \"\"\"\n    Main interface for the Fenec package.\n\n    This class provides methods to process a codebase and interact with it through a chat interface.\n\n    Attributes:\n        - `updater` (GraphDBUpdater): The updater for the graph database.\n            - default: GraphDBUpdater()\n\n    Methods:\n        - `process_entire_codebase`(updater: GraphDBUpdater = GraphDBUpdater()): Process the entire codebase using the GraphDBUpdater.\n        - `chat`(message: str, chat_config: ChatCompletionConfigs = ChatCompletionConfigs()): Interact with the processed codebase through a chat interface\n\n    Example:\n        ```python\n        summarizer = OpenAISummarizer()\n        updater = GraphDBUpdater(\"/path/to/project\", summarizer=summarizer, output_directory=\"output_json\")\n        fenec = Fenec(\"/path/to/project\", output_directory=\"output_json\")\n\n        fenec.process_entire_codebase(summarizer)\n        response = fenec.chat(\"What does the main function do?\")\n        print(response)\n        ```\n    \"\"\"\n\n    def __init__(\n        self,\n        path: Path = Path(\".\"),\n        summarization_configs: (\n            OpenAISummarizationConfigs | OllamaSummarizationConfigs\n        ) = OpenAISummarizationConfigs(),\n        chat_configs: OpenAIChatConfigs = OpenAIChatConfigs(),\n    ) -> None:\n        self.path: Path = path\n        self.summarization_configs: (\n            OpenAISummarizationConfigs | OllamaSummarizationConfigs\n        ) = summarization_configs\n        self.chat_configs: OpenAIChatConfigs = chat_configs\n        self.updater: GraphDBUpdater = GraphDBUpdater(\n            summarization_configs=self.summarization_configs\n        )\n        setup_logging()\n\n    def process_codebase(\n        self,\n        num_of_passes: int = 1,\n        process_all: bool = False,\n    ) -> None:\n        \"\"\"\n        Process the entire codebase using the GraphDBUpdater.\n\n        This method initializes the GraphDBUpdater, processes the codebase, and stores the resulting\n        ChromaCollectionManager for later use in chat interactions.\n\n        Args:\n            - `updater` (GraphDBUpdater): The updater for the graph database.\n\n        Raises:\n            - `Exception`: If there's an error during the codebase processing.\n        \"\"\"\n\n        try:\n            if process_all:\n                self.chroma_collection_manager: ChromaCollectionManager = (\n                    self.updater.update_all(num_of_passes)\n                )\n            else:\n                self.chroma_collection_manager: ChromaCollectionManager = (\n                    self.updater.update_changed(num_of_passes)\n                )\n            self.chroma_librarian = ChromaLibrarian(self.chroma_collection_manager)\n        except Exception as e:\n            raise Exception(f\"Error processing codebase: {str(e)}\")\n\n    def connect_to_vectorstore(self, chromadb_name: str = \"fenec\") -> None:\n        \"\"\"\n        Connect to an existing ChromaDB collection.\n\n        This method initializes the ChromaCollectionManager for the specified collection name\n        and stores it for later use in chat interactions.\n\n        Args:\n            - `chromadb_name` (str): Name of the ChromaDB collection.\n\n        Raises:\n            - `Exception`: If there's an error during the connection.\n        \"\"\"\n\n        try:\n            self.chroma_collection_manager: ChromaCollectionManager = setup_chroma(\n                chromadb_name\n            )\n            self.chroma_librarian = ChromaLibrarian(self.chroma_collection_manager)\n        except Exception as e:\n            raise Exception(f\"Error connecting to ChromaDB: {str(e)}\")\n\n    def chat(\n        self,\n        message: str,\n    ) -> str:\n        \"\"\"\n        Interact with the processed codebase through a chat interface.\n\n        This method uses the stored ChromaCollectionManager to process the user's message\n        and return a response.\n\n        Args:\n            - `message` (str): The user's input message or question.\n            - `chat_config` (ChatCompletionConfigs): Configuration for the chat completion.\n                - default: ChatCompletionConfigs().\n\n        Returns:\n            - `str`: The AI's response to the user's message.\n\n        Raises:\n            - `ValueError`: If the codebase hasn't been processed yet.\n        \"\"\"\n        if not self.chroma_librarian:\n            raise ValueError(\n                \"Codebase has not been processed. Call process_codebase() first.\"\n            )\n        openai_chat_agent = OpenAIChatAgent(\n            self.chroma_librarian, configs=self.chat_configs\n        )\n        response: str | None = openai_chat_agent.get_response(message)\n        return response if response else \"I'm sorry, I couldn't generate a response.\"\n",
    "important_comments": null,
    "dependencies": null,
    "summary": "The provided Python code defines the `Fenec` class, which serves as the primary interface for the Fenec package, designed to facilitate the analysis and interaction with a codebase through a chat interface. The main goal of this code is to enable users to process a codebase by updating a graph database and then querying it using natural language, thereby enhancing codebase understanding and accessibility. This functionality is significant as it allows for dynamic querying and exploration of code functionalities through a conversational interface, bridging the gap between raw codebase data and user interaction.\n\nKey components of the code include the `Fenec` class, which encapsulates methods such as `process_codebase` for processing the codebase using `GraphDBUpdater`, `connect_to_vectorstore` for connecting to a ChromaDB collection, and `chat` for interacting with the processed data. The `process_codebase` method initializes the `GraphDBUpdater`, processes the codebase, and stores the resulting `ChromaCollectionManager` for later use in chat interactions. The `connect_to_vectorstore` method sets up a connection to an existing ChromaDB collection, while the `chat` method employs an `OpenAIChatAgent` to generate responses based on user queries.\n\nThe implementation leverages a modular design where the `GraphDBUpdater` processes the codebase, storing results in a `ChromaCollectionManager`, which is then used by a `ChromaLibrarian` to facilitate chat interactions. The `process_codebase` method can handle both full and incremental updates of the codebase, depending on the `process_all` flag. The `chat` method ensures that the codebase has been processed before attempting to generate a response, raising a `ValueError` if not. The `OpenAIChatAgent` is responsible for interfacing with the AI model to generate responses, utilizing the configurations provided by `OpenAIChatConfigs`.\n\nThe technical stack includes several components from the Fenec package, such as `GraphDBUpdater`, `ChromaCollectionManager`, and `ChromaLibrarian`, along with configuration classes like `OpenAIChatConfigs`, `ChatConfigs`, `OllamaChatConfigs`, `OpenAISummarizationConfigs`, and `OllamaSummarizationConfigs`. The code integrates with OpenAI's services for summarization and chat functionalities, using the `OpenAIChatAgent` to handle user interactions. The `setup_logging` function is used to configure logging for the application, ensuring that any errors or important events are recorded.\n\nIn the context of a larger system, this code acts as a bridge between raw codebase data and user interaction, allowing for dynamic querying and exploration of code functionalities through a conversational interface. It interacts with other components like AI summarizers and database managers to provide a comprehensive code analysis and interaction platform. The `Fenec` class is designed to be flexible and extensible, supporting different summarization and chat configurations, which makes it adaptable to various project requirements and user needs. This integration with AI services and database management systems positions the Fenec package as a valuable tool for developers and analysts seeking to gain insights from complex codebases.",
    "children_ids": [
        "fenec:api.py__*__MODULE__*__CLASS-Fenec"
    ]
}